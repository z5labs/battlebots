[{"body":"Overview gRPC is a modern, open-source, high-performance Remote Procedure Call (RPC) framework developed by Google. It uses HTTP/2 for transport, Protocol Buffers as the interface description language, and provides features like authentication, bidirectional streaming, and flow control. This analysis evaluates gRPC’s suitability for the Battle Bots bot-to-server communication interface.\nPerformance Characteristics Latency Unary RPC: Typically 1-2ms for local networks, comparable to optimized REST Streaming RPC: Near-zero latency for subsequent messages after connection establishment HTTP/2 multiplexing: Multiple streams over single TCP connection reduces overhead Binary protocol: Faster parsing than JSON/XML text protocols Throughput Bidirectional streaming: Can handle thousands of messages per second Flow control: Built-in backpressure prevents overwhelming slower clients Compression: gzip compression available for larger payloads Connection reuse: HTTP/2 persistent connections reduce handshake overhead Resource Overhead Memory: Protocol Buffer deserialization is memory-efficient CPU: Binary encoding/decoding faster than JSON parsing Network: Compact binary format reduces bandwidth usage by 30-50% vs JSON Benchmarks Industry benchmarks show gRPC typically delivers:\n7-10x better throughput than REST/JSON 20-30% lower latency for streaming scenarios 40-50% smaller payload sizes vs JSON Streaming Capabilities Unary RPC (Request-Response) rpc SubmitAction(BotAction) returns (ActionResult) {} Single request, single response Suitable for discrete bot actions (move, attack) Similar to REST API calls Server Streaming rpc WatchBattleState(BattleId) returns (stream GameState) {} Single request, stream of responses Ideal for pushing game state updates to bots Server controls message flow Client Streaming rpc BatchActions(stream BotAction) returns (BatchResult) {} Stream of requests, single response Useful for queuing multiple actions Less common in game networking Bidirectional Streaming rpc Battle(stream BotAction) returns (stream GameEvent) {} Both client and server send streams independently Perfect for real-time game interaction Bots send actions, receive continuous state/events Natural fit for turn-based and real-time battles Flow Control and Backpressure HTTP/2 flow control prevents fast senders from overwhelming receivers Application-level backpressure via streaming APIs Configurable window sizes for buffering Language \u0026 Platform Support Official Language Support gRPC has official support for:\nGo - Excellent, idiomatic integration (ideal for game server) Python - Mature, widely used for ML-based bots Java/Kotlin - Production-ready JavaScript/TypeScript - Node.js and browser support C++ - High-performance native implementation C# - Full .NET integration Rust - tonic library, growing ecosystem Ruby, PHP, Dart, Objective-C - Community support Code Generation protoc compiler generates client/server stubs Language-specific plugins for idiomatic code Type-safe interfaces reduce runtime errors Automatic serialization/deserialization Developer Experience Pros:\nStrong typing catches errors at compile time Self-documenting .proto schema files Consistent API across all languages Rich ecosystem of tools and libraries Cons:\nLearning curve for Protocol Buffers syntax Code generation step in build process Less human-readable than JSON (debugging) Cross-Platform Compatibility Works on Linux, macOS, Windows Container-friendly (Docker, Podman) Mobile platform support (iOS, Android) Browser support via grpc-web (requires proxy) OpenTelemetry Integration Native Instrumentation Support gRPC has excellent OpenTelemetry integration:\nAutomatic Instrumentation:\nTrace spans automatically created for each RPC Context propagation via gRPC metadata No manual span creation required for basic telemetry Metrics Collection:\nRPC duration (client and server-side) Request/response sizes Success/error rates Active connections and streams Language-specific OTEL libraries provide auto-instrumentation Example (Go):\nimport ( \"go.opentelemetry.io/contrib/instrumentation/google.golang.org/grpc/otelgrpc\" ) server := grpc.NewServer( grpc.UnaryInterceptor(otelgrpc.UnaryServerInterceptor()), grpc.StreamInterceptor(otelgrpc.StreamServerInterceptor()), ) Integration with Battle Bots OTLP Stack From ADR-0002 (OpenTelemetry SDK) and ADR-0003 (Observability Stack):\nTraces → Tempo (via OTLP) Metrics → Mimir (via OTLP) Logs → Loki (via OTLP) All integrate seamlessly with gRPC’s OTEL instrumentation Battle-specific Telemetry:\nSpan attributes for bot IDs, action types Custom metrics for game-specific events Distributed tracing across bot → server → storage Correlation of battle state with RPC calls Container Networking HTTP/2 Compatibility Excellent container support: HTTP/2 works natively in Docker/Podman Port mapping: Single port for all RPC methods (e.g., 50051) No special container configuration required Service Discovery Docker networks: Bots can resolve server by service name Kubernetes: Native Service discovery integration podman-compose: DNS-based service names work out of box Connection Management Connection pooling: gRPC clients maintain persistent connections Keepalive: Configurable HTTP/2 keepalive pings Reconnection: Automatic retry and backoff strategies Health checking: gRPC health check protocol Load Balancing Client-side load balancing: Built-in support Proxy load balancing: Works with Envoy, nginx, HAProxy Round-robin, least-request algorithms: Configurable NAT Traversal for P2P Challenges:\nHTTP/2 expects client-initiated connections P2P requires bots to act as both client AND server NAT hole-punching more complex with TCP vs UDP Solutions:\nUse rendezvous server for initial handshake Bots expose gRPC server on known ports STUN/TURN-like relay for unreachable bots Or leverage gRPC’s bidirectional streaming (one connection, two-way communication) Development Experience Tooling Ecosystem Protocol Development:\nprotoc - Protocol Buffer compiler buf - Modern protobuf toolchain (linting, breaking change detection) IDE plugins for .proto syntax highlighting and validation Testing:\ngrpcurl - curl-like tool for gRPC (manual testing) ghz - Benchmarking and load testing tool Built-in reflection for service discovery Mock server generation for unit tests Debugging:\ngRPC reflection for runtime introspection Interceptors for logging, debugging Wireshark protocol dissector for packet analysis Browser DevTools via grpc-web Documentation:\nProtocol Buffers are self-documenting Tools like protoc-gen-doc generate HTML/Markdown docs OpenAPI can be generated from .proto files Learning Curve For Bot Developers:\nLow barrier: Install client library, import generated code Moderate protobuf learning: Understanding .proto syntax Language familiarity: Use gRPC in familiar programming language For Platform Developers:\nModerate setup: Learning protoc, code generation Service design: Defining effective RPC interfaces Streaming patterns: Understanding bidirectional communication Implementation Complexity Client/Server Mode:\nSimple: Bots are gRPC clients, server is gRPC server Battle server implements service interface Clients use generated stubs P2P Mode:\nModerate complexity: Each bot runs gRPC server Bots act as both client and server Connection management more complex Discovery and coordination needed Pros and Cons Summary Advantages ✅ Performance: Fast binary protocol with low latency and high throughput\n✅ Bidirectional streaming: Natural fit for real-time battle communication\n✅ Strong typing: Protocol Buffers provide type safety and validation\n✅ Language-agnostic: Excellent support across all major languages\n✅ OpenTelemetry integration: Native instrumentation, seamless OTLP stack integration\n✅ Container-friendly: HTTP/2 works excellently in Docker/Podman\n✅ Versioning: Built-in backward/forward compatibility in protobuf\n✅ Tooling: Rich ecosystem for testing, debugging, documentation\n✅ Industry adoption: Proven at scale by Google, Netflix, Square\n✅ Code generation: Reduces boilerplate, enforces contracts\nDisadvantages ❌ Learning curve: Requires understanding Protocol Buffers\n❌ Build complexity: Code generation step in build pipeline\n❌ Browser support: Requires grpc-web proxy (not native browser)\n❌ Debugging: Binary format less human-readable than JSON\n❌ P2P complexity: NAT traversal more challenging with HTTP/2\n❌ Firewall traversal: Some networks block non-80/443 ports\n❌ Less flexible: Schema changes require .proto updates and recompilation\nSuitability for Battle Bots Client/Server Architecture: ⭐⭐⭐⭐⭐ (Excellent)\nBidirectional streaming perfect for real-time battles Strong OTEL integration meets observability requirements Language support enables diverse bot ecosystem P2P Architecture: ⭐⭐⭐⭐☆ (Good with caveats)\nBots can run as gRPC servers NAT traversal requires additional coordination Connection complexity manageable with proper design References gRPC Official Documentation Protocol Buffers Documentation gRPC Performance Best Practices OpenTelemetry gRPC Instrumentation gRPC Go Examples HTTP/2 Specification (RFC 7540) grpcurl - gRPC curl tool ghz - gRPC benchmarking tool ","categories":"","description":"Analysis of gRPC as a communication protocol for bot-to-server interface\n","excerpt":"Analysis of gRPC as a communication protocol for bot-to-server …","ref":"/battlebots/pr-preview/pr-153/research_and_development/analysis/protocols/grpc/","tags":"","title":"gRPC Protocol Analysis"},{"body":"Idea This proof of concept demonstrates containerized bots battling each other in a 1v1 match within a 2-dimensional space. To evaluate the optimal architecture for the final BattleBots platform, both a client/server implementation and a peer-to-peer implementation will be completed and compared.\nRequirements Client/Server Architecture Implement a client/server architecture to evaluate its suitability for the final BattleBots platform.\nPeer-to-Peer Architecture Implement a peer-to-peer architecture to compare against the client/server approach.\n1v1 Battle Bots compete in a 1v1 battle within a 2-dimensional space.\nContainerized Bots Each bot should be a container to ensure isolation and portability.\nLanguage-Agnostic Bot Implementation The game logic should be independent of each bot so that any programming language can be used to implement a bot.\nObservability Observability signals should be captured so the battle can be monitored in real-time.\nBattle Visualization A battle visualization should be implemented to display the battle state and actions.\nPending ADRs Game Mechanics ADRs (0005-0009) The core game mechanics for 1v1 battles are defined across multiple ADRs:\nADR-0005: BattleBot Universe Topological Properties: Mathematical and topological foundation defining the spatial structure (2D Euclidean space, Cartesian coordinates, rectangular boundaries) ADR-0006: BattleBot Universe Physics Laws: Physics properties (friction, collisions, gravity) governing movement mechanics and entity interactions ADR-0007: Bot Characteristics System: Four-stat system (Health, Speed, Defense, Mass) defining bot capabilities ADR-0008: Equipment and Loadout System: Equipment-based customization enabling diverse bot builds ADR-0009: Bot Actions and Resource Management: Dual-constraint action system with energy costs and cooldowns See also Game Mechanics Analysis for detailed technical specifications.\nADR-NNNN: Client/Server Architecture This ADR will document the design decisions for the client/server implementation, including the server’s responsibilities for game state management, turn coordination, and validation of bot actions.\nADR-NNNN: Peer-to-Peer Architecture This ADR will document the design decisions for the peer-to-peer implementation, including consensus mechanisms for game state, conflict resolution, and how bots communicate directly with each other.\nADR-NNNN: Game Runtime Architecture This ADR will define the “game loop” and core game mechanics, including turn-based vs. real-time gameplay, tick rates, state updates, and the overall flow of battle execution.\nADR-NNNN: Bot to Battle Server Interface This ADR will define the communication protocol between bots and the battle server or between bots in P2P mode, evaluating options such as gRPC, HTTP, or custom TCP/UDP packets.\nADR-NNNN: Observability Stack This ADR will document the observability architecture, including metrics collection, logging, tracing, and how battle telemetry is captured and exposed for monitoring and analysis.\nADR-NNNN: Battle Visualization This ADR will document the design of the battle visualization system, including the rendering approach, real-time updates, and how observability data is translated into visual representations.\n","categories":"","description":"Documents the proof of concept for running a 1v1 battle between two containerized bots using podman-compose\n","excerpt":"Documents the proof of concept for running a 1v1 battle between two …","ref":"/battlebots/pr-preview/pr-153/research_and_development/user-journeys/0001-poc/","tags":"","title":"[0001] Proof of Concept - 1v1 Battle"},{"body":" Context and Problem Statement As the project grows, architectural decisions are made that have long-term impacts on the system’s design, maintainability, and scalability. Without a structured way to document these decisions, we risk losing the context and rationale behind important choices, making it difficult for current and future team members to understand why certain approaches were taken.\nHow should we document architectural decisions in a way that is accessible, maintainable, and provides sufficient context for future reference?\nDecision Drivers Need for clear documentation of architectural decisions and their rationale Easy accessibility and searchability of past decisions Low barrier to entry for creating and maintaining decision records Integration with existing documentation workflow Version control friendly format Industry-standard approach that team members may already be familiar with Considered Options MADR (Markdown Architectural Decision Records) ADR using custom format Wiki-based documentation No formal ADR process Decision Outcome Chosen option: “MADR (Markdown Architectural Decision Records)”, because it provides a well-established, standardized format that is lightweight, version-controlled, and integrates seamlessly with our existing documentation structure. MADR 4.0.0 offers a clear template that captures all necessary information while remaining flexible enough for different types of decisions.\nConsequences Good, because MADR is a widely adopted standard with clear documentation and examples Good, because markdown files are easy to create, edit, and review through pull requests Good, because ADRs will be version-controlled alongside code, maintaining historical context Good, because the format is flexible enough to accommodate strategic, user-journey, and API design decisions Good, because team members can easily search and reference past decisions Neutral, because requires discipline to maintain and update ADR status as decisions evolve Bad, because team members need to learn and follow the MADR format conventions Confirmation Compliance will be confirmed through:\nCode reviews ensuring new architectural decisions are documented as ADRs ADRs are stored in docs/content/r\u0026d/adrs/ following the naming convention NNNN-title-with-dashes.md Regular reviews during architecture discussions to reference and update existing ADRs Pros and Cons of the Options MADR (Markdown Architectural Decision Records) MADR 4.0.0 is a standardized format for documenting architectural decisions using markdown.\nGood, because it’s a well-established standard with extensive documentation Good, because markdown is simple, portable, and version-control friendly Good, because it provides a clear structure while remaining flexible Good, because it integrates with static site generators and documentation tools Good, because it’s lightweight and doesn’t require special tools Neutral, because it requires some initial learning of the format Neutral, because maintaining consistency requires discipline ADR using custom format Create our own custom format for architectural decision records.\nGood, because we can tailor it exactly to our needs Bad, because it requires defining and maintaining our own standard Bad, because new team members won’t be familiar with the format Bad, because we lose the benefits of community knowledge and tooling Bad, because it may evolve inconsistently over time Wiki-based documentation Use a wiki system (like Confluence, Notion, or GitHub Wiki) to document decisions.\nGood, because wikis provide easy editing and hyperlinking Good, because some team members may be familiar with wiki tools Neutral, because it may or may not integrate with version control Bad, because content may not be version-controlled alongside code Bad, because it creates a separate system to maintain Bad, because it’s harder to review changes through standard PR process Bad, because portability and long-term accessibility may be concerns No formal ADR process Continue without a structured approach to documenting architectural decisions.\nGood, because it requires no additional overhead Bad, because context and rationale for decisions are lost over time Bad, because new team members struggle to understand why decisions were made Bad, because it leads to repeated discussions of previously settled questions Bad, because it makes it difficult to track when decisions should be revisited More Information MADR 4.0.0 specification: https://adr.github.io/madr/ ADRs will be categorized as: strategic, user-journey, or api-design ADR status values: proposed | accepted | rejected | deprecated | superseded by ADR-XXXX All ADRs are stored in docs/content/r\u0026d/adrs/ directory ","categories":"","description":"Adopt Markdown Architectural Decision Records (MADR) as the standard format for documenting architectural decisions in the project.\n","excerpt":"Adopt Markdown Architectural Decision Records (MADR) as the standard …","ref":"/battlebots/pr-preview/pr-153/research_and_development/adrs/0001-use-madr-for-architecture-decision-records/","tags":"","title":"[0001] Use MADR for Architecture Decision Records"},{"body":"Context and Problem Statement Battle Bots requires comprehensive observability to monitor game server performance, track bot behavior, debug issues, and visualize battle state in real-time. We need to select an observability SDK that will provide instrumentation for metrics, traces, and logs across our system. The choice will impact vendor lock-in, cost, flexibility, and integration complexity.\nWhich observability SDK should we adopt for instrumenting the Battle Bots platform?\nDecision Drivers Vendor neutrality and ability to switch backends Support for metrics, traces, and logs (unified observability) Language support (especially for our game server implementation) Integration with container environments Community adoption and long-term sustainability Cost implications (SDK licensing, vendor fees) Ease of integration and developer experience Performance overhead Support for custom attributes and semantic conventions Considered Options OpenTelemetry Datadog SDK Sentry SDK Decision Outcome Chosen option: OpenTelemetry, because it is an open standard that prevents vendor lock-in and aligns with the open-source nature of the Battle Bots project. As a CNCF-graduated project, it provides long-term sustainability and broad industry adoption while maintaining flexibility to switch observability backends without re-instrumentation.\nConsequences Good, because we maintain complete vendor neutrality and can switch backends (Prometheus, Jaeger, Loki, etc.) without changing instrumentation code Good, because we adopt an industry-standard approach to observability that is widely supported and documented Good, because the open-source SDK has no licensing costs and aligns with project philosophy Good, because semantic conventions will ensure consistent telemetry across all Battle Bots components Good, because comprehensive language support enables bot developers to use OpenTelemetry in their preferred languages Bad, because we need to deploy and manage separate backend infrastructure for metrics, traces, and logs Bad, because initial setup requires more configuration compared to all-in-one commercial solutions Bad, because debugging telemetry pipelines may require deeper understanding of the OpenTelemetry architecture Confirmation This decision will be considered successful when:\nGame server successfully exports metrics, traces, and logs via OpenTelemetry SDK Observability backends (selected via future ADRs) receive and display telemetry data correctly Developer experience for adding custom instrumentation is straightforward Performance overhead of instrumentation is acceptable (\u003c 5% CPU/memory impact) We can successfully switch between different backend providers without code changes Pros and Cons of the Options OpenTelemetry OpenTelemetry is an open-source observability framework providing vendor-neutral APIs, SDKs, and tools for generating and collecting telemetry data (metrics, logs, and traces).\nGood, because it is vendor-neutral and prevents lock-in to any specific observability backend Good, because it supports all three pillars of observability (metrics, traces, logs) Good, because it has broad language support including Go, Java, Python, JavaScript, and many others Good, because it is CNCF-graduated with strong industry adoption and long-term sustainability Good, because it allows flexibility to switch backends (Prometheus, Jaeger, Loki, commercial vendors) without changing instrumentation Good, because it has native Kubernetes and container environment support Good, because it defines semantic conventions for consistent telemetry across services Good, because it is free and open-source with no licensing costs Neutral, because it requires separate backend infrastructure (exporters to Prometheus, Jaeger, etc.) Bad, because initial setup complexity is higher than vendor-specific SDKs Bad, because some advanced features may require vendor-specific extensions Datadog SDK Datadog provides proprietary SDKs for instrumenting applications and sending telemetry to the Datadog platform.\nGood, because it offers a unified, fully-managed observability platform Good, because it provides excellent out-of-the-box dashboards and visualizations Good, because it has automatic instrumentation for many frameworks and libraries Good, because it offers strong APM (Application Performance Monitoring) features Good, because it has excellent documentation and developer experience Good, because it includes alerting, incident management, and collaboration features Neutral, because it requires a Datadog account and subscription Bad, because it creates vendor lock-in - switching away requires significant re-instrumentation Bad, because it has ongoing per-host/container costs that scale with usage Bad, because telemetry data is only compatible with Datadog’s backend Bad, because it may not align with open-source philosophy of the project Sentry SDK Sentry is primarily an error tracking and performance monitoring platform with SDKs for multiple languages.\nGood, because it excels at error tracking and exception reporting Good, because it has good performance monitoring capabilities Good, because it offers distributed tracing Good, because it has strong developer experience and debugging tools Good, because it provides issue grouping and notification features Good, because it has a generous free tier for open-source projects Neutral, because it focuses more on errors/exceptions than comprehensive observability Bad, because metrics support is less mature compared to dedicated observability platforms Bad, because it creates vendor lock-in similar to Datadog Bad, because log aggregation is not a primary feature Bad, because it’s more specialized for error tracking than full observability More Information Related Research Analysis documents on observability backends are available in docs/content/research_and_development/analysis/observability/ The POC user journey (ADR-0000 reference pending) identifies observability as a critical requirement Implementation Considerations If OpenTelemetry is chosen, separate ADRs will be needed for: Metrics backend selection (e.g., Prometheus, Mimir) Tracing backend selection (e.g., Jaeger, Tempo) Log aggregation backend selection (e.g., Loki) OpenTelemetry Collector deployment strategy If Datadog or Sentry is chosen, consider OpenTelemetry compatibility for future flexibility Consider hybrid approaches (e.g., OpenTelemetry for instrumentation + commercial backend) Questions to Resolve What is the expected scale of telemetry data (events/sec, log volume)? What is the budget for observability infrastructure and services? Is vendor neutrality a hard requirement or nice-to-have? What are the specific visualization and alerting requirements? Will bots require observability instrumentation, or only game server? ","categories":"","description":"Select OpenTelemetry as the observability SDK for instrumenting metrics, traces, and logs across the Battle Bots platform.\n","excerpt":"Select OpenTelemetry as the observability SDK for instrumenting …","ref":"/battlebots/pr-preview/pr-153/research_and_development/adrs/0002-observability-sdk-selection/","tags":"","title":"[0002] Observability SDK Selection"},{"body":"Overview HTTP-based protocols represent the most widely-adopted communication patterns on the web. This analysis evaluates three approaches for Battle Bots bot-to-server communication:\nHTTP/REST - Request/response pattern with polling or long-polling WebSockets - Full-duplex bidirectional communication over TCP Server-Sent Events (SSE) - Unidirectional server-to-client streaming Each approach offers different trade-offs in complexity, performance, and developer familiarity.\nHTTP/REST Analysis Architecture Pattern Traditional Request/Response:\nBot → POST /battles/{id}/actions → Server Bot ← 200 OK {result} ← Server Bot → GET /battles/{id}/state → Server Bot ← 200 OK {gameState} ← Server RESTful API Design:\nPOST /battles/{id}/actions - Submit bot action GET /battles/{id}/state - Poll for current game state GET /battles/{id}/events?since={timestamp} - Fetch events since last poll DELETE /battles/{id}/connections/{botId} - Disconnect from battle State Updates Polling:\nBot repeatedly requests /state endpoint (e.g., every 100ms) Simple to implement High latency (up to poll interval) Wasted requests when no state changes Long-Polling:\nServer holds request open until state changes Immediately returns new state when available Better latency than polling, worse than streaming Reconnection overhead between state changes Performance Characteristics Latency:\nPolling: 50-500ms depending on interval Long-polling: 10-100ms with reconnection overhead HTTP/1.1: Head-of-line blocking, connection limits HTTP/2: Multiplexing improves concurrent requests Throughput:\nLimited by request/response cycle time High overhead for frequent small updates Better for discrete actions than continuous state Resource Usage:\nConnection churning with polling/long-polling Server load from repeated requests Client CPU from polling loops Advantages ✅ Universal language support (every language has HTTP client)\n✅ Simple mental model - stateless request/response\n✅ Easy debugging with curl, browser DevTools\n✅ RESTful conventions well-understood\n✅ HTTP caching for read-heavy scenarios\n✅ Firewall-friendly (port 80/443)\nDisadvantages ❌ Poor real-time performance without long-polling\n❌ Polling wastes bandwidth and CPU\n❌ High latency for state updates\n❌ No server push (without long-polling hacks)\n❌ Inefficient for streaming game state\nSuitability for Battle Bots ⭐⭐☆☆☆ (Marginal) - Only viable for very slow turn-based games with infrequent updates.\nWebSockets Analysis Architecture Pattern Full-Duplex Communication:\nBot → WS Connect ws://server/battle/123 → Server ← WS Upgrade (101 Switching Protocols) ← Bot → {\"action\": \"move\", \"x\": 10} → ← {\"event\": \"state_update\", \"positions\": [...]} ← Bot → {\"action\": \"attack\", \"target\": \"bot2\"} → ← {\"event\": \"damage\", \"target\": \"bot2\", \"hp\": 50} ← Persistent Connection:\nSingle TCP connection for bidirectional messages No HTTP overhead after handshake Both sides can send messages anytime Connection stays open for battle duration Message Framing Text Frames:\nJSON messages (human-readable) Easy debugging and development Larger payload sizes Binary Frames:\nMessagePack, Protocol Buffers, CBOR Efficient encoding/decoding Smaller payload sizes (30-50% reduction) Performance Characteristics Latency:\n5-20ms for message round-trip (local network) Near-zero after connection establishment No polling overhead Comparable to gRPC streaming Throughput:\nThousands of messages per second per connection Limited by TCP bandwidth, not protocol overhead Efficient for rapid state updates Resource Usage:\nOne TCP connection per bot (persistent) Lower CPU than polling (no repeated handshakes) Memory for message buffering Connection scaling considerations (1000s of concurrent bots) Connection Management Lifecycle:\nHTTP upgrade handshake Persistent WebSocket connection Keepalive pings/pongs Graceful or abrupt close Reconnection:\nNot automatic - client must implement State synchronization after reconnect Resume semantics (message IDs, sequence numbers) Heartbeats:\nPing/Pong frames for keepalive Detect half-open connections Configurable timeout Language \u0026 Platform Support Excellent support across languages:\nGo: gorilla/websocket, nhooyr/websocket Python: websockets, aiohttp JavaScript: Native WebSocket API (browser + Node.js) Java: Java WebSocket API (JSR 356), Spring WebSocket Rust: tokio-tungstenite C#: ASP.NET Core SignalR Browser Native:\nWebSockets work in all modern browsers Enables browser-based bot development Web-based battle visualization OpenTelemetry Integration Challenges:\nNo standard instrumentation like gRPC Manual span creation for each message Context propagation requires custom headers/metadata Implementation Approach:\n// Manual tracing ctx, span := tracer.Start(ctx, \"websocket.message\") defer span.End() span.SetAttributes( attribute.String(\"message.type\", msg.Type), attribute.String(\"bot.id\", botID), ) Metrics:\nMessage count, size, latency Connection duration, errors Custom battle-specific metrics Trace Correlation:\nEmbed trace context in JSON messages Reconstruct distributed trace manually More complex than gRPC auto-instrumentation Container Networking Proxy Considerations:\nSticky sessions required: Connection affinity Nginx: ip_hash or sticky directive HAProxy: stick-table for session persistence Envoy: Consistent hashing HTTP/1.1 Limitation:\nWebSocket upgrade uses HTTP/1.1 One WebSocket per TCP connection No multiplexing like HTTP/2 Kubernetes:\nService type LoadBalancer with session affinity Ingress controllers support WebSocket Readiness probes need special handling Development Experience Tooling:\nwscat: Command-line WebSocket client Browser DevTools: Inspect WebSocket frames Postman: WebSocket request support websocat: Netcat-like WebSocket tool Debugging:\nMessages visible in browser DevTools Text frames easy to inspect Binary frames require decoder Testing:\nUnit test with mock WebSocket Integration test with test server Load testing with ws-bench Advantages ✅ True bidirectional communication (no polling)\n✅ Low latency for real-time updates\n✅ Efficient - single persistent connection\n✅ Universal support across languages and browsers\n✅ Familiar to web developers\n✅ Flexible - text or binary messages\n✅ Firewall-friendly (works on port 80/443)\nDisadvantages ❌ No automatic reconnection (client must implement)\n❌ Scaling challenges (sticky sessions, connection limits)\n❌ OpenTelemetry integration requires manual instrumentation\n❌ No built-in backpressure mechanism\n❌ HTTP/1.1 only (no HTTP/2 multiplexing)\n❌ Connection state complicates load balancing\nSuitability for Battle Bots Client/Server Architecture: ⭐⭐⭐⭐☆ (Very Good)\nExcellent real-time performance Manual OTEL integration is manageable Sticky sessions solvable with proper load balancing P2P Architecture: ⭐⭐⭐☆☆ (Moderate)\nBots must run WebSocket servers NAT traversal challenges (similar to gRPC) Discovery and connection complexity Server-Sent Events (SSE) Analysis Architecture Pattern Unidirectional Server → Client:\nBot → GET /battles/{id}/events → Server ← HTTP/1.1 200 OK ← Content-Type: text/event-stream ← data: {\"event\": \"state_update\", \"positions\": [...]} ← data: {\"event\": \"damage\", \"target\": \"bot2\", \"hp\": 50} Bot → POST /battles/{id}/actions → Server (separate connection) Hybrid Approach:\nSSE for server → bot (game state, events) HTTP POST for bot → server (actions) Protocol Details Event Stream Format:\nevent: gameStateUpdate data: {\"positions\": [...], \"tick\": 42} id: 42 event: botDamaged data: {\"botId\": \"bot2\", \"damage\": 10} id: 43 Text-based format Named events for filtering Auto-incrementing IDs for resume Automatic Reconnection:\nBrowser automatically reconnects on disconnect Last-Event-ID header for resuming from last event Built-in retry with exponential backoff Performance Characteristics Latency:\n10-30ms for server → bot messages Similar to WebSocket for downstream POST latency for bot → server actions (20-50ms) Throughput:\nExcellent for server → bot (streaming) Limited by HTTP POST for bot → server Asymmetric performance Resource Usage:\nOne long-lived connection per bot (SSE) Short-lived connections for actions (POST) Lower than polling, higher than WebSocket Advantages ✅ Automatic reconnection with event ID resume\n✅ Simple - just HTTP GET, no upgrade handshake\n✅ Browser native - EventSource API\n✅ Text-based - easy debugging\n✅ Firewall-friendly (HTTP)\n✅ Built-in event types and filtering\nDisadvantages ❌ Unidirectional only (server → client)\n❌ Requires separate channel for client → server (HTTP POST)\n❌ Text-only (no binary without base64 encoding)\n❌ HTTP/1.1 connection limits (6 per domain in browsers)\n❌ Less efficient than WebSocket for bidirectional\n❌ Not widely adopted outside browser contexts\nSuitability for Battle Bots ⭐⭐⭐☆☆ (Moderate) - Viable for slow-paced battles, but WebSocket is simpler for bidirectional needs.\nSerialization Format Comparison JSON (JavaScript Object Notation) Characteristics:\nText-based, human-readable Language-agnostic Schema-optional (self-describing) Pros:\nEasy debugging (read with eyes) Universal support Browser-native parsing No build step Cons:\nLarger payload size (2-3x vs binary) Slower parsing than binary No built-in versioning No schema validation Example:\n{ \"action\": \"move\", \"botId\": \"bot-123\", \"position\": {\"x\": 10, \"y\": 20}, \"timestamp\": 1701820800 } Size: ~120 bytes\nMessagePack Characteristics:\nBinary JSON-like format Schema-optional Faster and smaller than JSON Pros:\n30-50% smaller than JSON 2-5x faster encoding/decoding Language support: Go, Python, JS, Java, Rust Drop-in JSON replacement Cons:\nNot human-readable Less ubiquitous than JSON No schema enforcement Example (binary):\n\\x84\\xa6action\\xa4move\\xa5botId\\xa7bot-123\\xa8position\\x82... Size: ~70 bytes\nProtocol Buffers over HTTP Characteristics:\nBinary protocol with schema (.proto) Same as gRPC but over HTTP/WebSocket Strong typing and versioning Pros:\nSmallest payload (50-70% smaller than JSON) Type safety and validation Forward/backward compatibility Code generation Cons:\nRequires .proto files and code generation Not human-readable Build complexity Size: ~50 bytes\nCBOR (Concise Binary Object Representation) Characteristics:\nBinary JSON alternative (RFC 8949) Self-describing like JSON Designed for IoT/constrained environments Pros:\nSmaller than JSON More data types (binary, dates) IETF standard Cons:\nLess adoption than MessagePack Not as compact as Protocol Buffers Recommendation for Battle Bots Development/Debugging: JSON (easy to inspect)\nProduction: Protocol Buffers (best performance + type safety)\nAlternative: MessagePack (good middle ground)\nOpenTelemetry Integration Summary Protocol OTEL Support Implementation Effort Trace Propagation Auto-Instrumentation HTTP/REST ⭐⭐⭐⭐⭐ Easy W3C Trace Context headers Yes (most languages) WebSockets ⭐⭐⭐☆☆ Moderate Manual (custom metadata) No SSE ⭐⭐⭐☆☆ Moderate W3C headers on GET Partial Best OTEL Integration: HTTP/REST (but worst real-time performance)\nCompromise: WebSocket with manual instrumentation\nContainer Networking Summary Protocol Container Support Load Balancing Session Affinity NAT Traversal HTTP/REST Excellent Easy Not required N/A WebSockets Good Moderate Required Challenging SSE Good Moderate Required Moderate Development Experience Summary Protocol Learning Curve Tooling Debugging Language Support HTTP/REST Low Excellent Easy Universal WebSockets Low-Moderate Good Moderate Excellent SSE Low Moderate Easy Good Pros and Cons Summary Overall Assessment HTTP/REST:\n✅ Simple, universal, well-tooled ❌ Poor real-time performance Use case: Admin APIs, non-real-time operations WebSockets:\n✅ Excellent real-time performance, bidirectional ❌ Manual OTEL, scaling complexity Use case: Real-time battle communication (strong candidate) SSE:\n✅ Auto-reconnect, simple server-push ❌ Unidirectional, requires POST for bot actions Use case: Asymmetric scenarios (server-heavy updates) References WebSocket Protocol (RFC 6455) Server-Sent Events Specification HTTP/2 Specification (RFC 7540) MessagePack Specification CBOR (RFC 8949) OpenTelemetry HTTP Instrumentation WebSocket vs Server-Sent Events gorilla/websocket - Go WebSocket library ","categories":"","description":"Analysis of HTTP/REST, WebSockets, and SSE for bot-to-server communication\n","excerpt":"Analysis of HTTP/REST, WebSockets, and SSE for bot-to-server …","ref":"/battlebots/pr-preview/pr-153/research_and_development/analysis/protocols/http/","tags":"","title":"HTTP-based Protocols Analysis"},{"body":"Context and Problem Statement Following the decision to adopt OpenTelemetry as our observability SDK (ADR-0002), we need to select the backend components for our observability stack. The stack must handle three distinct observability signals: traces, metrics, and logs. We need to decide on the ingestion mechanism for telemetry data, the storage backends for each signal type, and the visualization layer for unified observability.\nWhich combination of ingestion, backend, and visualization components should we deploy for the Battle Bots observability stack?\nDecision Drivers Vendor neutrality and avoiding lock-in Open-source preference to align with project philosophy Resource efficiency (memory, CPU, storage) Ease of deployment and operational overhead Query performance and scalability Long-term storage capabilities and retention policies Unified visualization across all observability signals Community support and maturity Cost of infrastructure and licensing Feature completeness for each signal type Flexibility to swap components independently Considered Options Ingestion Option I1: OpenTelemetry Collector Option I2: Direct export to signal-specific systems Traces Option T1: Tempo Option T2: Jaeger Option T3: Zipkin Metrics Option M1: Prometheus Option M2: Mimir Logs Option L1: OpenSearch Option L2: Loki Visualization Option V1: Grafana Option V2: Datadog Option V3: Dynatrace Option V4: New Relic Decision Outcome Chosen option: Open-Source Observability Stack with Grafana Ecosystem\nIngestion: OpenTelemetry Collector (Option I1) Visualization: Grafana (Option V1) Logs: Loki (Option L2) Traces: Tempo (Option T1) Metrics: Mimir (Option M2) This combination provides a fully open-source, vendor-neutral observability stack that leverages the Grafana ecosystem for seamless integration across all three signals. The stack prioritizes cost-effectiveness (object storage for all backends), operational simplicity (unified Grafana Labs components), and maintains flexibility to swap individual components as needs evolve.\nArchitecture Diagram architecture-beta service gameserver(server)[Game Server] service botruntime(server)[Bot Runtime] service battleviz(server)[Battle Visualization] service otelcollector(server)[OpenTelemetry Collector] service tempo(database)[Tempo] service mimir(database)[Mimir] service loki(database)[Loki] service grafana(internet)[Grafana] junction ingest junction export junction juncTempo1 junction juncTempo2 junction juncMimir junction juncLoki1 junction juncLoki2 gameserver:B -- T:ingest botruntime:R -- L:ingest battleviz:T -- B:ingest ingest:R --\u003e L:otelcollector otelcollector:R -- L:export export:T --\u003e B:tempo export:R --\u003e L:mimir export:B --\u003e T:loki tempo:R \u003c-- L:juncTempo1 mimir:R \u003c-- L:juncMimir loki:R \u003c-- L:juncLoki1 juncTempo1:R -- L:juncTempo2 juncLoki1:R -- L:juncLoki2 grafana:T -- B:juncTempo2 grafana:L -- R:juncMimir grafana:B -- T:juncLoki2 Consequences Good, because all components are open-source, avoiding vendor lock-in and licensing costs Good, because Grafana ecosystem provides unified, seamless integration across all signals Good, because Tempo, Loki, and Mimir all use object storage, minimizing infrastructure costs Good, because OpenTelemetry Collector decouples applications from backend systems Good, because we maintain flexibility to swap individual components independently Good, because resource efficiency is optimized (Loki and Tempo avoid expensive indexing) Good, because the stack aligns with the project’s open-source philosophy Good, because PromQL, LogQL, and TraceQL provide consistent query language patterns Neutral, because we need to self-host and manage all components Neutral, because Grafana requires learning three query languages (PromQL, LogQL, TraceQL) Bad, because operational overhead is higher than managed commercial solutions Bad, because Mimir is more complex to deploy than single-instance Prometheus Bad, because Loki requires careful label design to avoid high cardinality issues Bad, because we lack some enterprise features (advanced RBAC, managed services) Confirmation This decision will be considered successful when:\nAll three observability signals (traces, metrics, logs) are collected and queryable Visualization layer provides unified view across all signals Performance overhead of the stack is acceptable (\u003c 10% infrastructure cost) Operators can effectively debug issues using the observability data Retention policies maintain historical data for at least 30 days The stack can scale to handle expected production load Costs (infrastructure + licensing) fit within budget constraints Pros and Cons of the Options Ingestion Option I1: OpenTelemetry Collector OpenTelemetry Collector is a vendor-agnostic service for receiving, processing, and exporting telemetry data.\nGood, because it provides a unified ingestion point for all observability signals Good, because it decouples applications from backend systems Good, because it supports protocol translation (OTLP, Jaeger, Zipkin, Prometheus, etc.) Good, because it enables sending data to multiple backends simultaneously Good, because it provides data processing (filtering, sampling, enrichment) Good, because it allows backend changes without application redeployment Good, because it can aggregate telemetry from multiple sources Good, because it reduces load on applications by offloading export logic Good, because it supports tail-based sampling for traces Neutral, because it adds another component to deploy and manage Bad, because it introduces an additional hop in the telemetry pipeline Bad, because it becomes a critical point of failure if not properly configured Bad, because it requires additional infrastructure resources Option I2: Direct Export to Signal-Specific Systems Direct export means OpenTelemetry SDK sends telemetry directly to backend systems without an intermediary collector.\nGood, because it reduces architectural complexity (fewer moving parts) Good, because it eliminates an additional network hop Good, because it reduces infrastructure requirements (no collector to deploy) Good, because it has lower operational overhead Good, because latency is reduced for telemetry delivery Neutral, because applications must be configured with backend endpoints Bad, because changing backends requires application reconfiguration and redeployment Bad, because applications must handle export logic and retries Bad, because it couples applications to specific backend protocols Bad, because sending to multiple backends requires multiple exporters in each application Bad, because advanced processing (sampling, filtering) must be done in applications Bad, because it increases load on applications Traces Option T1: Tempo Grafana Tempo is a high-volume, cost-effective distributed tracing backend that requires only object storage.\nGood, because it uses object storage (S3, GCS, local disk), making it extremely cost-effective Good, because it has minimal operational overhead (no complex indexing) Good, because it integrates seamlessly with Grafana Good, because it scales horizontally and handles high trace volumes Good, because it supports multiple trace formats (Jaeger, Zipkin, OpenTelemetry) Good, because it has native OpenTelemetry Collector support Good, because it uses TraceQL for powerful trace queries Good, because resource usage is low compared to full-text indexing solutions Neutral, because trace discovery relies on trace IDs or service metadata Bad, because it lacks full-text search across all trace data Bad, because it is relatively newer compared to Jaeger/Zipkin Option T2: Jaeger Jaeger is a CNCF-graduated distributed tracing system originally developed by Uber.\nGood, because it is mature and battle-tested in production environments Good, because it has comprehensive trace search and filtering capabilities Good, because it provides its own UI in addition to Grafana integration Good, because it is CNCF-graduated with strong community support Good, because it supports multiple storage backends (Cassandra, Elasticsearch, Badger) Good, because it has native OpenTelemetry Collector support Neutral, because it requires additional storage infrastructure (database) Bad, because operational overhead is higher than Tempo Bad, because storage costs can be significant with Elasticsearch/Cassandra Bad, because resource consumption is higher due to indexing Option T3: Zipkin Zipkin is a distributed tracing system originally created by Twitter.\nGood, because it is very mature and widely adopted Good, because it has a simple architecture and deployment model Good, because it provides its own UI for trace visualization Good, because it supports multiple storage backends (MySQL, Cassandra, Elasticsearch) Good, because it has low resource requirements for small deployments Neutral, because OpenTelemetry Collector support is available but less emphasized Bad, because it has less active development compared to Tempo/Jaeger Bad, because Grafana integration is not as seamless Bad, because it lacks some modern features found in Tempo/Jaeger Bad, because community momentum has shifted toward newer solutions Metrics Option M1: Prometheus Prometheus is a CNCF-graduated monitoring and alerting toolkit designed for reliability and simplicity.\nGood, because it is the industry standard for metrics collection Good, because it has excellent Grafana integration Good, because it is CNCF-graduated with massive community support Good, because it has a powerful query language (PromQL) Good, because it uses efficient time-series storage Good, because it has extensive ecosystem of exporters and integrations Good, because it has native OpenTelemetry Collector support Good, because it is simple to deploy and operate for small-to-medium scale Good, because it has built-in alerting capabilities Neutral, because it is designed for single-server deployments Bad, because it has limited long-term storage capabilities (local disk only) Bad, because high availability requires complex federation setups Bad, because it doesn’t scale horizontally for writes Option M2: Mimir Grafana Mimir is a horizontally scalable, long-term storage for Prometheus metrics.\nGood, because it provides unlimited scalability for metrics storage Good, because it is fully compatible with Prometheus (PromQL, remote write) Good, because it uses object storage for cost-effective long-term retention Good, because it has seamless Grafana integration Good, because it supports multi-tenancy out of the box Good, because it provides high availability natively Good, because it has native OpenTelemetry Collector support Good, because it can act as a Prometheus replacement with better scalability Neutral, because it is more complex to deploy than single-instance Prometheus Bad, because operational overhead is higher than Prometheus Bad, because it requires more infrastructure (object storage, multiple components) Bad, because it may be over-engineered for small deployments Logs Option L1: OpenSearch OpenSearch is an open-source fork of Elasticsearch, providing search and analytics capabilities.\nGood, because it offers powerful full-text search across all log data Good, because it has rich query capabilities (SQL, DSL) Good, because it has strong data visualization tools (OpenSearch Dashboards) Good, because it integrates with Grafana Good, because it is mature and well-documented Good, because it supports structured and unstructured log data Good, because it has native OpenTelemetry Collector support Neutral, because it requires significant infrastructure (cluster setup) Bad, because resource consumption is high (CPU, memory, storage) Bad, because operational complexity is significant (cluster management, shard optimization) Bad, because storage costs can be expensive at scale Bad, because it may be over-engineered if simple grep-style queries suffice Option L2: Loki Grafana Loki is a log aggregation system designed to be cost-effective and easy to operate.\nGood, because it is extremely resource-efficient compared to full-text search solutions Good, because it uses object storage, making it cost-effective Good, because it has seamless Grafana integration (native support) Good, because operational overhead is minimal Good, because it scales horizontally Good, because it indexes only metadata (labels), not full log content Good, because it has native OpenTelemetry Collector support via OTLP Good, because it uses LogQL, which is similar to PromQL for consistency Neutral, because it requires labels to be well-structured for efficient queries Bad, because it doesn’t support full-text search across log content Bad, because complex queries across unlabeled data are slow Bad, because it requires careful label design to avoid high cardinality Visualization Option V1: Grafana Grafana is an open-source observability platform for visualizing metrics, logs, and traces.\nGood, because it is open-source and free, avoiding vendor lock-in Good, because it provides unified visualization for all three signals Good, because it has native integrations with Prometheus, Tempo, Loki, Jaeger, and many others Good, because it supports custom dashboards with powerful query editors Good, because it has a large community and extensive plugin ecosystem Good, because it supports alerting capabilities Good, because it can correlate data across different data sources Good, because it aligns with open-source philosophy of the project Good, because it has no per-user or per-host licensing costs Neutral, because it requires self-hosting and operational management Bad, because creating effective dashboards requires learning different query languages (PromQL, LogQL, TraceQL) Bad, because advanced features may require additional plugins or configuration Bad, because it lacks some enterprise features of commercial platforms (advanced RBAC, audit logs) Option V2: Datadog Datadog is a commercial observability platform providing unified monitoring, logging, and tracing.\nGood, because it provides a fully-managed, unified observability platform Good, because it has excellent out-of-the-box dashboards and visualizations Good, because it offers advanced analytics and correlation across signals Good, because it provides APM, RUM (Real User Monitoring), and many integrated features Good, because it has strong alerting, incident management, and collaboration tools Good, because operational overhead is minimal (fully managed) Good, because it has comprehensive documentation and support Neutral, because it can ingest OpenTelemetry data via OTLP Bad, because it creates significant vendor lock-in Bad, because it has substantial per-host/container costs that scale with usage Bad, because it contradicts open-source philosophy Bad, because costs can become prohibitive at scale Bad, because data is stored in Datadog’s infrastructure only Option V3: Dynatrace Dynatrace is an enterprise observability and AIOps platform.\nGood, because it provides AI-powered automatic root cause analysis Good, because it has comprehensive full-stack monitoring capabilities Good, because it offers automatic discovery and dependency mapping Good, because it excels at application performance monitoring Good, because operational overhead is minimal (fully managed) Good, because it has strong enterprise features and support Neutral, because it supports OpenTelemetry ingestion Bad, because it creates significant vendor lock-in Bad, because it has premium pricing model (enterprise-focused) Bad, because it contradicts open-source philosophy Bad, because it may be over-engineered for Battle Bots scale Bad, because costs are typically higher than other commercial solutions Option V4: New Relic New Relic is a commercial observability platform with full-stack monitoring capabilities.\nGood, because it provides unified observability for metrics, logs, and traces Good, because it has a generous free tier for small projects Good, because it offers good out-of-the-box visualizations and dashboards Good, because operational overhead is minimal (fully managed) Good, because it has native OpenTelemetry support Good, because it provides powerful query language (NRQL) Good, because it has decent community and documentation Neutral, because pricing is based on data ingestion rather than hosts Bad, because it creates vendor lock-in Bad, because costs scale with data volume Bad, because it contradicts open-source philosophy Bad, because advanced features require paid tiers Bad, because data is stored in New Relic’s infrastructure only More Information Related Decisions ADR-0002: Observability SDK Selection - establishes OpenTelemetry as the instrumentation layer Related Research Analysis documents available in docs/content/research_and_development/analysis/observability/ Architecture Overview The selected observability stack architecture:\n[Battle Bots Services] → [OpenTelemetry SDKs] → [OpenTelemetry Collector] → [Tempo (Traces)] → [Mimir (Metrics)] → [Loki (Logs)] → [Grafana (Visualization)] All three backends (Tempo, Mimir, Loki) use object storage (S3, GCS, or local disk) for cost-effective, scalable storage. Grafana provides the unified visualization layer with native support for all three data sources.\nImplementation Considerations OpenTelemetry Collector Configuration: Deploy as a sidecar or gateway to receive OTLP data and export to Tempo, Mimir, and Loki Object Storage: Configure S3-compatible object storage (or local disk for development) for all three backends Label Design: Carefully design log labels for Loki to balance query performance and cardinality Mimir vs Prometheus: Start with Mimir for long-term storage capabilities, though Prometheus could be used initially if simpler deployment is preferred Data Retention: Configure retention policies per signal type (e.g., traces: 7 days, metrics: 30 days with downsampling, logs: 14 days) Deployment Order: Deploy in order: object storage → Tempo + Mimir + Loki → OTel Collector → Grafana → configure data sources Grafana Data Sources: Configure three data sources in Grafana (Tempo, Mimir/Prometheus, Loki) for unified querying Correlation: Leverage trace IDs in logs and metrics to enable correlation across all three signals in Grafana Resource Planning: Monitor resource usage in POC environment to right-size deployments for production Migration Path: The OpenTelemetry Collector allows future migration to alternative backends without changing application instrumentation Rationale for Selection This specific combination was selected based on the following factors:\nUnified Ecosystem: Tempo, Loki, and Mimir are all Grafana Labs projects, ensuring consistent design patterns and seamless integration Cost Optimization: All three backends use object storage, significantly reducing storage costs compared to indexed solutions Operational Simplicity: Managing components from the same ecosystem reduces operational complexity versus mixing vendors Vendor Neutrality: All components are open-source, avoiding commercial lock-in while maintaining professional quality Scalability: Each component scales horizontally and is designed for high-volume production use Query Languages: PromQL (Mimir), LogQL (Loki), and TraceQL (Tempo) share similar syntax patterns, reducing learning curve OpenTelemetry Native: All components have native OpenTelemetry support via OTLP protocol Resource Efficiency: Loki and Tempo avoid expensive full-text indexing, keeping resource usage low Project Alignment: Open-source approach aligns with Battle Bots project philosophy Migration Flexibility: OpenTelemetry Collector allows swapping backends without re-instrumenting applications Next Steps POC Deployment: Deploy the full stack (OTel Collector + Tempo + Mimir + Loki + Grafana) in development environment Instrumentation: Instrument Battle Bots services with OpenTelemetry SDK (per ADR-0002) and verify all three signals are collected Object Storage Setup: Configure S3-compatible storage or local disk for backend storage Grafana Dashboards: Create initial dashboards for key metrics, traces, and logs Label Strategy: Define and document label naming conventions for Loki and Mimir Retention Policies: Configure appropriate retention for each signal type based on storage constraints Performance Testing: Generate load and measure resource usage, query performance, and storage costs Documentation: Document deployment procedures, configuration, and operational runbooks Production Readiness: Evaluate high availability, backup, and disaster recovery requirements before production deployment Open Questions What object storage provider should be used (S3, GCS, MinIO, local disk)? Should Mimir be deployed immediately, or start with Prometheus and migrate later? What are the specific retention requirements for each signal type? Do we need multi-tenancy support for isolating different battle arenas? What high availability requirements exist for the observability stack? ","categories":"","description":"Deploy an OpenTelemetry Collector with Tempo for traces, Prometheus for metrics, and Loki for logs, unified by Grafana for visualization.\n","excerpt":"Deploy an OpenTelemetry Collector with Tempo for traces, Prometheus …","ref":"/battlebots/pr-preview/pr-153/research_and_development/adrs/0003-observability-stack-architecture/","tags":"","title":"[0003] Observability Stack Architecture"},{"body":"Overview Custom TCP and UDP protocols offer maximum control and potential performance optimization for game networking. This analysis evaluates whether the complexity and development cost of custom protocols is justified for Battle Bots, drawing on lessons from game industry networking.\nTCP Custom Protocol Analysis Protocol Design Message Format Example:\n[4 bytes: magic number 0x42544C00] [2 bytes: protocol version] [2 bytes: message type] [4 bytes: message length] [4 bytes: sequence number] [N bytes: payload (JSON, MessagePack, Protobuf)] [4 bytes: CRC32 checksum] Connection-Oriented Characteristics:\nReliable, ordered delivery (TCP guarantees) Stream-based (requires message framing) Connection handshake and teardown Flow control and congestion avoidance built-in Message Framing Strategies Length-Prefixed:\n[4-byte length][payload] Simple to parse Requires buffering until full message received Delimiter-Based:\n[payload]\\n Easy to implement Inefficient if payload contains delimiters Fixed-Length Headers:\nHeader describes payload structure Best practice for custom protocols Allows for protocol evolution Performance Characteristics Latency:\n5-15ms round-trip (local network) Similar to gRPC/WebSocket (all use TCP) No inherent advantage over HTTP/2 or WebSocket Throughput:\nLimited by TCP, not protocol overhead Custom framing slightly more efficient than HTTP Marginal gain (5-10%) vs WebSocket CPU Overhead:\nCustom parsing faster than HTTP header parsing Binary protocols minimize serialization cost Negligible difference in practice for Battle Bots scale Advantages ✅ Maximum control over message format\n✅ Minimal overhead (no HTTP headers)\n✅ Custom flow control if needed\n✅ Protocol optimizations for specific use case\nDisadvantages ❌ High implementation cost (build, test, debug)\n❌ Language-specific implementations (no code generation)\n❌ Limited tooling (manual packet inspection)\n❌ No standard libraries (roll your own)\n❌ Bug-prone (protocol state machines, edge cases)\n❌ No advantage over WebSocket/gRPC for this use case\nComparison with WebSocket Both use TCP, so performance is nearly identical:\nWebSocket has ~6 bytes per frame overhead Custom protocol saves ~6 bytes per message Conclusion: Negligible benefit, massive implementation cost UDP Custom Protocol Analysis Protocol Design Unreliable Datagram Characteristics:\nNo connection (connectionless) Packets can be lost, duplicated, reordered Low latency (no TCP handshake/ACK overhead) Manual reliability layer required Custom Reliability Layer Example:\n[4 bytes: sequence number] [4 bytes: ack bitfield] [1 byte: reliability flags] [N bytes: payload] Reliability Modes:\nUnreliable: Send and forget (position updates) Reliable: Retransmit until ACK (critical events) Ordered: Sequence numbers, discard out-of-order Sequenced: Latest only, discard older packets Performance Characteristics Latency:\n2-10ms round-trip (no TCP handshake) 30-50% lower latency than TCP in ideal conditions Worse under packet loss (retransmissions) Throughput:\nHigher ceiling than TCP (no congestion control) Prone to network congestion without custom control Better for bursty traffic Packet Loss Handling:\n1-5% packet loss is common on Internet Game engines interpolate/extrapolate positions Critical events need reliability layer Use Cases in Game Networking Good for UDP:\nPlayer position updates (frequent, latest is best) Input state (redundant, lose older packets) Non-critical effects (particle systems, audio) High tick-rate simulations (60+ updates/sec) Bad for UDP:\nPlayer actions (attack, use item - must be reliable) Inventory changes (critical state) Chat messages (must arrive) Battle Bots actions (move, attack decisions are critical) Game Networking Patterns Client-Side Prediction:\nClient predicts local movement → Send input to server Server authoritative simulation → Send correction Client reconciles prediction with server state Masks network latency Requires complex reconciliation logic Server Reconciliation:\nServer is authoritative Clients show approximate state Server corrects divergence Snapshot Interpolation:\nServer sends state snapshots Client interpolates between snapshots Smooth animation despite packet loss Delta Compression:\nSend only changed fields Reduces bandwidth for large state objects Requires baseline tracking Are these needed for Battle Bots?\nTurn-based or low tick-rate: No Real-time FPS-style: Maybe Current POC requirements: No OpenTelemetry Integration Challenges Major Issues:\nNo standard trace propagation (no HTTP headers) Custom metadata format required Manual span creation for every packet Sampling complexity (trace 1/1000 packets?) Implementation Approach:\n// Custom trace context in UDP packet type PacketHeader struct { TraceID [16]byte SpanID [8]byte Flags byte // ... rest of packet } Metrics Collection:\nPacket send/receive counters Loss rate calculation Latency histogram (manual timing) Battle-specific metrics Complexity vs gRPC/WebSocket:\n10x more complex to instrument No automatic integration with OTLP High maintenance burden Container Networking Port Mapping:\nUDP ports must be explicitly mapped Each bot needs unique port (or shared port with routing) Firewall Traversal:\nMany networks block UDP Corporate firewalls often UDP-hostile NAT64 environments problematic Load Balancing:\nStateless load balancing possible Consistent hashing needed for session affinity More complex than TCP NAT Traversal for P2P:\nHole Punching:\nBoth bots connect to rendezvous server Server shares IP:port of each bot Bots send UDP packets to each other NAT creates temporary mappings Direct P2P communication established STUN/TURN:\nSTUN: Discover public IP:port TURN: Relay server for firewall traversal TURN required when symmetric NAT prevents hole-punching Complexity:\nSignificantly more complex than TCP Failure rate: 5-20% of connections may require TURN Additional infrastructure cost Development \u0026 Tooling Implementation Cost:\nHigh: Build protocol from scratch in each language Testing: Unit tests, integration tests, fuzz testing Edge cases: Connection state, packet loss, reordering Debugging Tools:\ntcpdump: Capture packets Wireshark: Decode custom protocol (requires dissector plugin) Custom tooling: Packet replayer, simulator Logging: Extensive logging required Language Support:\nManual implementation per language No code generation (unlike gRPC/Protobuf) Consistency challenges across languages Maintenance:\nProtocol versioning complexity Backward compatibility testing Documentation burden for bot developers Industry Examples \u0026 Lessons Unreal Engine Networking Architecture:\nUDP-based with custom reliability layer RPCs for critical events (reliable) Property replication for state (unreliable with delta compression) Client-side prediction and server reconciliation Why UDP:\nFast-paced FPS games (60-120 tick rate) Hundreds of position updates per second Packet loss acceptable for intermediate positions Applicability to Battle Bots:\nUnclear if Battle Bots needs 60+ tick rate If turn-based, UDP advantage disappears Unity DOTS NetCode Architecture:\nUDP with custom reliable channel Delta compression for snapshot synchronization Ghost entities (networked objects) Client-side prediction Why UDP:\nReal-time multiplayer games Low latency critical High entity count Valve Source Engine Architecture:\nUDP with separate reliable/unreliable channels Lag compensation for hit detection Client-side prediction Command acknowledgment Lessons:\nUDP justified for \u003c 50ms latency requirements Complex to implement correctly Years of refinement What Battle Bots Can Learn Question: Does Battle Bots need \u003c 50ms latency?\nTurn-based or slow tick-rate (\u003c 10/sec):\nTCP is sufficient (WebSocket, gRPC) UDP complexity not justified Real-time fast-paced (\u003e 30/sec tick rate):\nUDP may provide benefits Requires client-side prediction High development cost POC Requirement:\nNo specific tick rate mentioned Suggests UDP is premature optimization Protocol Design Considerations Message Format Design Efficiency:\nBinary \u003e Text for bandwidth Protocol Buffers balance efficiency + maintainability Versioning:\nProtocol version field in header Feature negotiation during handshake Backward compatibility strategy Extensibility:\nReserve fields for future use TLV (Type-Length-Value) encoding Protocol Buffers automatically extensible Error Handling Connection Errors:\nTimeout handling Reconnection logic State recovery Protocol Errors:\nInvalid message format Unexpected message type Version mismatch Application Errors:\nInvalid bot actions Game rule violations Rate limiting Authentication \u0026 Security Connection Authentication:\nToken-based (JWT in handshake) Mutual TLS (mTLS) API keys Message Integrity:\nHMAC signatures CRC/checksum for corruption Encryption (TLS for TCP, DTLS for UDP) Denial of Service:\nRate limiting per bot Connection limits Packet flood protection Development Complexity Comparison Aspect Custom TCP Custom UDP gRPC WebSocket Implementation High Very High Low Low Language Support Manual Manual Generated Libraries Tooling Minimal Minimal Excellent Good OTEL Integration Hard Very Hard Native Moderate Maintenance High Very High Low Low Debugging Hard Very Hard Easy Moderate Effort Estimate:\nCustom TCP: 4-6 weeks per language Custom UDP: 8-12 weeks per language (+ reliability layer) gRPC: 1-2 days (define .proto, generate code) WebSocket: 1-3 days (use library) Pros and Cons Summary Custom TCP ✅ Maximum protocol control\n✅ Minimal wire overhead\n❌ High implementation cost (weeks per language)\n❌ No tooling ecosystem\n❌ Difficult OTEL integration\n❌ No performance advantage over WebSocket\nVerdict: ❌ Not justified for Battle Bots\nCustom UDP ✅ Lowest latency (2-10ms)\n✅ No TCP overhead\n✅ Good for high tick-rate (60+/sec)\n❌ Very high implementation cost (months)\n❌ Reliability layer complexity\n❌ Poor firewall/NAT traversal\n❌ Very difficult OTEL integration\n❌ Only beneficial if \u003c 50ms latency critical\nVerdict: ❌ Premature optimization for POC\nWhen Custom Protocols Make Sense Justified:\nExtreme performance requirements (\u003c 10ms latency) Specialized hardware or protocols Unique constraints not met by standards Not Justified (Battle Bots POC):\nUnknown tick rate requirements Observability is priority (ADR-0002) Language-agnostic bot interface Development velocity matters Suitability for Battle Bots Custom TCP: ⭐☆☆☆☆ (Not Recommended)\nNo performance benefit over WebSocket Massive implementation cost Poor observability integration Custom UDP: ⭐☆☆☆☆ (Not Recommended for POC)\nUnclear if latency requirements justify complexity OTEL integration extremely difficult Firewall/NAT traversal issues Defer until POC proves need Recommendation: Use standard protocols (gRPC/WebSocket) for POC. Re-evaluate custom UDP only if profiling shows \u003c 50ms latency is critical and unachievable with TCP-based protocols.\nReferences Game Networking Patterns (Gaffer On Games) Source Multiplayer Networking Unreal Engine Network Architecture Unity DOTS NetCode Fast-Paced Multiplayer (Gabriel Gambetta) NAT Traversal Techniques STUN Protocol (RFC 5389) TURN Protocol (RFC 5766) TCP vs UDP for Games (Glenn Fiedler) ","categories":"","description":"Analysis of custom TCP and UDP protocols for bot-to-server communication\n","excerpt":"Analysis of custom TCP and UDP protocols for bot-to-server …","ref":"/battlebots/pr-preview/pr-153/research_and_development/analysis/protocols/custom/","tags":"","title":"Custom TCP/UDP Protocol Analysis"},{"body":" Context and Problem Statement The Battle Bots platform requires a communication protocol for bots to interact with the battle server (client/server architecture) or with each other (peer-to-peer architecture). This protocol must support real-time communication while remaining language-agnostic to enable bot development in any programming language.\nRelated to User Journey [0001] Proof of Concept - 1v1 Battle, which identifies bot-to-server interface as a pending ADR required for POC implementation.\nKey Requirements:\nReal-time communication capabilities Language-agnostic interface (Python, Go, Java, JavaScript, Rust, etc.) Low-latency performance Support for both client/server and P2P architectural modes Integration with OpenTelemetry observability stack (ADR-0002, ADR-0003) Container-friendly networking (Docker/Podman) Which communication protocol should Battle Bots adopt for the bot-to-server and bot-to-bot interface?\nDecision Drivers Performance: Low latency and high throughput for real-time battle interaction Language Support: Must enable bot development in diverse programming languages Observability: Seamless integration with OpenTelemetry (ADR-0002) and OTLP stack (ADR-0003) Developer Experience: Ease of implementation for bot authors Communication Flexibility: Support for various communication patterns Type Safety: Schema validation and versioning for protocol evolution Container Networking: Compatibility with Docker/Podman environments Dual Architecture Support: Viability for both client/server and P2P modes Tooling Ecosystem: Availability of debugging, testing, and development tools Implementation Complexity: Development and maintenance cost Industry Maturity: Proven technology with active community support Considered Options Option 1: gRPC Option 2: WebSockets with JSON/MessagePack Option 3: HTTP/REST with Server-Sent Events (SSE) Option 4: Custom TCP protocol Option 5: Custom UDP protocol Decision Outcome Chosen option: “gRPC”, because it provides the optimal balance of performance, developer experience, and observability integration while meeting all functional requirements for both client/server and P2P architectures.\ngRPC delivers excellent performance with superior type safety (Protocol Buffers), native OpenTelemetry instrumentation, and excellent language support through code generation. The protocol provides flexible communication patterns suitable for real-time battle interactions.\nConsequences Positive:\n✅ Excellent OpenTelemetry integration - Native auto-instrumentation for traces, metrics, and logs with zero manual setup aligns perfectly with ADR-0002 and ADR-0003 ✅ Language-agnostic via Protocol Buffers - Code generation for all major languages (Go, Python, Java, JavaScript, Rust, C++, C#) enables diverse bot ecosystem ✅ Type safety and versioning - .proto schema enforces contracts and provides forward/backward compatibility ✅ Flexible communication patterns - Supports unary, server streaming, client streaming, and bidirectional streaming for various use cases ✅ Performance - Binary protocol with 7-10x better throughput than REST/JSON and 30-50% smaller payloads ✅ Container-friendly - HTTP/2 works natively in Docker/Podman with simple port mapping ✅ Rich tooling - grpcurl for testing, ghz for benchmarking, reflection for discovery ✅ Industry proven - Used at scale by Google, Netflix, Square for production systems ✅ Self-documenting - .proto files serve as both implementation and documentation Negative:\n❌ Learning curve - Bot developers must understand Protocol Buffers syntax (mitigated by examples and generated code) ❌ Build complexity - Requires protoc compiler and code generation step in build pipeline ❌ Binary debugging - Not human-readable like JSON (mitigated by grpcurl and reflection) ❌ Browser support - Requires grpc-web proxy for browser-based bots (not native WebSocket) ❌ P2P NAT traversal - More complex than UDP for peer-to-peer due to HTTP/2 over TCP Neutral:\n⚪ HTTP/2 requirement - Benefits from multiplexing but limited to HTTP/2 capabilities ⚪ Port considerations - Non-standard ports (e.g., 50051) may require firewall rules in some environments Confirmation Implementation compliance will be verified through:\nProtocol Definition: All bot-to-server communication defined in .proto files in repository OTEL Instrumentation: Automated tests verify traces/metrics are emitted to Tempo/Mimir Language SDK Examples: Reference bot implementations in at least 3 languages (Go, Python, JavaScript) Integration Tests: Client/server and P2P battle scenarios with containerized bots Performance Benchmarks: Latency and throughput meet \u003c 50ms round-trip target Pros and Cons of the Options gRPC Description: HTTP/2-based RPC framework with Protocol Buffers for serialization and support for multiple communication patterns.\nDetailed Analysis: See gRPC Protocol Analysis\nPros:\n✅ Native OpenTelemetry support - Automatic trace propagation, span creation, and metrics collection integrate seamlessly with ADR-0002 observability stack ✅ Protocol Buffers - Strong typing, schema validation, and versioning prevent runtime errors and enable protocol evolution ✅ Flexible communication patterns - Supports unary, server streaming, client streaming, and bidirectional streaming ✅ Code generation - Eliminates boilerplate, enforces API contracts across all languages ✅ Performance - Binary serialization achieves 5-20ms latency, thousands of messages/sec throughput ✅ Language coverage - Official support for Go, Python, Java, JavaScript, C++, C#, Rust, and more ✅ Container networking - HTTP/2 works natively in Docker/Podman without special configuration ✅ Tooling ecosystem - grpcurl, ghz, reflection, IDE plugins provide excellent developer experience ✅ Dual architecture support - Client/server: bots as clients. P2P: bots expose gRPC servers and connect to each other Cons:\n❌ Learning curve - Developers must learn .proto syntax (estimated 1-2 hours for basics) ❌ Build step - Code generation adds complexity to build pipelines ❌ Binary format - Debugging requires tools like grpcurl vs simple curl for JSON ❌ Browser limitation - Requires grpc-web proxy, not native browser support ❌ P2P NAT - TCP-based NAT traversal requires rendezvous server or relay for some networks Suitability:\nClient/Server: ⭐⭐⭐⭐⭐ (Excellent) - Ideal fit for all requirements P2P: ⭐⭐⭐⭐☆ (Very Good) - NAT traversal manageable with coordination server WebSockets with JSON/MessagePack Description: Full-duplex bidirectional communication over persistent TCP connection with JSON or binary serialization.\nDetailed Analysis: See HTTP-based Protocols Analysis\nPros:\n✅ True bidirectional - Full-duplex communication without polling ✅ Low latency - 5-20ms, comparable to gRPC ✅ Universal support - Native in browsers and all major languages ✅ Flexible serialization - JSON for debugging, MessagePack for efficiency ✅ Familiar to web developers - Lower barrier than learning gRPC/protobuf ✅ Simple protocol - No code generation or build complexity Cons:\n❌ Manual OpenTelemetry instrumentation - No automatic trace propagation or span creation ❌ No schema enforcement - JSON lacks type safety, versioning requires custom logic ❌ Sticky sessions required - Load balancing complexity for stateful connections ❌ No code generation - Manual client/server implementation in each language ❌ HTTP/1.1 only - No HTTP/2 multiplexing benefits ❌ Reconnection logic - Client must implement reconnect and state recovery Suitability:\nClient/Server: ⭐⭐⭐⭐☆ (Very Good) - Viable, but lacks gRPC’s OTEL integration P2P: ⭐⭐⭐☆☆ (Moderate) - Similar NAT challenges as gRPC HTTP/REST with Server-Sent Events Description: Hybrid approach using HTTP POST for bot actions and SSE for server-to-bot event streaming.\nDetailed Analysis: See HTTP-based Protocols Analysis\nPros:\n✅ Automatic reconnection - SSE handles reconnect with Last-Event-ID resume ✅ Simple model - Standard HTTP requests plus event stream ✅ Excellent OTEL support - HTTP instrumentation is mature ✅ Text-based - Easy debugging with curl and browser DevTools ✅ Browser native - EventSource API built into browsers Cons:\n❌ Unidirectional streaming - Requires separate HTTP POST for bot → server ❌ Asymmetric performance - Different latency for upstream vs downstream ❌ HTTP/1.1 connection limits - Browser constraint (6 per domain) ❌ Text-only - No native binary support (requires base64 encoding) ❌ Less common - Fewer production examples than WebSocket or gRPC ❌ Two separate channels - More complex than single bidirectional stream Suitability:\nClient/Server: ⭐⭐⭐☆☆ (Moderate) - Workable but awkward bidirectional pattern P2P: ⭐⭐☆☆☆ (Marginal) - SSE not designed for P2P scenarios Custom TCP Protocol Description: Application-specific binary protocol over raw TCP sockets with custom message framing.\nDetailed Analysis: See Custom TCP/UDP Protocol Analysis\nPros:\n✅ Maximum control - Full control over wire format and protocol behavior ✅ Minimal overhead - No HTTP headers or protocol baggage Cons:\n❌ Very high implementation cost - 4-6 weeks per language for production-quality code ❌ No performance advantage - TCP latency same as WebSocket/gRPC (both use TCP) ❌ Manual OTEL integration - No automatic instrumentation, requires custom trace context ❌ No tooling - Must build custom debugging and testing tools ❌ Maintenance burden - Protocol bugs, versioning, cross-platform issues ❌ Language fragmentation - Manual implementation in each language, consistency challenges Suitability:\nClient/Server: ⭐☆☆☆☆ (Not Recommended) - Cost far exceeds marginal benefit P2P: ⭐☆☆☆☆ (Not Recommended) - Same TCP limitations as gRPC/WebSocket Verdict: ❌ Rejected - No measurable performance benefit over gRPC/WebSocket while requiring 10-20x more development effort.\nCustom UDP Protocol Description: Connectionless packet-based protocol with custom reliability layer for critical messages.\nDetailed Analysis: See Custom TCP/UDP Protocol Analysis\nPros:\n✅ Lowest latency - 2-10ms potential vs 5-20ms for TCP ✅ No head-of-line blocking - Lost packets don’t block subsequent packets ✅ Suitable for high tick-rate - Games running at 60+ updates/sec benefit Cons:\n❌ Very high complexity - 8-12 weeks per language plus reliability layer ❌ Unclear requirement - Battle Bots tick rate and latency needs undefined ❌ Firewall hostile - Many networks block UDP, requires fallback ❌ NAT traversal complexity - Hole punching, STUN/TURN infrastructure needed for P2P ❌ Extreme OTEL difficulty - No standard trace propagation, manual packet-level instrumentation ❌ Premature optimization - POC should prove \u003c 50ms latency is insufficient before custom UDP Suitability:\nClient/Server: ⭐☆☆☆☆ (Not Recommended for POC) - Defer until profiling proves TCP inadequate P2P: ⭐⭐☆☆☆ (Marginal) - NAT traversal challenges significant Verdict: ❌ Rejected for POC - Re-evaluate only if client/server POC demonstrates that TCP-based protocols cannot meet latency requirements (evidence currently absent).\nMore Information Related ADRs ADR-0002: OpenTelemetry SDK Selection - Establishes OTEL as observability standard ADR-0003: Observability Stack Architecture - Defines Tempo, Mimir, Loki as backends Future ADR: Game Runtime Architecture - Will define tick rate and game loop mechanics Future ADR: Client/Server vs P2P Architecture - Will choose primary architecture mode Related Requirements From User Journey [0001] Proof of Concept - 1v1 Battle:\nLanguage-agnostic bot implementation Containerized bots (Docker/Podman) Observability signals capture Real-time battle visualization Open Questions Tick Rate: What is the target game tick rate? (Informs whether gRPC performance is sufficient) P2P Consensus: How will bots reach consensus in P2P mode? (Future ADR) Browser Bots: Should we support browser-based bots via grpc-web? Rate Limiting: What are the action rate limits per bot? Further Reading gRPC Protocol Analysis - Detailed gRPC evaluation HTTP-based Protocols Analysis - WebSocket and SSE analysis Custom Protocols Analysis - TCP/UDP evaluation gRPC Official Documentation Protocol Buffers Language Guide OpenTelemetry gRPC Instrumentation ","categories":"","description":"Selection of gRPC as the communication protocol for bot-to-server and bot-to-bot interfaces\n","excerpt":"Selection of gRPC as the communication protocol for bot-to-server and …","ref":"/battlebots/pr-preview/pr-153/research_and_development/adrs/0004-bot-battle-server-interface/","tags":"","title":"[0004] Bot to Battle Server Communication Protocol"},{"body":" Context and Problem Statement Battle Bots requires a rigorous mathematical foundation for the spatial environment where battles occur. We need to define the topological and geometric properties of the “BattleBot Universe” that govern all spatial interactions, movement mechanics, collision detection, and distance calculations.\nThis decision defines four fundamental topological properties that characterize the battle space:\nDimensionality: The number of spatial dimensions (2D vs 3D) Vector Space: The mathematical space structure (continuous Euclidean space vs discrete lattice) Coordinate Chart: The coordinate system for position representation (Cartesian vs Polar) Boundary: The manifold topology (unbounded vs bounded space) These properties form the mathematical foundation upon which all spatial mechanics, bot characteristics, equipment systems, and action mechanics are built. The choice of topological structure has cascading implications for implementation complexity, computational efficiency, tactical depth, and accessibility.\nWithout well-defined topological properties, we cannot:\nImplement consistent position and movement mechanics Establish arena boundaries and out-of-bounds handling Provide a predictable spatial framework for bot developers Design algorithms that work with the spatial structure Support visualization and rendering systems Create a coherent foundation for all spatial game mechanics Decision Drivers Mathematical Rigor - Spatial system should have well-defined mathematical properties Implementation Complexity - Simpler topologies reduce development and computational cost Tactical Depth - Spatial structure should enable meaningful strategic positioning Accessibility - Bot developers should have accessible algorithms (pathfinding, movement) Computational Efficiency - Spatial calculations should be performant in real-time Predictability - Physics and movement should be deterministic and understandable Visualization Clarity - Positions must map cleanly to visual representation Engagement Guarantee - Topology should ensure bots cannot avoid combat indefinitely Protocol Integration - Must integrate with gRPC protocol for position updates (ADR-0004) Extensibility - Should support future enhancements (obstacles, terrain, variable arenas) Standard Tooling - Should leverage standard mathematical libraries and algorithms Decision Outcome Property 1: Dimensionality Chosen: Option 1.1 - 2D\nRationale:\nSimplicity First: 2D pathfinding (A*, Dijkstra) and collision detection (2D circle intersection) are well-documented and accessible Lower Barrier to Entry: Bot developers familiar with 2D algorithms from games, robotics simulations, and common CS education Computational Efficiency: 2D physics orders of magnitude less expensive than 3D (O(n²) vs O(n³) for many operations) Visualization Simplicity: Direct 2D rendering without camera controls, 3D projection, or depth perception complexity Sufficient Strategic Depth: 2D space provides adequate complexity for flanking, positioning, range control, and tactical movement Aligns with Other Decisions: Complements bounded rectangular arena and Cartesian coordinates Alternative Considered: Option 1.2 - 3D would add significant complexity to pathfinding (3D A*), collision detection (3D physics), and visualization (3D rendering, camera controls) without proportional gameplay benefit for 1v1 battles. Can be reconsidered for future game modes if aerial combat or vertical positioning becomes strategically important.\nProperty 2: Vector Space Chosen: Option 2.1 - R^n (Continuous Euclidean Space)\nRationale:\nSmooth Continuous Movement: Enables fluid, realistic movement that integrates naturally with real-time gameplay model Infinite Precision: Floating-point coordinates allow sub-unit positioning (no grid snapping artifacts) Standard Physics: Continuous space supports standard physics (velocity, acceleration, friction) using well-established formulas Tactical Positioning Depth: Precise positioning enables fine-grained strategy (optimal range, exact angles) Real-time Protocol Integration: gRPC can stream continuous position updates without discrete grid jumps Extensibility: Supports future terrain effects, obstacles, dynamic boundaries without discretization constraints Alternative Considered: Option 2.2 - n-dimensional Lattice would simplify collision detection (grid occupancy) and eliminate floating-point precision issues, but would sacrifice movement fluidity and create discrete grid-to-grid jump artifacts that feel unnatural in real-time gameplay. Grid-based pathfinding is simpler, but requires discrete approximation that limits tactical positioning depth.\nProperty 3: Coordinate Chart Chosen: Option 3.1 - Cartesian\nRationale:\nUniversal Familiarity: Cartesian (x, y) coordinates are universally taught and understood Algorithmic Simplicity: Distance, angle, and vector calculations use standard formulas Library Support: Every programming language has extensive Cartesian math libraries Rectangular Arena Alignment: Cartesian coordinates naturally align with rectangular boundaries Grid Visualization: Maps directly to pixel grids for rendering (x → screen x, y → screen y) Pathfinding Compatibility: A* and pathfinding algorithms designed for Cartesian grids Alternative Considered: Option 3.2 - Polar (r, θ) coordinates would be more natural for rotational mechanics but require trigonometric conversions for most operations, have less library support, and align poorly with rectangular boundaries. Polar coordinates are better suited for radial-specific mechanics (turrets, circular arenas) which are not part of the current design.\nProperty 4: Boundary Configuration Note: Boundary configuration has been transferred to ADR-0011 (1v1 Battles) where it is treated as a selectable arena property rather than a fixed universal topological property.\nRationale for Transfer: While a default rectangular boundary ([-50, 50] × [-50, 50]) was appropriate for establishing the spatial system’s mathematical foundation, enabling different game modes to use different arena sizes requires decoupling boundary dimensions from universal topology. ADR-0011 provides comprehensive boundary definition and selection mechanism for 1v1 battle instances.\nReference: See ADR-0011: 1v1 Battles for complete boundary specification, alternative boundary options, and battle instance configuration.\nSpatial System Implementation Specification The four topological properties define the following concrete spatial system implementation:\nCoordinate System The battle space uses a 2D Cartesian coordinate system with the following properties:\nDimensionality: Two-dimensional space (x, y coordinates only; no z-axis or vertical elevation) Origin (0, 0): Located at the center of the arena X-axis: Horizontal axis, with positive values extending to the right and negative values to the left Y-axis: Vertical axis, with positive values extending upward and negative values downward Units: Abstract spatial units (not meters, pixels, or other real-world measurements) Precision: Floating-point coordinates allow for sub-unit positioning accuracy This centered origin simplifies calculations for distance, angle, and relative positioning between bots. It also provides symmetry for balanced starting positions in various battle configurations.\nBoundaries Boundary configuration for specific battle types is defined in type-specific ADRs. See ADR-0011: 1v1 Battles for:\nBoundary Dimensions: Arena size and shape configuration (initially 100 x 100 units rectangular) Boundary Selection: How arena boundaries are chosen for specific battles Out-of-Bounds Handling: Movement clamping, wrapping rules, boundary contact, force effects Alternative Boundaries: Future boundary shapes and sizes (circular, hexagonal, dynamic) Principle: The BattleBot Universe defines the universal 2D Euclidean topological space and Cartesian coordinate system. Individual game modes (1v1 battles, team battles, etc.) configure specific bounded regions within this space through arena selection.\nMovement Constraints The following basic movement constraints apply to the battle space:\nContinuous Movement: Bots cannot instantly teleport from one position to another; all movement follows continuous paths through the 2D Euclidean space Boundary Enforcement: Any movement that would place a bot outside the rectangular boundaries is prevented (specific collision mechanics will be defined in a separate ADR) No Coordinate Wrapping: The space does not wrap around (i.e., exiting one side does not place a bot on the opposite side) Deterministic Physics: All spatial calculations use deterministic algorithms to ensure consistent behavior across platforms Consequences Dimensionality Decision (2D) Good, because simplest spatial implementation (2D algorithms, 2D visualization) Good, because lower barrier to entry for bot developers Good, because sufficient strategic depth for positioning and tactics Good, because reduces computational requirements vs 3D Good, because integrates seamlessly with rectangular boundaries and Cartesian coordinates Neutral, because limits future aerial or vertical combat mechanics Bad, because eliminates vertical positioning as strategic dimension Bad, because may feel limiting if users expect 3D movement Vector Space Decision (R^n Continuous) Good, because enables smooth, realistic movement Good, because supports standard continuous physics formulas Good, because infinite precision for tactical positioning Good, because integrates naturally with real-time gRPC protocol Good, because extensible to terrain effects and obstacles Neutral, because requires careful floating-point handling Bad, because floating-point edge cases more complex than integer lattice Bad, because pathfinding requires discretization step Coordinate Chart Decision (Cartesian) Good, because universally familiar coordinate system Good, because extensive library and tooling support Good, because aligns naturally with rectangular boundaries Good, because direct mapping to pixel rendering Good, because standard distance and angle formulas Neutral, because polar coordinates may be more natural for some rotational mechanics Bad, because bot developers must calculate angles for directional actions Overall Integration Good, because all four properties create coherent mathematical foundation Good, because choices are mutually reinforcing (Cartesian + Rectangular, 2D + R^n) Good, because extensible framework supports future enhancements Good, because spatial system implementation follows naturally from topological properties Good, because creates foundation for ADR-0006 (physics), ADR-0007 (movement), ADR-0008 (characteristics), ADR-0009 (equipment), ADR-0010 (actions) Good, because property-based decision structure allows independent tuning and future modifications Good, because balances mathematical rigor with practical accessibility Confirmation The decision will be confirmed through:\nTopological Consistency: Verify mathematical properties are correctly implemented\n2D coordinate representation in all spatial data structures Continuous floating-point position values (no grid snapping) Cartesian coordinate system throughout codebase Metric calculations accurate (distance formulas) Spatial Mechanics Validation:\nContinuous movement paths validated Coordinate calculations accurate and deterministic Coordinate transformations correct Developer Accessibility:\nBot SDK exposes Cartesian (x, y) coordinates Movement API uses familiar vector representations Documentation includes standard formulas (distance, angle) Sample bots demonstrate pathfinding in continuous 2D space Performance Testing:\n2D coordinate calculations meet real-time tick rate requirements Floating-point calculations deterministic across platforms Spatial queries (distance, angle) performant Protocol Integration:\ngRPC messages correctly encode 2D positions Position updates stream smoothly in continuous space Coordinate system correctly transmitted and received Visualization Testing:\n2D Cartesian coordinates map correctly to screen pixels Bot positions and movements display accurately Coordinate system visualization clear Extensibility Validation:\nSystem can support future battle types and game modes Coordinate system independent of specific arena configurations Spatial queries abstracted for future enhancements Boundary Validation: See ADR-0011 for boundary-specific confirmation criteria\nArena boundaries implemented per ADR-0011 Boundary enforcement working correctly for selected arenas Out-of-bounds handling per game mode specification Future Consideration:\nDocument path to 3D extension if needed (would add z coordinate) Evaluate polar coordinates for specific game mechanics (turrets, sensors) Consider extending to support non-Euclidean spaces if needed Pros and Cons of the Options Property 1: Dimensionality Option 1.1: 2D (CHOSEN) Battles occur in two-dimensional space (x, y coordinates).\nGood, because simplest spatial implementation (2D pathfinding, collision detection, physics) Good, because lower computational requirements compared to 3D Good, because easier visualization (direct 2D display, no camera controls needed) Good, because lower barrier to entry for bot developers (2D algorithms more accessible) Good, because well-documented algorithms (A*, 2D vector math, 2D physics) Good, because sufficient strategic depth for positioning and movement tactics Neutral, because appropriate for ground-based combat scenarios Neutral, because may be extended to 3D in future if needed Bad, because eliminates vertical positioning as strategic dimension Bad, because no aerial combat or flying units Bad, because may feel limiting if users expect 3D movement Option 1.2: 3D Battles occur in three-dimensional space (x, y, z coordinates).\nGood, because enables vertical positioning strategy (height advantage) Good, because supports aerial combat and flying units Good, because additional strategic dimension (above/below positioning) Good, because familiar from many modern games Neutral, because enables jump mechanics or flight equipment Neutral, because may be more engaging for some users Bad, because significantly more complex implementation (3D pathfinding, collision, physics) Bad, because much higher computational requirements (3D calculations expensive) Bad, because complex visualization (3D rendering, camera controls, depth perception) Bad, because higher barrier to entry (3D algorithms more complex) Bad, because more difficult to debug and visualize battles Bad, because may be unnecessary complexity for 1v1 ground combat Property 2: Vector Space Option 2.1: R^n - Continuous Euclidean Space (CHOSEN) Positions represented as continuous floating-point coordinates in standard n-dimensional Euclidean space.\nGood, because enables smooth, continuous movement Good, because supports standard continuous physics formulas (velocity, acceleration, friction) Good, because infinite precision for tactical positioning (no grid snapping) Good, because integrates naturally with real-time gRPC protocol Good, because extensible to terrain effects, obstacles, dynamic boundaries Good, because familiar from most modern games and simulations Neutral, because requires careful floating-point handling for determinism Neutral, because pathfinding requires discretization for algorithms like A* Bad, because floating-point precision can introduce edge cases Bad, because collision detection more complex than grid occupancy Bad, because requires careful handling of floating-point comparisons Option 2.2: n-dimensional Lattice of R^n Positions represented as discrete points on an integer lattice (grid).\nGood, because eliminates floating-point precision issues Good, because simpler collision detection (grid cell occupancy) Good, because natural fit for grid-based pathfinding (A*, BFS) Good, because deterministic integer mathematics Good, because easier to reason about and debug Neutral, because grid resolution determines precision (finer grids approach continuous) Bad, because discrete movement creates grid-to-grid jump artifacts Bad, because feels unnatural and less fluid in real-time gameplay Bad, because limits tactical positioning precision (can’t be “between” grid cells) Bad, because requires special handling for diagonal movement distances Bad, because poor integration with real-time streaming protocol (discrete jumps) Property 3: Coordinate Chart Option 3.1: Cartesian (CHOSEN) Positions represented using Cartesian coordinates (x, y).\nGood, because universally familiar coordinate system Good, because algorithmic simplicity (standard distance and angle formulas) Good, because extensive library support in every programming language Good, because aligns naturally with rectangular boundaries Good, because direct mapping to pixel grids for rendering Good, because pathfinding algorithms designed for Cartesian grids Good, because simple boundary checks (x \u003c min, x \u003e max) Neutral, because appropriate for most spatial scenarios Bad, because requires trigonometry for angle calculations Bad, because polar coordinates may be more natural for rotational mechanics Option 3.2: Polar Positions represented using polar coordinates (r, θ) - distance and angle from origin.\nGood, because natural for rotational and radial mechanics Good, because distance from center is explicit (r coordinate) Good, because angle of position is explicit (θ coordinate) Neutral, because appropriate for circular arenas or radial gameplay Neutral, because familiar from mathematics and physics Bad, because requires trigonometric conversions for most operations Bad, because less universal familiarity (more complex than Cartesian) Bad, because limited library support (often converted to Cartesian internally) Bad, because aligns poorly with rectangular boundaries Bad, because distance between two polar points requires conversion Bad, because visualization requires conversion to screen coordinates Option 3.3: Discrete Cartesian (for Lattice) Positions represented using discrete Cartesian coordinates on a lattice (integer x, y).\nGood, because familiar Cartesian coordinate system Good, because simple integer arithmetic Good, because natural for grid-based pathfinding Good, because deterministic (no floating-point issues) Neutral, because only viable option for lattice vector space Bad, because limited to discrete grid positions Bad, because creates grid-to-grid jump artifacts Bad, because not chosen due to vector space decision (R^n continuous chosen) Property 4: Boundary Configuration Note: Boundary options and pros/cons have been moved to ADR-0011: 1v1 Battles where boundary selection is defined as a configurable arena property.\nFor comprehensive evaluation of boundary options (rectangular, circular, hexagonal, dynamic) and their trade-offs, see ADR-0011 Property 2: Boundary.\nMore Information Related Documentation Spatial and Physics Foundation:\nADR-0004: Bot to Battle Server Interface: gRPC protocol for streaming position updates in continuous 2D space\nADR-0006: BattleBot Universe Physics Laws: Physics properties (friction, collisions, gravity) that govern movement mechanics in this spatial system\nADR-0007: Bot Movement Mechanics: Defines how bots apply thrust forces to control their movement within this spatial system\nADR-0008: Bot Characteristics System: Mass and other characteristics that govern movement and combat in this spatial system\nADR-0009: Equipment and Loadout System: Equipment that modifies characteristics and movement capabilities within this spatial framework\nADR-0010: Bot Actions and Resource Management: Movement and combat actions that operate within this spatial system\nBattle Configuration and Arena System:\nADR-0011: 1v1 Battles: Defines Arena concept and configurable battle properties (boundary, biome, visibility, positioning, win conditions) for 1v1 battles. Boundary ownership transferred from ADR-0005 to ADR-0011. Implementation and Testing:\nPOC User Journey: Proof of concept implementation using this spatial foundation Note: This ADR supersedes and integrates the former ADR-0006 (Battle Space Spatial System), which is now deprecated.\nFuture ADRs: The following topics were removed from this ADR and will be addressed in separate architectural decisions:\nCollision Detection and Bot Positioning (bot size, collision mechanics, collision resolution) Friction and Movement Physics (friction coefficients, velocity decay, variable friction zones) Line of Sight (visibility calculations, obstacle blocking) Implementation Notes Mathematical Foundation:\nThe BattleBot Universe is mathematically defined as:\nTopological Space: 2-dimensional Euclidean space R² Metric: Standard Euclidean metric d(p,q) = √((x₂−x₁)² + (y₂−y₁)²) Coordinate Chart: Cartesian coordinates φ: R² → R² where φ(p) = (x, y) Note on Boundaries: Specific bounded regions are defined in game mode ADRs (e.g., ADR-0011 for 1v1 battles). This ADR defines the universal topological space; game modes define specific arenas within that space. Numeric Value Refinement:\nDefault arena size (100×100 units) is marked TBD and will be refined through playtesting. See ADR-0011 for specific arena configuration and tuning details.\nPlaytesting to tune arena size for engagement frequency (per game mode) Visualization testing for rendering clarity Timeout scenario frequency analysis (tuned with game mode timeout values) Equipment balance testing to ensure stat-based equipment choices remain meaningful Key Design Insights:\n2D + R^n continuous + Cartesian create mutually reinforcing topological framework Mathematical rigor provides clear foundation for implementation independent of game modes Simplicity enables focus on core battle mechanics and accessibility Complete spatial framework enables users to implement sophisticated pathfinding and AI solutions Extensibility allows future enhancements (3D, new game modes, new physics properties) without disrupting foundation Separation of universal topology (ADR-0005) from game mode configuration (e.g., ADR-0011) enables flexibility Future Considerations:\nMultiple Game Modes: Different battle types can use different arena configurations (team battles, tournaments, special events) 3D Spatial System: If aerial combat or vertical positioning becomes strategically important, extend to R³ with (x, y, z) coordinates Variable Physics: Different game modes may apply different physics properties (gravity, friction models, collision mechanics) Obstacles and Terrain: Spatial system designed to support static/dynamic obstacles and variable terrain effects Polar Coordinate Option: For specific mechanics (turret rotation, sensor sweeps) polar coordinates could supplement Cartesian system Non-Euclidean Space: Theoretical extensibility to hyperbolic or spherical geometry for future game modes Design Principles The BattleBot Universe topological properties follow these principles:\nMathematical Rigor: Well-defined topological and geometric properties provide clear foundation Simplicity First: 2D continuous Euclidean space with Cartesian coordinates and rectangular boundaries reduce complexity Accessibility: Bot developers have familiar coordinate systems and well-documented algorithms Guaranteed Engagement: Bounded rectangular arena ensures battles conclude with interaction Predictability: Deterministic physics and movement with clear boundary rules Fairness: Symmetric arena and equal access to space for all bots Integration: Spatial framework seamlessly combines with characteristics, equipment, and actions Extensibility: Property-based structure allows future enhancements without disrupting core mechanics ","categories":"","description":"Mathematical and topological foundation defining the spatial structure of the battle space\n","excerpt":"Mathematical and topological foundation defining the spatial structure …","ref":"/battlebots/pr-preview/pr-153/research_and_development/adrs/0005-battlebot-universe-topological-properties/","tags":"","title":"[0005] BattleBot Universe Topological Properties"},{"body":" Context and Problem Statement The BattleBot Universe requires well-defined physics laws to govern gameplay mechanics. ADR-0005 established the mathematical and spatial foundation (2D Euclidean continuous space, rectangular boundaries, Cartesian coordinates), but did not define the physical forces and interactions that govern how objects move, collide, and behave within that space.\nThis decision defines four fundamental physics properties that characterize the physical laws of the battle space:\nMass - Universal entity property defining physical weight Surface Friction - Resistance force opposing bot movement in the 2D plane Air Friction - Resistance force affecting projectile movement through the air Collisions - Mechanics governing bot-to-bot and bot-to-wall interactions These properties form the physics framework upon which all movement mechanics, projectile behavior, collision resolution, and force-based interactions are built. The choice of physics properties has cascading implications for:\nBot movement characteristics and mobility (integration with Mass) Weapon effectiveness and range mechanics (future weapon ADRs) Tactical positioning and collision-based strategies Computational complexity and determinism Developer predictability and accessibility Without well-defined physics laws, we cannot:\nImplement consistent movement mechanics Design weapon systems with predictable projectile behavior Resolve collisions deterministically Create physics-based tactical depth Provide bot developers with predictable physics for strategy implementation Ensure deterministic gameplay across all platforms Decision Drivers Deterministic Gameplay - Physics must be consistent and repeatable across all platforms and battles Spatial Integration - Must work seamlessly with 2D Euclidean continuous space from ADR-0005 Tactical Depth - Physics should enable meaningful strategic positioning and movement decisions Computational Efficiency - Physics calculations must be performant in real-time tick-based gameplay Developer Predictability - Bot developers should be able to predict and calculate physics behavior Simplicity First - Start with simple, constant physics models that can be enhanced in future ADRs Equipment Support - Physics must integrate with equipment system (ADR-0008) that modifies Mass Future Weapons - Must support future weapon mechanics without requiring physics redesign Universal Mass Property - Every entity (bots, projectiles) must have mass Realism vs Gameplay - Balance realistic physics with engaging gameplay mechanics Decision Outcome We define four fundamental physics properties that create a coherent physics framework for the BattleBot Universe. Each property follows the property-based decision structure from ADR-0005, with multiple options evaluated and chosen options with detailed rationale.\nThe chosen physics framework consists of:\nMass - Universal entity property (every bot and projectile has mass) Surface Friction - Variable Friction Air Friction - Constant Uniform Air Resistance Collisions - Elastic Collisions This physics framework integrates with the spatial system (ADR-0005), movement mechanics (ADR-0007), and equipment system (ADR-0008) to create deterministic, tactically deep gameplay with predictable behavior for bot developers.\nProperty 0: Mass Every entity in the BattleBot Universe has mass. This is a fundamental property that affects friction, collisions, projectile behavior, and all force-based interactions.\nMass Specification Bot Mass:\nComposition: Base mass + equipment mass Base Mass: Every bot has an intrinsic starting mass (TBD: placeholder value) Equipment Mass: Equipment from ADR-0008 (weapons, armor, modules) contributes to total mass Total Mass Formula: M_total = M_base + Σ(M_equipment) Dynamic Property: Changes based on equipped items Projectile Mass:\nWeapon-Specific: Each weapon type defines projectile mass (TBD) Impacts Behavior: Mass affects projectile momentum, air friction effects, and collision outcomes Examples: Rifle projectiles lighter than shotgun pellets Mass Impact on Physics Friction: Higher mass experiences greater friction force (F_friction = μ × M × |v|) Collisions: Mass determines momentum transfer in collisions (heavier entities push lighter ones) Movement: Higher mass reduces acceleration from applied forces (A = F / M, defined in ADR-0007) Projectiles: Mass affects air resistance and collision damage Consequences Good, because universal mass property enables consistent physics calculations across all entity types Good, because mass provides tuning parameter for equipment balance (heavier weapons, heavier armor) Good, because mass creates natural mobility-firepower tradeoffs Good, because single mass property simplifies physics implementation Neutral, because mass is not directly allocated by developers (derived from equipment choices) Bad, because equipment mass must be carefully tuned to avoid dominant builds Property 1: Surface Friction Chosen: Option 1.3 - Variable Friction\nOptions Considered Option 1.1: None (frictionless surface) Option 1.2: Constant Uniform Friction Option 1.3: Variable Friction (CHOSEN) Rationale for Chosen Option Terrain-Based Tactical Depth: Variable friction zones create interesting terrain effects (ice zones, mud zones) enabling tactical positioning decisions Strategic Positioning: Players can exploit low-friction areas for speed advantages or avoid high-friction areas, adding positional complexity Future Biome Support: Enables future “biome” mechanics with different terrain types that naturally have different friction characteristics Gameplay Variety: Different arena regions have distinct movement characteristics, encouraging dynamic tactics and positioning Equipment Balance Opportunities: Equipment that modifies friction interaction or gives better traction creates additional build diversity Real-World Intuition: Players intuitively understand that different surfaces have different friction properties Enhanced Strategic Decision-Making: Movement planning becomes more complex as players must navigate variable friction zones Long-Term Extensibility: Provides foundation for future weather effects (mud, ice storms) and hazard-based mechanics Implementation Formula F_friction = μ(position) × M × |v| Where:\nμ(position) = position-dependent surface friction coefficient (varies by arena location/terrain type) M = bot Mass (calculated from base mass + equipment mass) |v| = magnitude of bot velocity vector Implementation Notes Friction coefficient varies based on bot’s current position in arena (terrain-dependent) Arena map defines friction zones with different coefficient values (e.g., μ_ice = 0.2, μ_mud = 1.5) Friction force opposes velocity direction (acts opposite to velocity vector) Friction applies continuously to all moving bots every game tick Stationary bots (v = 0) have no friction force (no static friction model in initial design) Heavier bots (higher Mass from equipment) experience proportionally greater friction force Friction force opposes movement forces (as defined in ADR-0007) to determine net acceleration Transitions between friction zones should be smooth to prevent unrealistic instant changes Alternative Rejected: Option 1.1 - None (Frictionless) Would create perpetual motion where bots never stop unless they hit boundaries, making movement control extremely difficult and unintuitive. Eliminates integration with Mass characteristic.\nAlternative Rejected: Option 1.2 - Constant Uniform Friction While simpler to implement, constant friction eliminates opportunities for terrain-based tactical depth. Variable friction provides more engaging gameplay with positional decision-making while still maintaining consistent physics calculations. The framework supports both approaches through the friction coefficient, so variable friction doesn’t preclude simpler terrain designs in future arenas.\nProperty 2: Air Friction Chosen: Option 2.2 - Constant Uniform Air Resistance\nOptions Considered Option 2.1: None (no air resistance) Option 2.2: Constant Uniform Air Resistance (CHOSEN) Rationale for Chosen Option Projectile Range Limiting: Air friction creates natural maximum range for weapons without arbitrary cutoffs, enabling range-based tactics Tactical Range Decisions: Weapon effectiveness decreases with distance due to velocity decay, creating optimal engagement ranges Velocity-Based Decay: Faster projectiles experience more air resistance (quadratic relationship), balancing high-velocity weapons Computational Efficiency: Constant air resistance coefficient is simple to calculate per projectile per tick Deterministic Behavior: Same air resistance everywhere ensures predictable projectile paths for weapon aiming Future Weapon Support: Air friction applies uniformly to all projectile-based weapons (bullets, rockets, thrown objects) No Arbitrary Cutoffs: Projectiles slow down naturally rather than disappearing at arbitrary range limits Implementation Formula F_air = k × v² Where:\nk = air resistance coefficient (TBD, requires weapon balance testing) v = projectile velocity magnitude Implementation Notes Air friction applies only to projectile objects (bullets, rockets, future thrown weapons) Air friction does NOT apply to bots (bot movement governed by surface friction only) Projectile velocity decreases over time due to air resistance Higher initial velocity = faster deceleration (quadratic relationship) Air friction works in combination with gravity to limit projectile lifetime Alternative Rejected: Option 2.1 - None Would create infinite-range projectiles or require arbitrary hard range cutoffs, eliminating range-based tactical decisions and weapon diversity.\nProperty 3: Collisions Chosen: Option 3.2 - Elastic Collisions\nOptions Considered Option 3.1: Inelastic Collisions (energy absorbed, bots stop or slow significantly) Option 3.2: Elastic Collisions (CHOSEN) Option 3.3: Hybrid (context-dependent collision types) Rationale for Chosen Option Physics-Based Interactions: Elastic collisions create momentum transfer based on Mass, rewarding strategic Mass choices Mass-Based Mechanics: Heavy bots displace light bots in collisions, creating meaningful consequences for equipment loadout Mass Tactical Positioning: Bots can use collisions to push opponents into unfavorable positions (corners, walls) Knockback Mechanics: Elastic collisions enable weapon knockback effects for future weapon systems Deterministic Calculations: Standard elastic collision formulas are well-defined, predictable, and mathematically rigorous Strategic Depth: Bot developers must account for collision physics in pathfinding, positioning, and tactical decisions Standard Physics: Elastic collision model is familiar to developers from physics education and game development Implementation Formulas Bot-to-Bot Collision (1D collision along collision normal):\nv1' = ((m1 - m2) × v1 + 2 × m2 × v2) / (m1 + m2) v2' = ((m2 - m1) × v2 + 2 × m1 × v1) / (m1 + m2) Where:\nm1, m2 = bot masses (base mass + equipment mass) v1, v2 = bot velocities before collision (projected onto collision normal) v1', v2' = bot velocities after collision (along collision normal) Bot-to-Wall Collision (perfect reflection):\nv_reflected = -v_incident (Wall has infinite mass, perfect elastic reflection)\nImplementation Notes Collision Detection: Continuous collision detection to prevent bots tunneling through each other or walls Collision Normal: Collision calculations performed along the line connecting bot centers (1D reduction) Tangent Conservation: Velocity component perpendicular to collision normal is preserved Coefficient of Restitution: e = 1.0 (perfectly elastic) - can be tuned if needed Mass Advantage: Heavy bots (high equipment Mass) push light bots more effectively Boundary Collisions: Bot-to-wall collisions reflect velocity perfectly (no energy loss) Alternative Rejected: Option 3.1 - Inelastic Would cause bots to lose significant velocity on collision, making movement feel sluggish and frustrating. Eliminates Mass-based tactical advantages in collisions.\nAlternative Rejected: Option 3.3 - Hybrid Adds complexity without clear benefit for initial implementation. Can be introduced later for specific mechanics.\nPhysics System Implementation Specification Movement Physics Bot movement is defined in ADR-0007 (Movement Mechanics). The physics laws in this ADR apply to movement:\nApplied movement forces (defined in ADR-0007) oppose surface friction Surface friction (μ × M × |v|) opposes movement, creating velocity decay Heavier bots (higher Mass from equipment) require more force to overcome friction Bots reach terminal velocity when applied force equals friction force Collisions transfer momentum based on Mass (elastic collision model) Integrated Projectile Physics Projectiles launch with initial velocity (weapon-specific) Air friction (k × v²) causes velocity decay over distance Projectiles disappear when velocity reaches zero or when hitting bots/walls Effective range determined by air friction velocity decay Integrated Collision Physics Bot-to-bot collisions use elastic collision formula with momentum conservation Bot-to-wall collisions reflect velocity (wall has infinite mass) Collision detection prevents bots from overlapping or tunneling through walls Mass determines collision outcomes (heavy pushes light) Physics Constants (All TBD) Surface friction coefficient (μ): TBD Air resistance coefficient (k): TBD Coefficient of restitution (e): 1.0 (perfectly elastic, may be tuned) Deterministic Implementation Requirements All physics calculations use deterministic algorithms Floating-point calculations must be consistent across platforms Physics tick rate: TBD (must align with game server tick rate from ADR-0004) Physics update order (per tick): Calculate all forces (movement forces from ADR-0007, friction, air resistance, collision forces) Update velocities based on net forces Update positions based on velocities Resolve collisions and adjust velocities/positions Consequences Overall Integration Good, because four physics properties create coherent and predictable gameplay framework Good, because physics integrates seamlessly with spatial system (ADR-0005), movement mechanics (ADR-0007), and equipment loadout (ADR-0008) Good, because constant friction and air resistance enable deterministic movement and projectile calculations Good, because elastic collisions create tactical depth through Mass-based momentum transfer Good, because air friction alone determines projectile range without need for virtual third dimension Good, because physics framework is extensible for future enhancements (variable friction zones, terrain effects, weather modifiers) Good, because property-based structure allows independent tuning and future modifications Good, because universal mass property simplifies physics implementation Surface Friction (Variable) Good, because creates natural velocity decay and prevents perpetual motion artifacts Good, because integrates with Mass to reward/penalize bot weight choices from equipment Good, because enables force-based movement requiring continuous force application (defined in ADR-0007) Good, because terrain-based friction zones add tactical positioning depth to gameplay Good, because naturally supports future “biome” and weather-based mechanics Good, because players have intuitive understanding of how different surfaces affect movement Neutral, because variable friction zones require arena design and tuning for each map Neutral, because friction lookups per position adds modest computational overhead Bad, because bot developers must account for variable friction in pathfinding algorithms Bad, because slightly more complex to communicate and document physics behavior Air Friction (Constant Uniform) Good, because creates natural weapon range limitations without arbitrary cutoffs Good, because enables tactical range-based gameplay (optimal engagement distances for different weapons) Good, because velocity-based decay (v² relationship) rewards careful aim and positioning Good, because provides weapon balance tuning parameter Good, because computationally efficient (single coefficient calculation per projectile) Neutral, because air resistance coefficient k requires weapon balance testing Bad, because adds projectile physics calculation complexity Collisions (Elastic) Good, because elastic collisions create Mass-based tactical interactions Good, because heavy bots gain collision advantage, rewarding Mass optimization from equipment Good, because enables knockback mechanics for future weapon systems Good, because standard physics formulas are well-documented and deterministic Good, because creates emergent tactical opportunities (pushing opponents into corners/walls) Good, because bot developers can calculate collision outcomes for strategic planning Neutral, because elastic collisions may feel “bouncy” if coefficient of restitution not tuned correctly Neutral, because collision physics adds computational overhead for detection and resolution Bad, because requires careful tuning to prevent exploitative collision-based strategies Confirmation The decision will be confirmed through:\nPhysics Implementation Validation:\nSurface friction correctly reduces bot velocity over time based on Mass Air friction correctly reduces projectile velocity over distance Gravity TTL correctly limits projectile lifetime Elastic collisions correctly transfer momentum based on Mass All physics calculations deterministic across platforms and game ticks Mass System Implementation:\nBot mass correctly calculated as base mass + equipment mass Projectile mass correctly assigned per weapon type Mass is used in all relevant physics calculations (friction, collisions) Integration Testing:\nPhysics integrates correctly with spatial system (ADR-0005) coordinate system and boundaries Movement mechanics (ADR-0007) correctly apply movement forces within physics framework Equipment system (ADR-0008) Mass contributions correctly modify physics behavior Gameplay Validation:\nBot movement feels responsive and controllable with surface friction Projectile behavior feels fair and predictable with air friction and gravity TTL Collision mechanics create interesting tactical decisions without exploits Physics constants (μ, k, g, e) tuned for engaging gameplay through playtesting Performance Testing:\nPhysics calculations meet real-time tick rate requirements (60+ ticks per second target) Collision detection performs efficiently for multiple bots in arena Floating-point calculations consistent across platforms (Linux, Windows, macOS) No physics-based performance bottlenecks in worst-case scenarios Developer Accessibility:\nBot SDK exposes physics constants for bot developer calculations Documentation provides physics formulas for movement and collision prediction Sample bots demonstrate physics-aware movement, aiming, and tactical positioning Physics behavior is predictable enough for bot AI implementation Balance Testing:\nMass-based friction advantages are meaningful but not overwhelming Mass-based collision advantages create tactical depth without dominance Surface friction doesn’t make movement feel sluggish or unresponsive Air resistance doesn’t make weapons ineffective at intended ranges Collision mechanics don’t enable griefing or camping strategies Pros and Cons of the Options Property 0: Mass Universal Entity Property (CHOSEN)\nGood, because every entity having mass creates physically consistent system Good, because mass provides tuning parameter for equipment balance Good, because mass creates natural mobility-firepower tradeoffs Good, because single universal property simplifies implementation Good, because mass integrates with all physics calculations Neutral, because mass is derived from equipment (not directly allocated) Bad, because equipment mass must be carefully tuned Property 1: Surface Friction Option 1.1: None (Frictionless Surface)\nGood, because simplest physics model (no friction calculations) Good, because eliminates friction calculation overhead Good, because maximizes bot responsiveness (instant acceleration/deceleration) Bad, because creates perpetual motion (bots never stop without hitting walls) Bad, because makes movement control extremely difficult (no natural deceleration) Bad, because no integration with Mass characteristic Bad, because unrealistic and unintuitive gameplay feel Bad, because eliminates force-based movement mechanics (no force to overcome) Option 1.2: Constant Uniform Friction\nGood, because simplest friction model (single coefficient everywhere) Good, because predictable movement throughout arena Good, because integrates with Mass for mobility-weight tradeoffs Good, because creates natural velocity decay when movement force not applied Good, because enables force-based movement requiring continuous force application Good, because computationally efficient (single constant coefficient) Good, because deterministic behavior across all battles Good, because intuitive movement feel (objects slow down without force) Neutral, because requires tuning friction coefficient μ for gameplay feel Bad, because eliminates opportunities for terrain-based tactical depth Bad, because adds physics calculation complexity compared to frictionless Option 1.3: Variable Friction (CHOSEN)\nGood, because creates interesting terrain effects (ice zones, mud zones) Good, because adds tactical positioning depth (seek low-friction areas for speed) Good, because enables future “biome” mechanics Good, because naturally supports weather-based effects (storms, mud, ice) Good, because players intuitively understand different surfaces have different friction Good, because provides emergent tactical opportunities through map design Good, because enriches gameplay with positional decision-making Neutral, because provides additional game design opportunities Neutral, because variable friction zones require careful arena design Neutral, because friction lookups add modest computational overhead per tick Bad, because more complex to implement than constant friction Bad, because bot developers must account for variable friction in pathfinding Bad, because requires additional arena design and content creation (friction maps) Bad, because slightly more difficult to visualize and communicate to developers Property 2: Air Friction Option 2.1: None (No Air Resistance)\nGood, because simplest projectile physics model Good, because eliminates air friction calculations per projectile Good, because maximizes weapon range Bad, because requires arbitrary hard range cutoffs for weapons Bad, because no natural projectile velocity decay over distance Bad, because eliminates range-based tactical decisions Bad, because projectiles travel indefinitely or require artificial limits Bad, because no weapon balance tuning parameter for effective range Option 2.2: Constant Uniform Air Resistance (CHOSEN)\nGood, because natural weapon range limitations based on velocity decay Good, because creates optimal engagement distances for tactical gameplay Good, because velocity-based decay (v² relationship) balances high-velocity weapons Good, because applies uniformly to all projectile weapons (consistency) Good, because computationally efficient (single constant coefficient) Good, because deterministic behavior across all battles Good, because provides weapon balance tuning parameter (k coefficient) Good, because eliminates need for virtual third dimension to limit projectile range Neutral, because requires tuning air resistance coefficient k for weapon balance Bad, because adds projectile physics calculation complexity Property 3: Collisions Option 3.1: Inelastic Collisions\nGood, because simpler collision model (bots lose energy and slow down) Good, because prevents bouncy collision feel Good, because may feel more “realistic” for robot collisions Neutral, because could create sticky collision mechanics Bad, because bots lose significant velocity on collision (frustrating movement) Bad, because Mass has limited impact on collision outcomes (both bots slow) Bad, because no momentum transfer or knockback mechanics Bad, because eliminates tactical collision-based positioning strategies Option 3.2: Elastic Collisions (CHOSEN)\nGood, because physics-based momentum transfer Good, because Mass determines collision outcomes (heavy pushes light) Good, because enables knockback mechanics for future weapon systems Good, because creates tactical positioning through collision physics Good, because standard formulas are well-documented and predictable Good, because deterministic calculations for bot AI planning Good, because rewards strategic Mass optimization from equipment loadout Good, because creates emergent tactical opportunities (push opponents into walls) Neutral, because requires tuning coefficient of restitution e for collision feel Neutral, because may feel “bouncy” if not tuned correctly Bad, because adds computational overhead for momentum transfer calculations Bad, because requires careful balancing to prevent collision-based exploits Option 3.3: Hybrid (Context-Dependent Collision Types)\nGood, because flexibility for different collision scenarios (bot vs wall, bot vs bot) Good, because could enable specialty mechanics (equipment that changes collision type) Neutral, because provides additional game design opportunities Bad, because adds significant implementation and calculation complexity Bad, because difficult to predict collision outcomes for bot developers Bad, because requires context detection overhead per collision Bad, because less deterministic behavior (context-dependent outcomes) More Information Related Documentation ADR-0005: BattleBot Universe Topological Properties: Mathematical and spatial foundation (2D Euclidean space, rectangular boundaries, Cartesian coordinates) that physics laws operate within\nADR-0007: Bot Movement Mechanics: Defines how bots apply movement forces within this physics framework (thrust-based force application)\nADR-0008: Equipment and Loadout System: Equipment system that modifies Mass through equipment weight, affecting friction and collision physics\nADR-0009: Bot Actions and Resource Management: Actions that operate within physics framework (movement actions interact with friction, combat actions create projectiles)\nImplementation Notes Physics Integration Design:\nThe physics laws create an integrated framework where:\nSurface friction + Mass + movement forces = movement mechanics\nBots apply movement forces (defined in ADR-0007) to overcome friction Heavier bots (more equipment Mass) require more force to achieve same velocity Creates natural mobility-firepower tradeoffs through equipment loadout choices Air friction + initial projectile velocity = weapon range mechanics\nProjectile velocity decays based on v² relationship Effective weapon range emerges from air resistance coefficient Gravity (simplified TTL) = projectile lifetime mechanics\nProjectile TTL calculated from initial velocity, mass, and gravity constant Works in combination with air friction to limit effective range Elastic collisions + Mass = tactical collision mechanics\nMomentum transfer based on bot masses Heavy bots push light bots, creating tactical advantages for Mass optimization Numeric Value Refinement:\nAll physics constants (μ, k, e) are marked TBD (To Be Determined) and will be refined through:\nMovement feel testing: Tune surface friction coefficient μ for responsive but controlled movement Weapon balance testing: Tune air resistance coefficient k for appropriate weapon effective ranges and projectile lifetime Collision mechanics testing: Tune coefficient of restitution e for satisfying collision feel Mass integration testing: Validate friction-Mass and collision-Mass interactions create meaningful tradeoffs Competitive gameplay: Identify physics exploits or imbalances through player testing Cross-platform testing: Ensure floating-point physics calculations deterministic across platforms Key Design Insights:\nConstant friction and air resistance provide simplicity, predictability, and computational efficiency Air resistance alone determines projectile range without introducing a virtual third dimension Elastic collisions create Mass-based tactical depth and emergent positioning strategies Universal mass property enables consistent physics across all entity types Physics framework integrates seamlessly with spatial system (ADR-0005) and equipment loadout (ADR-0008) Extensible design allows future enhancements (variable friction zones, weather effects, terrain modifiers) without redesigning core physics Future Considerations:\nVariable Friction Zones: Different terrain types with different friction coefficients (biomes, hazards, power-up zones) Weather Effects: Wind affecting air resistance direction/magnitude, rain affecting surface friction Collision Damage: High-velocity collision-based damage for ramming strategies Equipment-Modified Collision Type: Equipment that changes collision behavior (shock absorbers for inelastic, spikes for damage) Momentum-Based Knockback Weapons: Weapons that apply impulse forces for knockback effects Projectile Drag Coefficient Tuning: Per-projectile type air resistance for different weapon characteristics Design Principles The physics laws follow these principles:\nSimplicity First: Constant coefficients over position-dependent complexity for initial implementation Deterministic Behavior: Consistent physics calculations across all platforms and battles Mass Integration: Physics interacts with Mass to create strategic equipment tradeoffs Tactical Depth: Physics enables strategic positioning, range management, and collision-based tactics Extensibility: Framework supports future enhancements without breaking core mechanics Developer Predictability: Bot developers can calculate and predict physics behavior for AI implementation Realism Balanced with Gameplay: Physics feels consistent and intuitive but prioritizes engaging gameplay over simulation accuracy Computational Efficiency: Physics calculations performant in real-time tick-based gameplay model ","categories":"","description":"Physics properties defining movement, projectile behavior, and collision mechanics in the battle space\n","excerpt":"Physics properties defining movement, projectile behavior, and …","ref":"/battlebots/pr-preview/pr-153/research_and_development/adrs/0006-battlebot-universe-physics-laws/","tags":"","title":"[0006] BattleBot Universe Physics Laws"},{"body":" Context and Problem Statement The BattleBot Universe requires a clearly defined movement system that specifies how bots control their movement in the 2D battle space. ADR-0005 established the spatial foundation (2D continuous Euclidean space with rectangular boundaries), and ADR-0006 defined the physics laws that govern movement (surface friction, collisions, Mass property). However, neither ADR has explicitly decided the movement mechanics - specifically, what API do bot developers use to move their bot, and how does the game engine translate those commands into position updates?\nThis decision defines how bots initiate and sustain movement through the battle space. The choice of movement model has cascading implications for:\nBot developer experience (complexity of movement control API) Tactical depth (ability to manage momentum and positioning) Physics consistency (integration with friction and Mass properties) Equipment tradeoffs (how loadout weight affects mobility) Computational requirements (per-tick physics calculations) Determinism (predictability of movement for bot AI) Without a well-defined movement system, we cannot:\nProvide bot developers with a clear API for movement control Ensure consistent integration with friction physics (ADR-0006) Create meaningful equipment-based mobility tradeoffs through Mass Support deterministic trajectory calculation for bot AI Guarantee realistic physics-based gameplay Balance different bot builds (heavy vs light loadouts) Decision Drivers Physics Integration - Movement model must seamlessly integrate with friction (F = μ × M × |v|) and Mass (A = F/M) from ADR-0006 Spatial Integration - Must work with continuous 2D Euclidean space and rectangular boundaries from ADR-0005 Mass-Based Tradeoffs - Equipment weight should meaningfully affect movement capability Tactical Depth - Movement system should enable strategic positioning, momentum management, and skill expression Developer Accessibility - Movement control API should be understandable and implementable by bot developers Determinism - Same movement commands should produce identical results across platforms Computational Efficiency - Per-tick physics calculations must be performant in real-time gameplay (60+ ticks/second target) Realism vs Gameplay - Balance realistic physics with engaging movement mechanics Future-Proofing - Should support future mechanics (knockback, explosions, variable thrust equipment) gRPC Integration - Real-time streaming of position updates (ADR-0004) should work smoothly Decision Outcome Chosen: Option 2 - Thrust Model Bots control their movement by applying thrust force vectors. The game engine calculates acceleration based on thrust and friction, updates velocity, and applies friction opposing movement. Bots must continuously apply thrust to sustain movement; friction causes natural deceleration when thrust stops.\nThis model is chosen because:\nPerfect physics integration: Naturally integrates with surface friction (F = μ × M × |v|) and Mass-based acceleration (A = F/M) Strong equipment tradeoffs: Heavy equipment significantly reduces mobility through increased Mass Tactical depth: Enables momentum management, acceleration/deceleration gameplay, pursuit/kiting dynamics Deterministic physics: Standard force-based physics with well-defined formulas for trajectory prediction Future-proof: Naturally supports knockback weapons, collision momentum transfer, explosive forces Consistent with existing ADRs: ADR-0006 physics laws and ADR-0007→0008 characteristics already assume thrust-based movement Movement System Implementation Specification Thrust Action API Bot Command: apply_thrust(force_x: float, force_y: float)\nAlternative representation: apply_thrust(force_magnitude: float, angle_radians: float)\nParameters:\nforce_x, force_y: Cartesian components of thrust force (in abstract force units) Represents the force magnitude and direction a bot applies each game tick Thrust is omnidirectional (can be applied in any direction within the 2D plane) Thrust Capacity:\nMaximum thrust: Fixed universal constant (TBD value, e.g., 100 force units maximum) All bots have equal maximum thrust capacity (not equipment-dependent in initial design) Rationale: Mass already creates sufficient mobility differentiation through acceleration formula (A = F/M) Future ADRs may introduce equipment-based variable thrust (engines, thrusters) if universal constant becomes limiting Action Frequency: Bots can apply thrust every game tick (continuous control)\nPer-Tick Physics Update The game engine performs the following physics update each game tick to apply thrust-based movement:\n1. Collect Forces:\nF_thrust = thrust force applied by bot command (clamped to maximum capacity) F_friction = surface friction opposing movement (calculated next) F_collision = collision response forces (if colliding with other bots or walls) F_external = knockback, explosions, and other forces (future mechanics) 2. Calculate Friction Force:\nF_friction = μ(position) × M × |v| Where:\nμ(position) = position-dependent surface friction coefficient (varies by terrain/arena zone) M = total bot mass = base mass + sum of equipped item masses |v| = magnitude of velocity vector Direction of friction: opposite to velocity vector (opposes movement) 3. Calculate Net Force:\nF_net = F_thrust - F_friction + F_collision + F_external (Friction opposes thrust; only movement forces contribute to net force)\n4. Calculate Acceleration:\nA = F_net / M Where M is total mass from Step 2.\n5. Update Velocity:\nv_new = v_current + A × dt Where dt is time per game tick (TBD, likely 1/60 second for 60 ticks/second gameplay)\n6. Update Position:\nposition_new = position_current + v_new × dt 7. Boundary Enforcement:\nCheck if new position exceeds arena boundaries ([-50, 50] × [-50, 50]) If boundary violation: clamp position to boundary edge If bot hits wall: reflect velocity component perpendicular to boundary (elastic collision with infinite-mass wall) Hit x-boundary (x = ±50): reflect x-component: v_x → -v_x, keep v_y unchanged Hit y-boundary (y = ±50): reflect y-component: v_y → -v_y, keep v_x unchanged 8. Collision Detection and Resolution:\nDetect bot-to-bot collisions (bots touching or overlapping) Apply elastic collision momentum transfer (formulas from ADR-0006): v1' = ((m1 - m2) × v1 + 2 × m2 × v2) / (m1 + m2) v2' = ((m2 - m1) × v2 + 2 × m1 × v1) / (m1 + m2) Where:\nm1, m2 = bot masses\nv1, v2 = velocities before collision (projected onto collision normal)\nv1', v2' = velocities after collision\nUpdate bot velocities based on collision results\nTerminal Velocity When thrust force balances friction force, bots reach terminal velocity (maximum speed):\nF_thrust = F_friction F_thrust = μ(position) × M × v_terminal v_terminal = F_thrust / (μ(position) × M) Implications:\nHeavier bots (high M from equipment) reach lower terminal velocity for same thrust Light bots (minimal equipment) reach higher terminal velocity Variable friction zones affect terminal velocity: Ice terrain (low μ): higher terminal velocity (less friction resistance) Mud terrain (high μ): lower terminal velocity (more friction resistance) Creates natural mobility-firepower tradeoff: Heavy weapons/armor reduce movement speed Example calculations (TBD values for illustration):\nHeavy bot (M = 50): v_terminal = 100 / (0.5 × 50) = 4 units/tick Light bot (M = 10): v_terminal = 100 / (0.5 × 10) = 20 units/tick On ice (μ = 0.2): v_terminal = 100 / (0.2 × M) = 500/M (higher) On mud (μ = 1.5): v_terminal = 100 / (1.5 × M) = 67/M (lower) Movement Characteristics Integration Mass (from ADR-0008, renumbered from ADR-0007) affects movement:\nForce-to-Velocity Relationship:\nAcceleration = Applied Thrust Force / Mass A = F_thrust / M Implications:\nHeavier bots require more thrust to achieve same acceleration Equipment-derived Mass (weapons, armor) directly affects mobility Light bots with minimal equipment are nimble and responsive Heavy bots sacrifice speed for firepower and protection Creates meaningful equipment loadout decisions (offensive/defensive power vs mobility) Thrust Capacity (not a characteristic; universal constant):\nAll bots share same maximum thrust capacity Mass determines how efficiently thrust translates to acceleration Skill expression: managing thrust within capacity to optimize trajectory Boundary and Collision Handling Boundary Collisions (bots hitting arena walls):\nPosition clamped to [-50, 50] × [-50, 50] Velocity reflected elastically (walls have infinite mass) Bot can apply thrust away from boundary to escape Prevents indefinite evasion (engagement guaranteed) Bot-to-Bot Collisions (momentum transfer):\nHeavy bots push light bots (mass determines collision outcome) Momentum conserved (elastic collision model) Light bots can be pushed into unfavorable positions Heavy bots harder to displace Creates tactical collision-based strategies (ramming, positioning) Continuous Movement Requirement:\nWithout thrust, friction decelerates bot to stop Bots cannot “coast” indefinitely at high velocity Requires active thrust command to sustain movement Creates continuous engagement (bots must keep acting) Consequences Movement Model Advantages Good, because thrust model creates realistic physics-based movement with direct Force → Acceleration → Velocity integration Good, because Mass (A = F/M) creates strong equipment-based mobility tradeoffs Good, because friction (F = μ × M × |v|) creates natural velocity decay without artificial speed caps Good, because terminal velocity emerges naturally from physics (not a hard-coded limit) Good, because momentum management enables tactical depth and skill expression Good, because deterministic force-based physics allows bot developers to predict trajectories Good, because consistent with ADR-0005 continuous Euclidean space and ADR-0006 physics laws Good, because supports future mechanics (knockback forces, explosions, momentum transfer) Good, because elastic collisions with momentum transfer create emergent tactical opportunities Good, because variable friction zones (ice, mud) create positional strategy through terrain effects Thrust Capacity Decision Good, because universal constant simplifies bot design (no thrust capacity stat to allocate) Good, because Mass already provides sufficient mobility differentiation Neutral, because leaves room for future equipment-based variable thrust engines Neutral, because numeric value (max thrust) requires playtesting to balance with Mass Implementation Complexity Neutral, because force-based control requires learning curve (mitigated by documentation and examples) Neutral, because per-tick physics calculations have modest computational overhead Neutral, because numeric values (friction coefficients, base mass, max thrust) need playtesting Bad, because more complex API than simple velocity-setting model Bad, because trajectory prediction requires integration (harder than discrete steps) Bad, because requires continuous thrust application (bots must act every tick to sustain movement) Integration and Consistency Good, because clear separation of concerns: ADR-0006 = physics laws, ADR-0007 = movement mechanics Good, because physics laws apply consistently regardless of movement model Good, because Mass characteristic directly influences movement through acceleration formula Good, because friction creates natural coupling between movement and terrain Confirmation The decision will be confirmed through:\nMovement API Implementation:\nBot SDK exposes apply_thrust(force_x: float, force_y: float) method Thrust parameters validated and clamped to maximum capacity Movement action successfully processes thrust commands each tick Physics Update Validation:\nPer-tick update correctly calculates: forces → acceleration → velocity → position Friction force correctly calculated: F = μ(pos) × M × |v| Friction opposes velocity direction (not arbitrary direction) Acceleration correctly calculated: A = F_net / M Velocity correctly updated: v_new = v_old + A × dt Position correctly updated: pos_new = pos_old + v_new × dt Terminal Velocity Verification:\nTerminal velocity emerges correctly: v = F_thrust / (μ × M) Heavier bots reach lower terminal velocity than light bots Variable friction zones affect terminal velocity appropriately No artificial speed caps needed (physics alone limits speed) Mass Integration:\nEquipment-derived Mass correctly reduces acceleration Heavy equipment loadouts noticeably reduce bot mobility Light loadouts enable nimble, responsive movement Acceleration formula (A = F/M) validated across different Mass values Boundary Handling:\nPosition clamped correctly at arena edges Velocity reflected elastically at boundaries (not lost) Bots can thrust away from boundaries and escape Clamping prevents bots exiting arena Collision Physics:\nBot-to-bot collisions use elastic formula correctly Momentum conserved in collisions Heavy bots push light bots as expected Velocity components updated correctly Collision detection prevents overlapping bots Variable Friction Zones:\nDifferent arena zones have different friction coefficients Friction correctly reduces velocity based on terrain Terminal velocity varies by zone (ice faster, mud slower) Smooth transitions between friction zones Determinism:\nSame movement commands produce identical results Floating-point calculations consistent across platforms No chaotic sensitivity to initial conditions Bots can reliably predict trajectories Developer Accessibility:\nBot SDK documentation explains thrust-based movement clearly Example bots demonstrate movement control (pursuit, kiting, flanking) Trajectory calculation utilities provided Physics formulas exposed for bot AI implementation Performance Testing:\nPhysics update loop executes in \u003c16ms for 60 ticks/second (60+ Hz target) Multiple simultaneous bots move smoothly without lag Collision detection performs efficiently No physics-based performance bottlenecks Gameplay Validation:\nMovement feels responsive and controllable Mass-based mobility differences are noticeable and meaningful Friction creates engaging terrain-based tactical decisions No dominant movement strategy (various approaches viable) Skill expression through thrust management evident Integration with ADRs:\nADR-0006 refactored to remove thrust assumptions, remains physics-agnostic ADR-0008 (renumbered from 0007) updated to reference ADR-0007 for movement mechanics Cross-references in all ADRs accurate and non-circular Pros and Cons of the Options Option 1: Velocity Model Bots set a desired velocity vector (vx, vy). Game moves bot based on velocity each tick. Friction continuously reduces velocity. Bot must repeatedly set velocity to maintain movement.\nHow it works:\nBot command: set_velocity(vx: float, vy: float) Per-tick: Apply friction to velocity, then update position from velocity Friction reduces velocity each tick; bot must reapply velocity to maintain speed Velocity can change instantly (no acceleration phase) Integration with Friction:\nFriction decays velocity: v_new = v_current - (μ × M × |v| × dt) Bot must reapply velocity to overcome friction Natural deceleration when bot stops setting velocity Terminal velocity emerges naturally Integration with Mass:\nMass affects friction magnitude (heavier bots decelerate faster) Mass does NOT affect initial velocity setting (instant velocity change) Problem: Violates realistic physics (instant velocity ignores inertia and Mass) Pros:\nSimple API (just set desired velocity) Direct control over movement direction Easy to calculate trajectories (just vector math) Minimal computational overhead Natural integration with friction (velocity decay) Intuitive for developers (familiar from many games) Cons:\nViolates realistic physics: Instant velocity changes ignore Mass and inertia Poor Mass integration: Mass only affects friction, not acceleration - heavy bots don’t feel “heavy” No acceleration phase: Bots teleport to target velocity (unrealistic) Limited tactical depth: No momentum management or acceleration gameplay Weak equipment tradeoffs: Heavy equipment penalty is just faster deceleration (minimal impact) No momentum mechanics: Collisions would need special handling Inconsistent with ADR-0006: Physics laws assume forces and acceleration Option 2: Thrust Model (CHOSEN) Bots apply thrust force. Game calculates acceleration (A = F/M), updates velocity, applies friction, updates position. Bots must continuously apply thrust to sustain movement.\nHow it works:\nBot command: apply_thrust(force_x: float, force_y: float) Per-tick physics update: Calculate net force: F_net = F_thrust - F_friction Calculate acceleration: A = F_net / M Update velocity: v_new = v_current + A × dt Update position: pos_new = pos_current + v_new × dt Friction opposes thrust force Bots reach terminal velocity when thrust equals friction Natural deceleration when thrust stops Integration with Friction:\nFriction opposes thrust: F_friction = μ(pos) × M × |v| Net force: F_net = F_thrust - F_friction Acceleration emerges from net force: A = F_net / M Terminal velocity: v_term = F_thrust / (μ × M) Variable friction zones affect terminal velocity Integration with Mass:\nExcellent integration: Acceleration directly proportional to thrust and inversely proportional to Mass Heavy bots (high M) accelerate slower from same thrust Light bots (low M) are nimble and responsive Creates strong mobility-firepower tradeoff through equipment Mass Heavier equipment → higher Mass → lower acceleration → harder to move quickly Pros:\nRealistic physics: Force → Acceleration → Velocity → Position (standard physics) Perfect Mass integration: A = F_thrust / M means heavy bots are truly heavier Strong equipment tradeoffs: Heavy weapons/armor significantly reduce mobility Tactical depth: Momentum management, acceleration/deceleration gameplay, pursuit/kiting Consistent with ADR-0006: Physics laws already assume this model Deterministic and calculable: Standard force-based physics with predictable trajectories Supports future mechanics: Naturally supports knockback, collisions, explosions Skill expression: Managing thrust for optimal movement and positioning Terminal velocity emerges: No arbitrary speed caps (physics determines max speed) Elastic collisions work naturally: Momentum transfer based on Mass and velocity Cons:\nComplex API: Bot developers must think in forces, not positions Harder trajectory calculation: Must integrate forces over time (not simple vector math) Requires continuous thrust: Bots must apply thrust every tick to sustain movement (not passive) Computational overhead: Force summation, acceleration calculation each tick Learning curve: Force-based control less intuitive than direct position/velocity control Numeric tuning needed: Max thrust, base mass, friction coefficients require playtesting Option 3: Steps Model Bot requests to move a distance in a direction. Game moves bot that distance in a single tick (or configurable duration). Bot must issue new step command each tick to continue moving.\nHow it works:\nBot command: move_step(distance: float, angle: float) or move_step(dx: float, dy: float) Per-tick: Move bot by specified distance (with friction penalty), check boundaries Discrete movement: Bot either moves the requested distance or is blocked Friction applies as penalty to step distance: actual_distance = requested_distance × friction_modifier(M, terrain) Integration with Friction:\nFriction reduces effective step distance per tick Discrete penalty (not continuous force opposing movement) Different terrains have different distance penalties Awkward mismatch: Friction is continuous force in physics (ADR-0006), but discrete penalty here Uncomfortable dissonance between physics model and movement model Integration with Mass:\nHeavy bots (high M) move less distance per step Step distance formula: d_effective = d_requested × mass_modifier(M) Reasonable mobility reduction, but not physics-based Pros:\nSimple API (bot specifies distance and direction) Intuitive (like moving a game piece on a board) Easy trajectory planning (discrete steps with fixed distances) Bounded per-tick movement (prevents runaway velocity) Deterministic (same step = same result) No floating-point precision issues Minimal computational overhead Cons:\nPoor friction integration: Friction is continuous force (ADR-0006), not discrete penalty Discrete feel in continuous space: Grid-like movement in continuous 2D Euclidean space (mismatch with ADR-0005) No momentum or physics: Steps are teleports within bounds, not physical movement Collision handling awkward: No velocity for momentum transfer (bots have no “speed” in physics sense) Limited tactical depth: No acceleration, deceleration, or momentum management gameplay Inconsistent with ADR-0006: Physics laws assume continuous forces, not discrete penalties Artificial and game-y: Doesn’t feel like physical robots moving with realistic physics Weak Mass integration: Mass penalty is multiplicative factor, not force-based Terminal velocity meaningless: No velocity accumulation (just discrete steps) More Information Related Documentation ADR-0005: BattleBot Universe Topological Properties: Defines 2D continuous Euclidean space, rectangular boundaries, and continuous movement requirement that thrust-based movement operates within\nADR-0006: BattleBot Universe Physics Laws: Defines physics laws (surface friction F = μ × M × |v|, air friction, elastic collisions, Mass property) that thrust-based movement relies on. Friction physics and Mass-based acceleration are core to thrust mechanics\nADR-0008: Bot Characteristics System: Defines Mass characteristic (base + equipment-derived) that affects thrust-to-acceleration conversion. Movement force-to-velocity relationship depends on Mass\nADR-0004: Bot to Battle Server Interface: gRPC protocol for real-time streaming of position updates generated by thrust-based physics\nImplementation Notes Physics Integration Design:\nThe thrust model creates a cohesive physics framework where all systems reinforce each other:\nThrust + Friction + Mass = Movement Mechanics\nBot applies thrust force each tick Friction opposes movement (magnitude depends on velocity and Mass) Net force determines acceleration: A = (F_thrust - F_friction) / M Acceleration updates velocity; velocity updates position Terminal Velocity Emerges\nWhen F_thrust = F_friction, net force = 0, acceleration = 0 Velocity stabilizes at: v = F_thrust / (μ × M) No artificial speed caps needed (physics alone limits speed) Variable Friction Zones Affect Mobility\nIce terrain (μ = 0.2): higher terminal velocity, easier movement Normal terrain (μ = 0.5): medium terminal velocity Mud terrain (μ = 1.5): lower terminal velocity, harder movement Creates tactical positioning decisions (seek ice for speed, use mud for defensive chokepoints) Equipment Mass Directly Affects Mobility\nHeavy weapons increase M, reducing A = F / M Heavy armor increases M, reducing acceleration Heavy equipment creates meaningful mobility penalty Light loadouts sacrifice firepower/protection for mobility Creates strategic equipment loadout decisions Elastic Collisions with Momentum Transfer\nBot-to-bot collisions transfer momentum based on Mass and velocity Heavy bots push light bots (greater momentum) Light bots cannot easily move heavy bots Creates tactical collision-based strategies Momentum conservation ensures physically realistic outcomes Numeric Values (all TBD, require playtesting):\nBase Mass: M_base (placeholder value needed)\nInitial mass of bot without equipment Affects acceleration and friction Every bot starts with same base mass (equipment differentiation added separately) Maximum Thrust Capacity: F_max (placeholder value, e.g., 100 force units)\nUniversal constant; all bots can apply up to F_max force Higher values enable faster acceleration Lower values make movement more constrained Requires tuning for responsive-but-controlled feel Surface Friction Coefficients: μ values by terrain type\nμ_ice ≈ 0.2 (low friction, high terminal velocity) μ_normal ≈ 0.5 (standard friction) μ_mud ≈ 1.5 (high friction, low terminal velocity) Affects how quickly friction opposes thrust Game Tick Duration: dt (placeholder value, likely 1/60 second)\nTime interval between physics updates Affects velocity and position change per tick Tied to game server tick rate (ADR-0004) Equipment Mass Contributions: M_equipment for each item\nDifferent weapons have different mass (light rifle, heavy shotgun) Different armor has different mass (light plating, heavy plating) Modules contribute mass based on complexity Affects total bot mass: M_total = M_base + Σ(M_equipment) Refinement Process:\nThese numeric values will be refined through:\nPhysics Simulation: Model stat interactions and balance implications Playtesting: Test movement feel with different Mass profiles (light vs heavy bots) Balance Analysis: Ensure equipment Mass penalties are meaningful but not punishing Friction Tuning: Adjust friction coefficients for appropriate movement speed ranges Thrust Capacity Tuning: Ensure max thrust creates responsive-but-controlled movement Competitive Testing: Identify dominant strategies and adjust numeric values accordingly Key Design Insights:\nThrust model emerges naturally from ADR-0006 physics laws (friction, Mass, acceleration) Mass creates mobility-firepower tradeoff without needing separate thrust capacity characteristic Terminal velocity formula (F / (μ × M)) provides predictable movement limits Force-based control enables realistic physics while maintaining complete determinism Separation of concerns: ADR-0006 defines laws of physics, ADR-0007 defines how bots move Continuous thrust requirement creates natural engagement (bots must keep acting) Variable friction zones enable terrain-based tactical decisions No arbitrary speed caps (physics alone determines terminal velocity) Future Considerations:\nThrust Capacity as Characteristic: If universal constant feels too limiting, could add thrust capacity as equipment-derived characteristic (engines, thrusters provide thrust) Burst/Boost Mechanic: Short-term burst of extra thrust beyond capacity (with cooldown or energy cost) Directional Thrust Constraints: Some bots might have directional movement constraints (tank-like: forward/backward thrust, separate rotation) Energy Cost for Thrust: Tie thrust to energy resource for additional strategic layer (future ADR) Momentum-Based Knockback: Weapon knockback could be modeled as impulse force (sudden acceleration) Terrain Effects on Traction: Different terrains could affect effective thrust (ice slippery, mud sticky) Rotational Movement: Could add angular velocity and rotation (currently treating as 2D point movement, not rigid body) Design Principles The thrust-based movement system follows these principles:\nPhysics First: Movement follows realistic force-based physics for predictability and depth Mass Integration: Equipment weight directly affects mobility through acceleration formula Continuous Forces: Friction and thrust are continuous, not discrete (consistent with ADR-0006) Deterministic Behavior: Same forces produce identical results (enabling bot AI prediction) Tactical Depth: Movement enables strategic positioning, momentum management, and skill expression Developer Accessibility: Complex physics abstracted into simple thrust API with documentation Extensibility: Framework supports future mechanics (knockback, explosions, variable engines) Separation of Concerns: Physics laws (ADR-0006) vs movement mechanics (ADR-0007) clearly separated Engagement Guarantee: Friction and boundaries combine to prevent indefinite evasion Equipment Tradeoffs: Heavy equipment creates meaningful, physics-based mobility penalties ","categories":"","description":"Defines how bots control their movement in the 2D battle space using thrust-based force application\n","excerpt":"Defines how bots control their movement in the 2D battle space using …","ref":"/battlebots/pr-preview/pr-153/research_and_development/adrs/0007-bot-movement-mechanics/","tags":"","title":"[0007] Bot Movement Mechanics"},{"body":" Context and Problem Statement Battle Bots requires an attribute system that defines bot capabilities and creates strategic differentiation between different bot builds. We need to determine how many stats, what they represent, how they interact, and how they integrate with equipment customization. The characteristic system must support diverse playstyles while remaining accessible and understandable to bot developers.\nWithout a well-defined characteristic system, we cannot:\nDefine bot capabilities and limitations Create meaningful equipment modifications Balance different bot builds and strategies Design combat calculations and damage systems Enable strategic depth through stat optimization Provide clear feedback to bot developers about their bot’s strengths Decision Drivers Strategic Depth - System should create meaningful build choices and optimization paths Equipment Integration - Stats must be modifiable by equipment to enable customization Build Diversity - Multiple viable stat allocations should exist (no single dominant build) Developer Accessibility - Stats should be understandable without being overwhelming Calculation Simplicity - Stat interactions should be calculable and predictable Playstyle Support - Should enable distinct archetypes (tank, DPS, mobile, balanced) Spatial Integration - Must work with continuous 2D Euclidean space (ADR-0005) Decision Outcome The bot characteristics system consists of three core attributes that create strategic depth through meaningful interactions while remaining accessible to bot developers:\nHealth - Bot’s survivability pool; total damage a bot can sustain before destruction Defense - Damage mitigation capability; reduces effective damage from enemy attacks Mass - Equipment-derived weight; calculated from equipped items and impacts effective thrust-to-movement conversion This three-attribute system creates strategic depth through stat interactions (Effective HP, force-based mobility), enables equipment-driven tradeoffs via Mass, balances complexity with accessibility, and provides diverse optimization paths without overwhelming developers. Movement is governed by a force-based system (ADR-0007) where bots apply continuous movement forces to overcome friction (ADR-0006), with Mass affecting how efficiently force translates into acceleration and velocity. The inclusion of equipment-derived Mass creates natural mobility-power tradeoffs that emerge from loadout choices.\nBot Characteristics Specification Health Health (HP) represents a bot’s survivability in combat. This is the primary resource that determines whether a bot remains operational in battle.\nKey Properties:\nHP Pool: Total damage a bot can sustain before destruction (TBD: placeholder 100-500 range) Damage Resistance: Works in conjunction with Defense stat to reduce incoming damage Destruction Threshold: Bot is eliminated when Health reaches 0 No Regeneration: Health does not regenerate during battle (current design) Gameplay Impact:\nHigher Health allows bots to sustain longer engagements Critical for aggressive playstyles that prioritize direct confrontation Must be balanced against offensive capabilities to ensure threat viability Low Health bots must rely on mobility (via movement mechanics ADR-0007) and tactical positioning to survive Defense Defense represents a bot’s ability to mitigate incoming damage. This stat reduces the effective damage from enemy attacks.\nKey Properties:\nDamage Reduction: Percentage or flat reduction applied to incoming damage (TBD: placeholder 1-10) All Damage Types: Applies to all incoming damage sources (current design) Multiplicative with Health: Effective HP = Health × Defense multiplier No Evasion Component: Defense reduces damage taken, not hit chance Gameplay Impact:\nHigh Defense enables tank strategies and prolonged engagements Multiplicatively increases effective Health pool Critical for front-line and damage-absorbing playstyles Low Defense bots must rely on mobility (via movement mechanics ADR-0007) for damage avoidance Defense vs. Health allocation creates build optimization choices Mass Mass represents the total physical weight of a bot, consisting of an intrinsic base mass plus the weight of equipment and components it carries. Unlike other characteristics, Mass is not directly allocated but is determined by the bot’s base mass and loadout choices.\nKey Properties:\nBase Mass: Every bot has an intrinsic starting mass (TBD: placeholder value) Equipment-Derived: Total Mass = Base Mass + sum of all equipped items Dynamic Value: Changes based on equipped weapons, armor, and modules Movement Impact: Higher Mass reduces acceleration from applied movement forces (more force needed to overcome inertia and friction) Momentum Effects: Mass affects collision physics and knockback resistance (TBD) No Direct Damage Scaling: Mass affects mobility, not offensive capability Gameplay Impact:\nHeavy equipment loadouts reduce mobility through increased Mass (requiring more movement force to achieve same velocity) Creates natural tradeoff between firepower/protection and maneuverability Light bots sacrifice durability for superior acceleration and agility Mass cannot be optimized independently - it’s a consequence of equipment choices Forces strategic decisions between powerful equipment and tactical mobility Higher Mass requires sustained force application to overcome friction and maintain velocity (ADR-0007) May affect collision mechanics and position displacement (future mechanics) Equipment Examples (TBD):\nWeapons: Heavy weapons (high Mass) vs. light weapons (low Mass) Armor: Heavy plating (high Mass) vs. light armor (low Mass) Modules: Power cores, sensors, and systems each contribute Mass Loadout variety creates diverse Mass profiles across bot builds Stat Interactions Bot characteristics don’t operate in isolation - they create complex interactions that define combat dynamics:\nEffective Durability: Health and Defense combine to determine true survivability:\nEffective HP Formula: Health × (1 + Defense modifier) High Defense multiplies the value of each Health point Balanced allocation is more efficient than single-stat stacking Example: 100 Health + 50% Defense = 150 Effective HP Mass and Mobility: Mass directly impacts effective movement capability:\nForce-to-Velocity Relationship: Acceleration = Applied Force / Mass (influenced by friction from ADR-0006, movement from ADR-0007) Heavy equipment increases Mass, reducing acceleration from movement forces and requiring more sustained force application to overcome friction Light loadouts maximize agility and responsiveness at the cost of offensive/defensive power Equipment choices fundamentally alter tactical capabilities through Mass-based mobility tradeoffs Combat Positioning: Movement mechanics (ADR-0007) enable tactical positioning and engagement control:\nHigh movement force capacity allows kiting, pursuit, and disengagement Low-Mass bots have positioning advantage through superior acceleration Mass penalties from heavy equipment reduce positioning flexibility and increase movement force requirements Lightweight builds gain tactical mobility at the cost of durability Survivability Tradeoffs: Defensive investment creates complex build choices:\nHigh Health + Low Defense = vulnerable to sustained damage Low Health + High Defense = vulnerable to burst damage Mass from defensive equipment reduces mobility and increases thrust requirements for evasion Optimal defensive strategy depends on threat profile Loadout Optimization: Equipment choices (ADR-0009) create cascading effects across all characteristics:\nHeavy weapons increase offensive capability but increase Mass, reducing acceleration and requiring more movement force Armor improves Defense but adds Mass that limits mobility and increases friction effects Lightweight builds sacrifice protection for superior acceleration and lower movement force requirements No equipment configuration dominates all scenarios (intended design goal) Consequences Good, because three-stat system creates strategic depth without overwhelming developers Good, because stat interactions (Effective HP, force-based mobility) enable emergent complexity from simple rules Good, because equipment-derived Mass creates natural mobility-firepower tradeoffs through movement mechanics Good, because multiple playstyles are viable (tank, DPS, mobile, balanced) through different stat profiles Good, because Defense × Health interaction rewards balanced allocation over single-stat stacking Good, because movement mechanics (ADR-0007) with Mass and friction (ADR-0006) enables tactical gameplay through physics Good, because Mass cannot be optimized independently, forcing meaningful equipment tradeoffs Good, because stats map cleanly to combat calculations and physics-based movement Good, because movement physics create natural skill expression through force management Neutral, because stat values (Health range, Defense values) require extensive playtesting Neutral, because Mass modifier formulas and force-to-acceleration ratios need tuning to balance equipment weight penalties Neutral, because three stats create a minimal but sufficient foundation for strategic depth Bad, because force-based movement adds complexity compared to simple speed-based systems Bad, because stat interactions (especially Effective HP and force-Mass-friction relationships) add complexity to build optimization Bad, because equipment-derived Mass means loadout choices have cascading effects on movement that may confuse new developers Confirmation The decision will be confirmed through:\nImplementation of characteristic system in game server with stat calculation formulas Equipment system implementation (ADR-0008) that modifies stats and contributes Mass Playtesting with diverse bot builds (tank, DPS, balanced, mobile) to validate viability Balance analysis ensuring no single stat profile dominates all scenarios Developer feedback on stat system accessibility and understandability Combat simulation confirming stat interactions create meaningful tactical choices More Information Related Documentation ADR-0005: BattleBot Universe Topological Properties: Mathematical foundation and spatial system with friction mechanics that govern movement physics\nADR-0006: BattleBot Universe Physics Laws: Physics properties (friction, collisions, gravity) that govern movement mechanics and interactions with Mass\nADR-0007: Bot Movement Mechanics: Defines how bots apply movement forces within physics framework; movement force affects acceleration based on Mass (A = F/M)\nADR-0009: Equipment Type System: Defines equipment type categories (Weapons, Armor) that modify stats and contribute to Mass\nADR-0010: Bot Actions and Resource Management: Actions that consume resources and leverage bot characteristics\nBot Characteristics Analysis: Detailed technical specifications for the stat system\nImplementation Notes All numeric values in this ADR are marked TBD (To Be Determined) and serve as placeholder values to establish the framework structure. These values will be refined through:\nCombat simulation to model stat interactions and balance implications Playtesting with diverse bot builds across different stat profiles Equipment balance analysis to ensure Mass penalties are meaningful but not punishing Health and Defense tuning to create appropriate effective HP ranges Force-to-Mass ratio balancing to ensure mobility advantages are significant but not overwhelming Friction coefficient tuning (ADR-0006) to balance movement physics Competitive meta analysis to identify dominant builds and adjust accordingly Key Design Insight: Mass consists of intrinsic base mass plus equipment weight, not directly allocated as a stat. This creates emergent tradeoffs where powerful equipment inherently reduces mobility (through increased movement force requirements and friction effects), forcing strategic loadout decisions without requiring explicit stat allocation. Movement is governed by movement mechanics (ADR-0007) where bots apply force that must overcome both Mass-based inertia and friction forces (ADR-0006).\nFuture Considerations:\nAdditional derived stats (e.g., Effective HP, effective acceleration) may be exposed to developers Attack stat may be added if weapon damage needs per-bot customization Energy stat may become a direct characteristic if resource management complexity increases Evasion or Accuracy stats may be added if hit-chance mechanics are introduced Thrust capacity may become a direct characteristic if force-based movement requires per-bot customization beyond equipment Design Principles The characteristic system follows these principles:\nInteractions over Isolation: Stats combine to create emergent complexity Tradeoffs over Power: Equipment choices involve costs and benefits through Mass Diversity over Dominance: Multiple stat profiles should be competitively viable Clarity over Complexity: Four stats balance depth with accessibility Equipment Integration: Stats are modified by loadout choices (ADR-0009) ","categories":"","description":"Attribute system defining bot capabilities and creating strategic differentiation\n","excerpt":"Attribute system defining bot capabilities and creating strategic …","ref":"/battlebots/pr-preview/pr-153/research_and_development/adrs/0008-bot-characteristics-system/","tags":"","title":"[0008] Bot Characteristics System"},{"body":" Context and Problem Statement The BattleBot equipment system requires a clearly defined set of equipment type categories that bots can equip to customize their capabilities. ADR-0008 (Bot Characteristics System) established that equipment modifies bot stats—particularly Mass, Health, and Defense—and creates the foundation for equipment-based strategic differentiation. However, we have not yet decided which types of equipment will be supported in the initial implementation.\nEquipment types define broad categories of items with similar mechanical purposes. Each type represents a distinct customization axis that creates different strategic choices and playstyles. The choice of which equipment types to support impacts:\nBuild diversity: How many distinct bot archetypes are possible Tactical complexity: The depth of strategic decision-making in loadout selection Implementation scope: Development effort and balancing complexity Future extensibility: Ability to expand equipment options based on gameplay validation Without defined equipment types, we cannot:\nDesign specific equipment items (weapons, armor pieces, utility modules) Create equipment loadout constraints and balancing rules Implement equipment-based stat modifications in the game server Enable strategic build customization for bot developers Support future game modes that depend on specialized equipment (team battles with communication gear, fog of war with sensor equipment) This ADR establishes which equipment type categories are supported for the initial implementation, with explicit acknowledgment that future ADRs may expand the equipment type system as new game mechanics and modes are developed and validated through playtesting.\nDecision Drivers Strategic Depth - Equipment types should create meaningful build choices and optimization paths without overwhelming bot developers Implementation Feasibility - Initial release should focus on core equipment types that deliver maximum gameplay value relative to development effort Stat System Integration - Equipment must integrate cleanly with Health, Defense, and Mass characteristics from ADR-0008 Physics Integration - Equipment Mass must correctly affect movement mechanics (acceleration A = F/M from ADR-0007) and friction (F = μ × M × |v| from ADR-0006) Incremental Complexity - Start simple with fundamental types, expand based on gameplay validation and balance testing Future Game Modes - Consider which equipment types are essential now versus valuable for future features (team battles, fog of war, competitive modes) Balance Testability - Limit initial types to enable thorough balance testing and validation before expansion Developer Experience - Equipment categories should be understandable and implementable by bot developers with clear strategic roles Considered Options Option 1: Weapons - Equipment that enables bots to attack and damage other bots Option 2: Armor - Equipment that increases Defense stat (damage mitigation) at the cost of increased Mass Option 3: Load Bearing Gear - Equipment that increases equipment carrying capacity at significant Mass penalty Option 4: Communication - Equipment for bot-to-bot communication (useful in team battles) Option 5: Sensor - Equipment that detects nearby enemies (useful in fog of war battles) Option 6: Boost - Equipment that temporarily enhances bot characteristics Decision Outcome Chosen options: Weapons and Armor only for the initial implementation.\nThe equipment system will initially support two equipment type categories:\nWeapons - Enable offensive capabilities through damage output modification Armor - Enable defensive capabilities through Defense stat modification Both types modify bot Mass (affecting mobility per ADR-0007 and friction per ADR-0006), creating the fundamental mobility-firepower-protection tradeoff that defines strategic build diversity. This two-type system creates clear strategic depth through force balancing while remaining implementable within project scope.\nRationale:\nCore Combat Loop - Weapons (offense) and Armor (defense) define the fundamental combat interaction between bots; together they form the essential combat mechanics Complete Stat Coverage - Combined with base characteristics (Health, Defense, Mass from ADR-0008), these types create complete strategic build diversity enabling distinct archetypes (tank, DPS, mobile, balanced) Physics Integration Validation - Both types modify Mass, enabling thorough validation of movement mechanics (ADR-0007) where acceleration depends on Mass (A = F/M) and friction depends on Mass (F = μ × M × |v|) Testable Combat Triangle - Creates offensive builds, defensive builds, and balanced builds for comprehensive balance testing without single dominant strategy No System Dependencies - Function independently without requiring additional game mechanics, protocols, or systems Maximum Value per Complexity - Deliver core PvP gameplay experience with minimal implementation scope, enabling focus on balance and polish Pros and Cons of the Options Option 1: Weapons Equipment that enables bots to attack and damage other bots through various weapon types. Weapons modify offensive capability (damage output) and bot Mass.\nExamples: Rifles, shotguns, laser weapons, missile launchers, plasma cannons, melee weapons\nGood, because enables core offensive gameplay and damage dealing mechanics Good, because creates weapon variety opportunities (high damage vs high rate of fire, close range vs long range) Good, because Mass penalties create meaningful mobility tradeoffs (heavy weapons reduce acceleration and terminal velocity) Good, because integrates with future damage calculation system and combat flow Good, because familiar concept from existing games (accessible to bot developers) Good, because enables DPS and burst damage playstyles through different weapon types Good, because supports tactical positioning based on weapon effective ranges Neutral, because requires future ADRs to define specific weapons and damage mechanics Neutral, because requires weapon balance tuning through playtesting Option 2: Armor Equipment that increases Defense stat (damage mitigation) at the cost of increased bot Mass. Armor improves survivability through damage reduction.\nExamples: Light plating, medium armor, heavy plating, reactive armor, ablative armor, shields\nGood, because enables defensive gameplay and tank strategies Good, because creates Defense stat variation beyond base values (builds on ADR-0008) Good, because Mass penalties create protection vs mobility tradeoff Good, because interacts multiplicatively with Health for Effective HP (Effective HP = Health × (1 + Defense modifier) from ADR-0008) Good, because enables distinct tank archetype viable against offensive builds Good, because supports diverse survivability strategies (high Defense, medium Defense, low Defense approaches) Neutral, because requires future ADRs to define specific armor pieces and Defense values Neutral, because requires armor balance tuning and testing with weapons Option 3: Load Bearing Gear Equipment that increases equipment carrying capacity (equipment slots) at significant Mass penalty. Enables bots to equip more items.\nExamples: Backpacks, cargo frames, modular mounts, storage systems\nGood, because enables “heavy weapons platform” builds with multiple weapons or extra capacity Good, because creates emergent strategies for specialized loadouts Good, because expands equipment slot system for future equipment types Neutral, because requires equipment slot system design (not yet established) Neutral, because provides build customization options for advanced players Bad, because adds complexity without immediate gameplay value (weapons and armor needed first) Bad, because requires loadout constraint system beyond initial scope Bad, because creates management complexity for bot developers (slot optimization) Bad, because should be deferred until weapons and armor balance is established Option 4: Communication Equipment for bot-to-bot communication within team battles. Enables bots to share information and coordinate actions.\nExamples: Radio transmitters, encrypted communication systems, signal boosters, relay networks\nGood, because enables team coordination in future team battle modes Good, because adds strategic depth to multiplayer scenarios Good, because creates support role opportunities (communication specialist) Good, because can enable unique team strategies and synergies Neutral, because minimal Mass cost (communication gear is typically light) Bad, because only valuable in team battles (not in initial 1v1 PvP focus) Bad, because requires bot-to-bot communication protocol implementation (complex) Bad, because should be deferred until team battle modes are developed Bad, because adds scope without supporting initial single-player game modes Bad, because requires separate ADR for team battle architecture and team communication protocol Option 5: Sensor Equipment that detects nearby enemies, useful in fog of war battles where bots have limited visibility. Increases detection range and may provide tactical information.\nExamples: Radar systems, lidar, motion sensors, thermal scanners, sonar, detection modules\nGood, because enables information gathering in fog of war scenarios Good, because creates scout and reconnaissance roles Good, because adds strategic depth to asymmetric information scenarios Good, because supports recon builds with high sensor range Neutral, because minimal Mass cost (sensors are typically light) Bad, because only valuable with fog of war game mechanics (not in open-map initial design) Bad, because requires visibility system implementation (line of sight, detection radius, fog of war rendering) Bad, because should be deferred until fog of war game mode is developed Bad, because adds scope without supporting initial visibility model Bad, because requires separate ADR for visibility and fog of war architecture Option 6: Boost Equipment that temporarily enhances bot characteristics for tactical advantage. Provides time-limited stat bonuses or special effects.\nExamples: Repair modules, shield generators, thrust boosters, damage amplifiers, defense boosters, speed enhancers\nGood, because enables tactical burst capabilities and reactive gameplay Good, because adds resource management complexity (cooldowns, charges, activation timing) Good, because creates high-skill plays through optimal activation timing Good, because supports diverse playstyles (burst damage, defensive boost, speed boost) Neutral, because requires temporal effects and state management system Neutral, because adds complexity that may appeal to advanced players Bad, because adds significant implementation complexity (activation mechanics, cooldown system, temporal state) Bad, because requires resource management system (energy/charges/cooldowns) Bad, because should be deferred until core combat loop is validated and balanced Bad, because adds complexity that may overwhelm bot developers before core mechanics are learned Bad, because may require separate ADR for active abilities and temporal effects system Bad, because balance interactions between boost effects and base characteristics need careful analysis Consequences Overall Equipment System Good, because two-type system creates clear strategic depth through offense-defense-mobility triangle Good, because Weapons and Armor integrate perfectly with existing characteristics (Health, Defense, Mass from ADR-0008) Good, because Mass-based tradeoffs create natural balance between firepower, protection, and movement Good, because focused scope enables thorough balance testing and polish before expansion Good, because creates solid foundation for future equipment type additions without overcommitting implementation Good, because bot developers have understandable, clear equipment categories with distinct strategic roles Good, because supports diverse playstyles (tank, DPS, mobile, balanced) through equipment choices Neutral, because limits initial build diversity to combat-focused archetypes (no support/utility roles initially) Bad, because team battle features (Communication equipment) and fog of war (Sensor equipment) must wait for future implementation Bad, because specialized playstyles requiring Boost or Load Bearing Gear must wait for system expansion Weapons Equipment Type Good, because enables core offensive gameplay and weapon variety Good, because creates meaningful weapon differentiation (damage output, rate of fire, range) Good, because Mass penalties create observable mobility tradeoffs Good, because supports tactical positioning and range management gameplay Good, because integrates with future damage calculation and weapon mechanics systems Good, because provides clear offensive archetype for bot builders Neutral, because requires future ADRs to define specific weapon types and mechanics Neutral, because requires extensive balance tuning through playtesting Armor Equipment Type Good, because enables tank strategies and defensive gameplay Good, because creates Defense stat variation beyond base values Good, because Mass penalties create meaningful protection vs mobility tradeoff Good, because interacts multiplicatively with Health for Effective HP optimization Good, because enables distinct defensive archetype viable against offensive builds Good, because supports diverse survivability strategies Good, because provides clear defensive archetype for bot builders Neutral, because requires future ADRs to define specific armor and Defense values Neutral, because requires balance tuning with weapons Deferred Equipment Types Good, because focusing on core types (Weapons, Armor) ensures quality implementation and thorough balance testing Good, because incremental expansion allows learning from initial gameplay before adding complexity Good, because Load Bearing Gear, Communication, Sensor, and Boost remain available for future ADRs Good, because deferred types can be added based on community feedback and gameplay insights Neutral, because team battles and fog of war modes will require equipment expansion before competitive launch Neutral, because future types can be designed with knowledge from weapon/armor balance insights Bad, because limits initial game mode variety (1v1 combat only until expansion) Bad, because team-oriented players must wait for team battle features and Communication equipment Confirmation The decision will be confirmed through:\nEquipment Implementation Validation:\nWeapon equipment items successfully implement damage output mechanics Weapon equipment items correctly contribute to bot Mass Armor equipment items successfully modify Defense stat Armor equipment items correctly contribute to bot Mass Equipment loadout system integrates with bot SDK Mass Integration Testing:\nHeavy weapons increase bot Mass and reduce acceleration (A = F/M verification from ADR-0007) Heavy weapons reduce terminal velocity (v = F/(μ × M) verification from ADR-0006) Heavy armor increases bot Mass and reduces acceleration Heavy armor reduces terminal velocity Light equipment enables high-mobility builds with superior agility Build Diversity Validation:\nOffensive builds (heavy weapons, light armor) are strategically viable Defensive builds (light weapons, heavy armor) are strategically viable Balanced builds (medium weapons, medium armor) are strategically viable No single build dominates all scenarios or creates non-interactive gameplay Physics Integration Confirmation:\nAcceleration formula (A = F/M) correctly applies with equipment-derived Mass Friction formula (F = μ × M × |v|) correctly applies with equipment-derived Mass Terminal velocity varies appropriately with equipment Mass Equipment Mass changes are observable in movement behavior Balance Validation:\nWeapon damage scales appropriately with Mass penalty (heavy weapons balanced) Armor Defense bonus scales appropriately with Mass penalty (heavy armor balanced) Mobility penalties from Mass are significant and observable but not punishing Combat encounters have varied outcomes based on loadout choices No equipment combinations create trivial or unwinnable matchups Developer Experience Testing:\nBot developers understand weapon and armor choices and tradeoffs Equipment selection is intuitive in bot SDK Build optimization is accessible without requiring extensive analysis Documentation clearly explains Mass impact on movement Playtesting Feedback:\nWeapon/armor choices feel meaningful and impactful Equipment tradeoffs between firepower, protection, and mobility are clear Equipment variety creates distinct playstyles No dominant meta build emerges that eliminates alternatives Future Extensibility Validation:\nEquipment type system can accommodate future additions (Load Bearing Gear, Communication, Sensor, Boost) Adding new types does not break existing weapon/armor balance Type system is extensible through ADR without architectural changes required Future equipment items can modify Mass and other stats consistently More Information Related Documentation ADR-0005: BattleBot Universe Topological Properties: Defines 2D Euclidean continuous space and rectangular boundaries where equipped bots battle\nADR-0006: BattleBot Universe Physics Laws: Defines Mass as universal property affecting friction (F = μ × M × |v|) and collision physics; equipment contributes to Mass\nADR-0007: Bot Movement Mechanics: Defines thrust-based movement where acceleration depends on Mass (A = F/M); equipment-derived Mass directly affects acceleration and terminal velocity\nADR-0008: Bot Characteristics System: Defines Health, Defense, and Mass characteristics; establishes equipment-derived Mass formula (M_total = M_base + Σ(M_equipment)) and stat interactions (Effective HP = Health × (1 + Defense modifier))\nFuture Architecture Decision Records This ADR establishes the equipment type framework for initial implementation. Future ADRs will define:\nADR-0010 (or subsequent): Specific Weapon Items - Define individual weapons (rifle, shotgun, laser, etc.) with concrete damage values, projectile mechanics, and Mass contributions ADR-0011 (or subsequent): Specific Armor Items - Define individual armor pieces (light plating, medium armor, heavy plating, etc.) with concrete Defense bonuses and Mass values Future ADR: Load Bearing Gear Equipment Type - Define when equipment slot expansion is needed for advanced multi-item builds Future ADR: Communication Equipment Type - Define bot-to-bot communication protocols and mechanics for team battle modes Future ADR: Sensor Equipment Type - Define fog of war visibility and detection mechanics for visibility-limited game modes Future ADR: Boost Equipment Type - Define active abilities, temporal effects, cooldown system, and burst capability mechanics Implementation Notes Equipment Type Properties Each equipment type has these defining characteristics:\nStat Modifications: Which bot characteristics (Health, Defense, Mass) are affected Mass Contribution: All equipment contributes to bot Mass (varies by type and item) Strategic Purpose: The gameplay role and build archetype enabled Dependencies: Which game systems or modes require this type Weapons Type Specification Primary Function: Enable offensive capabilities through damage output Stat Modifications: Damage output (weapon-specific property, not bot characteristic); Mass contribution Mass Range (TBD): Light weapons 5-10 Mass units, Heavy weapons 20-30 Mass units Damage-Mass Tradeoff: Higher damage weapons have higher Mass, reducing acceleration and terminal velocity Integration Points: Future damage calculation system, combat resolution system Examples (to be defined in future ADRs): Rifle, Shotgun, Laser, Missile Launcher, Plasma Cannon, Melee Weapon Armor Type Specification Primary Function: Enable defensive capabilities through Defense stat modification Stat Modifications: Defense bonus (damage reduction percentage or flat reduction); Mass contribution Mass Range (TBD): Light armor 3-8 Mass units, Heavy armor 15-25 Mass units Defense-Mass Tradeoff: Higher Defense armor has higher Mass, reducing acceleration and terminal velocity Integration Points: Damage calculation system (applies Defense multiplier), stat interaction system Examples (to be defined in future ADRs): Light Plating, Medium Armor, Heavy Plating, Reactive Armor, Ablative Armor Mass Integration with Equipment From ADR-0008: M_total = M_base + Σ(M_equipment)\nFormula expansion with equipment types:\nM_total = M_base + M_weapon + M_armor Movement Impact:\nAcceleration: A = F_thrust / M_total Terminal Velocity: v_terminal = F_thrust / (μ(position) × M_total) Friction Effect: F_friction = μ(position) × M_total × |v| Implications:\nWeapons contribute Mass, reducing acceleration and terminal velocity Armor contributes Mass, reducing acceleration and terminal velocity Heavy loadouts (heavy weapon + heavy armor) dramatically reduce mobility Light loadouts (light weapon + light armor) enable superior acceleration and speed Creates natural mobility-firepower-protection tradeoff emerging from equipment choices Equipment Slot System (Future) Current implementation assumes all bots can equip:\nOne weapon (future Load Bearing Gear may enable multiple weapons) One armor piece (future may enable mixed armor or multiple pieces) This simplifies initial implementation while leaving room for future equipment slot expansion through Load Bearing Gear equipment type.\nIntegration with Bot Characteristics System From ADR-0008, equipment interacts with characteristics as follows:\nHealth Modification:\nSome equipment types may increase Health pool (future Boost equipment) Initial Weapons and Armor do not modify Health Equipment can be designed to increase survivability through Defense instead of Health Defense Modification:\nArmor equipment directly increases Defense stat Enables Effective HP optimization: Effective HP = Health × (1 + Defense modifier) Supports tank playstyle through Defense stacking Mass Modification:\nAll equipment contributes to Mass Creates universal mobility penalty for equipment load Enables balanced gameplay through physics-based tradeoffs Design Principles The equipment type system follows these principles:\nIncremental Expansion: Start with core types (Weapons, Armor) that enable core gameplay, expand based on gameplay validation and community feedback Stat Integration: All equipment types must integrate with the characteristic system (ADR-0008) Mass-Based Tradeoffs: All equipment contributes to Mass, creating universal mobility tradeoff across all types No Dead Types: Only include equipment types that provide immediate gameplay value and create meaningful strategic decisions Future-Proof Architecture: Type system designed to accommodate expansion without breaking existing balance or requiring architectural changes Strategic Clarity: Each type should enable distinct, understandable build archetype (tank, DPS, mobile, balanced) Physics Consistency: All equipment affects movement through Mass impact on physics formulas from ADR-0006 and ADR-0007 Developer Accessibility: Equipment categories should be clear and implementable by bot developers at various skill levels Future Considerations Load Bearing Gear:\nMay be added to enable “weapons platform” builds with multiple weapons or extra equipment Would expand equipment slot system (currently assumed single weapon, single armor) Useful for specialized loadouts and advanced build variety Should be added after weapon and armor balance is established Communication Equipment:\nWill be added when team battle modes are implemented Requires bot-to-bot communication protocol (separate ADR) Enables team coordination and support roles Should be prioritized for competitive/team play support Sensor Equipment:\nWill be added when fog of war visibility mechanics are implemented Requires visibility system and detection radius mechanics (separate ADR) Enables scout and reconnaissance roles Should be prioritized for game mode variety Boost Equipment:\nMay be added after core combat loop is balanced and validated Would require active ability system, temporal effects, cooldowns Enables burst gameplay and reactive tactics Should be subject of separate “Active Abilities” ADR May require resource management system (energy, charges) Mobility Equipment (potential future type):\nThrust enhancers, boosters, or hover systems Would modify movement characteristics without direct damage/defense Could enable mobility-focused builds as alternative to light equipment Requires separate ADR for movement enhancement mechanics Utility Equipment (potential future type):\nNon-combat equipment for specialized purposes Could include repair systems, decoys, or terrain-altering equipment Enables support and control playstyles Requires separate ADR for utility mechanics framework Design Insights Focused Scope: Weapons and Armor provide maximum strategic depth relative to implementation complexity, enabling quality release over feature-packed chaos Physics Foundation: Equipment-derived Mass creates emergent gameplay through physics formulas; no need for explicit mechanics to balance heavy equipment (physics does the work) Stat Integration: Equipment modifies existing characteristics (Health, Defense, Mass) rather than adding new stats, keeping bot developer mental model simple Future Extensibility: Adding new equipment types is straightforward—define stat modifications, Mass contribution, and strategic purpose; physics handles the rest Balance Considerations: All equipment types share universal Mass contribution, creating consistent physics-based balance across types and enabling predictable interaction analysis ","categories":"","description":"Define equipment type categories that enable bot customization through stat modification and tactical capabilities\n","excerpt":"Define equipment type categories that enable bot customization through …","ref":"/battlebots/pr-preview/pr-153/research_and_development/adrs/0009-equipment-type-system/","tags":"","title":"[0009] Equipment Type System"},{"body":" Context and Problem Statement BattleBots requires diverse battle arenas with distinct tactical characteristics to provide meaningful gameplay variety. Currently, the game physics system (ADR-0006) includes variable friction with position-dependent coefficients, explicitly anticipating terrain-based mechanics. To operationalize this capability, we need a consistent framework for defining what makes one arena distinct from another.\nA “Biome” is a meta-definition establishing which properties differentiate battle arenas. This ADR defines WHAT properties define biomes (not specific biomes themselves—those will follow in future ADRs). The framework must integrate seamlessly with existing spatial (ADR-0005) and physics (ADR-0006) systems.\nADR-0005 established the 2D Cartesian coordinate system with rectangular boundaries ([-50, 50] × [-50, 50]). ADR-0006 established variable friction with the formula F_friction = μ(position) × M × |v|, explicitly mentioning biomes as a future mechanic: “Variable friction zones create interesting terrain effects (ice zones, mud zones)” and “enables future ‘biome’ mechanics with different terrain types.” Biomes operationalize this vision by defining how geography provides the μ(position) function.\nWe must choose which properties will define biomes from five candidates: Geography, Climate, Vegetation, Animal Life, and Ecosystem. Future ADRs will define specific concrete biomes (Desert, Arctic, Forest) using the framework established here.\nDecision Drivers Physics System Integration - Biome properties must integrate with the variable friction μ(position) function from ADR-0006 Implementation Complexity - Properties must be implementable within reasonable development scope Gameplay Impact - Properties should create meaningful tactical differences between arenas Visual Clarity - Properties must be easily visualized and understandable to players Determinism - Must work with deterministic physics simulation requirements Extensibility - Framework must allow future property additions without invalidating existing biomes Computational Efficiency - Friction queries must be real-time calculable at game tick rates Developer Predictability - Bot developers must understand and predict terrain effects Spatial Integration - Must work seamlessly with 2D Euclidean space and arena boundaries Arena Balance - Properties must enable balanced competitive gameplay Considered Options Geography (topology and textures mapping to friction) Climate (weather, wind, temperature effects) Vegetation (obstacles, destructible plants, line-of-sight blocking) Animal Life (NPC entities, hazards, environmental challenges) Ecosystem (integrated climate, vegetation, and animal systems) Decision Outcome Chosen option: Geography, because it perfectly integrates with the variable friction system already built into ADR-0006, requires minimal implementation complexity, creates immediate tactical gameplay impact, provides visual clarity, and alone provides sufficient arena differentiation.\nGeography Definition Geography defines battle arena terrain through two complementary sub-properties:\nTopology - The position-dependent friction structure:\nMathematical definition: Position-dependent friction coefficient function μ(position) : R² → R⁺ Implementation: Arena divided into friction zones with distinct coefficient values Zone types: Uniform (single friction across arena), Zoned (distinct regions with different coefficients), Gradient (smooth friction transitions) Data structure: Friction zone maps associating region coordinates with coefficient values Textures - Visual representation communicating friction properties:\nVisual appearance tied to friction zones (ice, mud, sand, grass, rock, dirt, etc.) Texture-friction mapping: Low friction materials (ice → μ = 0.2), medium friction (grass → μ = 0.5), high friction (mud → μ = 1.2) Purely visual representation; friction coefficient is the source of truth Enables intuitive player understanding without memorizing numerical coefficients Rationale for Geography Selection:\nPerfect Physics Integration - Directly maps to μ(position) from ADR-0006; no new physics systems required Minimal Implementation - Purely data-driven; friction maps and texture assets are sufficient Immediate Gameplay Impact - Creates tactical positioning decisions, movement trade-offs, and strategic escape routes Visual Clarity - Terrain is naturally intuitive; players understand friction effects from visual appearance Complete Differentiation - Geography alone creates sufficient arena variety for meaningful gameplay Example Biome Definitions (from future ADRs):\nDesert: Sand regions (μ = 0.6), rocky outcrops (μ = 0.4), gravel paths (μ = 1.0) Arctic: Ice plains (μ = 0.2), snow banks (μ = 0.5), frozen rock (μ = 0.4) Forest: Grass clearings (μ = 0.5), muddy swamps (μ = 1.2), dirt paths (μ = 0.6) Rejected Properties All rejected properties share a core reason: implementation complexity exceeds current project scope. They are deferred to future ADRs after geography-based biomes are validated through gameplay.\nClimate - Rejected (deferred):\nRequirements: Dynamic weather simulation, wind force vectors, temperature state management, temporal tracking, dynamic friction modifiers Complexity: New physics systems (wind effects on movement), bot state expansion (temperature), significant development effort Status: Deferred until geography-based biomes validate biome concept Future ADR: “Add Climate Property to Biome Framework” Vegetation - Rejected (deferred):\nRequirements: Obstacle collision system, pathfinding around obstacles, destructible entity system, line-of-sight mechanics Complexity: Collision system expansion, visual rendering complexity, AI pathfinding integration Status: Deferred; static obstacles must prove tactically valuable through playtesting Future ADR: “Add Vegetation Obstacles to Biome Framework” Animal Life - Rejected (deferred indefinitely):\nRequirements: NPC entity system with AI, animal movement, collision detection, damage system expansion, visual rendering Complexity: Extremely high implementation cost; minimal tactical impact on bot-versus-bot combat Status: Deferred indefinitely unless specific game mode (e.g., “Survival Mode”) explicitly requires environmental hazards Unlikely path: Niche use case with separate development prioritization Ecosystem - Rejected (deferred indefinitely):\nRequirements: Climate + Vegetation + Animal Life as dependencies, dynamic interaction rules between systems Complexity: Exponential implementation cost; no clear mapping to arena combat mechanics Status: Deferred indefinitely; more appropriate for environmental simulation than arena combat games Design fit: Better suited for open-world or survival games than competitive PvP Design Principle: “Start with the simplest property that creates meaningful biome differentiation, validate through gameplay, then consider expansion.”\nConsequences Overall Geography Decision:\nGood, because it perfectly aligns with the variable friction system ADR-0006 already implements Good, because data-driven approach minimizes implementation complexity Good, because friction-based mechanics create clear tactical gameplay (positioning, escape routes, speed zones) Good, because visual textures provide intuitive player understanding Neutral, because friction coefficients require careful tuning per biome for balance Bad, because initial biomes are limited to terrain-based tactics (defers advanced environmental mechanics) Rejected Properties:\nGood, because reduced scope enables high-quality Geography implementation Good, because clear extensibility path allows future property additions without breaking existing biomes Bad, because defers dynamic environmental mechanics (weather, obstacles, hazards) Bad, because limits initial biome variety to terrain-only differentiation Bad, because some properties (climate, vegetation) offer rich gameplay potential (deferred, not eliminated) Confirmation Validation approach for ADR-0010 and subsequent biome implementations:\nGeography Framework Implementation - Friction coefficient maps query correctly based on bot position Integration Testing - ADR-0005 coordinates and ADR-0006 friction formula integrate seamlessly Concrete Biome ADRs - Future biome definitions successfully instantiate framework (Desert, Arctic, Forest) Playtesting - Confirms tactical differentiation between biomes; friction effects create meaningful positioning decisions Performance Validation - Real-time friction queries meet tick rate requirements (verify O(1) or O(log n) lookup) Developer Experience - Bot developers can predict and understand terrain effects on movement Pros and Cons of the Options Geography (Chosen) Primary mechanism: Position-dependent friction coefficients providing terrain differentiation.\nGood, because direct integration with ADR-0006 variable friction formula F_friction = μ(position) × M × |v| Good, because minimal complexity—purely data-driven friction maps and texture assets Good, because creates immediate tactical gameplay: positioning matters, escape routes vary, movement trade-offs Good, because visual clarity enables intuitive player understanding Good, because sufficient arena differentiation (Desert vs. Arctic vs. Forest feel distinctly different) Good, because completely non-breaking for future property additions Neutral, because friction coefficient tuning requires careful balance per biome Bad, because arena topology mapping requires design effort per biome Bad, because limited to terrain-based tactics initially (defers weather, obstacles, hazards) Climate Primary mechanism: Dynamic weather affecting movement, visibility, and damage.\nGood, because weather variety creates dynamic, changing tactical environments Good, because intuitive to players (ice is slippery, wind affects trajectory) Good, because rich gameplay potential (weather systems, temporal effects) Bad, because requires temporal state system (time progression, weather changes over match duration) Bad, because requires new physics: wind force vectors affecting movement trajectory Bad, because requires bot state expansion: temperature tracking, heat/cold effects Bad, because dynamic friction modifiers complicate ADR-0006 physics (time-dependent μ) Bad, because significant development effort for uncertain gameplay value Rejected: Implementation complexity too high for initial release Vegetation Primary mechanism: Static and destructible obstacles providing cover and tactical positioning.\nGood, because tactical obstacles create cover-based positioning strategies Good, because line-of-sight blocking enables stealth and ambush tactics Good, because destructible obstacles add dynamic environmental interaction Bad, because requires obstacle collision detection system (new physics component) Bad, because requires pathfinding enhancements for bot AI Bad, because requires destructible entity system and damage integration Bad, because visual complexity in rendering (obstacle placement, destruction states) Bad, because significant development effort before gameplay validation Rejected: Implementation complexity too high for initial release Animal Life Primary mechanism: NPC entities with AI providing hazards and environmental challenges.\nGood, because environmental hazards create immersive atmosphere Good, because NPC behavior adds unpredictability and engagement Neutral, because tactical impact on bot-versus-bot combat is marginal Bad, because requires NPC entity system with independent AI Bad, because requires animal movement, collision, and rendering Bad, because requires damage system expansion (animals attack bots) Bad, because extremely high implementation cost relative to gameplay impact Bad, because uncertain gameplay value in competitive PvP setting Rejected: Marginal tactical impact does not justify complexity cost Ecosystem Primary mechanism: Integrated systems where climate, vegetation, and animals interact dynamically.\nGood, because emergent environmental interactions create rich simulations Good, because integrated systems feel cohesive (weather affects vegetation, animals react to weather) Bad, because requires Climate + Vegetation + Animal Life as implementation prerequisites Bad, because exponential complexity with interdependent systems Bad, because no clear mapping to arena combat mechanics (design is for simulation, not competition) Bad, because prohibitive implementation cost Rejected: More suitable for open-world simulation games than competitive PvP More Information Related Documentation ADR-0005: BattleBot Universe Topological Properties - Defines 2D Cartesian coordinate system with [-50, 50]² boundaries ADR-0006: BattleBot Universe Physics Laws - Defines variable friction with μ(position) function and explicitly anticipates biomes ADR-0007: Bot Movement Mechanics - Demonstrates gameplay impact of friction through terminal velocity formula Future Concrete Biome ADRs ADR-00XX: Desert Biome - First concrete biome implementation with friction topology and texture definition ADR-00YY: Arctic Biome - Second biome demonstrating framework reusability ADR-00ZZ: Forest Biome - Third biome validating biome differentiation Future Deferred Properties Climate Property (Deferred)\nImplementation prerequisites: Temporal state system, visual weather effects, dynamic friction modifiers, bot temperature state Validation gate: Geography-only biomes must prove successful through playtesting Potential ADR: “Add Climate Property to Biome Framework” (depends on gameplay feedback) Vegetation Property (Deferred)\nImplementation prerequisites: Obstacle collision system, pathfinding enhancement, line-of-sight system, destructible entities Validation gate: Static obstacles must prove tactically valuable; requires prior work on collision systems Potential ADR: “Add Vegetation Obstacles to Biome Framework” (depends on terrain tactics validation) Animal Life Property (Deferred Indefinitely)\nImplementation prerequisites: NPC entity system, AI framework, entity collision/damage expansion Unlikely activation: Only if specific game mode (e.g., “Survival Mode”) explicitly requires environmental hazards Non-standard track: Would require separate design, playtesting, and development prioritization Ecosystem Property (Deferred Indefinitely)\nImplementation prerequisites: All three deferred properties implemented first, complex interaction rules Design fit: More appropriate for open-world or survival simulation games than competitive PvP Architectural note: Would require fundamental redesign of arena mechanics away from pure bot-versus-bot focus Extensibility Design Non-breaking addition of properties through future ADRs:\nExisting biomes remain valid with Geography-only definitions New biomes created after property additions can leverage additional properties Property additions require new ADRs and validation before adoption Each biome ADR explicitly documents which properties it uses Design Principles Simplicity First - Start with Geography, validate through gameplay, then expand properties Leverage Existing Systems - Use ADR-0006 variable friction; don’t invent new physics Minimize Initial Complexity - Defer properties until proven necessary by gameplay Validate Before Expanding - Demonstrate need through competitive playtesting before adding properties ","categories":"","description":"Meta-definition establishing which properties define biomes for battle arenas\n","excerpt":"Meta-definition establishing which properties define biomes for battle …","ref":"/battlebots/pr-preview/pr-153/research_and_development/adrs/0010-biome-definition-framework/","tags":"","title":"[0010] Biome Definition Framework"},{"body":"User Journeys This section contains detailed user journey documentation that defines how users interact with the Battlebots platform. Each journey document includes:\nUser personas and their goals Step-by-step flow diagrams Technical requirements (access control, analytics, etc.) Success metrics These documents serve as the foundation for feature development and help ensure a consistent, user-centered experience.\n","categories":"","description":"Documentation of user flows and experiences for the Battlebots platform\n","excerpt":"Documentation of user flows and experiences for the Battlebots …","ref":"/battlebots/pr-preview/pr-153/research_and_development/user-journeys/","tags":"","title":"User Journeys"},{"body":"In 1v1 battles, two bots face off in direct combat within a Battle Arena. The arena is a configured instance of the BattleBot Universe with five key properties:\nBiome - Terrain friction topology (selectable, future feature) Boundary - Arena dimensions (default: 100×100 rectangular, selectable in future) Visibility - Information available to bots (currently: full visibility) Start Positioning - Initial bot placement (random with 20-unit minimum separation) Win Conditions - Battle conclusion rules (disconnect, elimination, or timeout) Victory goes to the bot that satisfies any win condition first, checked in priority order.\nWhat You’ll Find Here This section contains complete mechanics documentation for 1v1 battles:\nGetting Started - Quick start guide with a minimal bot example Arena - The 2D battle space, coordinates, boundaries, collision, and physics Bot Characteristics - Health, Defense, and Mass stats that define your bot Equipment - Weapons and armor that customize your bot’s capabilities Actions - All available actions, energy costs, and cooldowns Key Concepts Real-Time Gameplay 1v1 battles operate in real-time with a continuous tick-based game loop. Your bot receives state updates each tick and can submit actions to perform.\nWin Conditions A battle concludes when any of the following conditions is met (checked in priority order):\nDisconnect (Highest Priority): Opponent disconnects and fails to reconnect within 30-second grace period (TBD) - prevents hung battles from technical failures Elimination (Primary): Your bot defeats opponent by reducing their Health to 0 - immediate decisive victory Timeout (Fallback): Battle reaches 5-minute time limit (TBD) - higher Health wins, or last bot to deal damage wins if Health is equal Priority ensures technical failures don’t hang battles, decisive victories end immediately, and all battles conclude within maximum duration.\nSee ADR-0011: 1v1 Battles for complete technical specification of arena properties and win conditions.\nBot Customization Before battle, you configure your bot’s equipment loadout (1 weapon + 1 armor). During battle, your bot performs actions that consume energy and have cooldown periods.\nProgramming Challenge This documentation explains the mechanics and rules. Developing effective bot logic, decision-making algorithms, and winning strategies is your challenge as a programmer!\nGet Started New to 1v1 battles? Start with the Getting Started guide to create your first bot, then explore the mechanics pages to understand the full system.\n","categories":"","description":"Complete mechanics guide for 1v1 battles - arena, bot characteristics, equipment, and actions\n","excerpt":"Complete mechanics guide for 1v1 battles - arena, bot characteristics, …","ref":"/battlebots/pr-preview/pr-153/gameplay/1v1-battles/","tags":"","title":"1v1 Battles"},{"body":"This guide will help you create your first bot for 1v1 battles. We’ll cover the basics of bot structure, equipment configuration, and connecting to the battle server.\nPrerequisites Programming experience in any language Battle Bots SDK installed for your chosen language Development environment set up Bot Structure A Battle Bots bot consists of:\nEquipment Configuration - Choose your weapon and armor before battle State Processing - Receive and process battle state updates each tick Action Submission - Decide which actions to perform based on current state Communication - Connect to the battle server via gRPC Minimal Bot Example Here’s a minimal bot structure to get you started:\nStep 1: Configure Equipment Before battle, configure your bot’s loadout with 1 weapon and 1 armor:\n# Example: Simple balanced loadout loadout = { \"weapon\": \"Rifle\", # Baseline precision weapon \"armor\": \"Light Armor\" # Minimal defense, maintains mobility } See the Equipment page for all available weapons and armor options.\nStep 2: Connect to Battle Server Your bot connects to the battle server using the SDK:\nfrom battlebots_sdk import BattleBot bot = BattleBot(loadout=loadout) bot.connect() Step 3: Process State Updates Each tick, your bot receives a state update with:\nYour bot’s position, health, energy Opponent bot’s position (if visible) Arena boundaries Available actions def process_state(state): my_position = state.my_bot.position # (x, y) coordinates my_health = state.my_bot.health my_energy = state.my_bot.energy opponent = state.opponent_bot # May be None if out of sight if opponent: opponent_position = opponent.position opponent_health = opponent.health return decide_action(state) Step 4: Submit Actions Based on the state, your bot decides which action to perform:\ndef decide_action(state): # Example: Simple logic if state.opponent_bot: # Opponent visible - check if in range distance = calculate_distance(state.my_bot.position, state.opponent_bot.position) if distance \u003c RIFLE_RANGE and state.my_bot.energy \u003e= 15: return Action.RifleShot(target=state.opponent_bot.position) # Move toward center if opponent not visible return Action.Move(target=(0, 0)) Step 5: Run Your Bot # Main bot loop while bot.is_battle_active(): state = bot.get_current_state() action = process_state(state) bot.submit_action(action) Next Steps Now that you have a basic bot structure, learn about the game mechanics:\nArena - Understand the battle space, coordinates, and collision rules Bot Characteristics - Learn about Health, Defense, and Mass stats Equipment - Explore different weapons and armor options Actions - Discover all available actions, their costs, and constraints Important Notes SDK Abstracts Complexity: Your SDK handles gRPC communication, coordinate calculations, and state management Tick-Based: Battles run in real-time ticks; your bot should process state and respond quickly Energy Management: Monitor your energy pool; actions cost energy to perform Cooldowns: Some actions have cooldown periods before they can be used again Start simple, test your bot in battles, and iterate on your approach. The mechanics documentation will help you understand the full system, but figuring out effective bot logic is your challenge!\n","categories":"","description":"Quick start guide for creating your first 1v1 battle bot\n","excerpt":"Quick start guide for creating your first 1v1 battle bot\n","ref":"/battlebots/pr-preview/pr-153/gameplay/1v1-battles/getting-started/","tags":"","title":"Getting Started"},{"body":" Context and Problem Statement BattleBot 1v1 battles require a formal definition of what constitutes an arena and how battle instances are configured. Currently, the BattleBot Universe (ADR-0005) defines the universal topological space (R² Euclidean coordinates with Cartesian system) and fixed boundary dimensions ([-50, 50] × [-50, 50]). However, this establishes a single static arena rather than a configurable system that enables tactical variety through property selection.\nThis ADR introduces the Arena concept as the bridge between the universal BattleBot Universe and concrete 1v1 battle instances.\nArena Definition An Arena is a configured instance of the BattleBot Universe, defined by a combination of selectable and fixed properties:\nArena = Bounded Region (from ADR-0005) + Biome (from ADR-0010) + Battle Configuration The arena concept enables:\nMultiple different battle configurations using the same underlying spatial and physics systems Pre-battle tactical selection through property choices Gameplay variety without changing universal topology or physics laws Clear separation: ADR-0005 defines universal spatial foundation; ADR-0011 defines how battle instances use that foundation Boundary Extraction and Architectural Shift ADR-0005 “BattleBot Universe Topological Properties” defined boundary as Property 4 with specific dimensions:\nRectangular boundary: [-50, 50] × [-50, 50] (100×100 units) Mathematical definition: Closed manifold M = {(x,y) ∈ R² : -50 ≤ x ≤ 50, -50 ≤ y ≤ 50} Boundary: ∂M = {(x,y) : x=±50 or y=±50} This universal boundary definition was appropriate for establishing the spatial system’s mathematical foundation. However, hardcoding a single boundary dimension:\nPrevents arena variety - All battles use identical dimensions Couples topology to game mode - Changing boundaries requires changing universal topology Limits future game modes - Different game modes need different arena sizes Reduces pre-battle strategy - Removes player choice in arena configuration Architectural Solution: Transfer boundary ownership from ADR-0005 (universal topology) to ADR-0011 (battle instance configuration).\nStays in ADR-0005: R² Euclidean topological space, Cartesian coordinate system, spatial properties Moves to ADR-0011: Boundary dimensions, shapes, and selection mechanism Benefit: Enables selectable boundaries while preserving topological rigor Problem Statement We must formalize the 1v1 battle type by defining five core properties:\nBiome Selection - How is arena geography determined? Boundary Configuration - How are arena dimensions determined? Visibility System - What information do bots receive? Start Positioning - Where do bots begin the battle? Win Conditions - What determines battle outcome? Each property has multiple options with distinct gameplay and implementation implications. This ADR evaluates options for each property and establishes the foundation for 1v1 battles as the game’s initial battle type.\nRelationship to Other ADRs ADR-0005 (BattleBot Universe Topological Properties): Defines universal R² space, Cartesian coordinates, spatial metrics. ADR-0011 applies this space to concrete battle instances. ADR-0006 (BattleBot Universe Physics Laws): Defines variable friction F_friction = μ(position) × M × |v|. ADR-0011 applies physics laws within configured arenas. ADR-0010 (Biome Definition Framework): Establishes Geography as the biome property, where μ(position) comes from terrain. ADR-0011 enables biome selection for arenas. ADR-0004 (Bot to Battle Server Interface): gRPC protocol for state exchange. ADR-0011 defines configuration transmitted via this protocol. Decision Drivers Biome Integration - Arena properties must enable ADR-0010 biome framework to create tactical variety through geography Boundary Flexibility - Different battle contexts should support different arena sizes without changing universal topology Gameplay Variety - Property-based configuration should enable diverse tactical environments and strategic choices Implementation Feasibility - Initial properties should be implementable in MVP, with complexity deferred to future ADRs Extensibility - Five-property framework should accommodate future additions (dynamic boundaries, new visibility modes) without breaking existing system Balanced Gameplay - Arena properties must create fair, competitive experiences that reward skill and adaptability Player Agency - Pre-battle property selection should provide meaningful strategic choices that affect gameplay Determinism - Battle outcomes must be reproducible given identical arena configuration and initial random seed Physics Integration - Arena configuration must work seamlessly with variable friction from ADR-0006 and movement mechanics from ADR-0007 Spatial Consistency - Arena must respect 2D Euclidean space and Cartesian coordinates from ADR-0005 Topology Independence - Selecting arena properties should not require changing universal spatial system properties Engagement Guarantee - Arena configuration should ensure meaningful interaction and prevent indefinite evasion Considered Options This ADR evaluates five distinct battle properties:\nProperty 1: Biome Selection - How is terrain/friction determined for the arena? Property 2: Boundary Configuration - What are the arena’s shape and dimensions? Property 3: Visibility System - What information do bots receive about opponents? Property 4: Start Positioning - Where are bots placed when battle begins? Property 5: Win Conditions - What determines how battle concludes and who wins? Each property has multiple options with distinct advantages and limitations. The outcome section details chosen options and integration rationale.\nDecision Outcome Chosen Arena Configuration Biome: Selectable (user chooses from available options) Boundary: Selectable (user chooses from available configurations) Visibility: Full (all bots see complete information) Start Positioning: Random (bots placed randomly within arena) Win Conditions: Health Depletion + Timeout + Disconnect This five-property framework creates the Arena as a configured instance of the BattleBot Universe. Different property selections produce different arenas with distinct tactical characteristics.\nArena Concept: Mathematical Foundation An Arena (A) is formally defined as:\nA = (M, B, μ(·), Σ, V, C)\nWhere:\nM = Arena manifold (boundary configuration) - a bounded region of R² B = Boundary ∂M - the frontier of the arena region μ(·) = Position-dependent friction coefficient function (from selected biome) Σ = Starting positions (initial bot placements) V = Visibility configuration (information available to bots) C = Win conditions (rules determining battle conclusion) Key Properties:\nInherits 2D Cartesian coordinate system (x, y) from ADR-0005 Inherits physics laws and movement mechanics from ADR-0006, ADR-0007 Respects variable friction through μ(position) provided by biome selection Enables deterministic reproducibility through seeded randomness Instance Example:\nArena_Desert_100x100_Full_Random = ( M = {(x,y) ∈ R² : -50 ≤ x ≤ 50, -50 ≤ y ≤ 50}, // Rectangular, 100×100 units B = {(x,y) : x=±50 or y=±50}, // Rectangular boundary μ(·) = Desert_Biome_Friction_Map, // Desert friction topology Σ = RandomPlacement(arena=A, seed=s, separation=20), // Random start positions V = FullVisibility, // All bots see everything C = [HealthDepletion, Timeout(300s), Disconnect(30s)] // Multi-path win conditions ) Property 1: Biome Chosen Option: Option 1.2 - Selectable\nDefinition User selects a biome from available options before battle initialization. The selected biome determines the arena’s geography property, including:\nFriction coefficient map μ(position): Arena → R⁺ Visual texture representation Tactical positioning differences Biome Integration Biomes operate per ADR-0010 “Biome Definition Framework”:\nGeography Property: Biomes define arena topology through position-dependent friction Friction Function: Each biome specifies μ(position) values across arena regions Tactical Differentiation: Different friction topologies create distinct movement characteristics: Low friction zones (ice): Increased speed, reduced maneuverability High friction zones (mud): Reduced speed, increased control Mixed zones: Complex tactical positioning opportunities Visual Clarity: Texture representation communicates friction properties intuitively Initial Biome Options At ADR-0011 acceptance, no concrete biomes are implemented. Future ADRs will define specific biomes following ADR-0010 framework:\nExample biomes (from ADR-0010): Desert: Sand regions (μ = 0.6), rocky outcrops (μ = 0.4), gravel paths (μ = 1.0) Arctic: Ice plains (μ = 0.2), snow banks (μ = 0.5), frozen rock (μ = 0.4) Forest: Grass clearings (μ = 0.5), muddy swamps (μ = 1.2), dirt paths (μ = 0.6) Implementation Note: MVP may initially support single biome (uniform friction μ(x,y) = constant) until concrete biome ADRs define geography specifics.\nPhysics Integration Friction from selected biome integrates with ADR-0006 physics:\nFriction Formula: F_friction = μ(position) × M × |v|\nWhere:\nμ(position) = position-dependent coefficient from selected biome M = bot mass (from ADR-0008 characteristics) |v| = velocity magnitude Affects terminal velocity: v_terminal = F_thrust / (μ(position) × M) Gameplay Impact: Bot movement characteristics vary by terrain location:\nSame bot in ice zone (low μ) accelerates faster, travels farther Same bot in mud zone (high μ) accelerates slower, stops quicker Forces positioning decisions: faster zones for retreat, control zones for combat Rationale for Selectable Biomes Framework Validation - Operationalizes ADR-0010 biome framework in actual gameplay; validates biome concept through practice Tactical Variety - Different friction topologies create distinct tactical environments; forces bot adaptability Strategic Selection - Biome choice becomes pre-battle strategic decision based on bot capabilities and opponent analysis Adaptability Testing - Forces bot developers to handle variable friction across arena rather than assuming constant Gameplay Depth - Geography-based positioning creates additional layer of tactical complexity beyond direct combat Future Extensibility - Framework enables adding new biomes without changing core arena system Future Considerations Concrete Biome ADRs (future): Separate ADRs will define Desert, Arctic, Forest, and additional biomes with specific friction topologies Biome Selection UI: Game implementation may randomize, present curated choices, or enable full selection Biome Rotation: Tournament modes might rotate biomes for fairness or focus on single biome for consistency Dynamic Biomes (future): Climate property (deferred in ADR-0010) could add weather effects modifying friction Property 2: Boundary Chosen Option: Option 2.2 - Selectable\nDefinition User selects boundary configuration from available options before battle initialization. Boundary defines:\nShape - Rectangular, circular, hexagonal, or other geometric form Dimensions - Size of bounded region (e.g., 100×100 units) Edge Behavior - Collision mechanics at boundaries Boundary Extraction from ADR-0005 ADR-0005 Property 4 established the universal boundary as part of topological properties. This ADR transfers boundary ownership:\nTransition Rationale:\nADR-0005 correctly defined universal R² space with fixed boundary for establishing spatial foundation Hardcoding prevented arena variety - single boundary couples topology to game mode Future flexibility needed - Different game modes require different arena sizes and shapes Clear separation - Universal topology (ADR-0005) separate from battle instance configuration (ADR-0011) What Remains in ADR-0005:\n2D Euclidean topological space R² Cartesian coordinate system and origin definition Spatial metrics and mathematical properties Coordinate system transformation rules What Moves to ADR-0011:\nSpecific boundary dimensions (e.g., 100×100) Boundary shapes (rectangular, circular, etc.) Boundary selection mechanism Per-boundary configuration options Preservation of Mathematical Rigor:\nMathematical definitions from ADR-0005 are preserved and reused Manifold notation (M, ∂M) maintained in ADR-0011 context Boundary mechanics and collision resolution detailed here Initial Boundary Option: Rectangular 100×100 Units (Default) Shape: Rectangular (aligned with x and y axes)\nMathematical Definition:\nArena Manifold: M = {(x,y) ∈ R² : -50 ≤ x ≤ 50, -50 ≤ y ≤ 50} Boundary: ∂M = {(x,y) : x = -50 or x = 50 or y = -50 or y = 50} Boundary Orientation: Closed manifold with boundary Interior: M° = {(x,y) ∈ R² : -50 \u003c x \u003c 50, -50 \u003c y \u003c 50} Metric: Standard Euclidean d(p₁, p₂) = √((x₂−x₁)² + (y₂−y₁)²) Geometric Properties:\nArena Center: (0, 0) Arena Dimensions: 100 units × 100 units Corners: (-50, -50), (50, -50), (-50, 50), (50, 50) X-axis Range: -50 to +50 units Y-axis Range: -50 to +50 units Perimeter: 400 units Area: 10,000 square units Symmetry: Rectangular boundary with origin at center provides symmetric access to all four quadrants for both bots (fair and balanced).\nMovement Clamping Mechanics Any bot movement command attempting to place bot outside arena boundary is clamped to valid position:\nClamping Algorithm:\nx_final = clamp(x_attempted, -50 + radius, 50 - radius) y_final = clamp(y_attempted, -50 + radius, 50 - radius) Where:\nx_attempted = requested x position from movement command radius = bot collision radius (typically 2 units) clamp(v, min, max) = constrains v to [min, max] range Behavior:\nBot position clamped to boundary edge if movement exceeds limits No wrapping (exiting right side doesn’t place bot on left side) Bot can position exactly on boundary line Ensures bot never overlaps arena boundary Collision Detection and Resolution Rectangular Boundary Collision Detection:\nSimple comparison checks determine wall collision:\nLeft wall collision: x - radius \u003c -50 Right wall collision: x + radius \u003e 50 Bottom wall collision: y - radius \u003c -50 Top wall collision: y + radius \u003e 50 Elastic Collision Resolution (per ADR-0006):\nWall treated as infinite-mass object. Velocity components are transformed:\nCollision with vertical wall (left or right):\nx-component velocity: v_x_final = -v_x_initial (reversed) y-component velocity: v_y_final = v_y_initial (preserved) Example: Bot moving right hits right wall → bounces left with same rightward energy redirected leftward Collision with horizontal wall (top or bottom):\nx-component velocity: v_x_final = v_x_initial (preserved) y-component velocity: v_y_final = -v_y_initial (reversed) Example: Bot moving up hits top wall → bounces down with same upward energy redirected downward Corner collision (both x and y exceed):\nBoth velocity components reversed x-component velocity: v_x_final = -v_x_initial y-component velocity: v_y_final = -v_y_initial No Damage: Boundary collisions do not reduce bot Health (colliding with walls is free).\nFriction Interaction: Variable friction μ(position) applies to deceleration during boundary contact (friction reduces velocity magnitude).\nFuture Boundary Options Option 2.3: Rectangular 150×150 units (larger arena)\nUse case: Extended battles, emphasis on maneuvering over direct combat Manifold: M = {(x,y) ∈ R² : -75 ≤ x ≤ 75, -75 ≤ y ≤ 75} Engagement dynamics: Lower encounter frequency, more room for positioning strategies Option 2.4: Rectangular 75×75 units (smaller arena)\nUse case: Fast-paced combat, emphasis on direct engagement Manifold: M = {(x,y) ∈ R² : -37.5 ≤ x ≤ 37.5, -37.5 ≤ y ≤ 37.5} Engagement dynamics: Higher encounter frequency, less room for evasion Option 2.5: Circular boundary (future ADR)\nShape: Circle centered at origin Advantage: Uniform distance from center, no corner camping strategies Challenge: More expensive boundary checks (distance calculations vs comparisons) Implementation: Requires O(1) distance check: d = √(x² + y²); collide if d \u003e radius Status: Deferred - rectangular implementation first, then circular as variant Option 2.6: Hexagonal boundary (future ADR)\nShape: Regular hexagon centered at origin Advantage: Balanced symmetry with six edges and corners Challenge: More complex collision detection (six edge checks) Gameplay: Creates different positional dynamics than rectangular (curved transition) Status: Deferred - more complex than rectangular and circular Rationale for Selectable Boundaries Arena Variety - Different sizes create different engagement dynamics: small arenas force frequent interaction, large arenas reward maneuvering Game Mode Flexibility - Tournament mode might use 100×100, quick play 75×75, tactical 150×150 without changing universal topology No Hardcoding - Avoids coupling single boundary dimension to spatial system; boundary becomes data not code Balance Tuning - Arena size can be adjusted empirically through playtesting without modifying ADRs Engagement Dynamics - Smaller boundaries increase combat frequency and timeout pressure; larger boundaries reward avoidance and positioning Future Game Modes - Different game modes (team battles, tournaments, special events) can use different boundaries Integration with Other Systems Physics (ADR-0006):\nElastic collisions apply at boundary Friction from biome applies during wall contact No additional forces required for boundary interaction Movement (ADR-0007):\nThrust-based movement respected but clamped at boundaries Movement commands execute within arena bounds Velocity reversal on collision is part of physics resolution Biome (ADR-0010):\nFriction map μ(position) defined over boundary region Different boundaries may have different friction topology layouts Boundary size doesn’t affect friction coefficient values Property 3: Visibility Chosen Option: Option 3.1 - Full Visibility\nDefinition All bots have complete visibility of all other bots at all times. No fog of war, visibility radius limitations, or occlusion mechanics.\nInformation Available:\nComplete position (x, y) of all opponents Velocity and direction of all opponents Health status of all opponents Equipment loadout of all opponents State of ongoing actions and cooldowns Implementation State Protocol (ADR-0004):\nEach game tick, battle server broadcasts complete state to all bots State includes positions of all bots (no filtering or occlusion) Bots receive complete information simultaneously Visibility Calculations: None required\nNo visibility radius checks No line-of-sight occlusion No state filtering or partial updates No information asymmetry between bots Determinism:\nComplete information enables pure strategy without luck Same game state + same bot logic → same decisions Enables perfect bot logic and strategic play Rationale for Full Visibility Simplest Implementation - MVP requires no visibility system; complete state updates sufficient Deterministic Gameplay - All information available enables pure strategic decisions without information asymmetry Accessibility - Bot developers need not implement visibility queries or partial information handling Baseline Validation - Core combat mechanics can be tested without visibility complexity Reproducibility - Complete information ensures identical replays with same seed Alternative: Constant Fog of War (Deferred) Definition: Bots see only within fixed radius around their position (e.g., 30 units).\nGameplay Implications:\nCreates reconnaissance gameplay and scouting strategy Enables ambush tactics and positioning for information advantage Requires visibility calculation: can bot at (x₁, y₁) see opponent at (x₂, y₂)? Distance check: d = √((x₂−x₁)² + (y₂−y₁)²); visible if d ≤ radius Implementation Complexity:\nRequires visibility radius system architecture State filtering: only broadcast visible bots Sensor equipment (ADR-0009) deferred; enables future sensor mechanics Computational cost increases with bot count Status: Deferred to future ADR after full visibility baseline validated through playtesting\nFuture ADR: “Constant Fog of War Visibility System” will define visibility mechanics comprehensively\nAlternative: Vanishing Fog of War (Deferred) Definition: Bots see within radius, but explored areas remain visible indefinitely (fog “vanishes” once explored).\nUser Note: Specified as providing “very nice” transition from full visibility to constant fog of war.\nGameplay Implications:\nCreates map control mechanics and information persistence Rewards positional control and exploration Bots can “remember” areas they’ve previously explored Information advantage grows with exploration during battle Strategic pacing: early scouting provides mid-game information advantage Implementation Complexity (Highest):\nRequires per-bot visibility memory (which areas explored by which bot) Fog state tracking: for each grid cell, is it visible now or was visible? State synchronization: must communicate explored areas to bot Memory management: growing visibility state over battle duration Visualization: show explored areas differently from unseen areas Status: Deferred pending full visibility and constant fog of war validation\nFuture ADR: “Vanishing Fog of War Visibility System” will define advanced visibility mechanics after simpler alternatives validated\nFuture Visibility Roadmap ADR-0011 (Current): Full visibility Future ADR-A: Constant fog of war with configurable radius Future ADR-B: Vanishing fog of war with explored area persistence Future Game Modes: Different visibility modes for different game types Property 4: Start Positioning Chosen Option: Option 4.2 - Random\nDefinition At battle initialization, each bot is assigned a random position within the arena boundaries. Position generation ensures valid placement:\nRandomized coordinates (x, y) within arena boundary Minimum separation between bots (prevent initial collision) Deterministic through seeded randomness (enables replay) Positioning Rules Random Coordinate Selection:\nx_coordinate ∈ [-50, 50] (uniform random distribution within x-range) y_coordinate ∈ [-50, 50] (uniform random distribution within y-range) Both coordinates selected independently Collision Radius Accommodation:\nBot collision radius ≈ 2 units Bot center must maintain 2-unit clearance from boundary Valid position range: x_center ∈ [-48, 48], y_center ∈ [-48, 48] Minimum Separation Requirement:\nDefault separation distance: 20 units (TBD based on playtesting) Distance between bot centers must be ≥ 20 units Prevents spawning overlapping or immediately touching Provides reaction time before first engagement Collision-Free Generation:\nPosition generator repeats until valid non-overlapping position found Ensures no bots spawn touching or overlapping Ensures all bots have minimum separation Deterministic Randomness:\nArena configuration includes random seed for reproducibility Same seed → same starting positions (enables battle replay and debugging) Seed can be derived from match ID, round number, or explicitly specified Orientation (Future):\nBot facing direction may also be randomized (if directional weapons exist) Prevents orientation-based spawn advantage Position Generation Algorithm function generate_start_positions(arena, num_bots, seed): rng = SeededRandomGenerator(seed) positions = [] for each bot: valid = false while not valid: x = rng.uniform(-48, 48) y = rng.uniform(-48, 48) position = (x, y) # Check separation from all existing positions valid = true for each existing_position in positions: distance = sqrt((x - existing_position.x)² + (y - existing_position.y)²) if distance \u003c 20: valid = false break positions.append(position) return positions Rationale for Random Positioning Forces Adaptability - Bots cannot rely on fixed spawn points; must adapt to variable initial positions Prevents Hardcoded Openings - Eliminates “spawn camping” or fixed-position opening tactics that exploit knowledge of spawns Simplifies Biome Design - Biomes don’t require predefined spawn point layouts per biome Simplifies Boundary Design - Boundary configuration doesn’t constrain spawn logic; works with any valid boundary Fair and Balanced - Uniform probability distribution ensures no positional advantage at battle start Encourages General AI - Bot logic must work from any starting position and orientation, not optimized for specific spawns Reproducible - Seed-based generation enables exact replay of same starting positions for debugging Rejected Alternative: Fixed Positioning Definition: Predefined spawn points (e.g., opposite corners, center edges).\nExample Configuration:\nBot A always spawns at (-40, -40) Bot B always spawns at (40, 40) Advantages:\nPredictable and consistent Simple for bot developers to optimize opening sequences Easier battle replay (no seed needed) Simpler implementation (hardcoded positions) Disadvantages:\nHardcoded opening sequences: Bots can exploit known spawns → meta-strategy instead of adaptability Per-boundary definitions required: Each boundary size needs spawn point definition (100×100 different from 150×150) Positional advantages: Different spawn locations create unequal advantages (corner spawns vs center spawns) Biome interaction: Friction topology may favor certain spawns (ice near spawn = speed advantage) Reduces AI quality: Bot optimization focuses on specific spawns rather than general play Less emergent gameplay: Predictability reduces strategic depth and surprise tactics Rejection Rationale: Sacrifices adaptability and bot quality for minor implementation convenience. Fixed spawns create meta-strategies that reward hardcoding over general intelligence.\nRejected Alternative: User-Selected Positioning Definition: Players choose spawn points for their bots before battle.\nAdvantages:\nStrategic pre-battle positioning choice Player agency in arena configuration Interesting metagame of spawn point selection Disadvantages:\nUI Complexity: Requires spawn point selection interface Information asymmetry: Who picks first? Creates advantage for second player Metagaming: Spawn point selection becomes meta-strategy (always pick corners vs always pick center) Startup delay: Spawn selection phase delays battle start Automation complexity: Unclear how automated/AI bots choose spawn points Fairness issues: Different spawn points create unequal opportunities Not applicable to all modes: Random automated tournaments don’t fit player selection model Rejection Rationale: Adds implementation and balance complexity without proportional strategic depth gain. Metagaming around spawn points is less interesting than adaptive gameplay.\nImplementation Notes Numeric Value Tuning:\nMinimum separation: 20 units (TBD - adjust based on playtesting) Too small: Bots spawn near collision, immediate panic Too large: Bots spawn far apart, artificial delay to combat Optimal: Enough reaction time for first action (~1-2 ticks) Arena position range: [-48, 48] (derived from 100×100 - 2 unit radius) Ensures bot collision radius doesn’t exceed boundary Automatic for different boundary sizes Seed Management:\nArena configuration must include explicit seed or seed derivation rule Seed should be tournament-round-stable (same seed for replay analysis) Can use hash(battle_id, round_number) as seed source Property 5: Win Conditions Chosen Option: Option 5.3 - Multi-Path Victory (Health Depletion + Timeout + Disconnect)\nWin Condition 1: Health Depletion (Primary) Trigger: Bot’s Health characteristic reaches 0\nHealth Definition (from ADR-0008):\nEach bot has Health value (initial health from characteristics + equipment) Health reduced by opponent attacks Health depleted when reduced to 0 Victory Resolution:\nImmediate: Battle ends immediately when any bot’s Health reaches 0 Winner: Bot with Health \u003e 0 Loser: Bot with Health = 0 (eliminated) Decisive: Cleanest victory condition; primary path for engagement-focused battles Gameplay Impact:\nRewards dealing damage to opponent Punishes taking damage without reciprocation Creates pressure to engage (can’t win without opponent damage) Eliminates stalling strategies (must take damage eventually) Win Condition 2: Timeout Trigger: Battle duration reaches maximum time limit\nTime Limit: 5 minutes (300 seconds) [TBD - Subject to Playtesting]\nTuning Rationale:\nInitial estimate based on expected engagement pacing 5 minutes allows ~60 combat exchanges at 2-second resolution Sufficient for positioning and maneuvering phases Short enough to prevent tournament bottleneck Will be empirically tuned through playtesting Expected Tuning Ranges:\nQuick Play: 3 minutes (120 seconds) - faster pacing Standard Match: 5 minutes (300 seconds) - balanced default Tournament: 7-10 minutes - allows complex strategies Training: Unlimited or 30 minutes - practice mode Winner Determination:\nWhen timeout expires, battle concludes and victory awarded:\nCase 1: Health Difference\nIf bots have different Health values: Winner: Bot with higher Health remaining Loser: Bot with lower Health remaining Rationale: Rewards both damage dealing AND damage avoidance Case 2: Equal Health (Tiebreaker)\nMultiple resolution options [TBD - requires playtesting to determine player preference]:\nOption A: Draw - Timeout with equal health = draw (both qualify for tournament advancement or both eliminated) Option B: Last Damage Wins - Whoever dealt the most recent damage wins (rewards aggression and engagement) Option C: Total Damage Dealt - Whoever dealt most cumulative damage wins (measures sustained aggression) Option D: Damage Efficiency - Whoever dealt most damage relative to health remaining wins Recommendation: Option B (Last Damage Wins) - simplest, rewards engaging gameplay Default Tiebreaker (Recommended): Last bot to deal damage wins\nRationale: Encourages aggressive engagement rather than passive waiting Implementation: Track timestamp of last damage dealt by each bot; winner is bot with more recent timestamp Gameplay Effect: Losing bot has incentive to take action before timeout (risk reward decision) Win Condition 3: Disconnect Trigger: Bot disconnects from battle server\nDisconnect Causes:\nNetwork connection loss Bot process crash or shutdown Protocol violation or invalid message Server-side connection termination Client timeout Reconnection Grace Period: 30 seconds [TBD - Subject to Testing]\nGraceful Recovery Procedure:\nInitial Disconnect: Bot loses connection (0-5 seconds: initial connection failure) Grace Period Active: Bot has 30 seconds to reconnect (5-35 seconds from disconnect) Battle continues with disconnected bot in last known state Disconnected bot cannot send commands Disconnected bot may be affected by opponent actions (unclear state) Grace Period Expires (35 seconds): If not reconnected, proceed to forfeit Forfeit: Disconnected bot loses battle immediately Reconnection Success:\nWithin Grace Period: Bot resumes control from last synchronized state Recovery State: Bot state (position, health, cooldowns) preserved from moment of disconnect Battle Continues: Battle proceeds normally with reconnected bot No Penalties: Reconnection carries no Health or action penalties (encourages recovery) Rationale for Grace Period:\nFairness for Transient Issues: Brief network hiccup shouldn’t forfeit match immediately Recovery Time: Allows reconnection within reasonable timeframe (~30 seconds typical for reconnection) Progress Guarantee: If grace period expires, battle progresses rather than hanging indefinitely Competitive Clarity: Clear rules for tournament play and ranking systems Connection Stability: Encourages implementing reliable connection logic; stability becomes competitive skill Numeric Value Tuning [TBD]:\nCasual Play: 60 seconds (forgiving, tolerates temporary network issues) Standard Match: 30 seconds (balanced default) Competitive: 15 seconds (strict, values consistent connection) Tournaments: 30 seconds (standard fairness) Win Condition Priority When multiple win conditions could trigger, priority order:\nDisconnect Grace Period Expiration (highest priority)\nIf grace period expires, disconnected bot forfeits immediately Prevents hung battles waiting for reconnection indefinitely Example: Timeout clock at 1 second, disconnect at 2 seconds → disconnect wins (forfeit overrides timeout) Health Depletion\nIf bot reaches Health = 0, battle ends immediately Higher priority than timeout (decisive victory) Example: Bot defeated at 4:50 (10 seconds before timeout) → immediate victory Timeout\nIf neither disconnect nor health depletion triggered, timeout determines winner Lowest priority (fallback condition) Example: Both bots at positive health, 5:00 elapsed → higher health bot wins Priority Ensures:\nTechnical failures don’t hang battles (disconnect highest) Decisive victories end battles immediately (health \u003e timeout) Battles always conclude within maximum duration (timeout guarantees conclusion) Rationale for Multi-Path Approach Prevents Single Strategy Dominance - Timeout prevents pure evasion (must deal damage or maintain health), health prevents pure attrition (timeout forces engagement) Guaranteed Battle Conclusion - Every battle concludes within 5 minutes maximum; no indefinite stalemates Handles Technical Failures - Disconnect condition prevents hung battles from network/server issues Competitive Clarity - Unambiguous win determination enables tournaments, rankings, and competitive play Encourages Engagement - Timeout + health comparison rewards aggressive tactics over pure evasion Risk-Reward Decisions - Multiple win paths create strategic choices (play safe for timeout, or risk damage for health depletion) Fairness - All conditions must be satisfied or triggered to end battle; no arbitrary early stopping Future Win Condition Extensions Additional Conditions for Future Game Modes:\nCapture Point: Control arena zone for duration (King of the Hill mode) Objective Completion: Destroy/protect specific targets (objective-based mode) Elimination: All opponents eliminated (free-for-all or team modes) Score Threshold: First bot to reach score target (best-of-N matches) Different Timeout Values by Mode:\nQuick Play: 3 minutes (faster matches) Tournament: 10 minutes (strategic depth) Training: No timeout (practice mode) Dynamic Boundaries (Future):\nShrinking arena boundaries could add pressure (arena gets smaller over time) Ring of fire approaching boundary (environmental hazard) Would require additional ADR defining shrinking mechanics Consequences Overall Arena System Good, because property-based framework enables diverse battle configurations through composition without changing core systems Good, because Arena concept cleanly separates universal topology (ADR-0005) from battle instances (ADR-0011) Good, because selectable properties (biome, boundary) create pre-battle strategic choices and player agency Good, because framework is extensible: add new properties, boundary shapes, biomes, visibility modes without breaking core system Good, because integrates seamlessly with existing systems (biome framework ADR-0010, physics ADR-0006, spatial system ADR-0005) Good, because provides foundation for future game modes (team battles, tournaments) with different arena properties Neutral, because property values (timeout duration, reconnection period, minimum separation) require playtesting for tuning Neutral, because property framework adds system complexity compared to single fixed arena Bad, because provides many configuration options that may overwhelm casual players without guidance Bad, because requires UI/UX for property selection and tournament configuration Property 1: Biome Selection Good, because operationalizes ADR-0010 biome framework in gameplay; validates biome concept through practice Good, because different friction topologies create tactical variety and environment differentiation Good, because pre-battle biome choice becomes strategic decision based on bot capabilities Good, because forces bot adaptability to handle variable friction across arena Good, because geography-based positioning creates additional tactical complexity Neutral, because initial implementation may support only single biome until concrete biome ADRs defined Bad, because biome balance tuning complex (different friction topologies may favor different bot types) Property 2: Boundary Configuration Good, because selectable boundaries enable arena variety without changing universal topology Good, because different sizes create different engagement dynamics (small = frequent combat, large = maneuvering) Good, because enables different game modes with appropriate arena sizes Good, because allows balance tuning through boundary size adjustment based on playtesting Good, because rectangular boundaries have simple collision detection (comparisons vs complex geometry) Neutral, because initial implementation supports only single rectangular size until additional boundary ADRs defined Neutral, because boundary size affects engagement pacing and requires tuning per game mode Bad, because corners enable defensive camping strategies (bots can position in corners safely) Bad, because rectangular boundaries provide less engagement pressure than shrinking or circular alternatives Property 3: Visibility System Good, because full visibility is simplest implementation for MVP (no visibility system required) Good, because complete information enables pure strategic gameplay without information luck Good, because bot developers don’t need visibility query implementation for initial release Good, because baseline validation of combat mechanics before adding visibility complexity Neutral, because full visibility may feel unrealistic or reduce immersion for some players Neutral, because complete information is advantage to experienced players (can execute perfect knowledge strategies) Bad, because eliminates reconnaissance and information advantage gameplay Bad, because defers interesting fog of war mechanics (ambush tactics, scouting, information control) Bad, because may not support future sensor equipment or tactical reconnaissance gameplay Property 4: Start Positioning Good, because random positioning forces bot adaptability to any starting location Good, because prevents hardcoded opening sequences that exploit fixed spawns Good, because simplifies biome and boundary design (no spawn point definitions needed) Good, because fair and balanced (uniform distribution ensures no positional advantage) Good, because encourages general-purpose bot AI rather than spawn-optimized logic Good, because seed-based randomness enables reproducible battles for debugging Neutral, because minimum separation distance requires playtesting tuning Neutral, because adds minor implementation complexity for position generation Bad, because unpredictable start positions may feel chaotic for casual players Bad, because eliminates strategic control over starting positions (some players prefer control) Property 5: Win Conditions Good, because multi-path approach prevents single strategy dominance (no pure evasion, no infinite attrition) Good, because guaranteed battle conclusion within 5 minutes ensures tournaments and rankings work Good, because health depletion provides decisive victory condition Good, because timeout ensures battles progress even with evasive opponents Good, because disconnect handling prevents hung battles from technical failures Good, because clear priority order eliminates ambiguity in edge cases Neutral, because timeout tiebreaker (last damage) requires playtesting validation Neutral, because 5-minute duration and 30-second reconnection grace period require empirical tuning Bad, because multiple win conditions add system complexity and player learning curve Bad, because timeout mechanics may reward passive play (wait for opponent to make mistakes) Bad, because reconnection grace period could allow unfair advantage (lag exploits) Confirmation The Arena system and 1v1 battle properties will be confirmed through:\n1. Arena System Implementation Arena configuration correctly specifies biome, boundary, visibility, positioning, win conditions Battle server instantiates arena from configuration Arena properties correctly constrain battle gameplay (bots respect boundaries, see correct information, spawn at designated positions) Multiple arena instances can be created and configured independently 2. Biome Integration Selected biome provides μ(position) function for friction physics Friction topology from biome correctly affects bot movement per ADR-0006 formula: F_friction = μ(position) × M × |v| Different biomes create observable tactical differences (ice zones faster, mud zones slower) Concrete biome ADRs successfully instantiate biome framework (Desert, Arctic, Forest) Friction map queries meet real-time tick rate requirements 3. Boundary Mechanics Bot movement clamped at boundaries (no escape outside arena) Elastic collisions apply correctly at walls Rectangular boundary collision detection uses simple comparisons (efficient) Bots can position exactly on boundary line without clipping Different boundary sizes work correctly (100×100, 150×150, etc.) 4. Visibility System State updates include complete position information for all bots No occlusion calculations or filtering performed Bot implementations receive full information each tick Deterministic gameplay with complete information 5. Start Positioning Random position generation produces valid placements Minimum 20-unit separation between bots enforced Seed-based generation enables reproducible start positions No bots spawn overlapping or outside boundaries Same seed produces identical starting positions (for replay) 6. Win Condition Detection Health Depletion: Battle ends immediately when Health = 0 Timeout: Battle concludes at 5 minutes with higher-health winner Disconnect: Grace period tracked, forfeit triggered at expiration Win condition priority correct (disconnect \u003e health \u003e timeout) 7. Integration Testing ADR-0005 topological properties respected (R² space, Cartesian coordinates) ADR-0006 physics laws applied correctly (friction, collisions, movement) ADR-0007 movement mechanics constrained by boundaries ADR-0008 health characteristic used for health depletion win condition ADR-0009 equipment mass affects movement within friction system ADR-0010 biome framework provides geography for selected biomes ADR-0004 gRPC protocol transmits arena configuration and state 8. Playtesting Validation Arena size (100×100) provides appropriate tactical space (not too cramped, not too sprawling) Engagement frequency appropriate for 5-minute timeout (not excessive running, not immediate combat) Biome friction variations create meaningful positioning decisions Random spawning produces varied and interesting battles Win conditions appropriately distributed (reasonable health vs timeout comparison frequency) Disconnect grace period (30 seconds) appropriately balances fairness and progress Pros and Cons of the Options Property 1: Biome Option 1.1: Fixed (Single Biome) All 1v1 battles use identical biome with uniform friction across entire arena.\nGood, because simplest implementation (no biome selection system required) Good, because consistent gameplay experience (no biome learning curve) Good, because avoids biome-specific UI and configuration complexity Good, because all bots compete on same terrain (fair from environment perspective) Neutral, because appropriate if only one biome is ever defined Bad, because eliminates tactical variety from geography differentiation Bad, because fails to validate ADR-0010 biome framework in practice Bad, because removes pre-battle strategic choice related to terrain Bad, because limits extensibility (makes future biome addition more complex) Status: REJECTED - Reduces gameplay variety and fails to validate biome framework Option 1.2: Selectable (CHOSEN) User selects biome from available options when starting battle. Biome determines friction topology.\nGood, because operationalizes ADR-0010 biome framework in gameplay Good, because validates biome concept through competitive practice Good, because creates tactical variety through different friction topologies Good, because enables pre-battle strategic selection based on bot capabilities Good, because forces bot adaptability to variable friction (tests AI quality) Good, because increases gameplay depth through terrain-based positioning Good, because extensible: adding new biomes doesn’t change core system Neutral, because requires future ADRs to define concrete biomes before meaningful choices exist Neutral, because biome balance requires careful tuning per biome Bad, because adds biome selection UI/UX complexity Bad, because increases testing scope (must balance multiple biomes) Bad, because players need education on biome differences and friction effects Property 2: Boundary Option 2.1: Fixed (Single Boundary) All 1v1 battles use identical 100×100 rectangular boundary.\nGood, because simplest implementation (no boundary selection system) Good, because consistent gameplay experience (predictable arena size) Good, because standard arena size familiar to all players Good, because matches existing documentation and expectation Neutral, because appropriate if single arena size sufficient Bad, because eliminates arena variety through size variation Bad, because prevents different game modes with different arena needs Bad, because hardcodes single boundary to topological system (tight coupling) Bad, because limits future expansion to different arena types Bad, because removes pre-battle strategic choice of arena scale Status: REJECTED - Reduces flexibility and couples topology to game mode Option 2.2: Selectable (CHOSEN) User selects boundary configuration from available options. Boundary determines arena shape and dimensions.\nGood, because enables arena variety without changing universal topology Good, because different sizes create different engagement dynamics Good, because allows different game modes with appropriate arena sizes Good, because supports balance tuning through boundary size adjustment Good, because enables pre-battle strategic selection (prefer maneuvering space or engagement frequency) Good, because rectangular boundaries have simple collision detection Good, because extracting boundary from ADR-0005 cleanly separates topology from game mode Good, because extensible: new boundary shapes and sizes don’t change core system Neutral, because initial implementation supports only single rectangular size until additional boundary ADRs defined Neutral, because rectangular boundaries may feel static compared to dynamic or circular alternatives Bad, because corners enable defensive camping strategies Bad, because rectangular boundaries provide less engagement pressure than shrinking/circular Bad, because adds boundary selection UI/UX complexity Option 2.3: Dynamic (Shrinking) Arena boundaries shrink over battle duration, forcing increasing interaction.\nGood, because creates increasing pressure for engagement over time Good, because prevents indefinite evasion (shrinking walls force approach) Good, because provides dynamic pacing (slow start, fast ending) Good, because creates comeback mechanics (losing bot has pressure incentive) Bad, because significantly more complex implementation (shrinking geometry, collision updates) Bad, because requires complex math for shrinking boundary collision detection Bad, because unfamiliar mechanic to most players (needs learning) Bad, because changes physics at runtime (friction, collision points shift) Bad, because may cause unexpected or frustrating boundary behavior Status: DEFERRED - High implementation complexity; defer until core arena system validated Property 3: Visibility Option 3.1: Full (CHOSEN) All bots see complete information about all opponents at all times.\nGood, because simplest implementation (no visibility system required) Good, because complete information enables pure strategic gameplay Good, because deterministic (same state + same logic = same decisions) Good, because bot developers don’t need visibility queries Good, because validates core combat mechanics without visibility complexity Good, because accessible to new bot developers (no advanced visibility concepts) Good, because baseline for future visibility system additions Neutral, because may feel unrealistic (unlimited visibility unusual) Neutral, because may provide advantage to experienced players (perfect information strategies) Bad, because eliminates reconnaissance and scouting gameplay Bad, because removes information advantage mechanics Bad, because doesn’t support future sensor equipment or visibility items Option 3.2: Constant Fog of War Bots see only within fixed radius around their position (e.g., 30 units).\nGood, because creates reconnaissance gameplay and scouting strategy Good, because enables information advantage through positioning Good, because supports ambush tactics and positional surprise Good, because enables sensor equipment mechanics (ADR-0009 deferred) Good, because more realistic visibility model Neutral, because appropriate after full visibility baseline validated Bad, because requires visibility radius system architecture Bad, because requires state filtering and partial updates Bad, because increases computational cost (visibility checks per tick) Bad, because adds bot developer complexity (visibility query implementation) Bad, because requires UI updates (fog of war visualization) Status: DEFERRED to future ADR - Defer until full visibility validated Option 3.3: Vanishing Fog of War Bots see within radius, but explored areas remain visible indefinitely (fog “vanishes” once explored).\nGood, because creates map control mechanics and exploration strategy Good, because provides persistent information advantage for early exploration Good, because creates nice transition from full visibility to constant fog (user-noted) Good, because enables scouting-focused bot strategies Good, because supports positional reconnaissance tactics Neutral, because more complex but not most complex Bad, because requires per-bot visibility memory (explored area state) Bad, because requires fog state tracking and synchronization Bad, because state grows over battle duration (memory management) Bad, because highest implementation complexity of visibility options Bad, because unfamiliar mechanic requiring player education Status: DEFERRED to future ADR - Defer until simpler fog of war options validated Property 4: Start Positioning Option 4.1: Fixed Predefined spawn points (e.g., opposite corners: Bot A at (-40, -40), Bot B at (40, 40)).\nGood, because predictable and consistent for all battles Good, because simplest implementation (hardcoded positions) Good, because enables bot optimization for specific spawns Good, because simple for replay and debugging Bad, because enables hardcoded opening sequences exploiting known spawns Bad, because requires per-boundary spawn definitions (100×100 different from 150×150) Bad, because different spawns create unequal positional advantages Bad, because biome interaction may favor certain spawns (ice near spawn = unfair speed advantage) Bad, because discourages general-purpose bot AI (rewards spawn-specific optimization) Bad, because reduces emergent gameplay and strategic variety Status: REJECTED - Hardcoded spawns enable exploit strategies over adaptive play Option 4.2: Random (CHOSEN) Bots placed at random positions within arena, seeded for reproducibility.\nGood, because forces bot adaptability to any starting position Good, because prevents hardcoded opening sequences that exploit fixed spawns Good, because simplifies biome and boundary design (no per-configuration spawn points needed) Good, because fair and balanced (uniform distribution, no positional advantage) Good, because encourages general-purpose bot AI rather than spawn optimization Good, because seed-based reproducibility enables debugging and replay Good, because enables emergent gameplay and tactical variety Neutral, because minimum separation distance (20 units) requires empirical tuning Neutral, because adds position generation implementation complexity Bad, because unpredictable spawning may feel chaotic to casual players Bad, because removes player control over starting positions Bad, because may spawn bots far apart (longer initial engagement delays) Option 4.3: User-Selected Players choose spawn points for their bots before battle.\nGood, because provides strategic pre-battle positioning choice Good, because gives player agency in arena configuration Good, because creates interesting metagame of spawn selection Bad, because requires spawn point selection UI Bad, because creates information asymmetry (who picks first advantage) Bad, because enables spawn metagaming (always pick corners vs always pick center) Bad, because delays battle start for spawn selection phase Bad, because unclear for automated bots (how do AI bots select spawns?) Bad, because fairness issues (different spawns = unequal opportunities) Status: REJECTED - Adds complexity without proportional strategic depth Property 5: Win Conditions Option 5.1: Health Depletion Only Battle ends immediately when any bot’s Health reaches 0.\nGood, because simplest win condition (single trigger) Good, because decisive victory condition Good, because rewards aggressive damage dealing Bad, because allows indefinite evasion (bot with health lead can avoid opponent) Bad, because creates stalemate scenarios (both bots evading, no damage dealt) Bad, because provides advantage to defensive bot (can outlast aggressive opponent) Bad, because no time pressure (battles could theoretically last indefinitely) Status: REJECTED - Allows evasion strategies that prevent engagement Option 5.2: Health Depletion + Timeout Health depletion is primary; timeout is fallback conclusion if neither bot depleted after 5 minutes.\nGood, because health depletion is decisive victory Good, because timeout prevents indefinite evasion Good, because simpler than three-path system (no disconnect handling) Neutral, because two conditions simpler than three Bad, because doesn’t handle disconnect scenarios (hanging battles on technical failure) Bad, because doesn’t address reconnection fairness Bad, because technical failures (network loss, bot crash) would hang battles Status: CONSIDERED - Works but incomplete without disconnect handling Option 5.3: Health Depletion + Timeout + Disconnect (CHOSEN) Multi-path victory with three independent win conditions each with priority.\nGood, because health depletion provides decisive victory (first path) Good, because timeout guarantees battle conclusion within 5 minutes (second path) Good, because disconnect handling prevents hung battles from technical failures (third path) Good, because prevents single strategy dominance (timeout prevents evasion, health prevents attrition) Good, because clear priority order eliminates ambiguity Good, because handles all edge cases (technical failures, prolonged evasion, sudden elimination) Good, because competitive clarity for tournaments and rankings Good, because encourages engagement (multiple paths reward different strategies) Good, because graceful recovery from transient connection issues (grace period) Neutral, because three conditions more complex than one or two Neutral, because timeout values and tiebreakers require empirical tuning Neutral, because disconnection grace period requires adjustment per use case (casual vs competitive) Bad, because more complex system than single win condition Bad, because requires timeout tiebreaker (last damage, health, score?) Bad, because timeout mechanics may reward passive play (wait for opponent to make mistakes) Bad, because reconnection grace period could enable lag exploitation More Information Related Documentation Core Spatial and Physics Foundation:\nADR-0005: BattleBot Universe Topological Properties - Defines R² Euclidean space, Cartesian coordinates, universal spatial properties ADR-0006: BattleBot Universe Physics Laws - Defines variable friction, elastic collisions, movement physics ADR-0007: Bot Movement Mechanics - Defines thrust-based movement, terminal velocity, movement constraints Bot Configuration and Characteristics:\nADR-0008: Bot Characteristics System - Defines Health, Defense, Mass properties that affect gameplay ADR-0009: Equipment and Loadout System - Defines weapons and armor affecting characteristics and mass Biome and Arena Framework:\nADR-0010: Biome Definition Framework - Defines Geography property and biome meta-framework ADR-0004: Bot to Battle Server Interface - gRPC protocol for arena configuration and state transmission User Documentation:\n1v1 Battles Documentation - User-facing guide to 1v1 game mechanics and arena system Boundary Extraction from ADR-0005 What ADR-0005 Previously Stated:\nProperty 4: Boundary - Rectangular Boundary (CHOSEN) Arena Size: 100 x 100 units (TBD - subject to tuning based on playtesting) X-axis Range: -50 to +50 units Y-axis Range: -50 to +50 units Mathematical Definition: - Topological Space: 2-dimensional Euclidean space R² - Manifold: Closed rectangular region [−50, 50] × [−50, 50] ⊂ R² - Metric: Standard Euclidean metric d(p,q) = √((x₂−x₁)² + (y₂−y₁)²) - Coordinate Chart: Cartesian coordinates φ: R² → R² where φ(p) = (x, y) - Boundary: ∂M = {(x,y) : x=±50 or y=±50} Why Extraction Was Necessary:\nCoupling Issue - Hardcoding boundary in universal topology couples spatial system to specific game mode (1v1) Inflexibility - Cannot modify boundary size without changing topological definition Future Scalability - Other game modes need different boundaries; would require topology changes for each Architectural Clarity - Separates universal properties (R²) from game-mode-specific properties (arena dimensions) What Transfers to ADR-0011:\nRectangular boundary dimensions ([-50, 50] × [-50, 50]) Boundary shapes and size options Boundary selection mechanism Movement clamping and collision mechanics Mathematical definitions (preserved from ADR-0005) What Remains in ADR-0005:\n2D Euclidean topological space R² Cartesian coordinate system and origin definition Spatial metrics and mathematical properties Universal coordinate system rules Integration Approach:\nADR-0011 preserves and reuses mathematical notation from ADR-0005 ADR-0011 applies boundary within specific game mode (1v1) Future game modes can apply different boundaries without topology changes Enables selective application of boundaries per game type Future Arena Extensions Visibility Systems (future ADRs):\nADR-TBD: Constant Fog of War - Visibility radius mechanics for reconnaissance gameplay ADR-TBD: Vanishing Fog of War - Explored area persistence for map control gameplay Boundary Variants (future ADRs):\nADR-TBD: Circular Boundaries - Circular arena for radial gameplay ADR-TBD: Hexagonal Boundaries - Hexagonal arena for balanced symmetry ADR-TBD: Dynamic Boundaries - Shrinking arena for increasing engagement pressure Biome Implementations (future ADRs):\nADR-TBD: Desert Biome - Sand, rock, gravel terrain with defined friction topology ADR-TBD: Arctic Biome - Ice, snow, frozen rock terrain with low-friction zones ADR-TBD: Forest Biome - Grass, swamp, dirt terrain with varied friction Additional Win Conditions (future ADRs):\nADR-TBD: King of the Hill - Control arena center zone for duration ADR-TBD: Capture Point - Objective-based victory conditions ADR-TBD: Free-for-All - Elimination with multiple bots Game Modes (future specifications):\nQuick Play: 3-minute timeout, 75×75 arena, random biome Tournament: 10-minute timeout, 100×100 arena, predefined biome selection Training: No timeout, 100×100 arena, selectable biome, practice mode Team Battles: Multiple 1v1 arenas in coordination (requires future ADR for team mechanics) Design Principles Property-Based Framework: Arena configured through composition of independent properties rather than predefined templates. Enables combinations and future extensibility.\nExtensibility First: Property system designed to add new options without breaking existing configurations. Each property can be extended independently.\nSimplicity First: Initial implementation uses simplest option for each property (Full visibility, Random positioning, Health + Timeout + Disconnect). More complex options deferred until basics validated through gameplay.\nLeverage Existing Systems: Builds on ADR-0005 topology, ADR-0006 physics, ADR-0010 biome framework. Does not invent new physics or spatial concepts.\nValidate Before Expanding: Biome framework must be proven through concrete implementations before properties like Climate, Vegetation added. Visibility must be tested with full visibility before introducing fog of war.\nClear Separation of Concerns:\nADR-0005: Universal topological space (R²) ADR-0006: Universal physics laws (friction, collisions) ADR-0010: Biome framework (what defines biomes) ADR-0011: Battle configuration (how to configure specific battles) Player Agency: Selectable properties (biome, boundary) enable pre-battle strategic choices without adding excessive complexity.\nImplementation Notes Numeric Values Marked TBD:\nAll numeric constants should be marked as TBD and tuned through playtesting:\nTimeout duration: 5 minutes [TBD]\nAdjust based on average battle engagement frequency If battles timeout too frequently: increase timeout If battles rarely timeout: decrease timeout Target: ~10-20% of battles end via timeout, 70-80% via health, \u003c5% via disconnect Reconnection grace period: 30 seconds [TBD]\nAdjust based on typical reconnection times observed If players can’t reconnect in time: increase period If period too long: battles stall waiting for reconnection Target: 80%+ successful reconnections, \u003c1% timeout waiting for reconnect Minimum spawn separation: 20 units [TBD]\nAdjust based on first-engagement timing If spawns too close: immediate panic and poor opening gameplay If spawns too far: excessive running before engagement Target: 1-2 ticks reaction time before first possible engagement Arena size 100×100 [TBD]\nAdjust based on engagement dynamics If battles feel cramped: increase to 150×150 If battles feel sparse: decrease to 75×75 Target: Balanced mix of positioning and direct combat Playtesting Priorities:\nBalance Testing: Do win condition paths trigger with appropriate frequency? (Health 70-80%, Timeout 10-20%, Disconnect \u003c5%) Engagement Testing: Is arena size appropriate for engagement frequency? Biome Testing: Do different biomes create observably different gameplay? Spawn Testing: Is minimum separation appropriate? Do bots have reaction time? Timeout Testing: Is 5-minute duration appropriate for expected match pacing? Disconnect Testing: Is 30-second grace period fair for connection recovery? Integration Matrix ADR Property How Used ADR-0004 Boundary, Biome, Visibility, Positioning, Win Conditions gRPC transmits arena configuration, state includes all properties ADR-0005 Boundary (Mathematical), Coordinates Arena uses R² topology, Cartesian coordinates, inherits metric ADR-0006 Boundary (Collisions), Biome (Friction) Physics applies within boundaries; friction from biome ADR-0007 Boundary (Movement Constraint), Positioning Movement constrained by boundaries; random positioning generated at start ADR-0008 Win Conditions (Health) Health characteristic used for health depletion win condition ADR-0009 Boundary (Mass affects movement), Biome (Friction interaction) Equipment mass interacts with biome friction ADR-0010 Biome (Geography) Selected biome provides friction topology μ(position) Design Patterns Used Property-Based Composition: Arena defined as collection of independent properties:\nEach property selectable independently Properties compose to form complete arena Similar pattern used in ADR-0010 (Biome properties: Geography, Climate, etc.) Deferred Alternatives: Complex alternatives documented but not implemented:\nFog of war modes documented but deferred Dynamic boundaries documented but deferred Alternative biomes documented but deferred Enables clear roadmap without initial bloat Seed-Based Determinism: Random positioning reproducible through seed:\nSame seed → same starting positions Enables battle replay and analysis Maintains randomness for gameplay variety Graceful Degradation: System supports both connected and disconnected states:\nGrace period allows recovery from transient failures Clear timeout prevents indefinite hangs No requirement for perfect connectivity Summary ADR-0011 introduces the Arena concept as the bridge between the universal BattleBot Universe (ADR-0005) and concrete 1v1 battle instances. Five key properties define arena configuration:\nBiome (Selectable) - Terrain type determining friction topology Boundary (Selectable) - Arena shape and dimensions Visibility (Full) - Information available to bots Start Positioning (Random) - Initial bot placement Win Conditions (Multi-Path) - Health + Timeout + Disconnect This property-based framework enables gameplay variety, player agency, and future extensibility while maintaining consistent spatial and physics foundations. The arena system formally separates universal topology (ADR-0005) from battle instance configuration (ADR-0011), enabling different game modes with different arena properties without changing core systems.\n","categories":"","description":"Arena concept definition and battle properties for 1v1 game mode\n","excerpt":"Arena concept definition and battle properties for 1v1 game mode\n","ref":"/battlebots/pr-preview/pr-153/research_and_development/adrs/0011-1v1-battles/","tags":"","title":"[0011] 1v1 Battles"},{"body":"","categories":"","description":"","excerpt":"","ref":"/battlebots/pr-preview/pr-153/research_and_development/analysis/","tags":"","title":"Analysis"},{"body":"1v1 battles take place in a 2D rectangular arena with defined boundaries. The arena uses a Cartesian coordinate system and applies physics rules for movement, collision, and friction.\nAbout Arenas: A Battle Arena is a configured instance of the BattleBot Universe with specific properties: terrain type (biome), boundary dimensions, visibility rules, starting positions, and win conditions. Different battles may use different arena configurations. For complete technical specification, see ADR-0011: 1v1 Battles.\nCoordinate System The arena uses a 2D Cartesian coordinate system - the same (x, y) coordinates you learned in math class.\ngraph TD subgraph Arena[\"Arena: 100x100 units\"] origin[\"Origin (0, 0)\u003cbr/\u003eCenter of arena\"] topRight[\"+50, +50\u003cbr/\u003eTop-Right Corner\"] topLeft[\"-50, +50\u003cbr/\u003eTop-Left Corner\"] bottomRight[\"+50, -50\u003cbr/\u003eBottom-Right Corner\"] bottomLeft[\"-50, -50\u003cbr/\u003eBottom-Left Corner\"] end style origin fill:#4CAF50 style topRight fill:#f9f style topLeft fill:#f9f style bottomRight fill:#f9f style bottomLeft fill:#f9f Key Properties Origin (0, 0): Located at the center of the arena X-axis: Horizontal axis Positive values extend to the right Negative values extend to the left Range: -50 to +50 Y-axis: Vertical axis Positive values extend upward Negative values extend downward Range: -50 to +50 Units: Abstract spatial units (not meters or pixels) Precision: Floating-point coordinates allow sub-unit positioning Distance Calculation Distance between two points uses the Pythagorean theorem:\ndistance = √((x₂ - x₁)² + (y₂ - y₁)²) Your SDK provides helper functions for distance calculations.\nArena Boundaries The battle space is bounded by a 100 × 100 unit rectangular arena.\nBoundary Rules X-axis boundaries: x = -50 (left wall) and x = +50 (right wall) Y-axis boundaries: y = -50 (bottom wall) and y = +50 (top wall) Movement clamping: Bots cannot move outside boundaries; position is clamped to the edge No wrapping: Coordinates do not wrap around (leaving right side doesn’t place you on left) No wall damage: Colliding with walls does not cause damage Elastic collisions: Bots bounce off walls with velocity reversal (horizontal velocity reversed on vertical walls, vertical velocity reversed on horizontal walls) Selectable: The 100×100 rectangular boundary is the default configuration. Future versions may offer different arena sizes (75×75, 150×150) and shapes (circular, hexagonal) as selectable options. Bot Positioning and Collision Each bot occupies a circular area in the arena.\nBot Footprint Bot radius: 2 units Center position: Bot coordinates (x, y) represent the center of its circular footprint No overlap: Bots cannot overlap; their circular areas must not intersect graph LR subgraph BotCollision[\"Bot Collision Detection\"] A[\"Bot A\u003cbr/\u003ePosition: (10, 20)\u003cbr/\u003eRadius: 2\"] B[\"Bot B\u003cbr/\u003ePosition: (14, 20)\u003cbr/\u003eRadius: 2\"] distance[\"Distance = 4 units\u003cbr/\u003eSum of radii = 4 units\u003cbr/\u003eStatus: Touching\"] end A -.Distance = 4.-\u003e B style A fill:#4CAF50 style B fill:#2196F3 Collision Detection Bot-to-Bot Collision:\nTwo bots collide when the distance between their centers is less than the sum of their radii For identical bots: collision occurs when distance \u003c 4 units (2 + 2) Collision prevents movement through the other bot Bot-to-Wall Collision:\nLeft wall: x - radius \u003c -50 Right wall: x + radius \u003e 50 Bottom wall: y - radius \u003c -50 Top wall: y + radius \u003e 50 Collision Resolution The arena uses elastic collisions where momentum is conserved based on bot masses.\nBot-to-Bot Collision:\nBots transfer momentum based on their masses (determined by equipment loadout) Heavier bots push lighter bots more effectively Velocity is updated along the collision normal (line connecting bot centers) Perpendicular velocity components are preserved No damage is applied from collision Bot-to-Wall Collision:\nWalls have infinite mass and reflect bots elastically Velocity component perpendicular to wall is reversed (bounce) Velocity component parallel to wall is preserved Example: Bot moving right hits right wall → x-velocity reversed (bounces left), y-velocity preserved Corner collisions reverse both velocity components Physics The arena applies physics laws that govern bot movement, collisions, and projectile behavior. See ADR-0006: BattleBot Universe Physics Laws and ADR-0007: Bot Movement Mechanics for detailed specifications.\nThrust-Based Movement Bots control their movement by applying thrust force. The game engine calculates acceleration, velocity, and position based on physics laws.\nMovement Model Each game tick, the physics engine performs:\nCollect forces: Bot’s thrust command, friction opposing movement, and any collision forces Calculate friction: F_friction = μ(position) × M × |v| where M is bot mass and v is velocity Calculate net force: F_net = F_thrust - F_friction (friction opposes thrust) Calculate acceleration: A = F_net / M (heavier bots accelerate slower) Update velocity: v_new = v_current + A × dt Update position: pos_new = pos_current + v_new × dt Apply boundary constraints: Clamp bot position to arena edges (prevents moving outside boundaries) If wall collision detected, apply elastic collision (reverse perpendicular velocity component) Resolve bot-to-bot collisions with momentum transfer Key Movement Properties Continuous Thrust Required: Without applying thrust each tick, friction decelerates your bot to a stop Mass-Based Mobility: Heavy equipment increases mass (M), reducing acceleration from the same thrust Terminal Velocity: When thrust force equals friction force, bots reach maximum speed: v_terminal = F_thrust / (μ(position) × M) Heavier bots reach lower terminal velocity Light bots reach higher terminal velocity Variable friction zones affect terminal velocity (ice = higher speed, mud = lower speed) Friction Mechanics Surface Friction: Position-dependent friction coefficient μ(position) resists bot movement Velocity-Dependent: Friction force magnitude depends on bot’s current velocity Natural Deceleration: Without continuous thrust, friction gradually slows bot to stop Equipment Impact: Heavy equipment increases mass, requiring more sustained thrust to overcome friction Variable Friction Zones Biome Selection: Before battle, you select an arena biome that determines the friction topology (terrain distribution) throughout the arena. Different biomes create different tactical environments through position-dependent friction. Example friction zones (from future biome implementations): Ice zones: Low friction (coefficient ~0.2) - faster movement, less control Grass zones: Medium friction (coefficient ~0.5) - balanced movement Mud zones: High friction (coefficient ~1.2) - slower movement, more control Planned biomes (not yet implemented): Desert (sand, rock, gravel), Arctic (ice, snow), Forest (grass, swamps, dirt) Initial implementation: MVP may support only uniform friction (constant across arena) until concrete biome ADRs are defined Selectable property: Different battles can use different biomes to create varied tactical challenges Visibility System The visibility system determines what information your bot receives about opponents.\nFull Visibility (Current Implementation) 1v1 battles currently use full visibility - your bot has complete information about the opponent at all times:\nComplete position: Opponent’s exact (x, y) coordinates Complete state: Opponent’s health, velocity, equipment loadout No restrictions: No fog of war, visibility radius, or line-of-sight limitations Deterministic gameplay: Complete information enables pure strategic decision-making This visibility mode is chosen for the initial implementation to validate core combat mechanics without visibility complexity.\nFuture Visibility Modes Future versions may introduce alternative visibility systems:\nFog of War: Limited visibility radius around your bot (e.g., 30 units) Line of Sight: Obstacles blocking vision between bots Vanishing Fog: Explored areas remain visible after initial scouting These advanced visibility modes will be defined in future ADRs after the full visibility baseline is validated through gameplay.\nStart Positioning At the beginning of each battle, bots are placed at random positions within the arena boundaries.\nRandom Positioning Rules Random coordinates: Each bot is assigned a random (x, y) position within the arena Valid placement range: Bot centers spawn within x ∈ [-48, 48] and y ∈ [-48, 48] (accounting for 2-unit bot radius) Minimum separation: Bots spawn at least 20 units apart (subject to playtesting adjustment) Collision-free: Position generator ensures no bots spawn overlapping or touching Deterministic: Seed-based randomness enables exact battle replay with same starting positions Why Random Positioning? Random start positions force bot adaptability:\nNo hardcoded openings: Bots cannot exploit fixed spawn points with pre-programmed strategies General-purpose AI: Bot logic must work from any starting position Fair and balanced: Uniform probability distribution ensures no positional advantage Varied gameplay: Each battle starts differently, creating diverse tactical situations Your bot must be prepared to start anywhere in the arena and adapt its initial strategy accordingly.\nMovement Constraints No teleportation: Bots cannot instantly jump to new positions; all movement follows continuous paths Terminal velocity: Bots reach maximum speed when thrust force equals friction force (determined by mass and equipment) Collision blocking: Cannot move through other bots or walls; momentum transfer via elastic collisions Friction decay: Velocity naturally decreases without continuous thrust application Continuous control: Each game tick requires explicit thrust commands to sustain movement Summary The 1v1 battle arena provides a configured battle environment with:\nSpatial System:\n2D Cartesian coordinates centered at origin (0, 0) Default 100×100 unit rectangular boundary (selectable property, other sizes planned) Bounded by walls at x=±50 and y=±50 Bots as circular footprints with 2-unit radius Physics and Movement:\nThrust-based movement with continuous friction opposing motion Terminal velocity determined by thrust, friction, and bot mass Elastic collisions: walls bounce bots (velocity reversal), bot-to-bot collisions transfer momentum Battle Configuration:\nBiome selection: Choose terrain friction topology (planned feature, MVP may use uniform friction) Full visibility: Complete information about opponent position and state Random start positions: Bots spawn randomly with 20-unit minimum separation For detailed physics specifications, see ADR-0006: BattleBot Universe Physics Laws and ADR-0007: Bot Movement Mechanics. For complete arena property definitions, see ADR-0011: 1v1 Battles.\nUnderstanding these spatial and physics mechanics is essential for implementing effective bot movement, positioning, and targeting logic.\n","categories":"","description":"The 2D battle space - coordinates, boundaries, collision detection, and physics\n","excerpt":"The 2D battle space - coordinates, boundaries, collision detection, …","ref":"/battlebots/pr-preview/pr-153/gameplay/1v1-battles/arena/","tags":"","title":"Arena"},{"body":"Welcome to the Battle Bots gameplay documentation! This section provides comprehensive mechanics guides for different battle types available in Battle Bots.\nEach battle type has its own self-contained documentation covering the specific rules, mechanics, and systems that apply to that mode. This organization allows each battle type to have unique mechanics while maintaining clear, focused documentation.\nAvailable Battle Types 1v1 Battles Two bots face off in a direct confrontation. Learn about the arena, bot characteristics, equipment systems, and available actions for 1v1 combat.\nWhat is Battle Bots? Battle Bots is a PVP game platform where you implement autonomous bots that battle each other in real-time. Each bot is independent software that reacts to game state and performs actions in a battle space. Your bot’s success depends on your programming skills and the algorithms you implement.\nGetting Started To start building your bot:\nChoose a battle type to learn about (start with 1v1 Battles) Read the mechanics documentation for that battle type Check out the bot SDK for your preferred programming language Implement your bot’s logic and decision-making Test your bot in battles and iterate on your approach Battle Bots is a programming challenge - the documentation explains the mechanics, but figuring out effective strategies is up to you!\n","categories":"","description":"Documentation for different battle types and game mechanics\n","excerpt":"Documentation for different battle types and game mechanics\n","ref":"/battlebots/pr-preview/pr-153/gameplay/","tags":"","title":"Gameplay"},{"body":"Architecture Decision Records (ADRs) This section contains architectural decision records that document the key design choices made for the Battlebots platform. Each ADR follows the MADR 4.0.0 format and includes:\nContext and problem statement Decision drivers and constraints Considered options with pros and cons Decision outcome and rationale Consequences (positive and negative) Confirmation methods ADR Categories ADRs are classified into three categories:\nStrategic - High-level architectural decisions affecting the entire system (frameworks, authentication strategies, cross-cutting patterns). Use for foundational technology choices. User Journey - Decisions solving specific user journey problems. More tactical than strategic, but still architectural. Use when evaluating approaches to implement user-facing features. API Design - API endpoint implementation decisions (pagination, filtering, bulk operations). Use for significant API design trade-offs that warrant documentation. Status Values Each ADR has a status that reflects its current state:\nproposed - Decision is under consideration accepted - Decision has been approved and should be implemented rejected - Decision was considered but not approved deprecated - Decision is no longer relevant or has been superseded superseded by ADR-XXXX - Decision has been replaced by a newer ADR These records provide historical context for architectural decisions and help ensure consistency across the platform.\n","categories":"","description":"Documentation of architectural decisions made in the Battlebots platform using MADR 4.0.0 standard\n","excerpt":"Documentation of architectural decisions made in the Battlebots …","ref":"/battlebots/pr-preview/pr-153/research_and_development/adrs/","tags":"","title":"Architecture Decision Records"},{"body":"Your bot’s capabilities are defined by three core characteristics: Health, Defense, and Mass. These stats determine your survivability, damage mitigation, and movement properties.\nHealth Health (HP) is your bot’s survivability pool - the total amount of damage your bot can sustain before being eliminated.\nKey Properties HP Pool: Total damage your bot can take before destruction Range: 100-500 HP (placeholder values, subject to balance tuning) Destruction: Bot is eliminated when Health reaches 0 No Regeneration: Health does not regenerate during battle (current design) Gameplay Impact Higher Health allows your bot to stay in battles longer Low-Health bots must rely on damage avoidance through mobility or defensive actions Health works multiplicatively with Defense to create Effective HP (see below) Defense Defense represents your bot’s ability to mitigate incoming damage. It reduces the effective damage from enemy attacks.\nKey Properties Damage Reduction: Reduces incoming damage by a percentage or flat amount Range: 1-10 Defense (placeholder values, subject to balance tuning) Applies to All Damage: Affects all incoming damage sources (current design) No Evasion: Defense reduces damage taken, not hit chance Gameplay Impact Each point of Defense makes your Health more valuable Defense and Health combine multiplicatively to increase effective survivability Higher Defense enables sustained engagements Effective HP Health and Defense work together to determine your true survivability:\nflowchart LR A[\"Health: 100\"] --\u003e C[\"Effective HP: 150\"] B[\"Defense: 50% reduction\"] --\u003e C C --\u003e D[\"Takes 150 damage\u003cbr/\u003eto eliminate\"] style C fill:#4CAF50 Effective HP Formula Effective HP = Health × (1 + Defense modifier) Example: A bot with 100 Health and 50% Defense has 150 Effective HP - it takes 150 points of damage to destroy.\nWhy This Matters Balanced allocation of Health and Defense is more effective than stacking one stat Example: 100 Health + 50% Defense (150 Effective HP) provides better burst damage resistance than 150 Health + 0% Defense Mass Mass represents your bot’s total weight, determined by your equipment loadout. Mass is not directly allocated - it’s calculated from your equipped items.\nKey Properties Equipment-Derived: Total Mass = Base Mass + Equipment Mass Dynamic Value: Changes based on equipped weapons, armor, and modules Movement Impact: Higher Mass reduces acceleration (more force needed to overcome inertia and friction) No Direct Damage Scaling: Mass affects mobility, not offensive capability flowchart TD A[\"Choose Equipment\"] --\u003e B[\"Light Armor:\u003cbr/\u003eMinimal Mass\"] A --\u003e C[\"Heavy Armor:\u003cbr/\u003eHigh Mass\"] B --\u003e D[\"Faster Acceleration\u003cbr/\u003eMore Responsive\"] C --\u003e E[\"Slower Acceleration\u003cbr/\u003eLess Maneuverable\"] style A fill:#2196F3 style B fill:#4CAF50 style C fill:#FF5722 style D fill:#8BC34A style E fill:#FF9800 Gameplay Impact Heavy equipment (powerful weapons, heavy armor) increases Mass, reducing mobility Light equipment maintains mobility but sacrifices offensive/defensive power Mass cannot be optimized independently - it’s a consequence of equipment choices Higher Mass requires sustained thrust to overcome friction and maintain velocity How Mass Affects Movement The thrust-based movement system makes Mass a critical factor in bot mobility:\nAcceleration Formula:\nAcceleration = Thrust Force / Mass Heavy bots (high Mass): Same thrust produces less acceleration Light bots (low Mass): Same thrust produces more acceleration Terminal velocity decreases with Mass: Terminal Velocity = Max Thrust / (Friction Coefficient × Mass) Example impact:\nLight bot (Mass = 10): Can reach high speeds quickly and maneuver rapidly Heavy bot (Mass = 30): Accelerates slowly but may carry heavier weapons Maximum speed depends on both Mass and friction of the terrain Equipment Examples Weapons: Heavy weapons (high Mass) vs. light weapons (low Mass) Armor: Heavy plating (high Mass) vs. light armor (low Mass) Each equipment choice contributes to your total Mass profile and directly affects how quickly you can move Stat Interactions Bot characteristics don’t operate in isolation - they combine to create complex gameplay dynamics.\nEffective Durability Health and Defense multiply together to determine true survivability:\nFormula: Effective HP = Health × (1 + Defense modifier) Optimization: Balanced allocation is more efficient than single-stat stacking Example: 100 Health + 50% Defense (150 Effective HP) is more effective against burst damage than 150 Health + 0% Defense Mass and Mobility Mass directly impacts movement capability through thrust-based physics:\nAcceleration: Acceleration = Thrust Force / Mass — heavier bots accelerate slower Terminal Velocity: v_terminal = F_thrust / (μ × Mass) — heavier bots reach lower maximum speeds Friction Impact: Higher Mass experiences greater friction force, requiring sustained thrust to maintain velocity Equipment Tradeoff: Heavy equipment increases power but reduces positioning flexibility and responsiveness Terrain Effects: Variable friction zones amplify Mass effects (heavy bots feel even slower on high-friction terrain) Survivability Tradeoffs Defensive investment creates build choices:\nHigh Health + Low Defense: Vulnerable to sustained damage Low Health + High Defense: Vulnerable to burst damage High Mass: Defense from heavy armor reduces mobility, increasing thrust requirements Summary Bot characteristics create a three-stat system:\nHealth: Your survivability pool (how much damage you can take) Defense: Damage mitigation (makes each Health point more valuable) Mass: Equipment weight (affects acceleration, friction, and maximum speed) These stats interact to create diverse bot profiles through a physics-based system:\nMobility-Survivability Tradeoff: Heavy defensive equipment increases survivability but reduces movement speed Force-Based Physics: Mass directly determines how effectively thrust translates to movement Terrain Dynamics: Equipment Mass interacts with terrain friction to determine actual maximum speeds Your equipment choices (covered in Equipment) determine your final stat allocation and Mass.\nFor detailed movement physics, see ADR-0007: Bot Movement Mechanics.\nUnderstanding these characteristics is essential for configuring effective bot loadouts and implementing smart combat logic.\n","categories":"","description":"Health, Defense, and Mass stats that define your bot's capabilities\n","excerpt":"Health, Defense, and Mass stats that define your bot's capabilities\n","ref":"/battlebots/pr-preview/pr-153/gameplay/1v1-battles/bot-characteristics/","tags":"","title":"Bot Characteristics"},{"body":" Subject to Change The equipment system described here is currently in the PROPOSED stage and may change based on playtesting and balance analysis. Check back for updates! Before battle, you configure your bot’s loadout by selecting equipment. Equipment modifies your bot’s characteristics and determines which actions are available during battle.\nLoadout Slots Each bot equips:\n1 Weapon - Determines available combat actions 1 Armor - Modifies Defense and Speed characteristics All equipment contributes to your bot’s total Mass, which affects movement acceleration.\nWeapons Weapons enable combat actions and determine offensive capabilities. Each weapon provides unique attack actions with different energy costs, damage patterns, and range characteristics.\nRifle Standard precision weapon enabling reliable ranged attacks.\nStat Effects:\nNo stat modifications (baseline weapon) Mass Contribution: TBD (baseline weapon mass) Characteristics:\nEnables: RifleShot action Damage: Moderate (TBD) Range: Long (TBD) Energy Cost: 15 per shot (TBD) Cooldown: 1 tick (TBD) Profile: Versatile baseline option suitable for various loadouts. No stat penalties, maintains mobility. Effective at medium to long range with consistent damage output.\nShotgun Close-range weapon enabling devastating burst damage with distance-based damage falloff.\nStat Effects:\nSpeed Penalty: -1 (TBD) Range Penalty: -1 (TBD) Mass Contribution: TBD (higher than Rifle) Characteristics:\nEnables: ShotgunBlast action Damage: High at close range, decreases with distance (TBD) Range: Short to medium (TBD) Energy Cost: 20 per shot (TBD) Cooldown: 2 ticks (TBD) Profile: High burst damage at close range. Weight penalty reduces mobility. Requires positioning to maximize effectiveness. Ineffective at long range due to damage falloff.\nArmor Armor provides defensive bonuses and damage mitigation. Armor modifies Defense and Speed characteristics, creating tradeoffs between survivability and mobility. All armor contributes to bot Mass.\nLight Armor Minimal protection that maintains mobility.\nStat Effects:\nDefense: +1 (TBD) Speed: No penalty (TBD) Mass Contribution: TBD (minimal) Profile: Minimal defense bonus with no speed penalty. Preserves mobility for positioning-focused loadouts. Relies on movement rather than damage absorption.\nMedium Armor Balanced protection with moderate defensive bonus and minor speed penalty.\nStat Effects:\nDefense: +2 (TBD) Speed: -1 (TBD) Mass Contribution: TBD (moderate) Profile: Reasonable defense without severe mobility cost. Versatile option for balanced loadouts. Moderate survivability increase with manageable speed reduction.\nHeavy Armor Maximum protection with significant defensive bonus and substantial speed penalty.\nStat Effects:\nDefense: +3 (TBD) Speed: -2 (TBD) Mass Contribution: TBD (high) Profile: Maximum damage reduction. Significant speed penalty limits mobility. Enables sustained engagements and damage absorption. Requires positional awareness due to low mobility.\nEquipment Combinations Here are example equipment combinations showing how weapons and armor create different bot profiles. These are presented as factual loadout options, not as recommendations.\ngraph TD subgraph \"Equipment Loadout Options\" A[\"Rifle + Light Armor\"] --\u003e A1[\"Moderate offense\u003cbr/\u003eLow defense\u003cbr/\u003eHigh mobility\u003cbr/\u003eLow Mass\"] B[\"Rifle + Medium Armor\"] --\u003e B1[\"Moderate offense\u003cbr/\u003eModerate defense\u003cbr/\u003eAverage mobility\u003cbr/\u003eModerate Mass\"] C[\"Rifle + Heavy Armor\"] --\u003e C1[\"Moderate offense\u003cbr/\u003eHigh defense\u003cbr/\u003eLow mobility\u003cbr/\u003eHigh Mass\"] D[\"Shotgun + Light Armor\"] --\u003e D1[\"High close-range offense\u003cbr/\u003eLow defense\u003cbr/\u003eGood mobility (with penalty)\u003cbr/\u003eModerate Mass\"] end style A fill:#4CAF50 style B fill:#2196F3 style C fill:#FF5722 style D fill:#FFC107 Rifle + Light Armor Stat Profile:\nOffense: Moderate (long-range precision) Defense: Low (+1 from Light Armor) Mobility: High (no speed penalties) Mass: Low (minimal equipment weight) Characteristics: Maintains mobility with consistent ranged damage. No speed penalties. Low defensive capability. Relies on positioning and movement.\nRifle + Medium Armor Stat Profile:\nOffense: Moderate (long-range precision) Defense: Moderate (+2 from Medium Armor) Mobility: Average (-1 from Medium Armor) Mass: Moderate Characteristics: Balanced offensive and defensive capabilities. Slight speed reduction. Versatile loadout with no extreme strengths or weaknesses.\nRifle + Heavy Armor Stat Profile:\nOffense: Moderate (long-range precision) Defense: High (+3 from Heavy Armor) Mobility: Low (-2 from Heavy Armor) Mass: High Characteristics: High damage reduction with sustained survivability. Significant mobility penalty. Reliable ranged offense. Positioning is critical due to low mobility.\nShotgun + Light Armor Stat Profile:\nOffense: High at close range (burst damage) Defense: Low (+1 from Light Armor) Mobility: Good (Shotgun -1 penalty, no armor penalty) Mass: Moderate (Shotgun has higher mass than Rifle) Characteristics: High burst damage potential at close range. Reduced effectiveness at distance. Relatively mobile despite shotgun weight. Low survivability requires damage avoidance.\nEquipment and Actions Equipment determines which actions are available:\nRifle: Enables RifleShot action Shotgun: Enables ShotgunBlast action Universal Actions: Move, Block, Evade, Shield, Scan, Charge are available regardless of equipment See the Actions page for complete action details.\nEquipment and Mass All equipment contributes to your bot’s total Mass:\nTotal Mass = Base Mass + Weapon Mass + Armor Mass Higher Mass reduces acceleration (you need more force to move the same speed). This creates a natural tradeoff where powerful equipment inherently reduces mobility.\nExample Mass Impacts:\nLight loadout (Rifle + Light Armor): Fast acceleration, responsive movement Heavy loadout (Shotgun + Heavy Armor): Slow acceleration, requires sustained thrust to overcome friction Mass calculations and specific values are TBD pending balance testing.\nConfiguration Equipment is configured before battle begins:\nloadout = { \"weapon\": \"Rifle\", # or \"Shotgun\" \"armor\": \"Light Armor\" # or \"Medium Armor\" or \"Heavy Armor\" } Equipment cannot be changed during battle.\nSummary The equipment system provides:\n2 Weapon Options: Rifle (baseline precision), Shotgun (close-range burst) 3 Armor Options: Light (mobility), Medium (balanced), Heavy (survivability) 4 Example Combinations: Demonstrating different stat profiles Mass Tradeoffs: Heavy equipment reduces mobility through increased Mass Action Enablement: Equipment determines available combat actions Equipment choices define your bot’s capabilities before battle. Understanding these tradeoffs is essential for effective loadout configuration.\n","categories":"","description":"Weapons and armor that customize your bot's capabilities and enable different actions\n","excerpt":"Weapons and armor that customize your bot's capabilities and enable …","ref":"/battlebots/pr-preview/pr-153/gameplay/1v1-battles/equipment/","tags":"","title":"Equipment"},{"body":" Subject to Change The action system described here is currently in the PROPOSED stage and may change based on playtesting and balance analysis. Energy costs, cooldowns, and action availability may be adjusted! During battle, your bot performs actions each tick. Actions allow your bot to move, attack, defend, and gather information. All actions are constrained by a dual-resource system: energy costs and cooldowns.\nPhysics Integration: The Move action implements thrust-based movement governed by physics laws. See ADR-0006: BattleBot Universe Physics Laws and ADR-0007: Bot Movement Mechanics for detailed specifications.\nResource Management System Actions are governed by two independent constraint systems that work together to prevent action spam while maintaining gameplay fluidity.\nEnergy Pool Capacity: Limited pool of energy (TBD, can be modified by equipment) Regeneration: Energy regenerates over time at a fixed rate (TBD) Consumption: All actions consume energy Constraint: Insufficient energy prevents action execution Cooldown System Time-Based: Actions have cooldown periods measured in game ticks Independent: Cooldowns are separate from energy (both must be satisfied) Prevents Re-Use: Actions cannot be used again until cooldown expires Varies by Action: Powerful actions have longer cooldowns Dual-Constraint System To perform an action, both conditions must be met:\nSufficient energy available Action cooldown has expired flowchart TD A[\"Bot wants to\u003cbr/\u003eperform action\"] --\u003e B{Energy\u003cbr/\u003eavailable?} B --\u003e|No| F[\"Action Rejected\"] B --\u003e|Yes| C{Cooldown\u003cbr/\u003eready?} C --\u003e|No| F C --\u003e|Yes| D{Equipment\u003cbr/\u003erequirement met?} D --\u003e|No| F D --\u003e|Yes| E[\"Action Executed\"] style E fill:#4CAF50 style F fill:#F44336 Why Both?\nEnergy creates resource management decisions Cooldowns prevent burst spam even with high energy Basic actions (Move) have low cost and no cooldown for fluid movement Powerful actions (Shield) have high cost and long cooldown for balance Action Categories Actions are organized into four categories:\nMovement - Navigate the arena Combat - Deal damage to opponents Defensive - Mitigate or avoid damage Utility - Information gathering and state modification Movement Actions Move Applies thrust force to your bot in a specified direction within the battle space.\nCosts and Constraints:\nEnergy Cost: 5 (TBD) Cooldown: 0 ticks (TBD) Equipment Required: None (universal action) Parameters:\nDirection: Specified as angle, vector, or cardinal direction Optional: Thrust magnitude (default: maximum thrust, clamped to bot’s capacity) How It Works:\nMove implements thrust-based movement governed by physics laws:\nBot applies thrust force in the specified direction Physics engine calculates net force: F_net = F_thrust - F_friction Acceleration is calculated: A = F_net / Mass Velocity updates: v_new = v_current + A × dt Position updates: pos_new = pos_current + v_new × dt Key Mechanics:\nContinuous Thrust: Without applying Move each tick, friction decelerates your bot Mass Impact: Heavy bots (from equipment) accelerate slower than light bots from the same thrust Terminal Velocity: Your bot reaches maximum speed when thrust equals friction Light bots reach higher speeds Heavy bots reach lower speeds Formula: v_max = F_thrust / (Friction Coefficient × Mass) Momentum-Based: Your bot maintains velocity and must apply opposite thrust to decelerate Constraints:\nCannot move through obstacles or other bots (collision detection applies) Friction continuously opposes movement, causing natural deceleration when thrust stops Position clamped to arena boundaries; collisions with walls reflect velocity elastically Maximum thrust capacity applies (TBD value) Strategy Tips:\nContinuous Movement: Maintain constant Move actions to sustain velocity Momentum Management: Plan your movement in advance; stopping requires active deceleration Equipment Choices: Light equipment enables rapid acceleration; heavy equipment sacrifices speed Terrain Exploitation: Variable friction zones (ice, mud) affect your maximum speed (ice faster, mud slower) Description: Move is the most fundamental action, enabling positioning, pursuit, evasion, and range control. Zero cooldown and low energy cost make movement fluid and responsive, but require continuous thrust application to sustain motion.\nCombat Actions Combat actions deal damage to opponent bots. Available combat actions depend on your equipped weapon.\nRifleShot Single-shot, precise ranged attack.\nCosts and Constraints:\nEnergy Cost: 15 (TBD) Cooldown: 1 tick (TBD) Equipment Required: Rifle Parameters:\nTarget position or bot Effects:\nDamage: Moderate (TBD) Range: Long (TBD) Constraints:\nRequires line of sight to target Rifle must be equipped Description: Consistent ranged damage with moderate energy cost and short cooldown. Reliable baseline offense for Rifle-equipped bots.\nShotgunBlast Spray of projectiles effective at close range with distance-based damage falloff.\nsequenceDiagram participant Bot as Your Bot participant Server as Battle Server participant Opponent as Opponent Bot Bot-\u003e\u003eServer: Submit RifleShot action Server-\u003e\u003eServer: Validate energy (15 available?) Server-\u003e\u003eServer: Validate cooldown (ready?) Server-\u003e\u003eServer: Validate equipment (Rifle equipped?) Server-\u003e\u003eServer: Validate line of sight Server-\u003e\u003eOpponent: Apply damage Server-\u003e\u003eBot: Action result + updated state Server-\u003e\u003eOpponent: Damage notification + updated state Costs and Constraints:\nEnergy Cost: 20 (TBD) Cooldown: 2 ticks (TBD) Equipment Required: Shotgun Parameters:\nTarget position or bot Effects:\nDamage: High at close range, decreases with distance (TBD) Range: Short to medium (TBD) Constraints:\nShotgun must be equipped Damage falloff reduces effectiveness at range Description: High burst damage at close range. Longer cooldown and higher energy cost than RifleShot. Positioning is critical to maximize damage output.\nDefensive Actions Defensive actions reduce or avoid incoming damage. These are universal actions available regardless of equipment.\nBlock Reduces damage from incoming attacks for one tick.\nCosts and Constraints:\nEnergy Cost: 10 (TBD) Cooldown: 2 ticks (TBD) Equipment Required: None (universal) Effects:\nDamage Reduction: X% of incoming damage (TBD) Duration: Active for current tick only Constraints:\nMust be activated before damage is received (prediction required) Description: Reduces incoming damage by a percentage. Active for only one tick, requiring anticipation of opponent actions.\nEvade Attempts to dodge incoming attacks with a chance-based mechanism.\nCosts and Constraints:\nEnergy Cost: 15 (TBD) Cooldown: Variable (TBD) Equipment Required: None (universal) Effects:\nSuccess Chance: TBD (may depend on bot Speed characteristic) Duration: Active for current tick only Constraints:\nSuccess is not guaranteed (chance-based) Higher energy cost than Block Description: Chance to completely avoid an attack. Higher risk than Block but potentially higher reward. Success rate may be influenced by bot characteristics.\nShield Activates energy shield that absorbs damage over multiple ticks.\nCosts and Constraints:\nEnergy Cost: 20 initial + ongoing drain per tick (TBD) Cooldown: Variable (TBD) Equipment Required: None (universal) Effects:\nDamage Absorption: Up to threshold (TBD) Duration: Sustained across multiple ticks with ongoing energy drain Constraints:\nOngoing energy cost while active may limit other actions Most expensive defensive action Description: Extended damage mitigation over multiple ticks. High initial and ongoing energy cost. Creates temporary window of increased survivability.\nUtility Actions Utility actions provide information gathering and state modification capabilities.\nScan Gathers information about environment and nearby bots.\nCosts and Constraints:\nEnergy Cost: 5 (TBD) Cooldown: Variable (TBD) Equipment Required: None (recommended: Sensor Array module for enhanced range) Effects:\nReturns information about nearby entities (positions, health, etc.) Detection Range: Limited radius, enhanced by Sensor Array equipment (TBD) Constraints:\nOnly reveals information within detection range Description: Information gathering about nearby bots and environment. Low energy cost. Detection range may be enhanced by optional equipment modules.\nCharge Increases energy regeneration rate temporarily.\nCosts and Constraints:\nEnergy Cost: Variable (may cost initial energy or pause regen - TBD) Cooldown: Variable (TBD) Equipment Required: None (universal) Effects:\nBoosts energy regeneration for duration (TBD) Duration: Multiple ticks (TBD) Constraints:\nBot may be vulnerable while charging (cannot perform other actions - TBD) Description: Enhances energy economy by boosting regeneration. Tradeoff between immediate action capability and future energy availability.\nEquipment-Dependent Actions Some actions require specific equipment modules. These are optional enhancements beyond the base weapon and armor system.\nBoost Temporary speed increase for repositioning.\nCosts and Constraints:\nEnergy Cost: Variable (TBD) Cooldown: Variable (TBD) Equipment Required: Boost Engine module Effects:\nIncreases Speed temporarily (TBD) Description: Rapid repositioning capability. Requires optional Boost Engine equipment module.\nRepair Limited self-repair during combat.\nCosts and Constraints:\nEnergy Cost: Variable (TBD) Cooldown: Variable (TBD) Equipment Required: Repair Kit module Effects:\nRestores HP (amount and usage limits TBD) Description: Self-healing capability. Requires optional Repair Kit equipment module.\nCloak Reduces detection range by enemies.\nCosts and Constraints:\nEnergy Cost: Variable (TBD) Cooldown: Variable (TBD) Equipment Required: Stealth Module Effects:\nReduces enemy detection range temporarily (TBD) Description: Stealth capability. Requires optional Stealth Module equipment.\nAction Execution and Processing Action Submission Bots submit actions via the SDK each tick Actions are queued and processed during the next game tick Multiple parallel actions may be possible (TBD) Action Validation The server validates three conditions before executing actions:\nEnergy Available: Sufficient energy in pool? Cooldown Ready: Action cooldown has expired? Equipment Requirement: Required equipment equipped? If any validation fails, the action is rejected with error feedback.\nAction Resolution Actions are resolved during the game tick cycle Action outcomes are broadcast to all bots State changes (damage, position, energy) are updated and synchronized Energy and Cooldown Management graph LR subgraph \"Energy System\" E1[\"Energy Pool: 100\"] --\u003e E2[\"Use Action: -15\"] E2 --\u003e E3[\"Remaining: 85\"] E3 --\u003e E4[\"Regenerate: +5/tick\"] end subgraph \"Cooldown System\" C1[\"Action Used: Tick 10\"] --\u003e C2[\"Cooldown: 2 ticks\"] C2 --\u003e C3[\"Available Again: Tick 12\"] end style E1 fill:#4CAF50 style E3 fill:#FFC107 style C1 fill:#2196F3 style C3 fill:#4CAF50 Managing Energy Monitor your current energy level Plan action sequences within energy budget Balance high-cost actions (combat, defense) with energy regeneration Consider Charge action for energy recovery Managing Cooldowns Track cooldowns for critical actions (combat, defense) Don’t rely on repeated use of actions with long cooldowns Plan alternative actions while waiting for cooldowns Dual-Constraint Strategy The dual-constraint system creates decision-making:\nCan’t spam powerful actions even with energy (cooldowns prevent) Can’t spam actions rapidly without energy (energy limits) Basic actions (Move) remain fluid with low cost and no cooldown Action Reference Table Action Category Energy Cooldown Equipment Description Move Movement 5 0 None Reposition in arena RifleShot Combat 15 1 tick Rifle Moderate damage, long range ShotgunBlast Combat 20 2 ticks Shotgun High damage close range Block Defensive 10 2 ticks None Reduce incoming damage Evade Defensive 15 Variable None Chance to avoid attack Shield Defensive 20 + drain Variable None Multi-tick damage absorption Scan Utility 5 Variable None Gather information Charge Utility Variable Variable None Boost energy regen All values are TBD and subject to balance adjustments.\nSummary The action system provides:\nDual-Constraint Resources: Energy + cooldowns govern action usage 4 Action Categories: Movement, Combat, Defensive, Utility Universal Actions: Available to all bots regardless of equipment Equipment-Dependent Actions: Enabled by specific equipment choices Fluid Movement: Move action has low cost and no cooldown Balanced Power: Powerful actions have high costs and long cooldowns Understanding action costs, cooldowns, and equipment requirements is essential for implementing effective bot logic and resource management.\n","categories":"","description":"All available actions, resource management, energy costs, and cooldowns\n","excerpt":"All available actions, resource management, energy costs, and …","ref":"/battlebots/pr-preview/pr-153/gameplay/1v1-battles/actions/","tags":"","title":"Actions"},{"body":"This section contains detailed technical analysis of communication protocol options evaluated for the Battle Bots bot-to-server and bot-to-bot interface.\nProtocol Evaluations gRPC - HTTP/2-based RPC with Protocol Buffers and bidirectional streaming HTTP-based Protocols - REST, WebSockets, and Server-Sent Events analysis Custom TCP/UDP - Low-level custom protocol evaluation These analyses inform ADR-0004: Bot to Battle Server Communication Protocol.\n","categories":"","description":"Analysis of communication protocols for Battle Bots bot-to-server interface\n","excerpt":"Analysis of communication protocols for Battle Bots bot-to-server …","ref":"/battlebots/pr-preview/pr-153/research_and_development/analysis/protocols/","tags":"","title":"Protocols"},{"body":"Welcome! Battle Bots is a game in which you, the human, implement an autonomous “bot” to do battle with “bots” implemented by other humans.\nWhat is a Bot? A bot is a independent piece of software which is programmed to battle other bots by reacting to state updates (e.g. bot B moved to point A) and performing its own actions (e.g. fire missile at point A).\n","categories":"","description":"Battle Bots is a PVP game for autonomous players","excerpt":"Battle Bots is a PVP game for autonomous players","ref":"/battlebots/pr-preview/pr-153/","tags":"","title":"Battle Bots"},{"body":"R\u0026D Process The Research \u0026 Design process follows a structured workflow to ensure comprehensive analysis and documentation of user experiences, technical solutions, and implementation details.\nProcess Steps Document the User Journey\nCreate a user journey document for the specific user experience Include flow diagrams using Mermaid to visualize user interactions Define prioritized technical requirements (P0/P1/P2) Use the /new-user-journey command to create standardized documentation Design the Solution\nCreate an ADR that designs a solution to implement the user journey Identify and document: Additional ADRs needed for specific components APIs that need to be defined User interface flows (mobile, web, etc.) Data flow from user to end systems (database, notification system, etc.) Capture the complete system architecture and integration points Document Component ADRs\nCreate ADRs for specific technical components identified in the solution design Examples: authentication strategy, session management, account linking, data storage Use the /new-adr command to create standardized MADR 4.0.0 format documents Document technical decisions with context, considered options, and consequences Document Required APIs\nFor each API endpoint identified in the solution, create comprehensive API documentation Use the /new-api-doc command to create standardized documentation Include: Request/response schemas Authentication requirements Business logic flows (Mermaid diagrams) Error responses and status codes Example curl requests Document API Implementation\nFor each documented API, create an ADR describing the implementation approach Document technical decisions including: Programming language selection Framework and libraries Architecture patterns Testing strategy Example: ADR-0006 documents the tech stack for API development (z5labs/humus framework) Design User Interface\nCreate UI/UX designs for the user journey Ensure designs align with the documented user flows and API contracts Consider platform-specific requirements (mobile, web, desktop) Documentation Structure The R\u0026D documentation is organized into the following sections:\nUser Journeys - User experience flows with technical requirements ADRs - Architectural Decision Records documenting technical decisions APIs - REST API endpoint documentation with schemas and examples Analysis - Research and analysis of technologies and solutions ","categories":"","description":"","excerpt":"R\u0026D Process The Research \u0026 Design process follows a structured …","ref":"/battlebots/pr-preview/pr-153/research_and_development/","tags":"","title":"Research \u0026 Design"},{"body":"","categories":"","description":"","excerpt":"","ref":"/battlebots/pr-preview/pr-153/categories/","tags":"","title":"Categories"},{"body":"Overview Grafana Loki is a horizontally scalable, highly available, multi-tenant log aggregation system inspired by Prometheus. Unlike other log aggregation systems, Loki is designed to be cost-effective and easy to operate by not indexing the contents of logs, but rather a set of labels for each log stream.\nThis analysis explores Loki as a potential log storage backend for the BattleBots platform, focusing on its architecture, deployment options, OTLP compatibility, and integration with the OpenTelemetry Collector.\nWhy Research Loki? For the BattleBots observability stack, Loki offers several compelling advantages:\nNative OTLP Support: Loki v3+ provides native OTLP ingestion endpoints, enabling seamless integration with the OpenTelemetry Collector Cost-Effective Storage: Index-free approach dramatically reduces storage costs compared to full-text indexing systems Horizontal Scalability: Microservices architecture supports scaling from development to production workloads Grafana Integration: Tight integration with Grafana provides unified visualization of logs, metrics, and traces Cloud-Native Design: Built for containerized environments with Kubernetes-first deployment patterns Document Structure The Loki analysis is organized into the following documents:\nLoki Overview Comprehensive overview covering architecture, deployment, and operational best practices.\nTopics covered:\nWhat is Loki and its design philosophy (index-free, label-based querying) Core concepts: streams, labels, chunks, index, LogQL Architecture components: distributor, ingester, querier, compactor Deployment modes: monolithic, simple scalable, microservices How to run Loki with Docker/Podman Compose for POC Best practices for label strategy and configuration When to use Loki vs. alternatives like Elasticsearch Audience: Everyone—provides foundational understanding for evaluating Loki as a log backend.\nOTLP Integration Deep dive into OTLP compatibility and OpenTelemetry Collector integration.\nTopics covered:\nNative OTLP support in Loki v3+ (endpoints, configuration) OTel Collector otlphttp exporter setup Resource attribute mapping to Loki labels Log-trace correlation via TraceID/SpanID Complete working configuration examples Authentication and multi-tenancy Troubleshooting common integration issues Audience: Developers and operators implementing the OTel Collector to Loki pipeline.\nBattleBots Integration Context For the BattleBots platform, Loki would serve as the centralized log storage backend, receiving logs from the OpenTelemetry Collector via OTLP. This enables:\nGame Event Logging Battle events (bot actions, damage calculations, victory conditions) Game state transitions and timing information Player actions and command processing Error conditions and system anomalies Infrastructure Logging Container logs from game servers System logs from host infrastructure Application logs from Go services Network and security logs Unified Observability Log-trace correlation through shared TraceID/SpanID Linking log events to metrics and distributed traces Grafana dashboards combining logs, metrics, and traces Streamlined debugging workflows across all telemetry signals Decision Context This research will inform the upcoming ADR-NNNN: Observability Stack Selection, which will determine the log storage backend for BattleBots. Key decision factors include:\nFunctional fit: Does Loki meet log storage, query, and correlation requirements? Operational complexity: How difficult is it to deploy, monitor, and maintain Loki? Cost: What are the infrastructure and operational costs at POC and production scale? Integration: How well does it integrate with OTel Collector, Grafana, and the broader observability stack? External Resources Grafana Loki Official Documentation Loki GitHub Repository Grafana Labs Blog CNCF Loki Project ","categories":"","description":"Research and analysis of Grafana Loki log aggregation system for the BattleBots observability stack.\n","excerpt":"Research and analysis of Grafana Loki log aggregation system for the …","ref":"/battlebots/pr-preview/pr-153/research_and_development/analysis/observability/logs/loki/","tags":"","title":"Grafana Loki"},{"body":"Overview Grafana Mimir is a horizontally scalable, highly available, multi-tenant, long-term storage solution for Prometheus metrics. It transforms Prometheus’s single-server architecture into a distributed microservices platform capable of handling over 1 billion active time series with unlimited retention.\nThis analysis explores Mimir as the metrics storage backend for the BattleBots platform, focusing on its architecture, native OTLP support, OpenTelemetry Collector integration, and operational characteristics.\nWhy Research Mimir? For the BattleBots observability stack, Mimir offers several compelling advantages over standalone Prometheus:\nNative OTLP Support: Direct ingestion via /otlp/v1/metrics endpoint since version 2.3.0, enabling seamless OpenTelemetry Collector integration without protocol translation Massive Scalability: Proven at 1 billion active time series (Grafana Labs internal testing) and 500 million series in production customer deployments Long-Term Storage: Object storage backend (S3, GCS, MinIO) enables months to years of retention at minimal cost compared to local disk storage Multi-Tenancy: Built-in tenant isolation with per-tenant limits, enabling future use cases like per-player metrics or per-battle analytics High Availability: 3x replication by default, distributed architecture, and automatic failover eliminate single points of failure Prometheus Compatibility: Full PromQL support ensures existing Prometheus queries, dashboards, and alerts work unchanged Document Structure The Mimir analysis is organized into the following documents:\nMimir Overview Comprehensive overview covering architecture, deployment modes, storage backends, and operational best practices.\nTopics covered:\nWhat is Mimir and its design philosophy (distributed Prometheus with object storage) Core concepts: blocks storage, time series, multi-tenancy, cardinality management Architecture components: distributor, ingester, querier, query-frontend, store-gateway, compactor, ruler Deployment modes: monolithic, read-write, microservices (with comparison table) How to run Mimir with Docker Compose and MinIO for POC environments Production deployment patterns with Kubernetes and Helm Best practices for label strategy, configuration, storage selection, and performance tuning When to use Mimir vs. Prometheus vs. Thanos (decision criteria matrix) Resource requirements and capacity planning guidance Complete configuration examples for all deployment modes Audience: Everyone—provides foundational understanding for evaluating Mimir as the metrics backend.\nOTLP Integration Deep dive into OTLP compatibility and OpenTelemetry Collector integration (addresses critical user requirements).\nTopics covered:\nNative OTLP support in Mimir (status, version requirements, endpoint configuration) OTLP vs. Prometheus remote write comparison and recommendations OpenTelemetry Collector otlphttp exporter configuration for Mimir Alternative: OpenTelemetry Collector prometheusremotewrite exporter setup Batch processor, retry policies, and queue management best practices Resource attribute mapping from OTel to Mimir labels Label strategy and cardinality control for OTel-generated metrics Authentication and multi-tenancy setup with X-Scope-OrgID headers Complete working configuration examples (OTel Collector + Mimir + Grafana) Troubleshooting common integration issues (connection errors, cardinality, performance) BattleBots-specific integration patterns and example queries Audience: Developers and operators implementing the OpenTelemetry Collector to Mimir pipeline.\nBattleBots Integration Context For the BattleBots platform, Mimir would serve as the centralized metrics storage backend, receiving metrics from the OpenTelemetry Collector via native OTLP ingestion. This enables:\nGame Metrics Storage Bot Performance: Action latency, damage calculations, movement speed, resource utilization per bot Battle Events: Start/end times, player actions, victory conditions, matchmaking metrics Game State: Active battles count, queued players, concurrent users, session durations Quality Metrics: Frame rates, tick rates, network latency, synchronization quality Infrastructure Metrics Container Metrics: CPU/memory usage, restart counts, health checks for bot containers and game servers Kubernetes Metrics: Pod status, node utilization, deployment health, scaling events Network Metrics: Request rates, latency distributions, error rates, bandwidth consumption Host Metrics: System-level CPU, memory, disk I/O, network traffic across infrastructure Observability Stack Metrics OpenTelemetry Collector: Pipeline throughput, batch sizes, queue depths, export success/failure rates Loki (Log Storage): Log ingestion rates, query latency, storage utilization Tempo (Trace Storage): Span ingestion, trace completeness, sampling rates Mimir Self-Monitoring: Ingester series counts, query performance, compaction status, object storage health Long-Term Analytics Capacity Planning: Historical resource usage trends to predict scaling needs Cost Optimization: Identify underutilized resources and optimize allocation Performance Baselines: Establish normal behavior patterns for anomaly detection Business Intelligence: Player engagement metrics, battle frequency, peak usage times Decision Context This research will inform the upcoming ADR-NNNN: Observability Stack Selection, which will determine the metrics storage backend for BattleBots. Key decision factors specific to Mimir include:\nScalability Requirements: Can Mimir handle expected growth from POC (thousands of series) to production (millions+ of series)? OTLP Integration: Does native OTLP support simplify the OpenTelemetry Collector integration compared to alternatives? Operational Complexity: Is the team prepared to operate a distributed metrics system, or should we start with standalone Prometheus? Cost vs. Value: Do Mimir’s features (long-term storage, scalability, multi-tenancy) justify the increased infrastructure cost and complexity? Migration Path: If starting with Prometheus, how difficult is migration to Mimir when scale demands it? The ADR will also consider alternative approaches:\nStandalone Prometheus: Simpler but limited to ~10M series and short retention Thanos: Similar capabilities to Mimir with different architectural trade-offs Managed Services: Grafana Cloud or other hosted Prometheus-compatible solutions External Resources Grafana Mimir Official Documentation Mimir GitHub Repository Grafana Mimir Blog Mimir Capacity Calculator OpenTelemetry Metrics to Mimir Guide Prometheus Remote Write Specification ","categories":"","description":"Research and analysis of Grafana Mimir metrics storage system for the BattleBots observability stack.\n","excerpt":"Research and analysis of Grafana Mimir metrics storage system for the …","ref":"/battlebots/pr-preview/pr-153/research_and_development/analysis/observability/metrics/mimir/","tags":"","title":"Grafana Mimir"},{"body":"Overview Grafana Tempo is a high-volume, minimal dependency distributed tracing backend designed for cost-efficiency and operational simplicity. Unlike traditional tracing systems that require complex database infrastructure, Tempo uses object storage as its only dependency, dramatically reducing operational complexity while providing powerful trace querying through TraceQL.\nThis analysis explores Tempo as the distributed tracing backend for the BattleBots platform, focusing on its architecture, native OTLP support, OpenTelemetry Collector integration, and integration with the broader Grafana observability stack (Loki, Mimir, Prometheus).\nWhy Research Tempo? For the BattleBots observability stack, Tempo offers several compelling advantages:\nNative OTLP Support: Full support for OTLP/gRPC (port 4317) and OTLP/HTTP (port 4318) protocols, enabling seamless integration with the OpenTelemetry Collector Cost-Effective Storage: Object storage-only design (S3, GCS, Azure, MinIO) eliminates expensive database infrastructure and reduces storage costs by 10x or more compared to Jaeger or Zipkin Minimal Dependencies: No Cassandra, Elasticsearch, or other complex databases required—only object storage Horizontal Scalability: Microservices architecture supports scaling from development to production workloads handling millions of spans per second TraceQL Query Language: Powerful SQL-like query language for filtering and analyzing traces by span attributes, duration, and relationships Grafana Integration: Seamless correlation with metrics (Mimir/Prometheus) and logs (Loki) through exemplars and trace IDs for unified observability Multi-Protocol Support: Accepts OTLP, Jaeger, Zipkin, and OpenCensus formats, enabling gradual migration from legacy tracing systems Document Structure The Tempo analysis is organized into the following documents:\nTempo Overview Comprehensive overview covering architecture, deployment modes, and operational best practices.\nTopics covered:\nWhat is Tempo and its design philosophy (index-free, object storage-based tracing) Core concepts: traces, spans, blocks storage, TraceQL, sampling strategies Architecture components: distributor, ingester, querier, query-frontend, compactor, metrics-generator Deployment modes: monolithic, scalable, microservices (with comparison table) How to run Tempo with Docker Compose for POC environments Best practices for sampling, storage optimization, and performance tuning When to use Tempo vs. Jaeger vs. Zipkin (decision criteria matrix) Resource requirements and capacity planning guidance Complete configuration examples with Grafana data source setup Audience: Everyone—provides foundational understanding for evaluating Tempo as the tracing backend.\nOTLP Integration Deep dive into OTLP compatibility and OpenTelemetry Collector integration (addresses critical user requirements).\nTopics covered:\nNative OTLP support in Tempo (status: YES since v1.3.0+, endpoint configuration) OTLP/gRPC and OTLP/HTTP protocol support and when to use each OpenTelemetry Collector otlp and otlphttp exporter configuration for Tempo Batch processor, retry policies, and queue management best practices Resource attribute mapping and span attribute strategies Sampling configuration (head-based, tail-based) in the OTel Collector Authentication and multi-tenancy setup with X-Scope-OrgID headers Complete working configuration examples (OTel Collector + Tempo + Grafana) Troubleshooting common integration issues (connection errors, missing traces) BattleBots-specific integration patterns and TraceQL query examples Audience: Developers and operators implementing the OpenTelemetry Collector to Tempo pipeline.\nBattleBots Integration Context For the BattleBots platform, Tempo would serve as the centralized distributed tracing backend, receiving traces from the OpenTelemetry Collector via OTLP. This enables:\nBattle Workflow Tracing Complete Battle Flow: Trace entire battle lifecycle from matchmaking → battle initialization → game loop execution → victory condition → results persistence Bot Action Traces: Track individual bot actions (move, attack, defend) with timing, success/failure, and resource costs State Transitions: Capture game state changes with span events marking key transitions (battle start, bot death, timer expiration) Latency Analysis: Identify performance bottlenecks in action processing, state synchronization, and event broadcasting Request Flow Tracing API Requests: Trace HTTP/gRPC requests from client → API gateway → game service → persistence layer WebSocket Connections: Track WebSocket connection lifecycle, authentication, and message flow Service Interactions: Visualize calls between microservices (matchmaking service → game server manager → bot runtime) External Dependencies: Monitor calls to external services (authentication, leaderboards, analytics) Error Investigation Exception Tracking: Capture stack traces and error context through span events Failure Propagation: Trace error propagation across service boundaries to identify root causes Timeout Analysis: Identify services or operations exceeding latency SLAs Retry Patterns: Visualize retry behavior and backoff strategies Unified Observability Trace-to-Logs Correlation: Link traces to logs via TraceID/SpanID for detailed debugging context Trace-to-Metrics Correlation: Use exemplars to jump from metric spikes to example slow traces Grafana Dashboards: Combine traces, metrics (Mimir), and logs (Loki) in unified visualizations Root Cause Analysis: Start with metric alert → find exemplar trace → examine correlated logs Performance Optimization Latency Profiling: Identify slow database queries, external API calls, or computational bottlenecks Resource Utilization: Correlate trace duration with CPU/memory metrics for capacity planning Sampling Strategies: Implement tail sampling to capture all errors and slow requests while reducing trace volume TraceQL Analysis: Query for patterns like “all traces with database latency \u003e 100ms” or “errors in bot action processing” Decision Context This research will inform the upcoming ADR-NNNN: Observability Stack Selection, which will determine the distributed tracing backend for BattleBots. Key decision factors specific to Tempo include:\nCost Efficiency: Does Tempo’s object storage-only design provide sufficient cost savings to justify its adoption over traditional tracing backends? OTLP Integration: Does native OTLP support simplify the OpenTelemetry Collector integration compared to alternatives requiring protocol translation? Search Trade-offs: Is Tempo’s trace-ID-first query model (with TraceQL for advanced queries) sufficient for BattleBots debugging workflows? Operational Complexity: Can the team operate Tempo with minimal infrastructure overhead compared to Jaeger (Cassandra/Elasticsearch) or Zipkin? Stack Integration: Does Tempo’s deep integration with Grafana, Loki, and Mimir provide enough value to justify adopting the full LGTM stack? Scalability: Can Tempo handle growth from POC (thousands of traces) to production (potentially millions of traces per day)? The ADR will also consider alternative approaches:\nJaeger: More mature with powerful tag-based search, but requires Cassandra or Elasticsearch and higher operational complexity Zipkin: Simpler but less scalable, requires database backend, limited query capabilities Elastic APM: Unified observability in Elasticsearch stack, but higher cost and complexity Managed Services: Grafana Cloud Tempo, Honeycomb, or Lightstep for reduced operational burden Related Observability Components Tempo completes the three-signal observability architecture alongside:\nGrafana Loki - Log aggregation and storage Grafana Mimir - Metrics storage and querying OpenTelemetry Collector - Telemetry data pipeline Together, these components form the LGTM stack (Loki, Grafana, Tempo, Mimir), providing unified observability with trace-metric-log correlation through exemplars and shared trace IDs.\nExternal Resources Grafana Tempo Official Documentation Tempo GitHub Repository TraceQL Query Language Reference Grafana Tempo Blog OpenTelemetry to Tempo Integration Guide Tempo Architecture Deep Dive LGTM Stack Overview ","categories":"","description":"Research and analysis of Grafana Tempo distributed tracing backend for the BattleBots observability stack.\n","excerpt":"Research and analysis of Grafana Tempo distributed tracing backend for …","ref":"/battlebots/pr-preview/pr-153/research_and_development/analysis/observability/traces/tempo/","tags":"","title":"Grafana Tempo"},{"body":"Overview This section contains research and analysis of log storage solutions for the BattleBots platform. Effective log storage is essential for:\nAggregating logs from distributed game servers and services Enabling fast search and filtering for debugging Correlating logs with traces and metrics for unified observability Long-term retention for compliance and historical analysis Cost-effective storage at scale Log Backend Options Grafana Loki Analysis of Grafana Loki, a horizontally scalable, multi-tenant log aggregation system optimized for storing and querying log data.\nLoki uses a unique index-free approach that indexes only metadata labels rather than full log content, significantly reducing storage and operational costs compared to traditional log aggregation systems.\nKey features include:\nNative OTLP support (Loki v3+) for seamless OpenTelemetry Collector integration Label-based querying through LogQL Efficient storage with compressed chunks Horizontal scalability and multi-tenancy Tight integration with Grafana for visualization Includes detailed analysis of:\nArchitecture and core concepts Deployment modes and how to run Loki OTLP compatibility and OTel Collector integration Best practices for running and operating Loki Future Analysis Additional log backend options may be researched based on BattleBots requirements:\nElasticsearch/OpenSearch - Full-text search capabilities Cloud-native options - AWS CloudWatch Logs, Google Cloud Logging Self-hosted alternatives - ClickHouse, Vector Related Documentation R\u0026D Documentation OpenTelemetry Collector Analysis - Log collection and processing Observability Analysis - Overall observability strategy Future ADR on observability stack selection External Resources Grafana Loki Documentation OpenTelemetry Documentation CNCF Observability Projects ","categories":"","description":"Research and analysis of log storage backends for the BattleBots observability stack.\n","excerpt":"Research and analysis of log storage backends for the BattleBots …","ref":"/battlebots/pr-preview/pr-153/research_and_development/analysis/observability/logs/","tags":"","title":"Log Storage Analysis"},{"body":"Overview Grafana Loki introduced native OpenTelemetry Protocol (OTLP) support in version 3.0, marking a significant advancement in how logs can be ingested into Loki. This native integration allows applications instrumented with OpenTelemetry to send logs directly to Loki using the standardized OTLP format, eliminating the need for format transformations and simplifying the observability pipeline.\nThe native OTLP endpoint provides a fully OpenTelemetry-compliant ingestion path where logs sent in OTLP format are stored directly in Loki without requiring conversion to JSON or logfmt blobs. This approach leverages Loki’s structured metadata feature, which stores log attributes and other OpenTelemetry LogRecord fields separately from the log body itself. The result is a more intuitive query experience and better performance, as queries no longer need to parse JSON at runtime to access fields.\nFor the BattleBots observability stack, native OTLP integration offers several advantages: unified telemetry collection across logs, metrics, and traces through the OpenTelemetry Collector; simplified configuration compared to legacy exporters; better correlation between logs and traces through preserved TraceId and SpanId fields; and vendor portability, making it easier to migrate between observability backends without changing instrumentation.\nOTLP Support in Loki Answer: YES - Loki versions 3.0 and later natively support the OpenTelemetry Protocol (OTLP) for log ingestion.\nNative OTLP Endpoint Loki exposes an OTLP-compliant endpoint at /otlp that accepts OpenTelemetry log data. When clients send logs to this endpoint, the collector automatically appends the appropriate path suffix (/v1/logs), resulting in requests to /otlp/v1/logs.\nSupported Protocols:\nHTTP: POST requests using HTTP/1.1 or HTTP/2 gRPC: Unary RPC calls using the OTLP service definition Default Port:\nLoki typically runs on port 3100 for all HTTP endpoints, including OTLP Version Requirements Minimum Loki Version: 3.0 or later\nSchema Requirements:\nSchema version: v13 or higher (required for structured metadata) Index type: tsdb (Time Series Database index required) Structured metadata is essential for OTLP ingestion because it stores the OpenTelemetry LogRecord fields (resource attributes, instrumentation scope, log attributes) separately from the log body. Without schema v13 and tsdb, Loki cannot properly handle OTLP data.\nBenefits of Native OTLP vs Legacy Loki Exporter The legacy lokiexporter component in the OpenTelemetry Collector encoded logs as JSON or logfmt blobs with Loki-specific label conventions. The native OTLP endpoint provides several improvements:\nSimplified Querying: No JSON parsing required at query time. Instead of {job=\"dev/auth\"} | json | severity=\"INFO\", you can query directly: {service_name=\"auth\"} | severity_text=\"INFO\"\nCleaner Log Bodies: The log message is stored as-is rather than wrapped in a JSON structure. A log “user logged in” is stored exactly as that string, with metadata in structured fields.\nStandard Resource Labels: Uses OpenTelemetry semantic conventions (service_name, service_namespace) instead of custom labels (job=service.namespace/service.name)\nBetter Performance: Structured metadata allows efficient filtering without parsing the entire log body\nVendor Portability: Standard OTLP configuration works across multiple backends without Loki-specific hints\nFuture-Proof: The native endpoint represents Grafana’s strategic direction for log ingestion\nOTLP Endpoint Configuration To enable OTLP ingestion in Loki, you must configure structured metadata support and optionally customize which resource attributes become index labels.\nEnabling Structured Metadata Structured metadata is enabled by default in Loki 3.0+, but you should explicitly configure it in your limits:\nlimits_config: allow_structured_metadata: true max_structured_metadata_entries_count: 128 # Maximum metadata entries per log record Schema Configuration Your Loki schema must use version 13 or higher with the tsdb index:\nschema_config: configs: - from: \"2024-04-01\" store: tsdb object_store: s3 # or filesystem, gcs, azure, etc. schema: v13 index: prefix: loki_index_ period: 24h Complete Loki Configuration Example Here’s a complete Loki configuration with OTLP support enabled:\nauth_enabled: false server: http_listen_port: 3100 grpc_listen_port: 9096 log_level: info common: path_prefix: /loki storage: filesystem: chunks_directory: /loki/chunks rules_directory: /loki/rules replication_factor: 1 ring: kvstore: store: inmemory schema_config: configs: - from: \"2024-04-01\" store: tsdb object_store: filesystem schema: v13 index: prefix: loki_index_ period: 24h limits_config: allow_structured_metadata: true max_structured_metadata_entries_count: 128 reject_old_samples: true reject_old_samples_max_age: 168h ingestion_rate_mb: 10 ingestion_burst_size_mb: 20 per_stream_rate_limit: 5MB per_stream_rate_limit_burst: 15MB # OTLP-specific configuration otlp_config: resource_attributes: # Configure which resource attributes become index labels attributes_config: - action: index_label attributes: - service.name - service.namespace - deployment.environment - k8s.cluster.name - k8s.namespace.name - cloud.region - cloud.provider # Convert high-cardinality attributes to structured metadata - action: structured_metadata attributes: - k8s.pod.name - service.instance.id - process.pid storage_config: tsdb_shipper: active_index_directory: /loki/tsdb-index cache_location: /loki/tsdb-cache filesystem: directory: /loki/chunks compactor: working_directory: /loki/compactor compaction_interval: 10m retention_enabled: true retention_delete_delay: 2h retention_delete_worker_count: 150 querier: max_concurrent: 4 query_scheduler: max_outstanding_requests_per_tenant: 4096 frontend: max_outstanding_per_tenant: 4096 OTel Collector Export Configuration Answer: YES - The OpenTelemetry Collector can export logs to Loki using the otlphttp exporter.\nBasic OTLP HTTP Exporter The recommended exporter for Loki is otlphttp/logs:\nexporters: otlphttp/logs: endpoint: \"http://loki:3100/otlp\" tls: insecure: true # For local development without TLS Important: Do not append /v1/logs to the endpoint URL. The OTLP exporter automatically adds the appropriate path suffix.\nComplete Exporter Configuration Here’s a production-ready configuration with retry, timeout, and queue settings:\nexporters: otlphttp/logs: endpoint: \"http://loki:3100/otlp\" # TLS Configuration tls: insecure: false ca_file: /etc/ssl/certs/loki-ca.crt cert_file: /etc/ssl/certs/client.crt key_file: /etc/ssl/private/client.key min_version: \"1.2\" # Timeout for individual requests (default: 30s recommended) timeout: 30s # Retry configuration retry_on_failure: enabled: true initial_interval: 5s # Time to wait before first retry max_interval: 30s # Maximum backoff interval max_elapsed_time: 300s # Give up after 5 minutes # Queue configuration for reliability sending_queue: enabled: true num_consumers: 10 queue_size: 5000 storage: file_storage # Reference to file_storage extension for persistence # Compression (gzip recommended for production) compression: gzip # Headers (for authentication, multi-tenancy) headers: X-Scope-OrgID: \"battlebots\" File Storage Extension for Persistence To persist queued logs across collector restarts, configure the file storage extension:\nextensions: file_storage: directory: /var/lib/otelcol/file_storage timeout: 10s service: extensions: [file_storage] pipelines: logs: receivers: [otlp] processors: [batch] exporters: [otlphttp/logs] Batch Processor Configuration Always include a batch processor before the exporter to optimize throughput:\nprocessors: batch: timeout: 10s # Send batch after this duration send_batch_size: 8192 # Send when batch reaches this size send_batch_max_size: 16384 # Never exceed this size Complete Service Pipeline service: extensions: [file_storage] pipelines: logs: receivers: [otlp, filelog] processors: [resource_detection, batch, attributes] exporters: [otlphttp/logs] Resource Attribute Mapping When logs arrive via OTLP, resource attributes from the OpenTelemetry SDK map to either index labels or structured metadata in Loki.\nDefault Resource Attributes as Index Labels By default, Loki converts these 17 resource attributes to index labels:\nservice.name → service_name service.namespace → service_namespace service.instance.id → service_instance_id deployment.environment → deployment_environment cloud.region → cloud_region cloud.availability_zone → cloud_availability_zone cloud.platform → cloud_platform k8s.cluster.name → k8s_cluster_name k8s.namespace.name → k8s_namespace_name k8s.pod.name → k8s_pod_name k8s.container.name → k8s_container_name container.name → container_name k8s.replicaset.name → k8s_replicaset_name k8s.deployment.name → k8s_deployment_name k8s.statefulset.name → k8s_statefulset_name k8s.daemonset.name → k8s_daemonset_name k8s.cronjob.name → k8s_cronjob_name Note: Attribute names with dots (.) are converted to underscores (_) for Loki label compatibility.\nAttribute Transformation in Collector To add or modify resource attributes before sending to Loki:\nprocessors: resource: attributes: # Add static attributes - key: deployment.environment value: production action: insert # Copy attributes with character transformations - key: service_name from_attribute: service.name action: insert # Delete attributes you don't want - key: telemetry.sdk.version action: delete attributes: actions: # Add log-level attributes - key: environment value: production action: insert # Extract correlation IDs from log body - key: correlation_id pattern: \"correlation_id=([a-z0-9-]+)\" action: extract Example Attribute to Label Mapping Input (OpenTelemetry SDK):\n{ \"resource\": { \"attributes\": { \"service.name\": \"game-server\", \"service.namespace\": \"battlebots\", \"deployment.environment\": \"production\", \"k8s.pod.name\": \"game-server-5d7c8f9b-xq2wr\", \"k8s.namespace.name\": \"battlebots-prod\" } } } Output (Loki Labels):\n{ service_name=\"game-server\", service_namespace=\"battlebots\", deployment_environment=\"production\", k8s_namespace_name=\"battlebots-prod\" } Note: k8s.pod.name should be converted to structured metadata (see Label Strategy section).\nLabel Strategy and Best Practices Loki’s performance depends heavily on proper label cardinality management. Every unique combination of label values creates a new stream, and too many streams degrade performance significantly.\nAvoiding High Cardinality Issues Problem: High cardinality causes Loki to build a huge index and flush thousands of tiny chunks to object storage, resulting in poor performance and high costs.\nHigh-Cardinality Attributes (Avoid as Labels):\nk8s.pod.name - Each pod instance creates a new label value service.instance.id - Each service instance is unique process.pid - Changes on every process restart User IDs, request IDs, transaction IDs Timestamps, UUIDs, hashes Which Attributes to Use as Labels Good Label Candidates (Low Cardinality):\nservice.name - Limited number of services service.namespace - Few namespaces (dev, staging, prod) deployment.environment - Usually 3-5 values k8s.cluster.name - Fixed cluster names k8s.namespace.name - Limited namespaces per cluster cloud.region - Fixed set of regions log.severity or severity_text - Limited severity levels Cardinality Rule of Thumb: Keep total stream count under 10,000. With 5 labels averaging 10 values each, you get 10^5 = 100,000 streams (too many). Reduce to 3-4 labels with controlled values.\nWhich Attributes to Keep as Structured Metadata Configure high-cardinality attributes as structured metadata:\nlimits_config: otlp_config: resource_attributes: attributes_config: - action: structured_metadata attributes: - k8s.pod.name - service.instance.id - process.pid - process.command_line - host.id Structured metadata remains queryable but doesn’t create new streams:\n{service_name=\"game-server\"} | k8s_pod_name=\"game-server-5d7c8f9b-xq2wr\" Recommended Label Strategy for BattleBots limits_config: otlp_config: resource_attributes: attributes_config: # Index labels (low cardinality) - action: index_label attributes: - service.name - service.namespace - deployment.environment - k8s.namespace.name - cloud.region # Structured metadata (high cardinality or optional) - action: structured_metadata attributes: - k8s.pod.name - k8s.container.name - service.instance.id - host.name - process.pid Expected Cardinality:\nservice.name: ~10 services (game-server, matchmaker, auth, etc.) service.namespace: 1 value (battlebots) deployment.environment: 3 values (dev, staging, production) k8s.namespace.name: ~5 namespaces cloud.region: ~3 regions Total streams: 10 × 1 × 3 × 5 × 3 = 450 streams (excellent)\nLog-Trace Correlation OpenTelemetry’s unified data model enables seamless correlation between logs and traces through TraceId and SpanId fields embedded in log records.\nTraceID and SpanID Storage When applications instrumented with OpenTelemetry SDKs emit logs within a trace context, the SDK automatically includes:\nTraceId: Unique identifier for the entire trace SpanId: Unique identifier for the current span TraceFlags: Sampling and other flags Loki stores these fields as structured metadata, making them queryable without parsing the log body.\nQuerying Logs by Trace ID Find all logs for a specific trace:\n{service_name=\"game-server\"} | trace_id=\"4bf92f3577b34da6a3ce929d0e0e4736\" Find logs with any trace context:\n{service_name=\"game-server\"} | trace_id != \"\" Find logs for a specific span:\n{service_name=\"game-server\"} | span_id=\"00f067aa0ba902b7\" Grafana Integration for Correlation Configure Grafana data source correlations to link Loki and Tempo:\nLoki Data Source Configuration:\n{ \"derivedFields\": [ { \"datasourceUid\": \"tempo-uid\", \"matcherRegex\": \"trace_id=(\\\\w+)\", \"name\": \"TraceID\", \"url\": \"${__value.raw}\" } ] } This creates clickable trace ID links in the Grafana Explore view, allowing you to:\nView a log entry in Loki Click the trace ID link Jump directly to the full trace in Tempo See the complete request flow with timing information Example Correlation Workflow Scenario: Investigating a slow game server response\nStart with metrics: Notice elevated response times in Prometheus metrics Query slow traces: Find traces with duration \u003e 1s in Tempo Jump to logs: Click trace ID to see all logs for that request Identify root cause: Read detailed error messages and debug logs Correlate with resources: Use k8s_pod_name metadata to check pod health Query pattern:\n{service_name=\"game-server\"} | trace_id=\"4bf92f3577b34da6a3ce929d0e0e4736\" | severity_text=\"ERROR\" Authentication \u0026 Multi-tenancy Loki supports both basic authentication and multi-tenant deployments for OTLP ingestion.\nBasic Authentication Setup Collector Configuration with Basic Auth:\nextensions: basicauth/otlp: client_auth: username: \"battlebots-collector\" password: \"${LOKI_PASSWORD}\" # Use environment variable exporters: otlphttp/logs: endpoint: \"http://loki:3100/otlp\" auth: authenticator: basicauth/otlp service: extensions: [basicauth/otlp] pipelines: logs: receivers: [otlp] processors: [batch] exporters: [otlphttp/logs] Loki Configuration with Basic Auth:\nConfigure authentication in your reverse proxy (nginx, Envoy) or API gateway rather than directly in Loki:\nlocation /otlp { auth_basic \"Loki OTLP Endpoint\"; auth_basic_user_file /etc/nginx/.htpasswd; proxy_pass http://loki:3100; } Multi-tenant Headers For multi-tenant Loki deployments, use the X-Scope-OrgID header to specify the tenant:\nexporters: otlphttp/logs: endpoint: \"http://loki:3100/otlp\" headers: X-Scope-OrgID: \"battlebots-production\" Dynamic Tenant Selection:\nRoute different services to different tenants using the resource processor:\nprocessors: resource: attributes: - key: loki.tenant from_attribute: deployment.environment action: insert exporters: otlphttp/logs: endpoint: \"http://loki:3100/otlp\" headers: X-Scope-OrgID: \"${LOKI_TENANT}\" Loki Multi-tenancy Configuration:\nauth_enabled: true limits_config: # Per-tenant rate limits ingestion_rate_mb: 10 ingestion_burst_size_mb: 20 # Per-tenant OTLP configuration per_tenant_override_config: /etc/loki/overrides.yaml Per-tenant overrides (/etc/loki/overrides.yaml):\noverrides: battlebots-production: ingestion_rate_mb: 50 retention_period: 720h # 30 days battlebots-staging: ingestion_rate_mb: 20 retention_period: 168h # 7 days TLS Configuration Collector with TLS:\nexporters: otlphttp/logs: endpoint: \"https://loki.battlebots.example.com/otlp\" tls: insecure: false ca_file: /etc/ssl/certs/ca-bundle.crt cert_file: /etc/ssl/certs/collector-client.crt key_file: /etc/ssl/private/collector-client.key min_version: \"1.3\" server_name_override: loki.battlebots.example.com Loki TLS Configuration:\nserver: http_listen_port: 3100 grpc_listen_port: 9096 http_tls_config: cert_file: /etc/loki/tls/server.crt key_file: /etc/loki/tls/server.key client_auth_type: RequireAndVerifyClientCert client_ca_file: /etc/loki/tls/ca.crt Complete Configuration Example This section provides a full, working configuration for integrating OpenTelemetry Collector with Loki OTLP.\nFull OpenTelemetry Collector Configuration # /etc/otelcol/config.yaml extensions: health_check: endpoint: 0.0.0.0:13133 pprof: endpoint: 0.0.0.0:1777 zpages: endpoint: 0.0.0.0:55679 file_storage: directory: /var/lib/otelcol/file_storage timeout: 10s receivers: otlp: protocols: grpc: endpoint: 0.0.0.0:4317 http: endpoint: 0.0.0.0:4318 filelog: include: - /var/log/battlebots/*.log include_file_path: true include_file_name: false operators: - type: json_parser timestamp: parse_from: attributes.time layout: '%Y-%m-%dT%H:%M:%S.%fZ' processors: resourcedetection: detectors: [env, system, docker, kubernetes] timeout: 5s resource: attributes: - key: deployment.environment value: production action: insert - key: service.namespace value: battlebots action: insert attributes: actions: - key: loki.attribute.labels value: severity_text, service_name action: insert batch: timeout: 10s send_batch_size: 8192 send_batch_max_size: 16384 memory_limiter: check_interval: 1s limit_mib: 512 spike_limit_mib: 128 exporters: otlphttp/logs: endpoint: \"http://loki:3100/otlp\" tls: insecure: true timeout: 30s retry_on_failure: enabled: true initial_interval: 5s max_interval: 30s max_elapsed_time: 300s sending_queue: enabled: true num_consumers: 10 queue_size: 5000 storage: file_storage compression: gzip headers: X-Scope-OrgID: \"battlebots\" debug: verbosity: detailed sampling_initial: 5 sampling_thereafter: 200 service: extensions: [health_check, pprof, zpages, file_storage] pipelines: logs: receivers: [otlp, filelog] processors: [memory_limiter, resourcedetection, resource, attributes, batch] exporters: [otlphttp/logs] telemetry: logs: level: info metrics: address: 0.0.0.0:8888 Full Loki Configuration with OTLP # /etc/loki/config.yaml auth_enabled: false server: http_listen_port: 3100 grpc_listen_port: 9096 log_level: info common: path_prefix: /loki storage: filesystem: chunks_directory: /loki/chunks rules_directory: /loki/rules replication_factor: 1 ring: kvstore: store: inmemory schema_config: configs: - from: \"2024-04-01\" store: tsdb object_store: filesystem schema: v13 index: prefix: loki_index_ period: 24h limits_config: allow_structured_metadata: true max_structured_metadata_entries_count: 128 reject_old_samples: true reject_old_samples_max_age: 168h ingestion_rate_mb: 50 ingestion_burst_size_mb: 100 per_stream_rate_limit: 10MB per_stream_rate_limit_burst: 20MB max_label_names_per_series: 15 otlp_config: resource_attributes: attributes_config: - action: index_label attributes: - service.name - service.namespace - deployment.environment - k8s.namespace.name - cloud.region - action: structured_metadata attributes: - k8s.pod.name - k8s.container.name - service.instance.id - host.name storage_config: tsdb_shipper: active_index_directory: /loki/tsdb-index cache_location: /loki/tsdb-cache filesystem: directory: /loki/chunks compactor: working_directory: /loki/compactor compaction_interval: 10m retention_enabled: true retention_delete_delay: 2h retention_delete_worker_count: 150 querier: max_concurrent: 4 query_scheduler: max_outstanding_requests_per_tenant: 4096 frontend: max_outstanding_per_tenant: 4096 Docker Compose Example version: '3.8' services: loki: image: grafana/loki:3.0.0 container_name: loki ports: - \"3100:3100\" - \"9096:9096\" volumes: - ./loki-config.yaml:/etc/loki/config.yaml - loki-data:/loki command: -config.file=/etc/loki/config.yaml networks: - battlebots-observability otel-collector: image: otel/opentelemetry-collector-contrib:0.96.0 container_name: otel-collector ports: - \"4317:4317\" # OTLP gRPC receiver - \"4318:4318\" # OTLP HTTP receiver - \"8888:8888\" # Metrics endpoint - \"13133:13133\" # Health check volumes: - ./otel-config.yaml:/etc/otelcol/config.yaml - /var/lib/otelcol:/var/lib/otelcol command: [\"--config=/etc/otelcol/config.yaml\"] depends_on: - loki networks: - battlebots-observability grafana: image: grafana/grafana:10.4.0 container_name: grafana ports: - \"3000:3000\" environment: - GF_SECURITY_ADMIN_PASSWORD=admin - GF_USERS_ALLOW_SIGN_UP=false volumes: - grafana-data:/var/lib/grafana - ./grafana-datasources.yaml:/etc/grafana/provisioning/datasources/datasources.yaml depends_on: - loki networks: - battlebots-observability volumes: loki-data: grafana-data: networks: battlebots-observability: driver: bridge Grafana Data Source Configuration # grafana-datasources.yaml apiVersion: 1 datasources: - name: Loki type: loki access: proxy url: http://loki:3100 jsonData: derivedFields: - datasourceUid: tempo matcherRegex: \"trace_id=(\\\\w+)\" name: TraceID url: \"$${__value.raw}\" Step-by-Step Setup Create configuration files:\nmkdir -p battlebots-observability cd battlebots-observability # Copy the configurations above into: # - loki-config.yaml # - otel-config.yaml # - grafana-datasources.yaml # - docker-compose.yaml Start the stack:\ndocker-compose up -d Verify Loki is running:\ncurl http://localhost:3100/ready # Expected: ready Verify OTel Collector is running:\ncurl http://localhost:13133 # Expected: {\"status\":\"Server available\"} Send test logs:\ncurl -X POST http://localhost:4318/v1/logs \\ -H \"Content-Type: application/json\" \\ -d '{ \"resourceLogs\": [{ \"resource\": { \"attributes\": [{ \"key\": \"service.name\", \"value\": {\"stringValue\": \"test-service\"} }] }, \"scopeLogs\": [{ \"logRecords\": [{ \"timeUnixNano\": \"1640000000000000000\", \"severityText\": \"INFO\", \"body\": {\"stringValue\": \"Test log message\"} }] }] }] }' Query logs in Grafana:\nOpen http://localhost:3000 Login with admin/admin Navigate to Explore Select Loki data source Query: {service_name=\"test-service\"} Troubleshooting Connection Errors Problem: Collector cannot connect to Loki OTLP endpoint\nSymptoms:\nerror exporting items: failed to push logs: Post \"http://loki:3100/otlp/v1/logs\": dial tcp: lookup loki: no such host Solutions:\nVerify Loki is running: curl http://loki:3100/ready Check DNS resolution: nslookup loki (or use IP address) Verify network connectivity: telnet loki 3100 Check Docker network configuration if using containers Verify endpoint URL doesn’t include /v1/logs suffix Problem: 404 Not Found on OTLP endpoint\nSymptoms:\nerror exporting items: failed to push logs: HTTP 404 Not Found Solutions:\nVerify Loki version is 3.0 or later: curl http://loki:3100/loki/api/v1/status/buildinfo Check schema version is v13 in Loki config Verify allow_structured_metadata: true in limits_config Restart Loki after configuration changes Label Cardinality Problems Problem: Too many streams causing performance degradation\nSymptoms:\nlevel=warn msg=\"stream limit exceeded\" limit=10000 streams=15234 Solutions:\nReview current label cardinality:\ncurl http://localhost:3100/loki/api/v1/label Check value distribution per label:\ncurl http://localhost:3100/loki/api/v1/label/service_name/values Move high-cardinality attributes to structured metadata:\nlimits_config: otlp_config: resource_attributes: attributes_config: - action: structured_metadata attributes: - k8s.pod.name - service.instance.id Set cardinality limits:\nlimits_config: max_label_names_per_series: 15 max_label_value_length: 2048 max_label_name_length: 1024 Structured Metadata Issues Problem: Structured metadata not appearing in queries\nSymptoms: Attributes missing from log entries in Grafana\nSolutions:\nVerify schema version 13 or higher Check allow_structured_metadata: true in limits Verify attributes aren’t being dropped by processors Query with explicit structured metadata filter: {service_name=\"game-server\"} | k8s_pod_name=\"pod-123\" Performance Issues Problem: Slow queries or high memory usage\nSymptoms: Grafana queries timeout or Loki OOM errors\nSolutions:\nEnable query limits:\nlimits_config: max_query_series: 500 max_query_lookback: 720h max_entries_limit_per_query: 5000 Optimize batch processor:\nprocessors: batch: timeout: 5s # Reduce for faster flushing send_batch_size: 4096 # Smaller batches Add memory limiter:\nprocessors: memory_limiter: check_interval: 1s limit_mib: 512 Use query acceleration:\nlimits_config: bloom_gateway_enable_filtering: true Debugging Techniques Enable debug logging in Collector:\nexporters: debug: verbosity: detailed service: pipelines: logs: receivers: [otlp] processors: [batch] exporters: [debug, otlphttp/logs] # Add debug exporter telemetry: logs: level: debug # Collector internal logs Enable debug logging in Loki:\nserver: log_level: debug Check Loki metrics:\ncurl http://localhost:3100/metrics | grep loki_distributor Verify OTLP data structure:\n# Send test log and capture response curl -v -X POST http://localhost:4318/v1/logs \\ -H \"Content-Type: application/json\" \\ -d @test-log.json BattleBots Integration Points Observability Stack Architecture The Loki OTLP integration fits into the BattleBots observability stack as follows:\nGame Servers (Go) └─\u003e OpenTelemetry SDK └─\u003e OTLP/gRPC (4317) └─\u003e OTel Collector ├─\u003e Loki (Logs via OTLP) ├─\u003e Tempo (Traces via OTLP) └─\u003e Prometheus (Metrics via OTLP) └─\u003e Grafana (Visualization \u0026 Correlation) Collector → Loki Pipeline for Game Servers Recommended pipeline configuration:\nReceive logs from game servers via OTLP Detect resource attributes (Kubernetes, cloud provider) Add BattleBots-specific labels (environment, service namespace) Filter out verbose debug logs in production Batch and compress for efficiency Export to Loki via OTLP HTTP Log Types and Labeling Strategy Game Event Logs:\nLabels: service_name: \"game-server\" service_namespace: \"battlebots\" deployment_environment: \"production\" event_type: \"game_event\" # Custom label Structured Metadata: match_id: \"uuid\" player_count: 4 game_mode: \"elimination\" System Logs:\nLabels: service_name: \"game-server\" service_namespace: \"battlebots\" deployment_environment: \"production\" log_type: \"system\" Structured Metadata: k8s_pod_name: \"game-server-abc123\" severity_text: \"ERROR\" Client Connection Logs:\nLabels: service_name: \"game-server\" service_namespace: \"battlebots\" deployment_environment: \"production\" Structured Metadata: client_id: \"uuid\" connection_state: \"connected\" trace_id: \"trace-id\" # For correlation Example Queries for BattleBots Find all errors in production:\n{service_namespace=\"battlebots\", deployment_environment=\"production\"} | severity_text=\"ERROR\" Find logs for a specific match:\n{service_name=\"game-server\"} | match_id=\"550e8400-e29b-41d4-a716-446655440000\" Find all logs related to a slow trace:\n{service_namespace=\"battlebots\"} | trace_id=\"4bf92f3577b34da6a3ce929d0e0e4736\" Count game events by type:\nsum by (event_type) ( count_over_time({service_name=\"game-server\"}[5m]) ) Further Reading OTLP Specification OpenTelemetry Protocol Specification - Complete OTLP specification OTLP Logs Data Model - OpenTelemetry logs data model OTLP Exporter Configuration - SDK configuration guide Grafana Loki OTLP Documentation Ingesting logs to Loki using OpenTelemetry Collector - Official Loki OTLP guide Getting started with OTel Collector and Loki - Step-by-step tutorial Native OTLP vs Loki Exporter - Migration guide Loki 3.0 Release Notes - Features announcement Migration to Native OTLP Format - Cloud migration guide OpenTelemetry Collector Documentation Collector Configuration - General configuration guide Collector Resiliency - Retry and queue configuration Configuration Best Practices - Security and performance Exporter Helper Documentation - Retry and queue details Loki Configuration and Operations Understanding Labels - Label strategy guide Structured Metadata - Structured metadata overview Loki Schema Configuration - Schema v13 setup Upgrade to Loki 3.0 - Migration instructions Grafana Integration Trace Integration in Explore - Log-trace correlation Trace Correlations - Setting up correlations Configure Loki Data Source - Data source configuration Community Guides and Tutorials Grafana Loki 101: Ingesting with OTel Collector - Official blog tutorial Building a Logging Pipeline with OTel, Loki, and Grafana - Docker Compose guide Logging with OpenTelemetry and Loki - Practical implementation Efficient Application Log Collection - Analysis guide Troubleshooting and Best Practices OTel Batching Best Practices - Batch configuration Collector Persistence and Retry - Deep dive Label Cardinality Issues - Common problems and solutions Related BattleBots Documentation OpenTelemetry Collector: Logs Support - Collector log processing OpenTelemetry Collector: Overview - Collector architecture ","categories":"","description":"Detailed guide for integrating Grafana Loki with OpenTelemetry Collector via native OTLP support.\n","excerpt":"Detailed guide for integrating Grafana Loki with OpenTelemetry …","ref":"/battlebots/pr-preview/pr-153/research_and_development/analysis/observability/logs/loki/loki-otlp-integration/","tags":"","title":"Loki: OTLP Integration"},{"body":"Overview Grafana Loki is a horizontally-scalable, highly-available, multi-tenant log aggregation system designed to be cost-effective and easy to operate. Inspired by Prometheus, Loki takes a fundamentally different approach to log storage compared to traditional systems like Elasticsearch.\nThe core innovation of Loki is its index-free architecture: instead of indexing the full contents of log lines, Loki only indexes metadata labels for each log stream. This design dramatically reduces storage costs, memory requirements, and operational complexity while still enabling fast queries through label-based filtering and grep-style text search.\nLoki integrates seamlessly with Grafana for visualization, supports native OTLP ingestion (v3+), and works alongside Prometheus and Tempo to provide a complete observability stack. The system is built for cloud-native environments with first-class support for Kubernetes, containerized workloads, and distributed architectures.\nKey Concepts Understanding Loki’s data model is essential for effective deployment and usage.\nStreams A stream is the fundamental data structure in Loki, representing a sequence of log entries that share the same set of labels. Each unique combination of labels creates a new stream. For example:\n{app=\"battleserver\", env=\"prod\", region=\"us-east\"} {app=\"battleserver\", env=\"prod\", region=\"us-west\"} {app=\"matchmaker\", env=\"prod\", region=\"us-east\"} These three label sets create three distinct streams. All log entries with identical labels are appended to the same stream in chronological order.\nLabels Labels are key-value pairs that categorize and identify log streams. Labels are the only metadata indexed by Loki, making label design the most critical aspect of Loki deployment.\nLabels should be:\nLow cardinality: Use labels that have bounded, predictable values (e.g., environment, service, host) Descriptive: Represent the source or context of logs (e.g., namespace, pod, container) Static: Avoid labels that change frequently or have unique values per log entry Anti-pattern: Using high-cardinality values like user IDs, trace IDs, or timestamps as labels will severely degrade performance.\n# Good label design (low cardinality) {service=\"game-server\", environment=\"production\", region=\"us-east-1\"} # Bad label design (high cardinality) {trace_id=\"abc123\", user_id=\"user456\", timestamp=\"2025-12-03T10:00:00Z\"} Loki recommends keeping total stream count below 10,000 for small deployments and under 100,000 active streams for larger deployments.\nChunks Chunks are compressed blocks of log data from a single stream. As logs arrive for a stream, the ingester accumulates them in memory, then periodically flushes completed chunks to object storage.\nKey chunk characteristics:\nContain only data from a single stream Compressed using LZ4 or Snappy Stored in object storage (S3, GCS, MinIO, filesystem) Typically span minutes to hours of log data Subject to configurable size and time limits The chunk format optimizes for sequential reads, making time-range queries efficient.\nIndex The index stores the mapping between label sets and their corresponding chunks. Unlike full-text indexes, Loki’s index only contains:\nLabel names and values Chunk references (location, time range) Stream metadata This minimal indexing approach is what makes Loki cost-effective. The index is stored separately from chunks, typically in a different backend (BoltDB, TSDB).\nLogQL LogQL is Loki’s query language, inspired by Prometheus’s PromQL. LogQL queries have two stages:\nLog stream selection: Filter streams using label matchers Log pipeline: Parse, filter, and transform selected log lines # Select streams, then filter log content {service=\"game-server\"} |= \"error\" | json | level=\"ERROR\" # Aggregate metrics from logs rate({service=\"game-server\"} |= \"battle completed\" [5m]) # Multi-stage pipeline with parsing and filtering {namespace=\"battlebots\"} | json | line_format \"{{.message}}\" | pattern `\u003c_\u003e level=\u003clevel\u003e \u003c_\u003e` | level = \"error\" LogQL supports metric queries, allowing you to generate time-series data from logs (e.g., error rates, request counts).\nArchitecture Components Loki uses a microservices architecture where each component can be scaled independently or combined into larger deployment targets.\ngraph TB A[Log Clients\u003cbr/\u003ePromtail/Alloy/Fluentd] --\u003e|Push logs| B[Distributor] B --\u003e|Replicate| C1[Ingester 1] B --\u003e|Replicate| C2[Ingester 2] B --\u003e|Replicate| C3[Ingester N] C1 \u0026 C2 \u0026 C3 --\u003e|Flush chunks| D[Object Storage\u003cbr/\u003eS3/GCS/MinIO] C1 \u0026 C2 \u0026 C3 --\u003e|Update index| E[Index Store\u003cbr/\u003eBoltDB/TSDB] F[Grafana/API] --\u003e|Query| G[Query Frontend] G --\u003e|Split queries| H[Querier] H --\u003e|Read recent| C1 \u0026 C2 \u0026 C3 H --\u003e|Read historical| D H --\u003e|Read index| E I[Compactor] --\u003e|Compact| D I --\u003e|Update| E J[Ruler] --\u003e|Evaluate rules| H J --\u003e|Store| D style B fill:#fff4e6 style C1 fill:#fff4e6 style C2 fill:#fff4e6 style C3 fill:#fff4e6 style G fill:#e1f5ff style H fill:#e1f5ff style I fill:#f3e5f5 style J fill:#e8f5e9 style D fill:#fce4ec style E fill:#fce4ec Distributor The distributor is the entry point for log ingestion. It receives log streams from clients (Promtail, Alloy, OTLP endpoints) and routes them to ingesters.\nResponsibilities:\nValidate incoming log streams for correctness and tenant limits Apply rate limiting per tenant Hash log streams by labels to determine target ingesters Replicate each stream to multiple ingesters (default: 3 replicas) Load balance across available ingesters Distributors are stateless and can be horizontally scaled to handle high ingestion rates.\nIngester The ingester receives log streams from distributors and is responsible for:\nBuffering logs in memory for each stream Building compressed chunks Flushing chunks to object storage periodically Writing index entries Serving queries for recent (unflushed) data Ingesters maintain an in-memory index of recent logs and use a write-ahead log (WAL) for crash recovery. Upon graceful shutdown, ingesters flush all buffered data to storage.\nIngesters are stateful and require careful scaling considerations. They use consistent hashing to distribute streams evenly across instances.\nQuerier The querier executes LogQL queries by:\nFetching index data to identify relevant chunks Retrieving chunks from object storage Querying ingesters for recent unflushed data Merging results from multiple sources Applying log pipeline operations (parsing, filtering) Returning results to the query frontend Queriers are stateless and can be scaled horizontally. They cache chunk data and index lookups to improve performance.\nQuery Frontend The query frontend sits in front of queriers and provides:\nQuery splitting: Breaks large time-range queries into smaller sub-queries Query queuing: Prevents overwhelming queriers during traffic spikes Caching: Stores query results to avoid redundant computation Fair scheduling: Ensures multiple tenants share query resources equitably The frontend is optional but highly recommended for production deployments. It significantly improves query performance and protects backend components from overload.\nCompactor The compactor is a background service that:\nMerges small chunks into larger ones to improve query performance Removes duplicate data from replicated writes Applies retention policies by deleting old data Updates index to reflect compacted chunks Only one compactor should run per tenant to avoid conflicts. The compactor is critical for long-term storage efficiency.\nRuler The ruler evaluates recording rules and alerting rules against stored logs:\nRuns LogQL queries on a schedule Generates derived metrics from log data Triggers alerts based on log patterns Stores rule evaluation results The ruler is optional and typically used for log-based alerting scenarios.\nIndex Gateway The index gateway (available in recent versions) centralizes index access:\nProvides a single point for index queries Reduces load on the index store Enables better caching of index data Simplifies index backend scaling This component is particularly useful with BoltDB index backends to avoid direct file access from multiple queriers.\nDeployment Modes Loki supports three deployment modes, each balancing simplicity against scalability and operational flexibility.\nMonolithic Mode In monolithic mode, all Loki components run in a single process. This is the simplest deployment option.\nConfiguration:\nloki -target=all -config.file=loki-config.yaml Characteristics:\nSingle binary or container All components share memory and resources Minimal operational complexity Limited horizontal scalability Suitable for development and small deployments When to use:\nDevelopment and testing environments Proof-of-concept deployments Small-scale production (\u003c100GB/day log ingestion) Single-server deployments Limitations:\nCannot scale components independently Single point of failure Resource contention between components Limited to vertical scaling (bigger instances) Simple Scalable Deployment (SSD) Simple scalable deployment groups components into three logical targets: read, write, and backend.\nTargets:\nRead (-target=read): Query Frontend, Querier Write (-target=write): Distributor, Ingester Backend (-target=backend): Compactor, Ruler, Index Gateway Configuration example:\n# Write path (3 replicas for high availability) loki -target=write -config.file=loki-config.yaml # Read path (scale based on query load) loki -target=read -config.file=loki-config.yaml # Backend (single instance) loki -target=backend -config.file=loki-config.yaml Characteristics:\nSeparates read and write paths Independent scaling of ingestion vs queries Easier to operate than full microservices Supports ~1TB/day log ingestion When to use:\nMedium-scale production deployments When you need to scale reads and writes independently Kubernetes environments using Helm charts Teams wanting operational simplicity with scalability This is the recommended starting point for most production deployments.\nMicroservices Mode Microservices mode runs each Loki component as a separate deployment, providing maximum flexibility.\nComponents:\nDistributor (multiple instances) Ingester (multiple instances, stateful) Querier (multiple instances) Query Frontend (multiple instances) Compactor (single instance per tenant) Ruler (multiple instances) Index Gateway (multiple instances) Characteristics:\nEach component scaled independently Fine-grained resource allocation Most complex to deploy and maintain Supports enterprise-scale deployments (multi-TB/day) When to use:\nVery large Loki clusters (\u003e1TB/day) Organizations requiring precise control over scaling Multi-tenant SaaS deployments Teams with dedicated Loki operations expertise Considerations:\nSignificantly higher operational complexity More components to monitor and maintain Requires sophisticated orchestration (Kubernetes) Network communication overhead between components How to Run Loki This section provides practical guidance for running Loki, focusing on Docker/Podman Compose for POC and development.\nQuick Start with Docker Compose The simplest way to evaluate Loki is using the official Docker Compose example.\nStep 1: Create directory and download configurations\nmkdir loki-poc \u0026\u0026 cd loki-poc # Download Loki configuration wget https://raw.githubusercontent.com/grafana/loki/main/examples/getting-started/loki-config.yaml # Download Alloy (log shipper) configuration wget https://raw.githubusercontent.com/grafana/loki/main/examples/getting-started/alloy-local-config.yaml # Download Docker Compose file wget https://raw.githubusercontent.com/grafana/loki/main/examples/getting-started/docker-compose.yaml Step 2: Review the Docker Compose file\nThe compose file includes:\nLoki (monolithic mode) Grafana (for visualization) Grafana Alloy (log collection agent) flog (log generator for testing) Step 3: Start the stack\ndocker compose up -d Step 4: Verify deployment\n# Check Loki readiness curl http://localhost:3100/ready # Check Loki metrics curl http://localhost:3100/metrics # Access Grafana # URL: http://localhost:3000 # Default credentials: admin / admin Step 5: Query logs\nIn Grafana, navigate to Explore and select the Loki datasource to query logs using LogQL.\nBasic Configuration File Structure A minimal Loki configuration for local development:\nauth_enabled: false server: http_listen_port: 3100 grpc_listen_port: 9096 common: instance_addr: 127.0.0.1 path_prefix: /tmp/loki storage: filesystem: chunks_directory: /tmp/loki/chunks rules_directory: /tmp/loki/rules replication_factor: 1 ring: kvstore: store: inmemory schema_config: configs: - from: 2020-10-24 store: tsdb object_store: filesystem schema: v13 index: prefix: index_ period: 24h limits_config: reject_old_samples: true reject_old_samples_max_age: 168h max_cache_freshness_per_query: 10m split_queries_by_interval: 15m query_range: align_queries_with_step: true cache_results: true ruler: alertmanager_url: http://localhost:9093 This configuration uses local filesystem storage and is suitable for development only.\nProduction Configuration with MinIO For a more production-like setup using MinIO as object storage:\nDocker Compose with MinIO:\nversion: \"3.8\" services: minio: image: minio/minio:latest entrypoint: - sh - -euc - | mkdir -p /data/loki-data minio server /data --console-address :9001 environment: - MINIO_ROOT_USER=loki - MINIO_ROOT_PASSWORD=supersecret - MINIO_PROMETHEUS_AUTH_TYPE=public ports: - \"9000:9000\" - \"9001:9001\" volumes: - minio-data:/data loki: image: grafana/loki:3.0.0 ports: - \"3100:3100\" volumes: - ./loki-config.yaml:/etc/loki/config.yaml command: -config.file=/etc/loki/config.yaml depends_on: - minio grafana: image: grafana/grafana:latest ports: - \"3000:3000\" environment: - GF_AUTH_ANONYMOUS_ENABLED=true - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin volumes: - grafana-data:/var/lib/grafana volumes: minio-data: grafana-data: Loki configuration with MinIO:\nauth_enabled: false server: http_listen_port: 3100 grpc_listen_port: 9096 common: instance_addr: 127.0.0.1 path_prefix: /loki storage: s3: endpoint: minio:9000 bucketnames: loki-data access_key_id: loki secret_access_key: supersecret s3forcepathstyle: true insecure: true replication_factor: 1 ring: kvstore: store: inmemory schema_config: configs: - from: 2024-01-01 store: tsdb object_store: s3 schema: v13 index: prefix: index_ period: 24h limits_config: ingestion_rate_mb: 10 ingestion_burst_size_mb: 20 max_global_streams_per_user: 10000 max_query_length: 721h max_query_parallelism: 16 max_streams_per_user: 0 max_cache_freshness_per_query: 10m query_range: align_queries_with_step: true cache_results: true results_cache: cache: embedded_cache: enabled: true max_size_mb: 100 frontend: encoding: protobuf compress_responses: true max_outstanding_per_tenant: 2048 chunk_store_config: max_look_back_period: 0s table_manager: retention_deletes_enabled: true retention_period: 336h Resource Requirements Minimum requirements for development/POC:\nCPU: 2 cores Memory: 4 GB RAM Storage: 20 GB (filesystem) or object storage bucket Recommended production requirements (simple scalable mode):\nWrite path (per instance):\nCPU: 4-8 cores Memory: 8-16 GB RAM (for buffering chunks) Network: High bandwidth for ingestion Read path (per instance):\nCPU: 4-8 cores Memory: 16-32 GB RAM (for query caching) Network: High bandwidth for chunk retrieval Backend:\nCPU: 2-4 cores Memory: 4-8 GB RAM Storage: Object storage (S3, GCS, MinIO) with sufficient capacity for retention period Storage sizing:\nEstimate: ~5-10 GB/day per 1 million log lines (varies by compression ratio) Retention: storage_size = daily_volume * retention_days Index: ~1-2% of total chunk storage Getting Started Steps Choose deployment mode: Start with monolithic for POC, plan for simple scalable in production Set up object storage: MinIO for local dev, S3/GCS for production Configure Loki: Use appropriate schema version (v13 recommended) Deploy Loki: Docker Compose for POC, Helm for Kubernetes Configure log shippers: Alloy, Promtail, or OTLP endpoints Verify ingestion: Check /ready endpoint and metrics Set up Grafana: Add Loki datasource and create dashboards Test queries: Use LogQL to validate data retrieval Monitor Loki: Set up self-monitoring (metrics, logs, traces) Optimize configuration: Tune based on ingestion rate and query patterns Best Practices for Running Loki Successful Loki deployments depend on following these operational best practices.\nLabel Strategy 1. Keep labels low cardinality\nAim for 10-15 labels maximum across all streams. Each unique label combination creates a new stream.\n# Good: Low cardinality (bounded values) { service=\"game-server\", environment=\"production\", region=\"us-east-1\", cluster=\"battlebot-cluster-01\" } # Bad: High cardinality (unbounded values) { service=\"game-server\", trace_id=\"7a3f8c2d-4e5f-11ec-81d3-0242ac130003\", user_id=\"user_12345\", session_id=\"sess_67890\" } 2. Use static labels that describe log sources\nLabels should represent where logs come from, not what’s in them:\nnamespace, pod, container (Kubernetes) host, instance (infrastructure) service, application, component (application) environment, region, cluster (deployment context) 3. Avoid pod names and instance IDs as labels\nPod names and container IDs change frequently, creating stream churn:\n# Avoid {pod=\"game-server-abc123-xyz456\"} # Instead use {service=\"game-server\", namespace=\"battlebots\"} 4. Use filter expressions for high-cardinality data\nSearch for user IDs, trace IDs, or other high-cardinality values using LogQL filters:\n# Query for specific trace ID {service=\"game-server\"} |= \"trace_id=7a3f8c2d\" # Query for specific user {service=\"game-server\"} | json | user_id=\"12345\" 5. Use structured metadata for supplemental high-cardinality data\nLoki v2.9+ supports structured metadata, which stores high-cardinality data without indexing it:\n# Structured metadata (not indexed, not creating streams) labels: {service=\"game-server\"} structured_metadata: trace_id: \"7a3f8c2d-4e5f-11ec-81d3-0242ac130003\" user_id: \"user_12345\" 6. Monitor stream count\nUse Loki metrics to track stream cardinality:\n# Total active streams loki_ingester_memory_streams # Streams per tenant sum by (tenant) (loki_ingester_memory_streams) Keep total streams under 10,000 for small deployments, under 100,000 for larger deployments.\nConfiguration Tips 1. Set appropriate limits\nlimits_config: # Rate limiting ingestion_rate_mb: 10 # MB/s per tenant ingestion_burst_size_mb: 20 # Burst allowance # Stream limits max_global_streams_per_user: 10000 # Total active streams max_line_size: 256000 # Bytes per log line max_entries_limit_per_query: 5000 # Max returned entries # Query limits max_query_length: 721h # 30 days max_query_parallelism: 16 # Concurrent query threads # Retention reject_old_samples: true reject_old_samples_max_age: 168h # 7 days 2. Configure retention\nlimits_config: retention_period: 744h # 31 days table_manager: retention_deletes_enabled: true retention_period: 744h Note: Retention requires compactor to be running.\n3. Enable caching\nquery_range: align_queries_with_step: true cache_results: true results_cache: cache: embedded_cache: enabled: true max_size_mb: 500 chunk_store_config: chunk_cache_config: embedded_cache: enabled: true max_size_mb: 1000 4. Use TSDB index (v13 schema)\nThe TSDB index (schema v13) offers better performance than BoltDB:\nschema_config: configs: - from: 2024-01-01 store: tsdb # Use TSDB object_store: s3 schema: v13 # Latest schema index: prefix: index_ period: 24h 5. Configure appropriate chunk settings\ningester: chunk_idle_period: 30m # Flush idle chunks after 30 min chunk_block_size: 262144 # 256 KB blocks chunk_encoding: snappy # Compression algorithm chunk_retain_period: 15m # Retain flushed chunks in memory max_chunk_age: 1h # Max time before forced flush wal: enabled: true dir: /loki/wal Storage Considerations 1. Choose appropriate object storage\nDevelopment: Filesystem or MinIO Production AWS: S3 with lifecycle policies Production GCP: GCS with object versioning Production Azure: Azure Blob Storage On-premises: MinIO cluster or compatible S3 service 2. Configure object storage lifecycle\nReduce storage costs by transitioning older data to cheaper tiers:\n# AWS S3 lifecycle example - Id: TransitionOldChunks Status: Enabled Transitions: - Days: 30 StorageClass: STANDARD_IA - Days: 90 StorageClass: GLACIER 3. Separate index and chunk storage\nFor better performance, use different backends:\nschema_config: configs: - from: 2024-01-01 store: tsdb object_store: s3 # Chunks in S3 schema: v13 index: prefix: index_ period: 24h storage_config: tsdb_shipper: active_index_directory: /loki/index cache_location: /loki/index_cache shared_store: s3 # Index in S3 aws: s3: s3://us-east-1/loki-chunks bucketnames: loki-chunks 4. Monitor storage usage\nTrack storage metrics to plan capacity:\n# Chunk storage rate rate(loki_ingester_chunk_stored_bytes_total[5m]) # Index entries created rate(loki_ingester_index_entries_total[5m]) Performance Tuning 1. Optimize ingestion\nUse batching in log shippers (Promtail, Alloy) Enable compression for network transport Scale distributors horizontally for high write load Scale ingesters based on stream count and retention 2. Optimize queries\nUse specific label matchers to reduce streams searched Limit query time ranges Use query frontend for splitting and caching Add parallelism for large queries # Good: Specific label selector, limited time range {service=\"game-server\", environment=\"prod\"} |= \"error\" [5m] # Suboptimal: Broad selector, large time range {environment=\"prod\"} [24h] 3. Use bloom filters (experimental)\nBloom filters can speed up log line filtering:\nbloom_compactor: enabled: true bloom_gateway: enabled: true 4. Tune querier parallelism\nquerier: max_concurrent: 10 # Concurrent queries per querier query_timeout: 1m # Per-query timeout limits_config: max_query_parallelism: 16 # Parallel workers per query Common Pitfalls to Avoid 1. High-cardinality labels\nProblem: Using trace IDs, user IDs, or timestamps as labels creates millions of streams.\nSolution: Use structured metadata or filter expressions instead.\n2. Not monitoring stream count\nProblem: Stream count grows unbounded, degrading performance.\nSolution: Monitor loki_ingester_memory_streams and set alerts at thresholds.\n3. Insufficient ingester memory\nProblem: Ingesters crash or flush chunks too frequently.\nSolution: Allocate 8-16 GB RAM per ingester, adjust max_chunk_age and chunk_idle_period.\n4. No retention policy\nProblem: Storage costs grow unbounded.\nSolution: Configure retention_period and enable compactor.\n5. Querying too much data\nProblem: Queries time out or overload queriers.\nSolution: Use query frontend, limit time ranges, add specific label selectors.\n6. Single ingester (no replication)\nProblem: Data loss during ingester failure.\nSolution: Set replication_factor: 3 in production.\n7. Using filesystem storage in production\nProblem: Data loss, no scalability, no durability.\nSolution: Always use object storage (S3, GCS, MinIO) for production.\n8. Not using WAL\nProblem: In-memory data lost on ingester crash.\nSolution: Enable write-ahead log:\ningester: wal: enabled: true dir: /loki/wal When to Use Loki Ideal Use Cases 1. Cloud-native and Kubernetes environments\nLoki excels in containerized environments with:\nAutomatic label extraction from Kubernetes metadata Efficient handling of ephemeral infrastructure Native Prometheus integration for unified observability 2. Cost-sensitive deployments\nLoki’s index-free architecture dramatically reduces:\nStorage costs (5-10x cheaper than Elasticsearch) Memory requirements Operational overhead 3. Integration with existing Prometheus/Grafana stacks\nIf you already use Prometheus and Grafana:\nUnified visualization across logs, metrics, and traces Similar query language (LogQL ~ PromQL) Consistent operational model 4. High-volume log aggregation with simple queries\nLoki handles massive log volumes efficiently when:\nQueries primarily filter by labels and time ranges Full-text search is limited to known patterns Aggregation and metrics-from-logs are common use cases 5. Correlation between logs, metrics, and traces\nLoki enables:\nLog-trace correlation via TraceID/SpanID Metrics extraction from logs Unified observability workflows in Grafana 6. Multi-tenant logging platforms\nLoki’s built-in multi-tenancy supports:\nIsolated log streams per tenant Per-tenant rate limiting and retention Shared infrastructure with tenant isolation Anti-Patterns 1. Complex full-text search requirements\nLoki is not a replacement for Elasticsearch when you need:\nAdvanced full-text search across all log content Complex query DSL with scoring and relevance Frequent regex searches without label filtering Ad-hoc exploratory searches without known labels 2. Frequent high-cardinality queries\nAvoid Loki if you regularly need to:\nSearch by unique identifiers (user IDs, session IDs) as primary access pattern Query without label-based filtering Perform analytics on unbounded dimensions 3. Long-term analytics and data warehouse use cases\nLoki is optimized for recent data access, not:\nHistorical data mining over years of logs Complex joins between log datasets Business intelligence and reporting workflows 4. Transactional workloads\nLoki does not provide:\nACID guarantees Immediate consistency for queries Strong durability guarantees (eventual consistency model) Loki vs. Elasticsearch Comparison Aspect Loki Elasticsearch Indexing Labels only (metadata) Full-text indexing Storage cost Low (index-free) High (full indexes) Memory usage Low High Query performance Fast for label-based queries Fast for full-text search Setup complexity Low Medium-high Operational overhead Low High Search capabilities Label filtering + grep-style Advanced full-text, DSL Best for Cloud-native, Kubernetes, cost-sensitive Enterprise search, analytics Scalability Horizontal (microservices) Horizontal (cluster) Multi-tenancy Built-in Via indexes/namespaces Integration Grafana, Prometheus, Tempo Kibana, Elastic ecosystem Decision Factors Choose Loki when:\nCost efficiency is a priority You have well-defined label taxonomy Logs are primarily time-series access patterns You use Kubernetes and Prometheus Queries filter by known dimensions (service, environment) Integration with Grafana is important Choose Elasticsearch when:\nComplex full-text search is required Ad-hoc exploratory queries are common Advanced analytics and aggregations are needed You need enterprise search capabilities Budget allows for higher infrastructure costs Team has existing ELK expertise BattleBots Integration Points For the BattleBots platform, Loki would serve as the centralized log storage backend in the observability stack.\nHow Loki Fits in the Observability Stack graph TB A[Game Servers\u003cbr/\u003eGo Services] --\u003e|Logs| B[OTel Collector] C[Infrastructure\u003cbr/\u003eContainers] --\u003e|Logs| B D[Application\u003cbr/\u003eLibraries] --\u003e|Logs| B B --\u003e|OTLP/HTTP| E[Loki\u003cbr/\u003eDistributor] E --\u003e F[Loki\u003cbr/\u003eIngesters] F --\u003e G[Object Storage\u003cbr/\u003eS3/MinIO] H[Grafana] --\u003e|LogQL| I[Loki\u003cbr/\u003eQuery Frontend] I --\u003e J[Loki\u003cbr/\u003eQueriers] J --\u003e F J --\u003e G B --\u003e|Metrics| K[Prometheus/Mimir] B --\u003e|Traces| L[Tempo] H -.Unified View.-\u003e K H -.Unified View.-\u003e L style B fill:#fff4e6 style E fill:#e1f5ff style F fill:#e1f5ff style H fill:#e8f5e9 style K fill:#f3e5f5 style L fill:#fce4ec Game Event Logging Use Cases 1. Battle event timeline\nLog all significant battle events with consistent labels:\n{service=\"battle-server\", battle_id=\"battle_123\"} | json | line_format \"{{.timestamp}} [{{.event_type}}] {{.description}}\" Example logs:\n2025-12-03T10:00:00Z [battle_start] Battle battle_123 initialized 2025-12-03T10:00:05Z [bot_action] Bot bot_456 executed attack on bot_789 2025-12-03T10:00:06Z [damage_calc] Bot bot_789 took 15 damage 2025-12-03T10:00:10Z [victory] Bot bot_456 won battle battle_123 2. Game state transitions\nTrack game state changes with structured logging:\n{ \"timestamp\": \"2025-12-03T10:00:00Z\", \"service\": \"game-server\", \"level\": \"info\", \"message\": \"Game state transition\", \"game_id\": \"game_123\", \"previous_state\": \"waiting_for_players\", \"new_state\": \"in_progress\", \"player_count\": 4 } Query pattern:\n{service=\"game-server\"} | json | message=\"Game state transition\" | game_id=\"game_123\" 3. Error tracking and debugging\nCapture errors with correlation to traces:\n{ \"timestamp\": \"2025-12-03T10:00:15Z\", \"service\": \"matchmaker\", \"level\": \"error\", \"message\": \"Failed to assign player to match\", \"error\": \"queue timeout exceeded\", \"trace_id\": \"7a3f8c2d-4e5f-11ec-81d3-0242ac130003\", \"span_id\": \"8b4g9d3e-5f6g-22fd-92e4-1353bd241114\", \"player_id\": \"player_456\", \"queue_wait_time_ms\": 30000 } Query errors for a trace:\n{service=\"matchmaker\"} | json | trace_id=\"7a3f8c2d-4e5f-11ec-81d3-0242ac130003\" | level=\"error\" Server Log Aggregation Patterns 1. Label strategy for BattleBots\n# Standard labels for all services { service=\"battle-server\", # Service name environment=\"production\", # Deployment environment namespace=\"battlebots\", # Kubernetes namespace region=\"us-east-1\", # Deployment region version=\"v1.2.3\" # Application version } # Container-level labels (auto-discovered) { container=\"battle-server\", pod=\"battle-server-abc123-xyz456\", node=\"node-01\" } 2. Aggregating logs from multiple sources\n# All battle-related services {namespace=\"battlebots\"} | json | level=\"error\" # Specific service across all environments {service=\"matchmaker\"} | json # All production services in a region {environment=\"production\", region=\"us-east-1\"} | json 3. Metrics extraction from logs\nGenerate metrics from log data:\n# Battle completion rate rate({service=\"battle-server\"} |= \"battle completed\" [5m]) # Error rate by service sum by (service) (rate({namespace=\"battlebots\"} | json | level=\"error\" [5m])) # Average match duration avg_over_time({service=\"matchmaker\"} | json | unwrap duration_ms [5m]) Integration with OTel Collector Loki integrates with the OpenTelemetry Collector via native OTLP endpoints or exporters.\nOTel Collector configuration (brief example):\nexporters: otlphttp/loki: endpoint: http://loki:3100/otlp service: pipelines: logs: receivers: [otlp] processors: [batch, resourcedetection] exporters: [otlphttp/loki] For comprehensive OTel Collector integration details, see the dedicated Loki OTLP Integration document.\nFurther Reading Official Documentation Grafana Loki Documentation - Official documentation home Loki Architecture - Detailed architecture overview Loki Components - Component reference Loki Deployment Modes - Deployment mode comparison LogQL Language - Query language reference Label Best Practices - Label design guidelines Cardinality Management - Cardinality considerations Configuration Reference - Full configuration documentation Installation and Setup Install Loki with Docker - Docker and Docker Compose setup Quick Start Guide - Getting started tutorial Helm Installation - Kubernetes Helm charts Configure Storage - Storage backend configuration Best Practices and Guides How Labels Work in Loki - Label design deep dive The Concise Guide to Grafana Loki Labels - Comprehensive label guide Loki 2.4 Simple Scalable Deployment - Simple scalable mode introduction Grafana Loki Architecture Guide - Architecture deep dive Storage and Integration Using MinIO with Loki - MinIO integration guide Loki and MinIO Configuration - MinIO setup tutorial Storage Configuration - Storage backend options Comparisons and Decision Making Loki vs Elasticsearch - Detailed comparison Grafana Loki vs ELK Stack - Use case comparison Loki vs ELK: A Light Alternative - Lightweight alternative perspective Community and Source Code Loki GitHub Repository - Source code and issues Loki Examples - Configuration examples Grafana Community Forums - Community discussions Related BattleBots Documentation OpenTelemetry Collector Overview - OTel Collector architecture OTel Collector Logs - Log handling in OTel Collector Loki OTLP Integration - Detailed OTLP integration guide User Journey 0001: POC - Observability requirements ","categories":"","description":"Comprehensive overview of Grafana Loki log aggregation system, covering architecture, deployment modes, and operational best practices.\n","excerpt":"Comprehensive overview of Grafana Loki log aggregation system, …","ref":"/battlebots/pr-preview/pr-153/research_and_development/analysis/observability/logs/loki/loki-overview/","tags":"","title":"Loki: Overview"},{"body":"Overview Metrics storage is essential for the BattleBots platform’s observability infrastructure, enabling:\nReal-time monitoring of battle events and game state Historical analysis of bot performance and system behavior Capacity planning and infrastructure optimization Alerting on critical system conditions Long-term trend analysis and reporting The metrics storage backend must handle time-series data at scale, support efficient querying, and integrate seamlessly with the OpenTelemetry Collector to provide a unified observability platform alongside logs and traces.\nWhy Metrics Storage Matters for BattleBots The BattleBots platform generates metrics across multiple dimensions:\nGame Metrics Battle Events: Damage calculations, bot actions, victory conditions Performance Metrics: Bot response times, action execution latency Game State: Active battles, queued matches, player counts Resource Utilization: CPU, memory, and network usage per bot container Infrastructure Metrics Container Metrics: Resource usage, restart counts, health checks Host Metrics: Node-level CPU, memory, disk, and network utilization Network Metrics: Request rates, latency distributions, error rates Kubernetes Metrics: Pod status, deployments, scaling events Observability Stack Metrics OpenTelemetry Collector: Pipeline throughput, batch sizes, export success rates Log Storage: Ingestion rates, query performance, storage utilization Trace Storage: Span ingestion, sampling rates, trace completeness Components Grafana Mimir Research on Grafana Mimir, a horizontally scalable, highly available, multi-tenant metrics storage system built for long-term Prometheus data storage.\nMimir transforms Prometheus from a single-server monitoring system into a distributed platform capable of handling over 1 billion active time series, providing:\nNative OTLP Support: Direct integration with OpenTelemetry Collector via OTLP over HTTP Horizontal Scalability: Independent scaling of write path, read path, and backend components Long-Term Storage: Object storage backend (S3, GCS, MinIO) enables months to years of retention Multi-Tenancy: Built-in tenant isolation with per-tenant limits and resource controls High Availability: Replication and distributed architecture eliminate single points of failure PromQL Compatibility: Full Prometheus query language support for dashboards and alerts Includes detailed analysis of:\nArchitecture components and deployment modes Native OTLP ingestion and OpenTelemetry Collector integration Object storage backends and retention policies Multi-tenancy and cardinality management Comparison with Prometheus, Thanos, and Cortex Production deployment and operational best practices BattleBots Integration Context For the BattleBots platform, metrics storage serves as the foundation for understanding system behavior and performance:\nReal-Time Monitoring Monitor active battles and player engagement in real-time Alert on critical conditions (bot container failures, API errors, resource exhaustion) Track game server health and availability Identify performance degradation before user impact Historical Analysis Analyze battle outcome patterns and bot performance trends Capacity planning based on player growth and peak usage patterns Cost optimization through resource utilization analysis Root cause analysis for system incidents Unified Observability Metric-to-trace correlation through shared labels and exemplars Jumping from metric anomalies to related distributed traces Linking metrics to logs for comprehensive debugging Grafana dashboards combining metrics, logs, and traces in single views Example Metrics for BattleBots Bot Performance:\n# Bot action latency by bot type histogram_quantile(0.95, sum(rate(bot_action_duration_seconds_bucket{action=\"attack\"}[5m])) by (bot_type, le) ) # Bot health over time avg(bot_health_points) by (battle_id, bot_id) Infrastructure Health:\n# Container resource utilization container_memory_usage_bytes{namespace=\"battlebots\", container=\"game-server\"} / container_spec_memory_limit_bytes{namespace=\"battlebots\", container=\"game-server\"} # API request rate and errors sum(rate(http_requests_total{service=\"battle-api\"}[5m])) by (status_code) Game State:\n# Active battles sum(battles_active{environment=\"production\"}) # Player queue depth avg(player_queue_length) by (region) Decision Context This research will inform the upcoming ADR-NNNN: Observability Stack Selection, which will determine the metrics storage backend for BattleBots. Key decision factors include:\nFunctional Fit: Does the solution meet metrics storage, query, and correlation requirements? Scalability: Can it handle expected growth from POC to production scale? Integration: How well does it integrate with OpenTelemetry Collector, Grafana, and other observability components? Operational Complexity: What is the operational burden for deployment, monitoring, and maintenance? Cost: What are the infrastructure and operational costs at POC and production scale? Multi-Tenancy: Does it support per-player or per-battle isolation if needed? Related Documentation R\u0026D Documentation Observability Overview - Parent observability analysis section OpenTelemetry Collector Analysis - Metrics collection and processing Loki Analysis - Log storage for correlation with metrics User Journey 0001: POC - Observability requirements context Future ADRs on observability stack architecture External Resources Prometheus Documentation PromQL Query Language OpenTelemetry Metrics Specification Grafana Metrics Documentation Contributing These analysis documents are living documents that should be updated as:\nNew metrics storage solutions emerge or mature BattleBots observability requirements evolve Team members gain operational experience with metrics backends Best practices and patterns are discovered Comparative analysis reveals new insights Updates should maintain the high-level overview focus with links to authoritative sources for technical deep-dives.\n","categories":"","description":"Analysis of metrics storage backends for the BattleBots observability stack, focusing on systems that integrate with the OpenTelemetry Collector.\n","excerpt":"Analysis of metrics storage backends for the BattleBots observability …","ref":"/battlebots/pr-preview/pr-153/research_and_development/analysis/observability/metrics/","tags":"","title":"Metrics Storage"},{"body":"Overview This document provides comprehensive guidance on integrating Grafana Mimir with the OpenTelemetry Collector, addressing two critical questions:\nDoes Mimir work with OTLP? → YES - Native OTLP ingestion since version 2.3.0 Can it be integrated with the OTel Collector? → YES - Full integration via otlphttp or prometheusremotewrite exporters The integration enables a vendor-neutral observability pipeline where the OpenTelemetry Collector collects metrics from instrumented applications and forwards them to Mimir for long-term storage, querying, and alerting.\nWhy OTLP Matters for Metrics OpenTelemetry Protocol (OTLP) is the native protocol of the OpenTelemetry project, designed as a vendor-neutral standard for telemetry data transmission. Using OTLP with Mimir provides:\nFuture-Proof: OTLP is becoming the industry standard for telemetry data Simplified Pipeline: No protocol translation required (OTel → OTLP → Mimir) Resource Attributes: OTel resource attributes preserved in target_info metric Unified Stack: Same protocol for logs (Loki), metrics (Mimir), and traces (Tempo) Vendor Independence: Easy migration between OTLP-compatible backends Mimir’s Position in the OTLP Ecosystem Mimir acts as an OTLP-compatible metrics backend, receiving metrics via:\nPrimary Path: OpenTelemetry Collector → OTLP/HTTP → Mimir /otlp/v1/metrics endpoint Alternative Path: OpenTelemetry Collector → Prometheus Remote Write → Mimir /api/v1/push endpoint Both paths are fully supported, with OTLP recommended by Grafana for new deployments.\nOTLP Support in Mimir Native OTLP Support: YES Status: Grafana Mimir has native OTLP ingestion support.\nEndpoint: /otlp/v1/metrics\nVersion History:\nv2.3.0 (September 2022): OTLP support introduced (experimental) v2.15.0 (January 2025): OTLP support matured (no longer experimental) Removed experimental -distributor.direct-otlp-translation-enabled flag Added support for lz4 compression Added support for integer exemplar values v3.0.0 (October 2025): Additional OTLP enhancements Experimental -distributor.otel-translation-strategy flag for metric name translation Experimental -distributor.otel-native-delta-ingestion for native delta metric ingestion Protocol Support:\nOTLP over HTTP: Primary protocol (recommended) Encoding: Protocol Buffers Compression: GZIP and lz4 OTLP Endpoint Configuration Endpoint URL The OTLP endpoint in Mimir is:\nhttp://\u003cmimir-endpoint\u003e/otlp/v1/metrics Important: OpenTelemetry Collector clients automatically append /v1/metrics to the base path, so you only need to configure:\nhttp://\u003cmimir-endpoint\u003e/otlp Example Requests Using curl:\n# Send OTLP metrics to Mimir curl -X POST http://mimir:8080/otlp/v1/metrics \\ -H \"Content-Type: application/x-protobuf\" \\ -H \"X-Scope-OrgID: tenant-123\" \\ --data-binary @metrics.pb Using OpenTelemetry Collector:\nexporters: otlphttp: endpoint: http://mimir:8080/otlp headers: X-Scope-OrgID: tenant-123 OTLP Features Supported Metric Types:\n✅ Gauge: Point-in-time values ✅ Sum (Counter): Cumulative or delta monotonic sums ✅ Histogram: Distribution of values with buckets ⚠️ Exponential Histogram: Requires enabling Prometheus Native Histograms first ✅ Summary: Pre-computed quantiles (compatibility mode) Resource Attributes:\n✅ Promoted Attributes: Converted to Prometheus labels (e.g., service.name → service_name) ✅ Target Info: Non-promoted attributes stored in separate target_info metric ✅ Queryable: Use info() function or join queries to access resource attributes Exemplars:\n✅ Metric Exemplars: Link metrics to traces via trace_id and span_id ✅ Integer Values: Support for integer exemplar values (v2.15.0+) Compression:\n✅ GZIP: Standard compression ✅ lz4: Faster compression (v2.15.0+) OTLP vs. Prometheus Remote Write Both protocols are supported by Mimir. Here’s a detailed comparison:\nFeature OTLP Prometheus Remote Write Grafana Recommendation ✅ Recommended Alternative Resource Attributes ✅ Stored in target_info ❌ Lost during conversion Bandwidth Efficiency Moderate ✅ Better (remote write 2.0: 40% reduction) Native Protocol ✅ OpenTelemetry native Prometheus native Exponential Histograms Requires config N/A (not applicable) Protocol Maturity Mature (since v2.15.0) Very Mature Configuration Complexity Simple Simple Future-Proof ✅ Industry standard Prometheus ecosystem Official Recommendation from Grafana:\n“It’s recommended that you use the OpenTelemetry protocol (OTLP).”\nGrafana Mimir Documentation Why Use OTLP Over Prometheus Remote Write? Advantages of OTLP:\nResource Attributes Preserved: Mimir stores OTel resource attributes in target_info metric, enabling rich context Native OpenTelemetry: Direct protocol compliance without translation Future Development: Active OTLP feature development in each Mimir release Unified Observability: Same protocol for logs (Loki), metrics (Mimir), traces (Tempo) Vendor Neutrality: Easy migration between OTLP-compatible backends When to Use Prometheus Remote Write:\nBandwidth Critical: Remote write 2.0 saves 40% bandwidth vs. remote write 1.0 Existing Prometheus Infrastructure: Already using Prometheus remote write Compatibility Issues: If encountering specific OTLP compatibility issues (rare) For BattleBots: Use OTLP as the primary integration path for future-proof observability.\nKnown OTLP Limitations (Minor) Request Size Units: OTel Collector uses samples-per-batch, Mimir uses bytes-per-batch (alignment difficult) Exponential Histograms: Must enable Prometheus Native Histograms in Mimir first Out-of-Order Samples: No ordering guarantees (can cause issues with Prometheus’s ordered data expectations) Response Format: Error responses don’t fully comply with OTLP spec (returns plain string vs. Protobuf Status) These are minor edge cases that don’t affect typical deployments.\nOpenTelemetry Collector Configuration This section provides complete configuration examples for integrating the OpenTelemetry Collector with Mimir.\nArchitecture Overview graph LR subgraph \"Application\" App[Instrumented App\u003cbr/\u003eOpenTelemetry SDK] end subgraph \"Collection\" OTel[OpenTelemetry Collector] App --\u003e|OTLP| OTel end subgraph \"Processing\" OTel --\u003e Batch[Batch Processor] Batch --\u003e Resource[Resource Processor] end subgraph \"Storage\" Resource --\u003e|OTLP HTTP| Mimir[(Grafana Mimir)] end subgraph \"Visualization\" Grafana[Grafana] --\u003e Mimir end style OTel fill:#e1f5ff style Mimir fill:#fff4e1 style Grafana fill:#ffe0b2 Option 1: OTLP HTTP Exporter (Recommended) The otlphttp exporter sends metrics using the native OTLP over HTTP protocol.\nBasic Configuration receivers: otlp: protocols: grpc: endpoint: 0.0.0.0:4317 http: endpoint: 0.0.0.0:4318 processors: batch: send_batch_size: 8192 timeout: 10s exporters: otlphttp: endpoint: http://mimir:8080/otlp compression: gzip service: pipelines: metrics: receivers: [otlp] processors: [batch] exporters: [otlphttp] Production Configuration with Authentication extensions: basicauth: client_auth: username: ${MIMIR_USERNAME} password: ${MIMIR_PASSWORD} receivers: otlp: protocols: grpc: endpoint: 0.0.0.0:4317 http: endpoint: 0.0.0.0:4318 processors: memory_limiter: check_interval: 1s limit_mib: 512 spike_limit_mib: 128 batch: send_batch_size: 8192 timeout: 10s send_batch_max_size: 10000 resourcedetection: detectors: [env, system, docker, gcp, ec2, k8s] timeout: 5s override: false resource: attributes: - key: environment value: ${ENVIRONMENT} action: upsert - key: cluster value: ${CLUSTER_NAME} action: upsert exporters: otlphttp: auth: authenticator: basicauth endpoint: ${MIMIR_ENDPOINT}/otlp timeout: 30s compression: gzip retry_on_failure: enabled: true initial_interval: 5s max_interval: 30s max_elapsed_time: 300s sending_queue: enabled: true num_consumers: 10 queue_size: 5000 headers: X-Scope-OrgID: ${MIMIR_TENANT_ID} service: extensions: [basicauth] pipelines: metrics: receivers: [otlp] processors: [memory_limiter, resourcedetection, resource, batch] exporters: [otlphttp] Option 2: Prometheus Remote Write Exporter The prometheusremotewrite exporter sends metrics using the Prometheus Remote Write protocol.\nBasic Configuration receivers: otlp: protocols: http: endpoint: 0.0.0.0:4318 processors: batch: send_batch_size: 8192 timeout: 10s exporters: prometheusremotewrite: endpoint: http://mimir:8080/api/v1/push service: pipelines: metrics: receivers: [otlp] processors: [batch] exporters: [prometheusremotewrite] Production Configuration extensions: basicauth: client_auth: username: ${MIMIR_USERNAME} password: ${MIMIR_PASSWORD} receivers: otlp: protocols: grpc: endpoint: 0.0.0.0:4317 http: endpoint: 0.0.0.0:4318 processors: memory_limiter: check_interval: 1s limit_mib: 512 spike_limit_mib: 128 batch: send_batch_size: 8192 timeout: 10s send_batch_max_size: 10000 resourcedetection: detectors: [env, system, docker, gcp, ec2, k8s] resource: attributes: - key: environment value: ${ENVIRONMENT} action: upsert exporters: prometheusremotewrite: auth: authenticator: basicauth endpoint: ${MIMIR_ENDPOINT}/api/v1/push # External labels added to all metrics external_labels: cluster: ${CLUSTER_NAME} environment: ${ENVIRONMENT} # Resource to telemetry conversion resource_to_telemetry_conversion: enabled: true # Target info generation target_info: enabled: true # Retry configuration retry_on_failure: enabled: true initial_interval: 1s max_interval: 30s max_elapsed_time: 1800s # Queue configuration remote_write_queue: enabled: true queue_size: 10000 num_consumers: 5 # WAL (Write-Ahead Log) for durability wal: directory: /var/lib/otelcol/wal buffer_size: 300 truncate_frequency: 1m service: extensions: [basicauth] pipelines: metrics: receivers: [otlp] processors: [memory_limiter, resourcedetection, resource, batch] exporters: [prometheusremotewrite] Batch Processor Configuration The batch processor is CRITICAL for production deployments. It improves efficiency by batching metrics before export.\nRecommended Settings processors: batch: # Number of items to batch before sending send_batch_size: 8192 # Default, works for most cases # Maximum time to wait before sending (even if batch not full) timeout: 10s # Maximum batch size (safety valve) send_batch_max_size: 10000 # Maximum metadata keys per batch metadata_keys: 1000 # Maximum cardinality per metadata key metadata_cardinality_limit: 1000 Tuning Guidelines High-Throughput Deployments:\nprocessors: batch: send_batch_size: 16384 # 2x default timeout: 5s # Shorter timeout for lower latency send_batch_max_size: 20000 Low-Latency Requirements:\nprocessors: batch: send_batch_size: 1000 # Smaller batches timeout: 1s # Quick flush send_batch_max_size: 2000 Key Principles:\nAlways use batch processor before network-based exporters Place after memory_limiter in pipeline Balance latency vs. efficiency: Larger batches = better compression but higher latency Retry and Timeout Configuration Configure retry logic to handle transient failures:\nexporters: otlphttp: # Request timeout timeout: 30s # Retry configuration retry_on_failure: enabled: true initial_interval: 5s # Wait 5s before first retry max_interval: 30s # Cap exponential backoff at 30s max_elapsed_time: 300s # Give up after 5 minutes # Sending queue (buffer during retries) sending_queue: enabled: true num_consumers: 10 # Parallel export workers queue_size: 5000 # Buffer size Guidelines:\ninitial_interval: Start with 1-5 seconds (avoid retry storms) max_interval: Cap at 30-60 seconds (prevent infinite backoff) max_elapsed_time: 300s (5 min): Low-latency, loss-tolerant 1800s (30 min): Standard production 3600s+ (1+ hour): Critical data that cannot be lost num_consumers: More consumers = more parallel requests (ensure backend can handle load) queue_size: Balance memory vs. buffering capacity Resource Attribute Mapping OpenTelemetry resource attributes provide context about the source of metrics. Mimir handles these attributes through two mechanisms:\nPromoted Attributes Certain resource attributes are automatically converted to Prometheus labels:\nDefault Promoted Attributes:\nservice.namespace + service.name → job label service.instance.id → instance label Example:\n# OpenTelemetry resource attributes resource: service.namespace: \"battlebots\" service.name: \"battle-api\" service.instance.id: \"pod-abc123\" # Resulting Prometheus labels { job=\"battlebots/battle-api\", instance=\"pod-abc123\" } Target Info Metric Non-promoted resource attributes are stored in a separate target_info metric:\nExample:\n# OpenTelemetry resource attributes resource: service.name: \"battle-api\" service.version: \"v1.2.3\" k8s.namespace.name: \"battlebots\" k8s.pod.name: \"battle-api-abc123\" k8s.deployment.name: \"battle-api\" cloud.provider: \"aws\" cloud.region: \"us-east-1\" # target_info metric created target_info{ job=\"battle-api\", instance=\"pod-abc123\", service_version=\"v1.2.3\", k8s_namespace_name=\"battlebots\", k8s_pod_name=\"battle-api-abc123\", k8s_deployment_name=\"battle-api\", cloud_provider=\"aws\", cloud_region=\"us-east-1\" } 1 Querying with Resource Attributes Direct Query (promoted attributes):\nhttp_requests_total{job=\"battlebots/battle-api\"} Join Query (non-promoted attributes):\n# Join metric with target_info to access resource attributes http_requests_total * on(job, instance) group_left(k8s_namespace_name, k8s_pod_name) target_info Using info() Function (Prometheus 3.0+):\n# Simpler syntax for joining with target_info http_requests_total * info(target_info) Label Name Conversion Prometheus labels don’t support . or - characters. OpenTelemetry attributes are converted:\nservice.name → service_name k8s-cluster → k8s_cluster http.method → http_method Resource Processor for Attribute Transformation Use the resource processor to add, modify, or remove resource attributes:\nprocessors: resource: attributes: # Add new attribute - key: environment value: production action: insert # Update existing attribute - key: service.version value: v2.0.0 action: update # Insert or update (upsert) - key: cluster value: us-east-1-prod action: upsert # Rename attribute - key: cluster_name from_attribute: k8s.cluster.name action: insert # Delete attribute - key: sensitive.data action: delete # Extract with regex - key: environment pattern: ^(dev|staging|prod)-.*$ action: extract Resource Detection Processor Automatically detect resource attributes from the environment:\nprocessors: resourcedetection: # Ordered list of detectors (first match wins) detectors: [env, system, docker, gcp, ec2, azure, k8s] timeout: 5s override: false # Don't overwrite existing attributes # System detector configuration system: hostname_sources: [\"os\", \"dns\", \"cname\", \"lookup\"] # Docker detector docker: resource_attributes: host.name: enabled: true os.type: enabled: true # GCP detector gcp: resource_attributes: gcp.project.id: enabled: true cloud.platform: enabled: true cloud.region: enabled: true # Kubernetes detector k8s: resource_attributes: k8s.namespace.name: enabled: true k8s.pod.name: enabled: true k8s.deployment.name: enabled: true k8s.node.name: enabled: true Detected Attributes by Detector:\nDetector Attributes env Reads from OTEL_RESOURCE_ATTRIBUTES environment variable system host.name, host.id, host.arch, os.type docker host.name, os.type from Docker environment gcp cloud.provider, cloud.platform, cloud.region, gcp.project.id, gcp.gce.instance.id ec2 cloud.provider, cloud.platform, cloud.region, cloud.account.id, host.id, host.type azure cloud.provider, cloud.platform, cloud.region, azure.vm.name, azure.resourcegroup.name k8s k8s.namespace.name, k8s.pod.name, k8s.deployment.name, k8s.node.name, k8s.cluster.name Label Strategy and Cardinality Control Managing cardinality is critical when using OpenTelemetry with Mimir. High cardinality can cause performance issues and increased costs.\nUnderstanding Cardinality in OTel Context Every unique combination of metric name + label key-value pairs = one time series.\nLow Cardinality (Good):\n# Resource attributes service.name: \"battle-api\" # Limited number of services environment: \"production\" # 3 values: dev, staging, prod region: \"us-east-1\" # Limited AWS regions # Metric-level attributes http.method: \"GET\" # ~7 HTTP methods http.status_code: \"200\" # ~50 HTTP status codes # Total series per metric = 10 services × 3 environments × 5 regions × 7 methods × 50 status codes = 52,500 series (ACCEPTABLE) High Cardinality (Bad):\n# Adding unbounded attributes user.id: \"user-12345\" # Millions of users # New total series = 52,500 × 1,000,000 users = 52.5 billion series (UNSUSTAINABLE!) Cardinality Best Practices 1. Avoid Unbounded Resource Attributes:\nBad:\nresource: user.id: \"12345\" # Unbounded session.id: \"abc-def-ghi\" # Unbounded request.id: \"uuid-...\" # Unbounded timestamp: \"1634567890\" # Unbounded Good:\nresource: service.name: \"battle-api\" # Bounded environment: \"production\" # Bounded (3 values) region: \"us-east-1\" # Bounded (AWS regions) version: \"v1.2.3\" # Bounded (release versions) 2. Use Metric Attributes Sparingly:\nOpenTelemetry SDK allows setting attributes on individual metric data points. Use bounded sets only:\n// Good: Bounded attribute meter.NewInt64Counter(\"http.requests\", metric.WithDescription(\"HTTP requests\"), ).Add(ctx, 1, attribute.String(\"method\", \"GET\"), // ~7 values attribute.Int(\"status_code\", 200), // ~50 values ) // Bad: Unbounded attribute meter.NewInt64Counter(\"http.requests\").Add(ctx, 1, attribute.String(\"user_id\", userID), // Unbounded! ) 3. Drop High-Cardinality Attributes:\nUse the resource processor to remove problematic attributes:\nprocessors: resource: attributes: # Drop user-specific attributes - key: user.id action: delete - key: session.id action: delete - key: request.id action: delete 4. Aggregate Before Storing:\nFor user-specific metrics, aggregate at collection time:\n// Instead of per-user metrics: // user_requests{user_id=\"123\"} → High cardinality // Use aggregated metrics: // requests_by_service{service=\"api\"} → Low cardinality // Then query logs for user-specific debugging Attribute Transformation Strategies Strategy 1: Bounded Enumeration\nConvert unbounded values to bounded categories:\nprocessors: attributes: actions: # Convert specific status codes to categories - key: http.status_code action: update pattern: ^2\\d\\d$ value: \"2xx\" - key: http.status_code action: update pattern: ^4\\d\\d$ value: \"4xx\" - key: http.status_code action: update pattern: ^5\\d\\d$ value: \"5xx\" Strategy 2: Drop After Threshold\nOnly keep top N values, drop the rest:\nThis requires custom collector processing or accept all values with limits configured in Mimir:\n# Mimir limits limits: max_global_series_per_metric: 50000 # Cap per metric Recommended Labels for BattleBots Infrastructure Labels:\nresource: service.name: \"battle-api\" # Service name service.namespace: \"battlebots\" # Application namespace service.instance.id: \"pod-abc123\" # Pod/container ID service.version: \"v1.2.3\" # Release version deployment.environment: \"production\" # dev/staging/prod cloud.region: \"us-east-1\" # Geographic region k8s.cluster.name: \"us-east-1-prod\" # Cluster identifier k8s.namespace.name: \"battlebots\" # Kubernetes namespace Game-Specific Labels (metric-level attributes):\n# Battle events battle.type: \"team-deathmatch\" # Limited game modes bot.type: \"tank\" # Enumerable bot types game.region: \"us-east\" # Geographic game region # DO NOT USE AS LABELS: # battle.id: \"12345\" # If battles are long-lived and accumulate # player.id: \"user-abc\" # High cardinality # bot.id: \"bot-xyz\" # High cardinality if bots are per-player Estimated Cardinality:\nhttp_requests_total{ service_name: 10 services environment: 3 environments region: 5 regions method: 7 methods status_code: 50 codes endpoint: 50 endpoints battle_type: 5 game modes } = 1 × 10 × 3 × 5 × 7 × 50 × 50 × 5 = 13,125,000 series # Acceptable for Mimir Authentication and Multi-Tenancy Basic Authentication Use the basicauth extension for username/password authentication:\nextensions: basicauth: client_auth: username: ${MIMIR_USERNAME} password: ${MIMIR_PASSWORD} exporters: otlphttp: auth: authenticator: basicauth endpoint: http://mimir:8080/otlp service: extensions: [basicauth] pipelines: metrics: exporters: [otlphttp] Bearer Token Authentication Use the bearertoken extension for token-based auth:\nStatic Token:\nextensions: bearertoken: token: ${MIMIR_API_TOKEN} exporters: otlphttp: auth: authenticator: bearertoken endpoint: http://mimir:8080/otlp service: extensions: [bearertoken] pipelines: metrics: exporters: [otlphttp] Token from File (rotating tokens):\nextensions: bearertoken: filename: /var/run/secrets/mimir-token exporters: otlphttp: auth: authenticator: bearertoken endpoint: http://mimir:8080/otlp service: extensions: [bearertoken] pipelines: metrics: exporters: [otlphttp] Multi-Tenancy with X-Scope-OrgID Mimir uses the X-Scope-OrgID header for tenant identification:\nSingle Tenant:\nexporters: otlphttp: endpoint: http://mimir:8080/otlp headers: X-Scope-OrgID: \"tenant-production\" Multiple Tenants (separate pipelines):\nexporters: otlphttp/tenant1: endpoint: http://mimir:8080/otlp headers: X-Scope-OrgID: \"tenant-1\" otlphttp/tenant2: endpoint: http://mimir:8080/otlp headers: X-Scope-OrgID: \"tenant-2\" service: pipelines: metrics/tenant1: receivers: [otlp] processors: [batch] exporters: [otlphttp/tenant1] metrics/tenant2: receivers: [otlp] processors: [batch] exporters: [otlphttp/tenant2] Dynamic Tenant Routing:\nFor dynamic tenant routing based on resource attributes, use the routing processor:\nprocessors: routing: from_attribute: tenant.id default_exporters: [otlphttp/default] table: - value: \"tenant-1\" exporters: [otlphttp/tenant1] - value: \"tenant-2\" exporters: [otlphttp/tenant2] exporters: otlphttp/tenant1: endpoint: http://mimir:8080/otlp headers: X-Scope-OrgID: \"tenant-1\" otlphttp/tenant2: endpoint: http://mimir:8080/otlp headers: X-Scope-OrgID: \"tenant-2\" otlphttp/default: endpoint: http://mimir:8080/otlp headers: X-Scope-OrgID: \"default\" service: pipelines: metrics: receivers: [otlp] processors: [routing, batch] exporters: [otlphttp/tenant1, otlphttp/tenant2, otlphttp/default] TLS Configuration Enable TLS for secure communication:\nexporters: otlphttp: endpoint: https://mimir.example.com/otlp tls: insecure: false # Verify server certificate cert_file: /path/to/client-cert.pem # Client certificate key_file: /path/to/client-key.pem # Client private key ca_file: /path/to/ca-cert.pem # CA certificate for server verification Mutual TLS (mTLS):\nexporters: otlphttp: endpoint: https://mimir.example.com/otlp tls: insecure: false cert_file: /path/to/client-cert.pem key_file: /path/to/client-key.pem ca_file: /path/to/ca-cert.pem min_version: \"1.2\" # Minimum TLS version max_version: \"1.3\" # Maximum TLS version Complete Configuration Example This example demonstrates a complete, production-ready OpenTelemetry Collector configuration for BattleBots integrating with Mimir.\n# OpenTelemetry Collector Configuration for BattleBots + Mimir # Production-ready configuration with OTLP HTTP exporter extensions: # Health check endpoint health_check: endpoint: 0.0.0.0:13133 # Memory ballast to reduce GC pressure memory_ballast: size_mib: 165 # 1/3 of memory_limiter limit_mib # Authentication for Mimir basicauth: client_auth: username: ${MIMIR_USERNAME} password: ${MIMIR_PASSWORD} receivers: # OTLP receiver for metrics from instrumented apps otlp: protocols: grpc: endpoint: 0.0.0.0:4317 http: endpoint: 0.0.0.0:4318 # Prometheus receiver for scraping Prometheus exporters prometheus: config: scrape_configs: # Scrape OpenTelemetry Collector's own metrics - job_name: 'otel-collector' scrape_interval: 30s static_configs: - targets: ['localhost:8888'] # Scrape BattleBots services - job_name: 'battlebots' kubernetes_sd_configs: - role: pod namespaces: names: ['battlebots'] relabel_configs: - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape] action: keep regex: true - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path] action: replace target_label: __metrics_path__ regex: (.+) - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port] action: replace regex: ([^:]+)(?::\\d+)?;(\\d+) replacement: $1:$2 target_label: __address__ processors: # Memory limiter (MUST be first in pipeline) memory_limiter: check_interval: 1s limit_mib: 512 spike_limit_mib: 128 # 25% of limit_mib # Resource detection resourcedetection: detectors: [env, system, docker, gcp, ec2, k8s] timeout: 5s override: false # Resource attribute transformation resource: attributes: # Add deployment environment - key: deployment.environment value: ${ENVIRONMENT} action: upsert # Add cluster name - key: cluster.name value: ${CLUSTER_NAME} action: upsert # Add BattleBots platform identifier - key: platform value: battlebots action: upsert # Add version - key: version value: ${APP_VERSION} action: upsert # Remove sensitive attributes - key: host.id action: delete # Filter processor (optional - drop unwanted metrics) filter: metrics: exclude: match_type: strict metric_names: - unwanted_metric_1 - unwanted_metric_2 # Batch processor (CRITICAL for production) batch: send_batch_size: 8192 timeout: 10s send_batch_max_size: 10000 exporters: # Primary: OTLP HTTP to Mimir otlphttp: auth: authenticator: basicauth endpoint: ${MIMIR_ENDPOINT}/otlp timeout: 30s compression: gzip retry_on_failure: enabled: true initial_interval: 5s max_interval: 30s max_elapsed_time: 300s sending_queue: enabled: true num_consumers: 10 queue_size: 5000 headers: X-Scope-OrgID: ${MIMIR_TENANT_ID} # Debug: Logging exporter (disable in production) logging: loglevel: info sampling_initial: 5 sampling_thereafter: 200 service: extensions: [health_check, memory_ballast, basicauth] # Collector's own telemetry telemetry: logs: level: info metrics: address: 0.0.0.0:8888 level: detailed pipelines: # Metrics pipeline metrics: receivers: [otlp, prometheus] processors: [memory_limiter, resourcedetection, resource, filter, batch] exporters: [otlphttp] # Optional: Separate pipeline for debugging # metrics/debug: # receivers: [otlp] # processors: [batch] # exporters: [logging] Environment Variables # Mimir connection export MIMIR_ENDPOINT=\"http://mimir-gateway:8080\" export MIMIR_USERNAME=\"battlebots-collector\" export MIMIR_PASSWORD=\"supersecret\" export MIMIR_TENANT_ID=\"battlebots-production\" # Application metadata export ENVIRONMENT=\"production\" export CLUSTER_NAME=\"us-east-1-prod\" export APP_VERSION=\"v1.2.3\" # Memory configuration export GOMEMLIMIT=\"410MiB\" # 80% of memory_limiter limit_mib Kubernetes Deployment apiVersion: v1 kind: ConfigMap metadata: name: otel-collector-config namespace: battlebots data: config.yaml: | # Paste complete configuration from above --- apiVersion: v1 kind: Secret metadata: name: mimir-credentials namespace: battlebots type: Opaque stringData: username: battlebots-collector password: supersecret --- apiVersion: apps/v1 kind: Deployment metadata: name: otel-collector namespace: battlebots spec: replicas: 3 selector: matchLabels: app: otel-collector template: metadata: labels: app: otel-collector spec: containers: - name: otel-collector image: otel/opentelemetry-collector-contrib:0.115.0 args: - --config=/conf/config.yaml env: - name: GOMEMLIMIT value: \"410MiB\" - name: MIMIR_ENDPOINT value: \"http://mimir-gateway.mimir.svc.cluster.local:8080\" - name: MIMIR_USERNAME valueFrom: secretKeyRef: name: mimir-credentials key: username - name: MIMIR_PASSWORD valueFrom: secretKeyRef: name: mimir-credentials key: password - name: MIMIR_TENANT_ID value: \"battlebots-production\" - name: ENVIRONMENT value: \"production\" - name: CLUSTER_NAME value: \"us-east-1-prod\" - name: APP_VERSION value: \"v1.2.3\" resources: limits: memory: 512Mi cpu: 500m requests: memory: 256Mi cpu: 200m ports: - containerPort: 4317 # OTLP gRPC name: otlp-grpc - containerPort: 4318 # OTLP HTTP name: otlp-http - containerPort: 8888 # Metrics name: metrics - containerPort: 13133 # Health check name: health livenessProbe: httpGet: path: / port: health readinessProbe: httpGet: path: / port: health volumeMounts: - name: config mountPath: /conf volumes: - name: config configMap: name: otel-collector-config --- apiVersion: v1 kind: Service metadata: name: otel-collector namespace: battlebots spec: selector: app: otel-collector ports: - name: otlp-grpc port: 4317 targetPort: 4317 - name: otlp-http port: 4318 targetPort: 4318 - name: metrics port: 8888 targetPort: 8888 Docker Compose Example version: '3.8' services: otel-collector: image: otel/opentelemetry-collector-contrib:0.115.0 command: [\"--config=/etc/otelcol/config.yaml\"] environment: - GOMEMLIMIT=410MiB - MIMIR_ENDPOINT=http://mimir:8080 - MIMIR_USERNAME=battlebots - MIMIR_PASSWORD=supersecret - MIMIR_TENANT_ID=battlebots - ENVIRONMENT=development - CLUSTER_NAME=local - APP_VERSION=v1.0.0 ports: - \"4317:4317\" # OTLP gRPC - \"4318:4318\" # OTLP HTTP - \"8888:8888\" # Metrics - \"13133:13133\" # Health check volumes: - ./otel-config.yaml:/etc/otelcol/config.yaml networks: - battlebots mimir: image: grafana/mimir:latest command: [\"-config.file=/etc/mimir.yaml\"] ports: - \"8080:8080\" volumes: - ./mimir-config.yaml:/etc/mimir.yaml - mimir-data:/data networks: - battlebots grafana: image: grafana/grafana:latest ports: - \"3000:3000\" environment: - GF_AUTH_ANONYMOUS_ENABLED=true - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin networks: - battlebots networks: battlebots: volumes: mimir-data: Troubleshooting Common Issues and Solutions 1. Connection Refused / Network Errors Symptoms:\nfailed to export metrics: connection refused Diagnosis:\nVerify Mimir is running and reachable:\ncurl http://mimir:8080/ready Check network connectivity:\n# From collector pod/container nc -zv mimir 8080 Verify endpoint configuration:\n# Ensure correct endpoint format endpoint: http://mimir:8080/otlp # Correct # NOT: http://mimir:8080/otlp/v1/metrics (client auto-appends) Solutions:\nFix network policies/firewall rules Verify Kubernetes service DNS resolution Check load balancer configuration Ensure Mimir port 8080 is exposed 2. Authentication Failures Symptoms:\nfailed to export metrics: 401 Unauthorized failed to export metrics: 403 Forbidden Diagnosis:\nCheck credentials in environment variables Verify basicauth extension configuration Test authentication manually: curl -u username:password http://mimir:8080/ready Solutions:\n# Verify basicauth configuration extensions: basicauth: client_auth: username: ${MIMIR_USERNAME} # Check env var set password: ${MIMIR_PASSWORD} # Check env var set exporters: otlphttp: auth: authenticator: basicauth # Must reference extension service: extensions: [basicauth] # Must be listed here 3. Multi-Tenancy Header Issues Symptoms:\nfailed to export metrics: no org id Solution:\nexporters: otlphttp: headers: X-Scope-OrgID: \"your-tenant-id\" # Must include header Or disable multi-tenancy in Mimir:\n# mimir-config.yaml multitenancy_enabled: false 4. Invalid Metric Names or Labels Symptoms:\nerr-mimir-metric-name-invalid err-mimir-label-invalid Cause: Metric names must match [a-zA-Z_:][a-zA-Z0-9_:]*\nSolution: Use the metricstransform processor to rename metrics:\nprocessors: metricstransform: transforms: - include: .* match_type: regexp action: update operations: # Replace invalid characters with underscores - action: update_label label: \"invalid-label\" new_label: \"invalid_label\" 5. High Memory Usage / OOM Kills Symptoms:\nCollector pod/container killed with OOM High memory usage in metrics Diagnosis:\n# Monitor collector memory process_runtime_go_mem_heap_alloc_bytes{job=\"otel-collector\"} Solutions:\nTune memory_limiter:\nprocessors: memory_limiter: check_interval: 1s limit_mib: 512 # Adjust based on container limit spike_limit_mib: 128 # 25% of limit Set GOMEMLIMIT (80% of container memory):\nenv: - name: GOMEMLIMIT value: \"410MiB\" # For 512Mi container limit Reduce batch sizes:\nprocessors: batch: send_batch_size: 4096 # Reduce from 8192 send_batch_max_size: 5000 # Reduce from 10000 Increase num_consumers:\nexporters: otlphttp: sending_queue: num_consumers: 20 # More parallel exports 6. Metrics Not Appearing in Mimir Diagnosis Checklist:\nCheck collector logs for export errors:\nkubectl logs -f deployment/otel-collector Verify metrics received by collector:\n# Check collector's own metrics otelcol_receiver_accepted_metric_points{receiver=\"otlp\"} otelcol_exporter_sent_metric_points{exporter=\"otlphttp\"} Check Mimir ingester logs:\nkubectl logs -f deployment/mimir-ingester Query Mimir directly:\ncurl -H \"X-Scope-OrgID: your-tenant\" \\ http://mimir:8080/prometheus/api/v1/query?query=up Common Causes:\nMetrics filtered out by filter processor Batch processor holding data (check timeout) Invalid metric names (check for errors in logs) Wrong tenant ID in query vs. export 7. Cardinality Limit Errors Symptoms:\nerr-mimir-max-series-per-metric err-mimir-max-series-per-user Diagnosis:\n# Check active series cortex_ingester_active_series # Check per-metric cardinality topk(10, count by (__name__) ({__name__=~\".+\"})) Solutions:\nIdentify high-cardinality metrics:\n# Use Mimir's cardinality analysis API curl -H \"X-Scope-OrgID: tenant\" \\ http://mimir:8080/prometheus/api/v1/cardinality/label_names Drop high-cardinality labels:\nprocessors: resource: attributes: - key: user_id action: delete - key: request_id action: delete Increase Mimir limits (temporary):\n# Mimir config limits: max_global_series_per_user: 10000000 # Increase limit max_global_series_per_metric: 100000 # Increase limit 8. Slow Query Performance Symptoms:\nQueries timeout High query latency Solutions:\nEnable caching in Mimir:\n# Mimir config query_frontend: results_cache: backend: memcached Reduce query time range:\n# Instead of querying 30 days: rate(http_requests_total[30d]) # Query smaller range: rate(http_requests_total[1h]) Optimize PromQL queries:\n# Inefficient sum(rate(metric[5m])) # Efficient (specify labels) sum(rate(metric{job=\"api\"}[5m])) by (status) Monitoring Collector Health Key Metrics to Monitor:\n# Successful exports rate(otelcol_exporter_sent_metric_points{exporter=\"otlphttp\"}[5m]) # Failed exports rate(otelcol_exporter_send_failed_metric_points{exporter=\"otlphttp\"}[5m]) # Batch processor metrics otelcol_processor_batch_batch_send_size otelcol_processor_batch_timeout_trigger_send # Memory limiter backpressure rate(otelcol_processor_refused_metric_points{processor=\"memory_limiter\"}[5m]) # Queue depth otelcol_exporter_queue_size{exporter=\"otlphttp\"} Recommended Alerts:\ngroups: - name: otel-collector-alerts rules: # Export failures - alert: OTelCollectorExportFailures expr: | rate(otelcol_exporter_send_failed_metric_points[5m]) \u003e 0 for: 5m annotations: summary: \"OpenTelemetry Collector failing to export metrics\" # Memory pressure - alert: OTelCollectorMemoryPressure expr: | rate(otelcol_processor_refused_metric_points[5m]) \u003e 0 for: 5m annotations: summary: \"OpenTelemetry Collector under memory pressure\" # Queue filling up - alert: OTelCollectorQueueFull expr: | otelcol_exporter_queue_size / otelcol_exporter_queue_capacity \u003e 0.8 for: 10m annotations: summary: \"OpenTelemetry Collector export queue filling up\" BattleBots Integration Points Complete Observability Pipeline graph TB subgraph \"BattleBots Services\" Bot[Bot Containers\u003cbr/\u003eOTel SDK] Game[Game Servers\u003cbr/\u003eOTel SDK] API[Battle API\u003cbr/\u003eOTel SDK] end subgraph \"Kubernetes\" K8s[kube-state-metrics] Node[node-exporter] end subgraph \"OpenTelemetry Collector\" OTLP[OTLP Receiver\u003cbr/\u003e:4317 / :4318] Prom[Prometheus Receiver] Bot --\u003e OTLP Game --\u003e OTLP API --\u003e OTLP K8s --\u003e Prom Node --\u003e Prom OTLP --\u003e ResDetect[Resource Detection] Prom --\u003e ResDetect ResDetect --\u003e ResTrans[Resource Transform] ResTrans --\u003e Batch[Batch Processor] Batch --\u003e Export[OTLP HTTP Exporter] end subgraph \"Grafana Mimir\" Export --\u003e|OTLP/HTTP| Dist[Distributor] Dist --\u003e Ing[Ingesters] Ing --\u003e ObjStore[(Object Storage)] Grafana[Grafana] --\u003e QF[Query Frontend] QF --\u003e Querier[Querier] Querier --\u003e Ing Querier --\u003e SG[Store Gateway] SG --\u003e ObjStore end style OTLP fill:#e1f5ff style Export fill:#e1f5ff style Dist fill:#fff4e1 style Grafana fill:#ffe0b2 Example Metrics for BattleBots Bot Action Latency (from OpenTelemetry SDK):\n// In bot implementation histogram, _ := meter.Int64Histogram( \"bot.action.duration\", metric.WithDescription(\"Bot action execution time\"), metric.WithUnit(\"ms\"), ) histogram.Record(ctx, durationMs, attribute.String(\"action\", \"attack\"), attribute.String(\"bot.type\", \"tank\"), ) Query in Mimir (after OTLP export):\n# 95th percentile attack latency by bot type histogram_quantile(0.95, sum(rate(bot_action_duration_bucket{action=\"attack\"}[5m])) by (bot_type, le) ) API Request Metrics:\n// In Battle API counter, _ := meter.Int64Counter( \"http.server.requests\", metric.WithDescription(\"HTTP requests\"), ) counter.Add(ctx, 1, attribute.String(\"http.method\", \"POST\"), attribute.String(\"http.route\", \"/api/v1/battles\"), attribute.Int(\"http.status_code\", 201), ) Query in Mimir:\n# Request rate by endpoint and status sum(rate(http_server_requests[5m])) by (http_route, http_status_code) # Error rate sum(rate(http_server_requests{http_status_code=~\"5..\"}[5m])) / sum(rate(http_server_requests[5m])) Resource Attribute Examples for BattleBots # Detected by resourcedetection processor resource: # Kubernetes attributes k8s.namespace.name: \"battlebots\" k8s.pod.name: \"battle-api-abc123\" k8s.deployment.name: \"battle-api\" k8s.node.name: \"node-us-east-1a\" # Cloud attributes cloud.provider: \"aws\" cloud.platform: \"aws_ec2\" cloud.region: \"us-east-1\" cloud.availability_zone: \"us-east-1a\" # Service attributes (from OTel SDK) service.name: \"battle-api\" service.namespace: \"battlebots\" service.version: \"v1.2.3\" service.instance.id: \"pod-abc123\" # Added by resource processor deployment.environment: \"production\" cluster.name: \"us-east-1-prod\" platform: \"battlebots\" Example PromQL Queries with Resource Attributes Query with promoted attributes:\n# All metrics from battle-api service {job=\"battlebots/battle-api\"} Query with target_info join:\n# Metrics filtered by Kubernetes deployment http_server_requests * on(job, instance) group_left(k8s_deployment_name) target_info{k8s_deployment_name=\"battle-api\"} Using info() function (Prometheus 3.0+):\n# Simpler syntax http_server_requests{job=\"battlebots/battle-api\"} * info(target_info) BattleBots Dashboards Request Rate Dashboard:\n{ \"title\": \"BattleBots API Request Rate\", \"targets\": [ { \"expr\": \"sum(rate(http_server_requests{job=~\\\"battlebots/.*\\\"}[5m])) by (http_route)\" } ] } Bot Performance Dashboard:\n{ \"title\": \"Bot Action Latency (p95)\", \"targets\": [ { \"expr\": \"histogram_quantile(0.95, sum(rate(bot_action_duration_bucket[5m])) by (bot_type, action, le))\" } ] } Linked Dashboard (Metrics → Traces):\nClick on metric spike in Grafana Grafana shows exemplars (trace IDs embedded in metrics) Click exemplar → Opens trace in Tempo Trace shows detailed spans with logs Further Reading Official Documentation Configure OpenTelemetry Collector for Mimir - Official integration guide OTLP Format Considerations - OTLP best practices Mimir OTLP Endpoint - API reference Prometheus Resource Attribute Promotion - How resource attributes become labels OpenTelemetry Collector Documentation OTLP HTTP Exporter - Official exporter docs Prometheus Remote Write Exporter - Alternative exporter Batch Processor - Batching guide Resource Detection Processor - Attribute detection Resource Processor - Attribute transformation Guides and Tutorials OpenTelemetry at Grafana Labs 2025 - Latest updates Using Prometheus as OpenTelemetry Backend - Prometheus perspective Mastering the Batch Processor - Deep dive Mastering the Memory Limiter - Prevent OOM OpenTelemetry Processors Best Practices - Configuration tips Troubleshooting OpenTelemetry Collector Troubleshooting - Official guide Mimir Runbooks - Operational guides Using Authenticator Extension - Auth setup Performance and Optimization Prometheus Remote Write Tuning - Optimize ingestion High Cardinality Management - Cardinality strategies Metric Cardinality Explained - Understanding cardinality Community Resources OpenTelemetry Community - Get help, contribute Grafana Community Forum - Ask questions CNCF OpenTelemetry Project - Project homepage ","categories":"","description":"Deep dive into Grafana Mimir's native OTLP support and integration with the OpenTelemetry Collector, including configuration examples, best practices, and troubleshooting guidance.\n","excerpt":"Deep dive into Grafana Mimir's native OTLP support and integration …","ref":"/battlebots/pr-preview/pr-153/research_and_development/analysis/observability/metrics/mimir/mimir-otlp-integration/","tags":"","title":"Mimir: OTLP and OpenTelemetry Collector Integration"},{"body":"Overview Grafana Mimir is a horizontally scalable, highly available, multi-tenant, long-term storage solution for Prometheus metrics. It transforms Prometheus’s single-server architecture into a distributed microservices platform capable of handling over 1 billion active time series with unlimited retention backed by object storage.\nWhat is Mimir? Mimir takes the Prometheus Time Series Database (TSDB) and splits it into microservices, creating a distributed system where each component can scale independently. While Prometheus excels at real-time monitoring on a single machine, Mimir extends this capability to enterprise scale with:\nHorizontal Scalability: Scale from thousands to billions of active time series Long-Term Storage: Store metrics for months or years using cost-effective object storage High Availability: Built-in replication and distributed architecture eliminate single points of failure Multi-Tenancy: Isolated metrics per tenant with per-tenant resource limits Prometheus Compatibility: 100% PromQL compatibility ensures existing queries and dashboards work unchanged Core Innovation Mimir’s key innovation is separating Prometheus into write path, read path, and backend components, each independently scalable:\nWrite Path (Distributor → Ingester): Handles metric ingestion with validation and replication Read Path (Query-Frontend → Querier → Store-Gateway): Executes queries across recent and historical data Backend (Compactor, Ruler): Background processing for storage optimization and alerting This separation enables scaling write throughput independently from query performance, and both independently from long-term storage management.\nRelationship to Prometheus and Cortex Prometheus Foundation: Mimir uses the Prometheus TSDB format and PromQL query language, providing seamless migration paths and familiar operations.\nCortex Successor: Mimir began as a fork of Cortex in March 2022 when Grafana Labs stopped contributing to Cortex. Mimir inherits Cortex’s distributed architecture while adding:\nReduced operational complexity through monolithic deployment mode Split-and-merge compactor that overcomes TSDB’s 64GB index limit Performance optimizations and simplified configuration Active development and feature additions Recommendation: Always choose Mimir over Cortex for new deployments. Cortex is in maintenance mode with minimal active development.\nKey Concepts Blocks Storage Architecture Mimir uses a blocks-based storage system derived from Prometheus TSDB:\nTSDB Blocks Time series data is broken into fixed-time blocks (default: 2 hours) containing:\nChunks: Highly compressed time series sample data (~1.5 bytes per sample) Index: Inverted index mapping metric names and labels to time series Meta.json: Block metadata including time range, statistics, and compaction level Block Lifecycle Creation: Ingesters create 2-hour blocks from in-memory data and upload to object storage Compaction: Compactor merges small blocks into larger, optimized blocks (2h → 12h → 24h) Querying: Queriers fetch recent data from ingesters, historical data from store-gateways Retention: Compactor deletes blocks older than configured retention period Cleanup: Soft-deleted blocks removed after deletion delay (default: 12 hours) Storage Backends Mimir requires object storage for long-term block storage:\nAmazon S3 or S3-compatible services (MinIO, Ceph, etc.) Google Cloud Storage (GCS) Microsoft Azure Blob Storage OpenStack Swift Object storage provides:\nDurability: Built-in replication and fault tolerance Cost-Effectiveness: ~$0.02-0.03/GB/month vs. ~$0.10-0.20/GB/month for SSD Unlimited Capacity: No practical storage limits Geographic Distribution: Multi-region replication for disaster recovery Time Series and Cardinality Time Series Definition A time series is uniquely identified by a metric name and a set of label key-value pairs:\nhttp_requests_total{method=\"GET\", endpoint=\"/api/battles\", status=\"200\"} This creates one time series. Each unique combination of labels creates a separate time series.\nCardinality Cardinality is the number of unique time series (distinct label combinations). High cardinality occurs when labels have many possible values:\nLow Cardinality (Good):\nhttp_requests{method=\"GET\"} # method has ~10 values (GET, POST, PUT, DELETE, etc.) http_requests{status=\"200\"} # status has ~50 values (HTTP status codes) High Cardinality (Problematic):\nhttp_requests{user_id=\"12345\"} # user_id could have millions of values http_requests{request_id=\"abc123\"} # request_id has infinite possible values Best Practice: Avoid labels with unbounded values (UUIDs, timestamps, user IDs, email addresses). Use labels with bounded, enumerable values (service names, environments, HTTP methods, status codes).\nMimir’s Scale: Tested at 1 billion active series, real-world deployments at 500 million series.\nTenants and Tenant Isolation Multi-Tenancy by Default Mimir is multi-tenant by default. Each request must include a tenant ID via the X-Scope-OrgID HTTP header:\ncurl -H \"X-Scope-OrgID: tenant-123\" \\ http://mimir:8080/prometheus/api/v1/query?query=up Tenant Isolation Mechanisms Automatic Creation: Tenants created on first write (no pre-registration needed) Data Segregation: Complete separation of data between tenants in object storage Resource Limits: Per-tenant limits for ingestion rate, active series, query concurrency Query Isolation: Tenants can only query their own data No Authentication: Mimir trusts the X-Scope-OrgID header; add authentication layer (reverse proxy/API gateway) for production Tenant Federation Query across multiple tenants using pipe-separated tenant IDs:\nX-Scope-OrgID: tenant-1|tenant-2|tenant-3 This enables cross-tenant analytics and aggregation while maintaining isolation for writes.\nDisabling Multi-Tenancy For single-tenant deployments, disable multi-tenancy:\nmultitenancy_enabled: false All requests use a default tenant ID without requiring the X-Scope-OrgID header.\nPromQL Compatibility Mimir provides 100% PromQL (Prometheus Query Language) compatibility:\nAll Prometheus query functions supported Recording rules and alerting rules work unchanged Grafana dashboards require no modifications Existing Prometheus alerts can be migrated directly Example Queries:\n# Instant query: Current values up{job=\"battlebots-api\"} # Range query: Historical data rate(http_requests_total[5m]) # Aggregation: Summary across labels sum(rate(http_requests_total[5m])) by (status_code) # Histogram quantiles: Latency percentiles histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service) ) Architecture Components Mimir’s microservices architecture comprises multiple horizontally scalable components that operate independently and in parallel.\nComponent Overview graph TB subgraph \"Write Path\" Prom[Prometheus\u003cbr/\u003eRemote Write] --\u003e Dist[Distributor] OTel[OpenTelemetry\u003cbr/\u003eCollector OTLP] --\u003e Dist Dist --\u003e Ing1[Ingester 1] Dist --\u003e Ing2[Ingester 2] Dist --\u003e Ing3[Ingester 3] end subgraph \"Storage\" Ing1 --\u003e ObjStore[(Object Storage\u003cbr/\u003eS3/GCS/MinIO)] Ing2 --\u003e ObjStore Ing3 --\u003e ObjStore Compact[Compactor] --\u003e ObjStore end subgraph \"Read Path\" Client[Grafana/API] --\u003e QF[Query Frontend] QF --\u003e QS[Query Scheduler] QS --\u003e Q1[Querier 1] QS --\u003e Q2[Querier 2] Q1 --\u003e Ing1 Q1 --\u003e Ing2 Q1 --\u003e Ing3 Q2 --\u003e Ing1 Q2 --\u003e Ing2 Q2 --\u003e Ing3 Q1 --\u003e SG[Store Gateway] Q2 --\u003e SG SG --\u003e ObjStore end subgraph \"Backend\" Ruler[Ruler] --\u003e QF Ruler --\u003e SG end style Dist fill:#e1f5ff style Ing1 fill:#fff4e1 style Ing2 fill:#fff4e1 style Ing3 fill:#fff4e1 style ObjStore fill:#e8f5e9 style QF fill:#f3e5f5 style Q1 fill:#f3e5f5 style Q2 fill:#f3e5f5 Write Path Components Distributor Role: Entry point for the write path; receives and validates incoming metrics.\nKey Functions:\nReceives write requests from Prometheus remote write or OTLP endpoints Validates metric format and labels (must match [a-zA-Z_:][a-zA-Z0-9_:]*) Enforces per-tenant rate limits and metadata limits Shards incoming time series across ingesters based on consistent hashing Replicates data to multiple ingesters (default: 3 replicas) Characteristics:\nStateless: Can be scaled horizontally without coordination CPU-Bound: Scales with sample ingestion rate Resource Estimate: 1 core per 25,000 samples/second Configuration Example:\ndistributor: ring: kvstore: store: memberlist # Service discovery pool: health_check_ingesters: true Ingester Role: Writes incoming time series to long-term storage; serves recent data for queries.\nKey Functions:\nReceives samples from distributors and appends to per-tenant TSDB on local disk Writes samples to Write-Ahead Log (WAL) for crash recovery Compacts in-memory samples into TSDB blocks (default: every 2 hours) Uploads newly created blocks to object storage Serves queries for recent data (within ingester retention window) Participates in hash ring for data sharding and replication Characteristics:\nStateful: Stores active series in memory and on local disk Memory-Bound: Scales with number of active series Resource Estimates: CPU: 1 core per 300,000 in-memory series Memory: 2.5 GB per 300,000 in-memory series Disk: 5 GB per 300,000 in-memory series (for WAL and blocks) Recommended Limits:\nConservative: Up to 1.5 million series per ingester Maximum: Up to 5 million series per ingester (with sufficient memory) Configuration Example:\ningester: ring: replication_factor: 3 # Number of ingester replicas kvstore: store: memberlist blocks_storage: tsdb: dir: /data/tsdb # Local TSDB directory block_ranges_period: [2h] # Block creation interval retention_period: 6h # Keep blocks locally for 6 hours Read Path Components Query-Frontend Role: Receives and optimizes PromQL queries before dispatching to queriers.\nKey Functions:\nProvides the same HTTP API as Prometheus (/prometheus/api/v1/query, etc.) Splits large time-range queries into smaller sub-queries (query splitting) Caches query results to avoid re-computation (query result caching) Shards queries across time series to enable parallel execution (query sharding) Dispatches queries to queriers via query scheduler for better load distribution Retries failed queries automatically Characteristics:\nStateless: Can be scaled horizontally CPU-Bound: Scales with query rate Resource Estimate: 1 core per 250 queries/second Configuration Example:\nquery_frontend: results_cache: backend: memcached memcached: addresses: memcached:11211 split_queries_by_interval: 24h # Split queries into 24h chunks Query-Scheduler (Optional) Role: Intermediary between query-frontend and queriers for better queue management.\nKey Functions:\nReceives queries from query-frontends and maintains a queue Dispatches queries to available queriers Provides fair scheduling across tenants (prevents single tenant monopolizing queriers) Enables scaling query-frontends independently from queriers Characteristics:\nStateless: Lightweight component Resource Estimate: 1 core per 500 queries/second Configuration Example:\nquery_scheduler: max_outstanding_requests_per_tenant: 100 Querier Role: Executes PromQL queries by fetching data from ingesters and store-gateways.\nKey Functions:\nReceives query requests from query-frontend or query-scheduler Fetches recent data (within retention window) from ingesters Fetches historical data (older than retention window) from store-gateways Merges data from multiple sources and evaluates PromQL expression Returns results to query-frontend Characteristics:\nStateless: Can be scaled horizontally CPU + Memory Bound: Scales with query complexity and time range Resource Estimate: 1 core per 10 queries/second (assumes ~100ms average latency) Configuration Example:\nquerier: max_concurrent: 20 # Maximum concurrent queries per querier timeout: 2m # Query timeout query_ingesters_within: 13h # Query ingesters for data within 13h query_store_after: 12h # Query store-gateway for data older than 12h Backend Components Store-Gateway Role: Provides access to historical blocks stored in object storage.\nKey Functions:\nSynchronizes the list of blocks from object storage (bucket index) Downloads and memory-maps index-header files for fast block querying Serves queries from queriers and rulers for historical data Implements block-level sharding (each store-gateway responsible for subset of blocks) Downloads only necessary portions of blocks (chunks and index sections), not entire blocks Characteristics:\nStateful: Memory-maps index-headers, participates in hash ring Disk I/O Bound: Benefits from SSD for index-header operations Resource Estimates: CPU: 1 core per 10 queries/second Memory: 1 GB per 10 queries/second Disk: 13 GB per 1 million active series (for index-header files) Configuration Example:\nstore_gateway: sharding_ring: replication_factor: 3 kvstore: store: memberlist blocks_storage: bucket_store: sync_dir: /data/tsdb-sync index_cache: backend: memcached memcached: addresses: memcached:11211 Compactor Role: Compacts and optimizes TSDB blocks; manages retention and cleanup.\nKey Functions:\nVertical Compaction: Merges blocks from same tenant covering same time range Deduplicates replicated samples (from replication factor \u003e 1) Reduces index size and chunk overhead Horizontal Compaction: Combines blocks across adjacent time periods (2h → 12h → 24h) Split-and-Merge Compaction: For large tenants (\u003e20M series), splits compaction into shards to overcome TSDB 64GB index limit Maintains per-tenant bucket index (metadata about all blocks) Deletes blocks older than configured retention period Implements two-stage deletion: soft delete (mark) → hard delete (remove after delay) Characteristics:\nStateful: Participates in hash ring for per-tenant compaction ownership I/O Bound: Downloads source blocks, writes compacted blocks Resource Estimates: CPU: 1 core per compactor instance Memory: 4 GB per instance Disk: 300 GB per instance (for downloading/uploading blocks) Scaling Guideline: 1 compactor instance per 20 million active series\nConfiguration Example:\ncompactor: data_dir: /data/compactor compaction_interval: 30m block_ranges: [2h, 12h, 24h] # Compaction levels sharding_ring: kvstore: store: memberlist # For large tenants (\u003e20M series) split_and_merge_shards: 4 # Number of shards split_groups: 4 # Number of groups (match shards or use next power of 2) Ruler Role: Evaluates Prometheus recording and alerting rules.\nKey Functions:\nExecutes Prometheus recording rules (pre-compute expensive queries) Evaluates alerting rules and sends alerts to Alertmanager Supports multi-tenant rules (per-tenant rule groups) Stores recording rule results back to Mimir via remote write Uses store-gateway for querying when evaluating rules Characteristics:\nStateful: Participates in hash ring for rule group sharding CPU Bound: Scales with number and complexity of rules Configuration Example:\nruler: enable_api: true # Enable ruler API for rule management rule_path: /data/rules ring: kvstore: store: memberlist ruler_storage: backend: s3 s3: bucket_name: mimir-ruler endpoint: s3.amazonaws.com Deployment Modes Mimir supports three deployment modes with different trade-offs between simplicity and scalability.\nComparison Table Feature Monolithic Read-Write Microservices Complexity Low Medium High Scalability Limited (all together) Medium (3 groups) Maximum (per-component) Resource Efficiency Lower (over-provisioning) Medium Highest (fine-grained) Failure Isolation Single process failure Tier-level failure Component-level isolation Ideal Scale \u003c1M series 1-10M series 10M+ series Operational Overhead Minimal Medium High Deployment Tool Docker/VM Kubernetes Kubernetes + Helm Monolithic Mode Architecture: All Mimir components run in a single process.\nConfiguration:\ntarget: all # Run all components in one process # Or via environment variable: # MIMIR_MODE=all Characteristics:\nSimplest deployment model with lowest operational overhead All components scale together (cannot scale independently) Single binary to deploy and monitor Suitable for development, testing, and small production deployments High Availability: Deploy multiple -target=all instances with shared object storage:\nEach instance runs full component stack Ingesters replicate data across instances (default: 3x replication) Queriers query all ingesters and merge results Provides HA without microservices complexity Resource Requirements:\nMemory: Sized for peak ingester + querier memory needs CPU: Sum of all component CPU needs Disk: Sized for WAL and local TSDB blocks When to Use:\nDevelopment and testing environments POC deployments Production deployments with \u003c1M active series Teams preferring operational simplicity over granular scalability When total resource requirements fit on a single machine (vertically scaled) Limitations:\nCannot scale write path independently from read path Resource-intensive queries impact ingestion performance Maximum scale limited by largest available machine Not supported in Jsonnet deployment tooling Example Docker Compose Configuration:\nversion: '3.8' services: mimir: image: grafana/mimir:latest command: [\"-config.file=/etc/mimir.yaml\"] ports: - \"9009:9009\" volumes: - ./mimir.yaml:/etc/mimir.yaml - mimir-data:/data volumes: mimir-data: Read-Write Mode (Experimental) Architecture: Three-tier deployment separating read, write, and backend responsibilities.\nTiers:\nWrite Tier: Distributors + Ingesters (handles data ingestion) Read Tier: Query-Frontends + Queriers (handles queries) Backend Tier: Store-Gateways + Compactors + Rulers (background processing) Configuration:\n# Write tier target: write # Read tier target: read # Backend tier target: backend Characteristics:\nSimpler than full microservices (3 tiers vs. 7+ components) Independent scaling of read vs. write workloads Logical grouping of related components Requires multi-zone ingesters and store-gateways When to Use:\nMedium-scale deployments (1-10M active series) Organizations wanting simpler architecture than microservices Workloads with varying read vs. write loads Teams with some distributed systems experience Limitations:\nLess granular scaling than microservices mode Currently experimental (use with caution in production) Cannot scale individual components within a tier Scaling Example:\nWrite-heavy workload: Scale write tier (more distributors + ingesters) Query-heavy workload: Scale read tier (more query-frontends + queriers) Storage optimization: Scale backend tier (more compactors) Microservices Mode Architecture: Each component runs as a separate process/deployment.\nConfiguration: Each process invoked with specific -target parameter:\n# Distributor mimir -target=distributor -config.file=mimir.yaml # Ingester mimir -target=ingester -config.file=mimir.yaml # Query-frontend mimir -target=query-frontend -config.file=mimir.yaml # Querier mimir -target=querier -config.file=mimir.yaml # Store-gateway mimir -target=store-gateway -config.file=mimir.yaml # Compactor mimir -target=compactor -config.file=mimir.yaml # Ruler mimir -target=ruler -config.file=mimir.yaml # Optional: Query-scheduler mimir -target=query-scheduler -config.file=mimir.yaml # Optional: Alertmanager mimir -target=alertmanager -config.file=mimir.yaml Characteristics:\nMaximum scalability and flexibility Each component scales independently based on workload Granular failure domains (component failures don’t affect entire system) Component-specific resource allocation and optimization Recommended for production environments When to Use:\nProduction deployments with \u003e10M active series Large-scale systems requiring fine-grained control Deployments with highly variable component loads Organizations with distributed systems expertise Kubernetes environments with operator/Helm support Scaling Strategies:\nWrite-Heavy Workload:\nScale distributors (1 core per 25K samples/sec) Scale ingesters (1 core per 300K series) Query-Heavy Workload:\nScale query-frontends (1 core per 250 queries/sec) Scale queriers (1 core per 10 queries/sec) Scale store-gateways (1 core per 10 queries/sec) Large Data Volume:\nScale compactors (1 per 20M series) Increase store-gateway replicas Example Kubernetes Deployment (using Helm):\nhelm repo add grafana https://grafana.github.io/helm-charts helm install mimir grafana/mimir-distributed \\ --namespace mimir \\ --values production-values.yaml Benefits:\nIndependent failure domains (ingester crash doesn’t affect queriers) Fine-tuned resource allocation (queriers get more CPU, ingesters get more memory) Targeted scaling based on bottlenecks Easier capacity planning and cost optimization Trade-offs:\nHigher operational complexity More components to monitor and maintain Network communication overhead between components Requires service discovery and coordination (Kubernetes, Consul, etcd) How to Run Mimir Quick Start with Docker Compose For POC environments and local development, Docker Compose provides the fastest path to running Mimir.\nPrerequisites Docker and Docker Compose installed At least 4 GB RAM available 10 GB free disk space Complete Docker Compose Stack This example deploys:\nMinIO: S3-compatible object storage Mimir (3 instances): High-availability monolithic deployment NGINX: Load balancer distributing traffic across Mimir instances Grafana: Visualization and dashboarding Directory Structure:\nmimir-poc/ ├── docker-compose.yml ├── config/ │ ├── mimir.yaml │ ├── nginx.conf │ └── alertmanager-fallback-config.yaml └── data/ (created automatically) docker-compose.yml:\nversion: '3.8' services: # MinIO object storage minio: image: minio/minio entrypoint: [\"\"] command: [\"sh\", \"-c\", \"mkdir -p /data/mimir-blocks /data/mimir-ruler /data/mimir-alertmanager \u0026\u0026 minio server --quiet /data --console-address :9001\"] environment: - MINIO_ROOT_USER=mimir - MINIO_ROOT_PASSWORD=supersecret ports: - \"9000:9000\" # S3 API - \"9001:9001\" # Web console volumes: - minio-data:/data healthcheck: test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:9000/minio/health/live\"] interval: 30s timeout: 10s retries: 3 # Mimir instance 1 mimir-1: image: grafana/mimir:latest command: [\"-config.file=/etc/mimir.yaml\"] hostname: mimir-1 depends_on: - minio ports: - \"8001:8080\" volumes: - ./config/mimir.yaml:/etc/mimir.yaml - ./config/alertmanager-fallback-config.yaml:/etc/alertmanager-fallback-config.yaml - mimir-1-data:/data # Mimir instance 2 mimir-2: image: grafana/mimir:latest command: [\"-config.file=/etc/mimir.yaml\"] hostname: mimir-2 depends_on: - minio ports: - \"8002:8080\" volumes: - ./config/mimir.yaml:/etc/mimir.yaml - ./config/alertmanager-fallback-config.yaml:/etc/alertmanager-fallback-config.yaml - mimir-2-data:/data # Mimir instance 3 mimir-3: image: grafana/mimir:latest command: [\"-config.file=/etc/mimir.yaml\"] hostname: mimir-3 depends_on: - minio ports: - \"8003:8080\" volumes: - ./config/mimir.yaml:/etc/mimir.yaml - ./config/alertmanager-fallback-config.yaml:/etc/alertmanager-fallback-config.yaml - mimir-3-data:/data # NGINX load balancer nginx: image: nginx:alpine ports: - \"9009:9009\" volumes: - ./config/nginx.conf:/etc/nginx/nginx.conf:ro depends_on: - mimir-1 - mimir-2 - mimir-3 # Grafana for visualization grafana: image: grafana/grafana:latest environment: - GF_AUTH_ANONYMOUS_ENABLED=true - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin ports: - \"3000:3000\" volumes: - grafana-data:/var/lib/grafana volumes: minio-data: mimir-1-data: mimir-2-data: mimir-3-data: grafana-data: config/mimir.yaml:\n# Monolithic mode configuration target: all,alertmanager # Multi-tenancy (disable for single-tenant POC) multitenancy_enabled: false # Server configuration server: http_listen_port: 8080 log_level: info # Common configuration (shared by all components) common: storage: backend: s3 s3: endpoint: minio:9000 access_key_id: mimir secret_access_key: supersecret insecure: true # Use HTTP (not HTTPS) for local MinIO # Blocks storage configuration blocks_storage: backend: s3 s3: bucket_name: mimir-blocks tsdb: dir: /data/tsdb bucket_store: sync_dir: /data/tsdb-sync # Compactor configuration compactor: data_dir: /data/compactor sharding_ring: kvstore: store: memberlist # Distributor configuration distributor: ring: instance_addr: 127.0.0.1 kvstore: store: memberlist # Ingester configuration ingester: ring: instance_addr: 127.0.0.1 kvstore: store: memberlist replication_factor: 3 # 3 replicas across 3 Mimir instances # Ruler storage configuration ruler_storage: backend: s3 s3: bucket_name: mimir-ruler # Alertmanager configuration alertmanager_storage: backend: s3 s3: bucket_name: mimir-alertmanager alertmanager: fallback_config_file: /etc/alertmanager-fallback-config.yaml data_dir: /data/alertmanager # Store-gateway configuration store_gateway: sharding_ring: replication_factor: 3 # Limits configuration limits: # Ingestion limits ingestion_rate: 10000 # Samples per second per tenant ingestion_burst_size: 20000 # Series limits max_global_series_per_user: 1000000 # 1M series max max_global_series_per_metric: 50000 # Query limits max_query_lookback: 0 # No limit on query time range # Retention compactor_blocks_retention_period: 0 # Indefinite retention (0 = disabled) config/nginx.conf:\nevents { worker_connections 1024; } http { upstream mimir { server mimir-1:8080; server mimir-2:8080; server mimir-3:8080; } server { listen 9009; location / { proxy_pass http://mimir; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } } } config/alertmanager-fallback-config.yaml:\nroute: receiver: 'default-receiver' group_wait: 10s group_interval: 10s repeat_interval: 1h receivers: - name: 'default-receiver' Launch the Stack # Start all services docker-compose up -d # Verify services are running docker-compose ps # Check Mimir logs docker-compose logs -f mimir-1 # Access MinIO console open http://localhost:9001 # Username: mimir, Password: supersecret # Access Grafana open http://localhost:3000 Configure Prometheus Remote Write prometheus.yml:\nglobal: scrape_interval: 15s scrape_configs: - job_name: 'prometheus' static_configs: - targets: ['localhost:9090'] remote_write: - url: http://localhost:9009/api/v1/push queue_config: capacity: 10000 max_shards: 10 min_shards: 1 Configure Grafana Data Source Navigate to Connections → Data sources Click Add data source Select Prometheus Configure: Name: Mimir URL: http://nginx:9009/prometheus Prometheus type: Mimir Click Save \u0026 test Production Configuration with MinIO For on-premises production deployments or when AWS S3 is not available, MinIO provides enterprise-grade S3-compatible object storage.\nDifferences from POC Setup:\nDistributed MinIO: Deploy 4+ MinIO servers for high availability (erasure coding) Persistent Volumes: Use network-attached storage or cloud block storage TLS Encryption: Enable HTTPS for MinIO and Mimir Authentication: Implement proper access control and API key rotation Resource Limits: Set CPU/memory limits based on capacity planning Monitoring: Deploy Prometheus + Grafana to monitor Mimir and MinIO Example Production Values:\n# Mimir production configuration with MinIO common: storage: backend: s3 s3: endpoint: minio.storage.svc.cluster.local:9000 access_key_id: ${MINIO_ACCESS_KEY} # From secret secret_access_key: ${MINIO_SECRET_KEY} # From secret insecure: false # Use HTTPS bucket_name: mimir-blocks ingester: ring: replication_factor: 3 instance_addr: ${POD_IP} kvstore: store: memberlist limits: ingestion_rate: 50000 # Higher for production max_global_series_per_user: 10000000 # 10M series blocks_storage: tsdb: retention_period: 24h # Ingesters retain blocks for 24h before relying on object storage block_ranges_period: [2h] compactor: compaction_interval: 30m cleanup_interval: 15m block_ranges: [2h, 12h, 24h] Resource Requirements Based on the capacity planning guide:\nSmall Deployment (~1M active series):\nDistributors: 2 instances × (1 core, 1 GB RAM) Ingesters: 3 instances × (2 cores, 8 GB RAM, 20 GB disk) Queriers: 2 instances × (1 core, 2 GB RAM) Query-Frontends: 2 instances × (1 core, 1 GB RAM) Store-Gateways: 2 instances × (1 core, 2 GB RAM, 15 GB disk) Compactor: 1 instance × (1 core, 4 GB RAM, 300 GB disk) Object Storage: ~50 GB (1 year retention) Large Deployment (~10M active series):\nTotal Resources: ~140 CPUs, 800 GB memory Use the Mimir capacity calculator for detailed estimates Grafana Data Source Setup After deploying Mimir, configure Grafana to query metrics:\nVia UI:\nConnections → Data sources → Add data source → Prometheus URL: http://mimir-gateway:8080/prometheus (adjust for your deployment) Prometheus type: Select “Mimir” from dropdown Save \u0026 test Via Provisioning (GitOps):\n# grafana/provisioning/datasources/mimir.yaml apiVersion: 1 datasources: - name: Mimir type: prometheus access: proxy url: http://mimir-gateway.mimir.svc.cluster.local:8080/prometheus jsonData: prometheusType: Mimir timeInterval: 15s httpMethod: POST Best Practices Label Strategy and Cardinality Management Golden Rule: Avoid unbounded labels (infinite possible values).\nGood Labels (bounded cardinality):\n{service=\"battle-api\"} # Limited number of services {environment=\"production\"} # dev, staging, production (3 values) {region=\"us-east-1\"} # Limited AWS regions {status_code=\"200\"} # ~50 HTTP status codes {method=\"GET\"} # GET, POST, PUT, DELETE, PATCH (~7 values) Bad Labels (unbounded cardinality):\n{user_id=\"12345\"} # Millions of users = millions of series {request_id=\"abc-123-def\"} # Every request unique = infinite series {email=\"user@example.com\"} # Unbounded user emails {timestamp=\"1634567890\"} # Infinite timestamp values {session_id=\"xyz789\"} # Every session unique Cardinality Calculation:\nTotal Series = Metric × (Label1_Values × Label2_Values × ... × LabelN_Values) Example:\nhttp_requests_total{service, environment, region, method, status_code} = 1 metric × (10 services × 3 environments × 5 regions × 7 methods × 50 status codes) = 1 × 52,500 = 52,500 time series Adding user_id (1M users):\n= 52,500 × 1,000,000 = 52.5 billion time series (UNSUSTAINABLE!) Best Practices:\nUse Bounded Sets: Labels should have enumerable values Aggregate Before Storing: Use recording rules to pre-aggregate high-cardinality metrics Drop Unused Labels: Use metric_relabel_configs in Prometheus to drop unnecessary labels Monitor Cardinality: Enable cardinality analysis in Mimir Set Limits: Configure per-tenant series limits to prevent runaway cardinality Configuration Best Practices Ingester Tuning File Descriptors:\n# Set system limits for ingester pods/containers ulimit -n 65536 # Minimum ulimit -n 1048576 # For 1000+ tenants Memory and Disk:\ningester: # Target 1.5M series per ingester (conservative) # Max 5M series per ingester (with sufficient memory) blocks_storage: tsdb: # Reduce block creation interval for lower memory usage block_ranges_period: [1h] # vs. default 2h # Tune for high tenant count head_chunks_write_buffer_size_bytes: 2097152 # 2MB (default 4MB) stripe_size: 8192 # Default 16384 Zone-Aware Replication:\ningester: ring: zone_awareness_enabled: true instance_availability_zone: ${AZ} # us-east-1a, us-east-1b, etc. Querier and Store-Gateway Optimization Enable Caching (CRITICAL for production):\nblocks_storage: bucket_store: # Metadata cache metadata_cache: backend: memcached memcached: addresses: memcached-metadata:11211 # Index cache (high CPU usage) index_cache: backend: memcached memcached: addresses: memcached-index:11211 # Chunks cache (high bandwidth usage) chunks_cache: backend: memcached memcached: addresses: memcached-chunks:11211 max_item_size: 5242880 # 5MB max chunk size query_frontend: # Query results cache results_cache: backend: memcached memcached: addresses: memcached-results:11211 timeout: 500ms File Descriptors:\n# Store-gateway needs many open files for index-headers ulimit -n 65536 # Minimum SSD Recommendations:\nIngesters: SSD for WAL performance Store-Gateways: SSD for index-header operations Compactor: SSD for faster compaction Compactor Configuration For Standard Tenants:\ncompactor: compaction_interval: 30m cleanup_interval: 15m data_dir: /data/compactor block_ranges: [2h, 12h, 24h] For Large Tenants (\u003e20M series):\ncompactor: # Enable split-and-merge compaction split_and_merge_shards: 4 # 1 shard per 8M series split_groups: 4 # Match shard count or next power of 2 Retention Configuration:\nlimits: # Global default: 1 year retention compactor_blocks_retention_period: 1y # Per-tenant overrides via runtime config overrides: tenant-production: compactor_blocks_retention_period: 2y # 2 years for production tenant-development: compactor_blocks_retention_period: 4w # 4 weeks for dev Storage Backend Selection Cloud Deployments:\nAWS: Use Amazon S3 (native integration, lowest latency in AWS) GCP: Use Google Cloud Storage (native integration, lowest latency in GCP) Azure: Use Azure Blob Storage (disable hierarchical namespace!) On-Premises Deployments:\nMinIO: Deploy distributed MinIO (4+ nodes with erasure coding) Ceph: Use Ceph RADOS Gateway (S3-compatible) OpenStack Swift: For OpenStack environments Bucket Configuration:\n# CRITICAL: Use separate buckets for each storage type blocks_storage: s3: bucket_name: mimir-blocks # TSDB blocks ruler_storage: s3: bucket_name: mimir-ruler # Recording/alerting rules alertmanager_storage: s3: bucket_name: mimir-alertmanager # Alertmanager state Bucket Lifecycle Policies (cost optimization):\n\u003c!-- AWS S3 Lifecycle Policy Example --\u003e \u003cLifecycleConfiguration\u003e \u003cRule\u003e \u003cID\u003eTransitionOldMetrics\u003c/ID\u003e \u003cStatus\u003eEnabled\u003c/Status\u003e \u003cTransition\u003e \u003cDays\u003e90\u003c/Days\u003e \u003cStorageClass\u003eSTANDARD_IA\u003c/StorageClass\u003e \u003c/Transition\u003e \u003cTransition\u003e \u003cDays\u003e180\u003c/Days\u003e \u003cStorageClass\u003eGLACIER_IR\u003c/StorageClass\u003e \u003c/Transition\u003e \u003c/Rule\u003e \u003c/LifecycleConfiguration\u003e Performance Tuning gRPC Compression Enable compression between components to reduce network bandwidth:\n# Ingester → Object Storage compression blocks_storage: s3: # Enable gzip compression for block uploads send_content_encoding: gzip # Query-Frontend → Querier compression querier: frontend_client: grpc_client_config: # Enable gzip compression grpc_compression: gzip Compression Trade-offs:\nSnappy: ~5x compression, 400 MiB/s throughput (low CPU) Gzip: 6-8x compression, 50-135 MiB/s throughput (higher CPU) Query Optimization Query Splitting:\nquery_frontend: # Split large time-range queries into smaller chunks split_queries_by_interval: 24h # Split into 24-hour chunks align_queries_with_step: true Query Sharding:\nquery_frontend: # Shard queries across time series for parallel execution parallelize_shardable_queries: true Query Caching:\nquery_frontend: cache_results: true results_cache: backend: memcached memcached: addresses: memcached:11211 # Cache queries for 10 minutes cache_unaligned_requests: true Avoid Querying Non-Compacted Blocks Use default values for these settings to avoid querying uncompacted blocks:\nquerier: # Query store-gateway for data older than 12h query_store_after: 12h # Query ingesters for data within 13h query_ingesters_within: 13h blocks_storage: bucket_store: # Store-gateway ignores blocks uploaded within 10h ignore_blocks_within: 10h This ensures queriers only fetch compacted, optimized blocks from store-gateways.\nMulti-Tenancy Best Practices Always Use Reverse Proxy:\nClient → Auth Proxy (validates user, injects X-Scope-OrgID) → Mimir Never expose Mimir directly to untrusted clients.\nPer-Tenant Limits:\n# Global defaults (conservative) limits: ingestion_rate: 10000 max_global_series_per_user: 1000000 # Runtime config for per-tenant overrides overrides: premium-tenant: ingestion_rate: 100000 max_global_series_per_user: 10000000 standard-tenant: ingestion_rate: 25000 max_global_series_per_user: 2500000 Enable Shuffle Sharding:\ningester: ring: # Reduce blast radius: each tenant uses subset of ingesters instance_enable_ipv6: false unregister_on_shutdown: true Common Pitfalls to Avoid Not Enabling Caching: Queries will hammer object storage (high cost, poor performance) Unbounded Label Cardinality: User IDs, request IDs, timestamps in labels Insufficient File Descriptors: Ingesters and store-gateways need high limits Same Bucket for Different Stores: Always use separate buckets Azure Hierarchical Namespace: Must be disabled (causes orphaned directories) No Monitoring: Deploy mimir-mixin dashboards and alerts from day one Under-provisioning Compactor Disk: Needs space for source + destination blocks Ignoring Latency Spikes: Upgrade to v2.15+ for improved block-cutting When to Use Mimir Ideal Use Cases 1. Enterprise Scale (\u003e10M active series)\nPrometheus hits memory and disk limits around 10-50M series depending on hardware. Mimir scales horizontally to billions of series.\nExample: Multi-region infrastructure with 100+ Kubernetes clusters, each running hundreds of services.\n2. Long-Term Retention (months to years)\nPrometheus retention limited by local disk capacity (typically days to weeks). Mimir uses object storage for years of retention.\nExample: Compliance requirements for 2-year metrics retention, capacity planning based on historical trends.\n3. Multi-Cluster Aggregation\nMultiple Prometheus instances across regions/environments need unified querying.\nExample: Global view of service health across US, EU, and APAC deployments.\n4. Multi-Tenancy\nPer-customer, per-team, or per-environment isolation with resource limits.\nExample: SaaS platform providing per-customer metrics dashboards, or large organization isolating team metrics.\n5. High Availability Requirements\nNo tolerance for data loss or query unavailability.\nExample: Financial services, healthcare, or e-commerce platforms requiring 99.9%+ uptime.\nAnti-Patterns (When NOT to Use Mimir) 1. Small-Scale Deployments (\u003c1M active series, \u003c30 days retention)\nProblem: Mimir’s complexity unjustified for workloads Prometheus handles easily.\nSolution: Use standalone Prometheus until scale demands distributed storage.\n2. Operational Complexity Constraints\nProblem: Team lacks distributed systems expertise or Kubernetes experience.\nSolution: Start with Prometheus, build expertise, migrate to Mimir when needed.\n3. Cost-Constrained Environments\nProblem: Mimir has higher baseline infrastructure costs (multiple components + object storage).\nSolution: Prometheus is more cost-effective at small scale.\n4. Real-Time Only (No Historical Analysis)\nProblem: If only real-time alerting needed (no dashboards, no historical queries).\nSolution: Prometheus sufficient; Mimir’s long-term storage unused.\nMimir vs. Prometheus Comparison Factor Prometheus Grafana Mimir Active Series Limit 10-50M (single machine) 1B+ (distributed) Retention Days to weeks (disk-limited) Months to years (object storage) Scalability Vertical only Horizontal (all components) High Availability Manual (federation/replica pairs) Built-in (replication + distribution) Multi-Tenancy Not built-in Native support Operational Complexity Low (single binary) High (microservices) Setup Time Minutes Hours to days Cost (Small Scale) Lower Higher Cost (Large Scale) Not feasible Medium (object storage efficient) Query Performance Excellent (local disk) Good (distributed, cached) Use Case Small-medium, real-time Enterprise, long-term, multi-cluster Mimir vs. Thanos Comparison Both Mimir and Thanos solve similar problems but with different approaches.\nFactor Thanos Grafana Mimir Architecture Sidecar or Receiver mode Receiver mode only (push-based) Design Focus Operational simplicity, cost Performance, scalability Compaction Standard TSDB compaction Split-and-merge (overcomes 64GB index limit) Max Index Size 64GB (TSDB limit) No practical limit Query Caching Metadata caching only Full query result caching Maturity Mature, CNCF project Newer, actively developed Deployment Model Pull (sidecar) or push (receiver) Push only (remote write) Grafana Integration Good Excellent (same vendor) Community Large CNCF community Grafana Labs + community When to Choose Mimir:\nNeed maximum performance and scalability Prefer Grafana ecosystem integration Large tenants (\u003e20M series per tenant) Active development and new features valued When to Choose Thanos:\nPrefer sidecar deployment model (pull-based) CNCF governance important Operational simplicity over raw performance Existing Thanos deployments Mimir vs. Cortex Relationship: Mimir is the successor to Cortex (forked March 2022).\nKey Differences:\nDevelopment: Mimir actively developed by Grafana Labs; Cortex in maintenance mode Features: Mimir has newer features (monolithic mode, improved compactor, OTLP support matured first) Complexity: Mimir simplified some operational aspects of Cortex Migration: Cortex → Mimir migration supported and documented Recommendation: Always use Mimir for new deployments. Only run Cortex if already deployed and not ready to migrate.\nDecision Criteria Matrix Use this matrix to determine if Mimir is right for your use case:\nCriterion Prometheus Mimir Thanos Active Series \u003c10M \u003e10M \u003e10M Retention Requirement \u003c30 days \u003e30 days \u003e30 days Multi-Cluster Single cluster Multiple clusters Multiple clusters Multi-Tenancy Not needed Required Via labels Team Expertise Limited Distributed systems Distributed systems Budget Constrained Medium-High Medium Deployment Model Any Kubernetes preferred Kubernetes or VMs Vendor Preference Neutral Grafana ecosystem CNCF ecosystem Decision Guide:\nChoose Prometheus if:\nActive series \u003c 10M Retention \u003c 30 days Single Kubernetes cluster Team prefers simplicity Choose Mimir if:\nActive series \u003e 10M (or expect to reach soon) Retention \u003e 30 days Multiple Prometheus instances to aggregate Multi-tenancy required Grafana ecosystem preferred Choose Thanos if:\nWant to keep Prometheus sidecar model CNCF governance important Operational simplicity over maximum performance Existing Thanos deployment BattleBots Integration Points For the BattleBots platform, Mimir would serve as the centralized metrics storage backend within the broader observability stack.\nObservability Stack Architecture graph TB subgraph \"Metric Sources\" Bot[Bot Containers] Game[Game Servers] API[Battle API] K8s[Kubernetes] Host[Host Systems] end subgraph \"Collection Layer\" OTel[OpenTelemetry Collector] Bot --\u003e OTel Game --\u003e OTel API --\u003e OTel K8s --\u003e OTel Host --\u003e OTel end subgraph \"Storage Layer\" OTel --\u003e|OTLP Metrics| Mimir[(Grafana Mimir\u003cbr/\u003eMetrics Storage)] OTel --\u003e|OTLP Logs| Loki[(Grafana Loki\u003cbr/\u003eLog Storage)] OTel --\u003e|OTLP Traces| Tempo[(Grafana Tempo\u003cbr/\u003eTrace Storage)] end subgraph \"Query \u0026 Visualization\" Grafana[Grafana] Grafana --\u003e Mimir Grafana --\u003e Loki Grafana --\u003e Tempo end subgraph \"Alerting\" Mimir --\u003e|Alerts| AM[Alertmanager] AM --\u003e|Notifications| Slack[Slack/PagerDuty] end style OTel fill:#e1f5ff style Mimir fill:#fff4e1 style Loki fill:#e8f5e9 style Tempo fill:#f3e5f5 style Grafana fill:#ffe0b2 Game Metrics Use Cases Bot Performance Metrics Action Latency:\n# 95th percentile attack action latency by bot type histogram_quantile(0.95, sum(rate(bot_action_duration_seconds_bucket{action=\"attack\"}[5m])) by (bot_type, le) ) # Slow bots (p95 \u003e 100ms) histogram_quantile(0.95, sum(rate(bot_action_duration_seconds_bucket[5m])) by (bot_id, le) ) \u003e 0.1 Bot Health Tracking:\n# Average bot health per battle avg(bot_health_points) by (battle_id, bot_id) # Bots eliminated in last hour count(bot_health_points == 0) by (battle_id) Resource Usage:\n# CPU usage per bot container rate(container_cpu_usage_seconds_total{ namespace=\"battlebots\", pod=~\"bot-.*\" }[5m]) # Memory usage per bot container_memory_working_set_bytes{ namespace=\"battlebots\", pod=~\"bot-.*\" } / 1024 / 1024 # Convert to MB Battle Event Metrics Battle State:\n# Active battles sum(battle_state{state=\"active\"}) # Average battle duration rate(battle_duration_seconds_sum[5m]) / rate(battle_duration_seconds_count[5m]) # Battles per minute rate(battles_total[1m]) * 60 Matchmaking Metrics:\n# Players in queue player_queue_length # Average queue wait time rate(queue_wait_seconds_sum[5m]) / rate(queue_wait_seconds_count[5m]) # Matchmaking success rate rate(matchmaking_success_total[5m]) / rate(matchmaking_attempts_total[5m]) Infrastructure Metrics Use Cases API Performance:\n# Request rate by endpoint and status sum(rate(http_requests_total{service=\"battle-api\"}[5m])) by (endpoint, status_code) # Error rate sum(rate(http_requests_total{status_code=~\"5..\"}[5m])) / sum(rate(http_requests_total[5m])) # p99 latency histogram_quantile(0.99, sum(rate(http_request_duration_seconds_bucket[5m])) by (endpoint, le) ) Kubernetes Metrics:\n# Pod restart rate rate(kube_pod_container_status_restarts_total{ namespace=\"battlebots\" }[1h]) # Pods not ready count(kube_pod_status_phase{ namespace=\"battlebots\", phase!=\"Running\" }) # Node resource utilization sum(node_memory_MemAvailable_bytes) / sum(node_memory_MemTotal_bytes) Label Strategy for BattleBots Recommended Labels:\n{ # Infrastructure labels cluster=\"us-east-1-prod\", namespace=\"battlebots\", service=\"battle-api\", environment=\"production\", # Game labels battle_id=\"12345\", # OK if battles are finite and expire bot_type=\"tank\", # Enumerable bot types game_mode=\"team-deathmatch\", # Bounded game modes region=\"us-east\", # Geographic regions # Avoid these! # player_id=\"...\", # High cardinality # session_id=\"...\", # Unbounded # request_id=\"...\", # Infinite values } Cardinality Estimate:\nhttp_requests_total { service: 10 values (battle-api, game-server, matchmaking, etc.) environment: 3 values (dev, staging, prod) region: 5 values (us-east, us-west, eu-west, ap-south, ap-east) method: 7 values (GET, POST, PUT, DELETE, PATCH, OPTIONS, HEAD) endpoint: 50 values (API endpoints) status_code: 50 values (HTTP status codes) } = 1 × 10 × 3 × 5 × 7 × 50 × 50 = 2,625,000 time series # Acceptable cardinality for 1 metric Example PromQL Queries for BattleBots Battle Analytics:\n# Total battles completed today increase(battles_completed_total[24h]) # Win rate by bot type sum(rate(battle_outcomes_total{outcome=\"victory\"}[1h])) by (bot_type) / sum(rate(battle_outcomes_total[1h])) by (bot_type) # Average players online by hour avg_over_time(players_online_total[1h]) Capacity Planning:\n# CPU headroom (sum(node_cpu_capacity_cores) - sum(rate(node_cpu_usage_seconds_total[5m]))) / sum(node_cpu_capacity_cores) # Memory headroom (sum(node_memory_MemTotal_bytes) - sum(node_memory_MemUsed_bytes)) / sum(node_memory_MemTotal_bytes) # Projected series growth predict_linear(mimir_ingester_active_series[24h], 7*24*3600) Cost Optimization:\n# Underutilized bot containers (CPU \u003c 10%) avg(rate(container_cpu_usage_seconds_total{pod=~\"bot-.*\"}[5m])) by (pod) \u003c 0.1 # Idle game servers count(game_server_active_battles == 0) by (instance) Alerting Examples Critical Alerts:\ngroups: - name: battlebots-critical interval: 30s rules: # Battle API down - alert: BattleAPIDown expr: up{job=\"battle-api\"} == 0 for: 1m labels: severity: critical annotations: summary: \"Battle API is down\" description: \"Battle API {{ $labels.instance }} has been down for more than 1 minute\" # High error rate - alert: HighErrorRate expr: | sum(rate(http_requests_total{status_code=~\"5..\"}[5m])) / sum(rate(http_requests_total[5m])) \u003e 0.05 for: 5m labels: severity: critical annotations: summary: \"High error rate detected\" description: \"Error rate is {{ $value | humanizePercentage }}\" # Ingester approaching series limit - alert: MimirIngesterSeriesLimit expr: | mimir_ingester_active_series / mimir_limits_overrides{limit_name=\"max_global_series_per_user\"} \u003e 0.8 for: 15m labels: severity: warning annotations: summary: \"Mimir ingester approaching series limit\" Integration with Loki and Tempo Metric-to-Log Correlation:\n# In Grafana, link from metric spike to logs {namespace=\"battlebots\", service=\"battle-api\"} |= \"error\" | logfmt | battle_id=\"12345\" Metric-to-Trace Correlation:\nUse exemplars in Prometheus metrics to link to traces Query by trace_id in Tempo from metric anomalies Grafana’s Explore view shows metrics → traces → logs correlation Unified Dashboard Example:\n┌─────────────────────────────────────┐ │ Battle API Request Rate (Mimir) │ │ [Graph showing spike at 14:30] │ └─────────────────────────────────────┘ ↓ Click spike ┌─────────────────────────────────────┐ │ Traces at 14:30 (Tempo) │ │ [Slow traces listed] │ └─────────────────────────────────────┘ ↓ Click trace ┌─────────────────────────────────────┐ │ Logs for trace_id (Loki) │ │ [Error logs with stack trace] │ └─────────────────────────────────────┘ Further Reading Official Documentation Grafana Mimir Documentation - Comprehensive official docs Mimir GitHub Repository - Source code, issues, discussions Mimir Architecture Overview - Detailed architecture guide Mimir Configuration Parameters - Complete config reference Mimir Runbooks - Troubleshooting guides Deployment and Operations Helm Chart Documentation - Kubernetes deployment guide Production Tips - Best practices Capacity Planning - Resource estimation Mimir Capacity Calculator - Interactive sizing tool Monitor Mimir Health - Self-monitoring setup Integration Guides Configure OpenTelemetry Collector for Mimir - OTLP integration Migrate from Prometheus to Mimir - Migration guide Remote Write Tuning - Optimize Prometheus → Mimir ingestion Grafana Dashboards for Mimir - Pre-built dashboards Performance and Scaling How We Scaled Mimir to 1 Billion Active Series - Grafana Labs blog Scaling Mimir to 500M Series (Customer Story) - Pipedrive case study Mimir vs Prometheus Scalability - Real-world comparison Query Performance Optimization - PromQL tuning Comparisons and Decision Guides Mimir vs Prometheus Comparison - Detailed comparison Mimir vs Thanos Discussion - Community comparison Prometheus and Centralized Storage - When to use centralized metrics Community and Support Mimir Community Forum - Ask questions, share knowledge Grafana Slack #mimir Channel - Real-time community support Mimir Release Notes - Version history and breaking changes CNCF OpenTelemetry Project - Related OTLP ecosystem Tutorials and Workshops Play with Grafana Mimir - Hands-on tutorial Mimir Workshop - Full Docker Compose examples OTLP Integration Tutorial - OpenTelemetry + Mimir guide Advanced Topics Cardinality Management - Label strategy Multi-Tenancy Setup - Tenant isolation guide Ingest Storage Architecture - Kafka-based ingestion (Mimir 3.0+) Split-and-Merge Compactor - Large tenant optimization ","categories":"","description":"Comprehensive overview of Grafana Mimir architecture, deployment modes, storage backends, and operational best practices for long-term Prometheus metrics storage.\n","excerpt":"Comprehensive overview of Grafana Mimir architecture, deployment …","ref":"/battlebots/pr-preview/pr-153/research_and_development/analysis/observability/metrics/mimir/mimir-overview/","tags":"","title":"Mimir: Overview and Architecture"},{"body":"Overview This section contains research and analysis of observability solutions for the BattleBots platform. Observability is critical for:\nMonitoring real-time battle events and game state Tracking bot performance and system health Debugging issues in distributed game architecture Analyzing player behavior and system usage patterns Ensuring reliable service operation Components OpenTelemetry Collector Analysis of the OpenTelemetry Collector, a vendor-agnostic telemetry data pipeline that can receive, process, and export logs, metrics, and traces to multiple backends.\nThe OpenTelemetry Collector serves as a centralized telemetry hub, providing:\nVendor neutrality for any observability backend Protocol translation between Prometheus, Jaeger, Zipkin, and OTLP Unified collection pipeline for logs, metrics, and traces Flexible deployment in agent, gateway, or hybrid modes Signal correlation linking traces, metrics, and logs Includes detailed analysis of:\nArchitecture and core components Logs, metrics, and traces support Self-monitoring and operational considerations BattleBots platform integration patterns Log Storage Analysis of log storage backends for the BattleBots observability stack, focusing on systems that integrate with the OpenTelemetry Collector.\nLog storage is essential for:\nAggregating logs from distributed game servers and services Enabling fast search and filtering for debugging Correlating logs with traces and metrics for unified observability Long-term retention for compliance and historical analysis Cost-effective storage at scale Grafana Loki Research on Grafana Loki, a horizontally scalable, multi-tenant log aggregation system designed for cost-effective log storage and querying.\nLoki uses an index-free approach that indexes only metadata labels rather than full log content, providing:\nNative OTLP support (Loki v3+) for seamless OpenTelemetry Collector integration Label-based querying through LogQL Efficient storage with compressed chunks Horizontal scalability and multi-tenancy Tight integration with Grafana for visualization Includes detailed analysis of:\nArchitecture and core concepts Deployment modes and operational best practices OTLP compatibility and OTel Collector integration Label strategy and performance considerations Metrics Storage Analysis of metrics storage backends for the BattleBots observability stack, focusing on systems that integrate with the OpenTelemetry Collector.\nMetrics storage is essential for:\nReal-time monitoring of battle events and game state Historical analysis of bot performance and system behavior Capacity planning and infrastructure optimization Alerting on critical system conditions Long-term trend analysis and reporting Grafana Mimir Research on Grafana Mimir, a horizontally scalable, highly available, multi-tenant metrics storage system for long-term Prometheus data retention.\nMimir transforms Prometheus from a single-server monitoring system into a distributed platform capable of handling over 1 billion active time series, providing:\nNative OTLP support for direct integration with OpenTelemetry Collector Horizontal scalability through independent scaling of write path, read path, and backend components Long-term storage using object storage backends (S3, GCS, MinIO) with months to years of retention Built-in multi-tenancy with per-tenant resource limits and isolation Full Prometheus (PromQL) compatibility for queries, dashboards, and alerts High availability through replication and distributed architecture Includes detailed analysis of:\nArchitecture components (distributor, ingester, querier, store-gateway, compactor) and deployment modes Native OTLP ingestion endpoints and OpenTelemetry Collector integration (otlphttp and prometheusremotewrite exporters) Object storage backends, blocks storage architecture, and retention policies Multi-tenancy setup, cardinality management, and label strategy Comparison with Prometheus, Thanos, and Cortex Production deployment patterns, resource requirements, and operational best practices Traces Storage Analysis of distributed tracing storage backends for the BattleBots observability stack, focusing on systems that integrate with the OpenTelemetry Collector.\nTraces storage is essential for:\nTracking end-to-end request flow through distributed game servers and services Debugging performance bottlenecks and latency issues in battle workflows Understanding service dependencies and call patterns Root cause analysis when correlating with metrics and logs Visualizing complete battle lifecycles from matchmaking to results Grafana Tempo Research on Grafana Tempo, a high-volume, minimal dependency distributed tracing backend designed for cost-efficiency and operational simplicity.\nTempo uses an object storage-only architecture that eliminates complex database dependencies, providing:\nNative OTLP support (gRPC port 4317, HTTP port 4318) for seamless OpenTelemetry Collector integration Cost-effective storage using object storage backends (S3, GCS, MinIO) with 10x+ cost reduction compared to traditional tracing systems TraceQL query language for powerful trace filtering and analysis Horizontal scalability through microservices architecture Seamless correlation with Grafana, Loki, and Mimir through exemplars and trace IDs for unified observability Multi-protocol support (OTLP, Jaeger, Zipkin, OpenCensus) for flexible integration Includes detailed analysis of:\nArchitecture components (distributor, ingester, querier, compactor, metrics-generator) and deployment modes Native OTLP ingestion endpoints and OpenTelemetry Collector integration (otlp and otlphttp exporters) Object storage backends, blocks storage architecture, and sampling strategies TraceQL query language and trace-to-metrics-to-logs correlation Comparison with Jaeger, Zipkin, and Elastic APM Production deployment patterns, resource requirements, and operational best practices Future ADR Dependencies This analysis will inform:\nADR-NNNN: Observability Stack Selection - Which backends to use (Loki, Prometheus, Jaeger, etc.) ADR-NNNN: Telemetry Collection Strategy - Agent vs. gateway deployment, sampling policies ADR-NNNN: Telemetry Data Retention - Storage duration and cost management Related Documentation R\u0026D Documentation User Journey 0001: POC - Observability requirements context Future ADRs on observability stack architecture External Resources OpenTelemetry Documentation OpenTelemetry Collector GitHub OpenTelemetry Collector Contrib CNCF OpenTelemetry Project Contributing These analysis documents are living documents that should be updated as:\nNew OpenTelemetry Collector features are released BattleBots observability requirements evolve Team members gain operational experience with the Collector Best practices and patterns are discovered Updates should maintain the high-level overview focus with links to authoritative sources for technical deep-dives.\n","categories":"","description":"Research and analysis of observability solutions for the BattleBots platform.\n","excerpt":"Research and analysis of observability solutions for the BattleBots …","ref":"/battlebots/pr-preview/pr-153/research_and_development/analysis/observability/","tags":"","title":"Observability Analysis"},{"body":"Overview The OpenTelemetry Collector serves as a centralized telemetry hub, removing the need to run multiple agents or collectors for different formats and backends. It provides:\nVendor neutrality: Works with any observability backend Protocol translation: Converts between Prometheus, Jaeger, Zipkin, and OTLP formats Unified collection: Single pipeline for logs, metrics, and traces Flexible deployment: Agent mode, gateway mode, or hybrid Signal correlation: Links traces, metrics, and logs through shared context Document Structure The analysis is organized into the following documents:\nOpenTelemetry Collector Overview High-level architectural overview covering:\nCore components (receivers, processors, exporters, extensions) Pipeline-based architecture and data flow Deployment patterns (agent, gateway, hybrid) Configuration fundamentals When to use the Collector vs. direct exports Audience: Everyone—provides foundational understanding for all subsequent documents.\nLogs Support Deep dive into log data handling:\nOTLP logs data model and structure Log receivers (filelog, syslog, OTLP) Log processors (attributes, filter, transform) Log exporters (Loki, Elasticsearch, OTLP) Log correlation with traces and metrics Configuration patterns for log collection Audience: Developers implementing log collection, operations teams configuring log pipelines.\nMetrics Support Deep dive into metrics data handling:\nOpenTelemetry metrics data model Metric types (counters, gauges, histograms, summaries) Temporality (delta vs. cumulative) Metrics receivers (Prometheus, hostmetrics, OTLP) Metrics processors and exporters Performance and cardinality considerations Audience: Developers instrumenting applications, SREs monitoring infrastructure.\nTraces Support Deep dive into distributed tracing:\nTrace and span data model Context propagation mechanisms Trace receivers (OTLP, Jaeger, Zipkin) Sampling strategies (head vs. tail sampling) Trace processors and exporters Multi-backend routing Audience: Developers implementing distributed tracing, architects designing observability strategy.\nSelf-Monitoring How to observe the Collector itself:\nInternal metrics and telemetry Extensions (health_check, zpages, pprof) Debugging and troubleshooting techniques Performance monitoring and optimization Production monitoring best practices Audience: Operations teams, SREs responsible for Collector reliability.\nBattleBots Platform Context For the BattleBots platform, the OpenTelemetry Collector would support:\nGame Event Observability Logs: Battle events, bot actions, game state transitions, error conditions Metrics: Match duration, action rates, player counts, system resource usage Traces: Request flows from player action to state update to broadcast Infrastructure Monitoring Host metrics: Server CPU, memory, disk, network utilization Application metrics: Go runtime metrics, HTTP latency, WebSocket connections Container metrics: Resource limits, restart counts, health status Cross-Signal Correlation The Collector enables powerful debugging workflows:\nAlert fires on high error rate (metrics) Drill down to traces showing failing requests View logs associated with failing trace spans Identify root cause with full context This unified observability is particularly valuable during live battles when quick diagnosis is essential.\nImplementation Considerations Deployment Architecture For BattleBots, a recommended deployment would include:\nAgent Mode:\nCollectors running alongside each game server Local log file collection with filelog receiver Host metrics collection for server monitoring OTLP receiver for application telemetry Gateway Mode:\nCentralized collectors receiving data from agents Tail sampling for intelligent trace retention Multi-backend routing (analytics, debugging, long-term storage) Buffering and retry for backend resilience Signal-Specific Patterns Logs:\nCollect structured JSON logs from game servers Parse and enrich with resource attributes Filter debug logs in production Route to Loki or Elasticsearch Metrics:\nScrape Prometheus metrics from Go services Collect host metrics from servers Aggregate and downsample for cost efficiency Export to Prometheus or cloud backends Traces:\nInstrument Go services with OpenTelemetry SDK Use head sampling for baseline reduction (10%) Apply tail sampling to always capture errors Export to Jaeger or Grafana Tempo External Resources OpenTelemetry Documentation OpenTelemetry Collector GitHub OpenTelemetry Collector Contrib CNCF OpenTelemetry Project Contributing These analysis documents are living documents that should be updated as:\nNew OpenTelemetry Collector features are released BattleBots observability requirements evolve Team members gain operational experience with the Collector Best practices and patterns are discovered Updates should maintain the high-level overview focus with links to authoritative sources for technical deep-dives.\n","categories":"","description":"Research and analysis of the OpenTelemetry Collector for logs, metrics, and traces collection and processing.\n","excerpt":"Research and analysis of the OpenTelemetry Collector for logs, …","ref":"/battlebots/pr-preview/pr-153/research_and_development/analysis/observability/otel-collector/","tags":"","title":"OpenTelemetry Collector"},{"body":"Overview The OpenTelemetry Collector is a vendor-agnostic application that receives, processes, and exports telemetry data (traces, metrics, and logs). It serves as a centralized component in observability architectures, removing the need to run multiple agents or collectors for different telemetry formats and backends.\nThe Collector supports open-source observability data formats including Jaeger, Prometheus, Fluent Bit, and others, while providing a unified approach to telemetry handling. It enables services to offload telemetry data quickly while the Collector handles retries, batching, encryption, and sensitive data filtering.\nKey benefits include vendor independence, reduced operational complexity, and the ability to route telemetry data to multiple backends simultaneously without modifying application code.\nKey Concepts The Collector is built around five guiding principles:\nUsability: Provides functional defaults with support for popular protocols out-of-the-box Performance: Maintains stability under varying loads with predictable resource usage Observability: Designed as an observable service itself, exposing its own metrics and health status Extensibility: Allows customization through plugins without requiring modifications to core code Unification: Single codebase supporting all three telemetry signals (traces, metrics, logs) Core Architecture The Collector uses a pipeline-based architecture where data flows through three primary component types, orchestrated by a configuration file.\ngraph LR A[Telemetry Sources] --\u003e B[Receivers] B --\u003e C[Processors] C --\u003e D[Exporters] D --\u003e E[Observability Backends] F[Extensions] -.Optional.-\u003e B F -.Optional.-\u003e C F -.Optional.-\u003e D style A fill:#e1f5ff style E fill:#e1f5ff style B fill:#fff4e6 style C fill:#f3e5f5 style D fill:#e8f5e9 style F fill:#fce4ec Data Flow Telemetry data flows unidirectionally through the Collector:\nReceivers accept incoming telemetry in various formats (OTLP, Jaeger, Prometheus) Processors transform, filter, or enrich the data in a sequential chain Exporters send processed data to one or more backend destinations This pipeline architecture allows the same data to be simultaneously:\nSampled differently for different backends Enriched with environment-specific attributes Routed to multiple observability platforms Components Receivers Receivers gather telemetry data through two mechanisms:\nPush-based: Listen on network endpoints for incoming data Pull-based: Actively scrape metrics from instrumented services Multiple receivers can feed into a single pipeline, with their outputs merged before reaching processors. Common receivers include:\notlp - OpenTelemetry Protocol (gRPC/HTTP) prometheus - Prometheus metrics scraping jaeger - Jaeger trace data filelog - Log file collection For comprehensive receiver documentation, see the OpenTelemetry Collector Receivers.\nProcessors Processors form a sequential chain that transforms data between receivers and exporters. Each processor in the chain operates on the data before passing it to the next processor.\nCommon operations include:\nAdding or removing attributes Sampling (probabilistic, tail-based) Batching for efficient transmission Filtering unwanted telemetry Resource detection (cloud provider, Kubernetes metadata) Important: Each pipeline maintains independent processor instances, even when referencing the same configuration name across multiple pipelines. This prevents unintended state sharing between pipelines.\nFor comprehensive processor documentation, see the OpenTelemetry Collector Processors.\nExporters Exporters forward processed data to external destinations, typically by sending to network endpoints or writing to logging systems. Multiple exporters can receive identical data copies through a fan-out mechanism, enabling simultaneous transmission to different backends.\nCommon exporters include:\notlp - OpenTelemetry Protocol destinations prometheus - Prometheus remote write jaeger - Jaeger backend logging - Standard output for debugging file - Local file storage For comprehensive exporter documentation, see the OpenTelemetry Collector Exporters.\nConnectors Connectors enable inter-pipeline communication and data flow between different telemetry signal types. A connector acts as both an exporter (for one pipeline) and a receiver (for another pipeline).\nUse cases include:\nGenerating metrics from trace spans Creating logs from metric anomalies Correlating signals for enhanced observability For more information, see the OpenTelemetry Collector Connectors.\nExtensions Extensions provide auxiliary functionality that doesn’t directly process telemetry data but supports Collector operations:\nhealth_check - HTTP endpoint for health monitoring pprof - Go profiling endpoint for performance analysis zpages - In-process debugging pages ballast - Memory ballast for GC optimization Extensions are optional but highly recommended for production deployments. See self-monitoring documentation for more details.\nConfiguration The Collector uses YAML configuration files (default: /etc/otelcol/config.yaml) with four main sections:\nreceivers: # Define how to collect telemetry processors: # Define how to transform telemetry exporters: # Define where to send telemetry service: pipelines: # Connect receivers → processors → exporters Pipeline Types Three pipeline types handle different telemetry signals:\ntraces: Distributed tracing data metrics: Time-series measurements logs: Event records Each pipeline independently connects receivers to exporters through an optional processor chain. The same receiver can feed multiple pipelines simultaneously, though this creates a potential bottleneck if one processor blocks.\nConfiguration Best Practices Validate configurations before deployment: otelcol validate --config=file.yaml Use environment variables for sensitive values: ${env:API_KEY} Bind endpoints to localhost for local-only access Apply TLS certificates for production environments Use the type/name syntax for multiple instances of the same component type For detailed configuration guidance, see the Configuration Documentation.\nDeployment Patterns The Collector supports multiple deployment models based on operational requirements and scale.\nAgent Mode In agent mode, lightweight Collector instances run as daemons alongside applications (on the same host, container, or Kubernetes pod). This pattern:\nCollects telemetry from co-located services Performs local sampling and aggregation Reduces network overhead by local processing Simplifies application configuration (default OTLP exporters assume localhost:4317) Use when: You need local collection with per-host resource limits and want to offload telemetry handling from application processes.\nGateway Mode In gateway mode, centralized Collector instances receive data from distributed agents and application libraries, then route to backend systems. This pattern:\nProvides centralized control over data transformation Enables consistent sampling decisions across services Supports complex routing logic to multiple backends Allows for sensitive data filtering before egress Use when: You need centralized policy enforcement, multi-backend routing, or want to isolate backend credentials from application environments.\nHybrid Mode Many production deployments use both agent and gateway patterns:\nAgents perform local collection and basic processing Gateways handle aggregation, complex transformations, and backend routing This hybrid approach balances local efficiency with centralized control.\nNo Collector For development environments or initial experimentation, services can export directly to backends using OTLP. However, this approach loses the benefits of buffering, retries, and transformation capabilities.\nWhen to Use the Collector Recommended Use Cases Deploy a Collector when you need to:\nSupport multiple telemetry formats (Jaeger, Prometheus, custom formats) Route telemetry to multiple backends simultaneously Perform data transformation or enrichment before export Sample or filter telemetry based on configurable rules Isolate backend credentials from application deployments Buffer telemetry during backend outages Offload retry and batching logic from applications Direct Export Scenarios Direct service-to-backend export may be sufficient for:\nDevelopment and testing environments Single-backend deployments with no transformation needs Prototyping and proof-of-concept work Very small-scale deployments Integration Points BattleBots Observability Requirements For the BattleBots platform, the Collector would support:\nBattle Event Tracking: Collecting logs of bot actions and game state changes Performance Metrics: Gathering metrics on bot response times and system resource usage Distributed Tracing: Tracking request flows across client/server or P2P architectures See User Journey 0001: POC for observability requirements context.\nMulti-Signal Correlation The Collector enables correlation between:\nTrace spans and related logs (via trace context) Metrics and traces (via exemplars) Resource attributes across all signals This correlation is particularly valuable for debugging battle scenarios where you need to understand both the timeline of events (traces), the quantitative measurements (metrics), and the detailed context (logs).\nFurther Reading Official Documentation OpenTelemetry Collector Main Documentation Collector Architecture Configuration Reference Component Registry Specifications OTLP Specification OpenTelemetry Specification Implementation Resources Collector GitHub Repository Collector Contrib Repository (additional components) Related Analysis Documents Logs Support - How the Collector handles log data Metrics Support - How the Collector handles metrics Traces Support - How the Collector handles distributed traces Self-Monitoring - Observing the Collector itself ","categories":"","description":"High-level architectural overview of the OpenTelemetry Collector, covering core components, deployment patterns, and use cases.\n","excerpt":"High-level architectural overview of the OpenTelemetry Collector, …","ref":"/battlebots/pr-preview/pr-153/research_and_development/analysis/observability/otel-collector/opentelemetry-collector-overview/","tags":"","title":"OpenTelemetry Collector Overview"},{"body":"Overview The OpenTelemetry Collector provides comprehensive support for collecting, processing, and exporting log data from various sources to multiple backends. Unlike traditional logging agents that focus on specific formats or destinations, the Collector treats logs as first-class observability signals alongside metrics and traces.\nThe Collector’s log support enables correlation between logs and traces through shared execution context (TraceId and SpanId), allowing unified observability across all three signal types. This correlation is particularly valuable for debugging complex distributed systems where understanding both the quantitative measurements and the detailed event context is essential.\nKey capabilities include parsing structured and unstructured log formats, enriching logs with resource attributes, filtering and transforming log content, and routing logs to multiple backends simultaneously.\nKey Concepts OTLP Logs Data Model OpenTelemetry defines a standardized log data model to establish a common understanding of what a LogRecord is and what data needs to be recorded, transferred, stored, and interpreted by logging systems.\nLogRecord Structure:\nA LogRecord contains several key components:\nTimestamp: The moment in time when the event occurred TraceId and SpanId: Execution context identifiers enabling correlation between logs and traces Resource: Describes the origin of the log (host name, container name, pod name, etc.) Instrumentation Scope: Identifies the library or component that generated the log Severity: Indicates the importance or criticality of the log entry Body: The actual log message content (string, structured data, or binary) Attributes: Structured key-value pairs providing additional context This standardized model allows logs from different sources to be processed uniformly while preserving correlation capabilities.\nLog Correlation The logs data model enables correlation across three dimensions:\nTemporal correlation: Based on timestamp alignment Execution context correlation: Using TraceId and SpanId to link logs to specific trace spans Origin correlation: Through Resource context describing the source infrastructure and application This unified approach allows observability backends to perform exact and unambiguous correlation between logs, metrics, and traces.\nLog Receivers Receivers collect log data from various sources and convert it into the OpenTelemetry logs data model.\nFilelog Receiver The filelog receiver tails and parses logs from files, making it ideal for collecting logs from applications that write to local disk.\nKey Capabilities:\nFile monitoring: Tracks multiple log files using glob patterns for inclusion and exclusion Automatic rotation handling: Detects and follows rotated log files and symlinks Compression support: Reads gzip-compressed files with auto-detection Multiline support: Combines log entries spanning multiple lines using custom patterns Format parsing: Built-in parsers for JSON, regex patterns, and structured text Metadata extraction: Parses timestamps, severity levels, and custom fields Persistent offsets: Maintains file positions across collector restarts Example use cases:\nCollecting application logs written to /var/log/ Parsing container logs from Kubernetes Reading structured JSON logs from microservices Configuration note: The filelog receiver uses a pipeline of operators that transform raw file content into structured LogRecords. Each operator performs a specific transformation (parsing, extraction, modification) before passing data to the next operator.\nOTLP Receiver The OTLP receiver accepts log data transmitted using the OpenTelemetry Protocol.\nSupported transports:\ngRPC (default port 4317): Uses unary requests with ExportLogsServiceRequest messages HTTP (default port 4318): POST requests to /v1/logs endpoint Encoding formats:\nBinary Protobuf (application/x-protobuf) JSON Protobuf (proto3 JSON mapping) Use when: Collecting logs directly from applications instrumented with OpenTelemetry SDKs or from upstream OpenTelemetry Collectors in a multi-tier deployment.\nSyslog Receiver The syslog receiver listens for syslog messages over TCP or UDP, supporting RFC 3164 and RFC 5424 formats.\nUse cases:\nCollecting system logs from Linux/Unix hosts Receiving logs from network devices (routers, switches, firewalls) Integrating with legacy applications that use syslog Other Log Receivers The OpenTelemetry Collector ecosystem includes receivers for:\njournald: Reads logs from systemd journal tcplog/udplog: Generic TCP/UDP log receivers windowseventlog: Collects Windows Event Logs kafka: Consumes logs from Kafka topics For a comprehensive list, see the Receiver Components documentation.\nLog Processors Processors transform, filter, and enrich log data as it flows through the pipeline.\nAttributes Processor The attributes processor modifies attributes of log records.\nCapabilities:\nInsert new attributes Update existing attributes Delete attributes Hash attribute values for privacy Extract values from one attribute to another Common use cases:\nAdding environment labels (e.g., environment=production) Removing sensitive data from log attributes Normalizing attribute names across different sources For more details, see the Mastering the OpenTelemetry Attributes Processor guide.\nFilter Processor The filter processor drops log records that match specified conditions using the OpenTelemetry Transformation Language (OTTL).\nCapabilities:\nFilter by log severity level Drop logs matching specific patterns Exclude logs from certain resources Reduce log volume by dropping debug logs in production Example scenarios:\nDropping health check logs to reduce noise Filtering out logs below a certain severity threshold Excluding logs from specific namespaces or services See also the Filter Processor for OpenTelemetry Collector documentation.\nTransform Processor The transform processor modifies log records using OTTL statements.\nCapabilities:\nParse log body content into structured attributes Modify log severity based on content Extract values using regex or JSON path Compute new attributes from existing ones Normalize timestamps Use cases:\nConverting unstructured log messages to structured attributes Extracting user IDs or request IDs from log text Standardizing log formats from multiple sources For transformation guidance, see Transforming telemetry.\nResource Detection Processor The resource detection processor enriches logs with metadata about their execution environment:\nCloud provider information (AWS, GCP, Azure) Kubernetes metadata (pod, namespace, node) Container information (Docker, containerd) Host information (hostname, OS, architecture) This automatic enrichment enables filtering and grouping logs by infrastructure context without manual configuration.\nBatch Processor The batch processor groups log records before sending to exporters, improving throughput and reducing network overhead.\nConfiguration considerations:\nTimeout: Maximum time to wait before sending a batch Batch size: Number of log records per batch Memory limits: Prevents excessive memory usage Batching is recommended for production deployments to optimize resource usage.\nLog Exporters Exporters send processed log data to observability backends and storage systems.\nOTLP HTTP Exporter The OTLP HTTP exporter is the recommended exporter for modern observability backends that support native OTLP ingestion.\nSupported destinations:\nGrafana Loki (v3+): Send logs to Loki’s native OTLP endpoint at http://loki:3100/otlp Elasticsearch: Use OTLP-compatible endpoints Commercial backends: Datadog, New Relic, Honeycomb, Dynatrace Important: The Loki-specific exporter is deprecated. Use the standard otlphttp/logs exporter for Loki v3+ which supports native OTLP ingestion.\nFor setup guidance, see Getting started with the OpenTelemetry Collector and Loki tutorial.\nElasticsearch Exporter The Elasticsearch exporter sends logs, metrics, traces, and profiles directly to Elasticsearch.\nSupported versions:\nElasticsearch 7.17.x Elasticsearch 8.x Elasticsearch 9.x Features:\nIndex routing based on log attributes Dynamic index naming with time-based patterns Bulk API for efficient ingestion File Exporter The file exporter writes logs to local files, useful for:\nDebugging collector pipelines Creating log archives Forwarding to systems that process files Note: Not recommended for production logging backends—use OTLP or dedicated exporters instead.\nLogging Exporter The logging (debug) exporter writes logs to the collector’s standard output. Use this for:\nDevelopment and testing Troubleshooting pipeline configuration Verifying data transformation For additional exporters, see the Exporter Components documentation.\nLog Pipeline Flow A typical log pipeline in the Collector follows this pattern:\ngraph LR A[Log Files] --\u003e B[Filelog Receiver] C[OTLP SDK] --\u003e D[OTLP Receiver] B --\u003e E[Resource Detection] D --\u003e E E --\u003e F[Transform Processor] F --\u003e G[Filter Processor] G --\u003e H[Attributes Processor] H --\u003e I[Batch Processor] I --\u003e J[OTLP HTTP Exporter] J --\u003e K[Loki] I --\u003e L[Elasticsearch Exporter] L --\u003e M[Elasticsearch] style A fill:#e1f5ff style C fill:#e1f5ff style B fill:#fff4e6 style D fill:#fff4e6 style E fill:#f3e5f5 style F fill:#f3e5f5 style G fill:#f3e5f5 style H fill:#f3e5f5 style I fill:#f3e5f5 style J fill:#e8f5e9 style L fill:#e8f5e9 style K fill:#e1f5ff style M fill:#e1f5ff Configuration Considerations Multiline Log Handling Many applications emit logs spanning multiple lines (e.g., stack traces, JSON objects). The filelog receiver supports multiline patterns to combine these entries:\nreceivers: filelog: include: [/var/log/app/*.log] multiline: line_start_pattern: '^\\d{4}-\\d{2}-\\d{2}' Parsing Structured Logs For JSON-formatted logs, configure the filelog receiver with JSON parsing:\nreceivers: filelog: include: [/var/log/app/*.log] operators: - type: json_parser timestamp: parse_from: attributes.time layout: '%Y-%m-%dT%H:%M:%S.%fZ' Log Volume Management High log volumes can overwhelm collectors and backends. Strategies include:\nSampling: Use the probabilistic sampler processor to keep a percentage of logs Filtering: Drop debug/trace logs in production using the filter processor Batching: Configure appropriate batch sizes to balance latency and throughput Tail sampling: Keep only logs associated with interesting traces Performance Tuning For high-throughput log collection:\nIncrease the number of concurrent file readers in filelog receiver Tune batch processor settings (size, timeout) Use multiple collector instances with load balancing Consider gateway deployment to centralize processing Integration Points BattleBots Log Collection For the BattleBots platform, log collection would capture:\nGame events: Bot actions, state transitions, match outcomes System logs: Server startup, configuration changes, errors Client logs: User actions, connection events, performance issues The filelog receiver can parse structured JSON logs from the game server while the OTLP receiver collects logs directly from instrumented Go services.\nLog-Trace Correlation When both logs and traces are collected, correlation enables:\nFinding all logs for a specific trace (query by TraceId) Jumping from a log entry to its parent trace span Identifying logs that occurred during slow requests This requires applications to inject trace context into log records, which OpenTelemetry SDKs handle automatically.\nCross-Signal Analysis Logs complement metrics and traces:\nMetrics show aggregate patterns (error rate spike) Traces show request flow (which service failed) Logs show detailed context (exception message, variable values) The Collector’s unified data model enables seamless correlation across all three signals.\nFurther Reading Official Documentation OpenTelemetry Logs Specification OTLP Specification Receiver Components Processor Components Exporter Components Transforming Telemetry Component-Specific Resources Filelog Receiver Attributes Processor Guide Filter Processor Guide Transform Processor Elasticsearch Exporter Integration Guides Ingesting logs to Loki using OpenTelemetry Collector Getting started with the OpenTelemetry Collector and Loki tutorial Honeycomb Filter Processor Documentation Related Analysis Documents OpenTelemetry Collector Overview - Core architecture and concepts Metrics Support - How the Collector handles metrics Traces Support - How the Collector handles distributed traces Self-Monitoring - Observing the Collector itself ","categories":"","description":"Deep dive into how the OpenTelemetry Collector handles log data, including receivers, processors, exporters, and the OTLP logs data model.\n","excerpt":"Deep dive into how the OpenTelemetry Collector handles log data, …","ref":"/battlebots/pr-preview/pr-153/research_and_development/analysis/observability/otel-collector/otel-collector-logs/","tags":"","title":"OpenTelemetry Collector: Logs Support"},{"body":"Overview The OpenTelemetry Collector provides comprehensive support for collecting, processing, and exporting metrics data from diverse sources to multiple backends. It serves as a bridge between different metrics ecosystems, enabling seamless integration of Prometheus metrics, host system metrics, and custom application metrics within a unified observability platform.\nThe Collector’s metrics support emphasizes signal correlation—connecting metrics to traces through exemplars and enriching attributes via Baggage and Context. This enables powerful observability patterns such as jumping from a metric anomaly to related traces or finding metrics that explain slow trace spans.\nKey capabilities include scraping Prometheus endpoints, collecting host system metrics, transforming metric formats, aggregating data points, and routing metrics to multiple backends simultaneously while handling different temporality preferences.\nKey Concepts OpenTelemetry Metrics Data Model The OpenTelemetry Metrics data model defines how metrics are represented and processed. The data model serves to:\nCapture raw measurements efficiently and simultaneously Decouple instrumentation from the SDK implementation Enable correlation with traces and logs Support migration from OpenCensus and Prometheus Architecture layers:\nMeterProvider \u0026 Instruments: Applications collect measurements through Meters and their associated Instruments In-Memory Aggregation: Measurements aggregate into an intermediate representation MetricReader: Processes aggregated metrics for export to backends Metric Types OpenTelemetry supports four primary metric types, each suited for different measurement scenarios.\nCounter (Sum) Counters represent cumulative or delta measurements that can only increase over time (or be reset to zero). Common examples include:\nRequest count Error count Bytes transmitted Items processed Characteristics:\nMonotonically increasing Supports both delta and cumulative temporality Can be aggregated across instances Typically visualized as rate-of-change For detailed specifications, see OTLP Metrics Types.\nGauge Gauges represent sampled values that can arbitrarily increase or decrease over time. Unlike counters, gauges are not cumulative—they reflect the current value at the time of measurement.\nCommon examples include:\nCPU usage percentage Memory utilization Queue depth Active connection count Temperature readings Characteristics:\nNon-monotonic (can increase or decrease) No aggregation temporality (uses “last sample value”) Represents point-in-time state Cannot be meaningfully aggregated across instances without additional context Histogram Histograms convey a population of recorded measurements in a compressed format by grouping measurements into configurable buckets. This enables statistical analysis without storing individual data points.\nCommon examples include:\nRequest latency distribution Response size distribution Query execution time Message size distribution Characteristics:\nProvides count, sum, and bucket distributions Supports both delta and cumulative temporality Enables percentile calculations (p50, p95, p99) More efficient than storing individual measurements Histograms are particularly valuable for understanding the distribution of latency or size measurements, revealing whether most requests are fast with occasional slow outliers, or if performance degrades uniformly.\nSummary Summaries provide pre-calculated quantile values (percentiles) over a time window. Unlike histograms, which send bucket distributions for backend calculation, summaries compute quantiles client-side.\nImportant: Summary points cannot always be merged meaningfully. This point type is not recommended for new applications and exists primarily for compatibility with other formats like Prometheus summaries.\nFor comprehensive metric type details, see OpenTelemetry Metrics.\nTemporality Temporality defines how metric values are accumulated and reported over time. OpenTelemetry supports two aggregation temporality modes:\nDelta Temporality Delta temporality reports the change since the last collection period. Each data point represents only new measurements since the previous export.\nCharacteristics:\nNon-overlapping time windows Measures rate of change Preferred by some backends (StatsD, Carbon) Requires stateless aggregation Example: A request counter shows +100 requests in period 1, then +150 requests in period 2.\nCumulative Temporality Cumulative temporality reports the total value since process start (or a fixed start point). Each data point includes all measurements from the beginning.\nCharacteristics:\nOverlapping time windows from fixed start Accumulates over application lifetime Preferred by Prometheus Resilient to collection gaps Example: A request counter shows 100 total requests in period 1, then 250 total requests in period 2.\nImportant note: Set the temporality preference to DELTA when possible, as setting it to CUMULATIVE may discard some data points during application or collector startup. However, Prometheus backends require cumulative temporality.\nFor more details, see OpenTelemetry Metrics Aggregation.\nMetrics Receivers Receivers collect metrics data from various sources and convert it into the OpenTelemetry metrics data model.\nPrometheus Receiver The Prometheus receiver enables the OpenTelemetry Collector to act as a Prometheus server by scraping Prometheus-compatible endpoints, then converting the metrics into OTLP format.\nKey capabilities:\nScrapes any Prometheus /metrics endpoint Supports service discovery mechanisms Converts Prometheus metrics to OpenTelemetry format Handles metric relabeling and filtering Scales with Target Allocator for large deployments Configuration example:\nreceivers: prometheus: config: scrape_configs: - job_name: 'otel-collector' scrape_interval: 15s static_configs: - targets: ['localhost:8888'] Scaling with Target Allocator:\nThe Target Allocator decouples service discovery and metric collection, allowing independent scaling. Each Collector pod registers with the Target Allocator, which uses consistent hashing to distribute discovered targets evenly among active Collectors, ensuring each target is scraped exactly once without overlap.\nFor comprehensive guidance, see Prometheus and OpenTelemetry Collector Integration.\nHost Metrics Receiver The hostmetrics receiver collects comprehensive system-level metrics from host machines, providing visibility into infrastructure health.\nAvailable scrapers:\ncpu: CPU utilization, time, and frequency disk: Disk I/O operations and throughput filesystem: Filesystem usage and available space memory: Memory utilization and swap usage network: Network interface statistics and errors load: System load averages paging: Paging and swapping activity processes: Process count and resource usage Configuration example:\nreceivers: hostmetrics: collection_interval: 30s scrapers: cpu: disk: filesystem: memory: network: The hostmetrics receiver is essential for infrastructure monitoring and provides context for application-level metrics. When deployed in Kubernetes, appropriate volumes and volumeMounts are automatically configured when the hostMetrics preset is enabled.\nOTLP Receiver The OTLP receiver accepts metrics data transmitted using the OpenTelemetry Protocol from instrumented applications or upstream collectors.\nSupported transports:\ngRPC (default port 4317) HTTP (default port 4318, endpoint /v1/metrics) Use cases:\nCollecting metrics directly from OpenTelemetry SDKs Multi-tier collector deployments (agent → gateway) Receiving metrics from serverless functions Other Metrics Receivers The ecosystem includes receivers for diverse metrics sources:\nstatsd: Receives StatsD protocol metrics kafka: Consumes metrics from Kafka topics influxdb: Receives InfluxDB line protocol carbon: Receives Graphite carbon metrics collectd: Receives collectd metrics postgresql: Scrapes PostgreSQL metrics redis: Scrapes Redis metrics mongodb: Scrapes MongoDB metrics For a complete list, see the Receiver Components documentation.\nMetrics Processors Processors transform and enrich metrics data as it flows through pipelines.\nMetrics Transform Processor The metrics transform processor modifies metric names, types, and attributes using transformation rules.\nCommon operations:\nRename metrics for consistency Change metric types (e.g., gauge to counter) Add or modify resource attributes Aggregate metrics across dimensions Filter Processor The filter processor drops metrics matching specified conditions, reducing data volume and costs.\nUse cases:\nDropping debug metrics in production Filtering metrics from test environments Excluding high-cardinality metrics Removing specific metric names or attribute values Cumulative to Delta Processor This processor converts cumulative temporality metrics to delta temporality, useful when backends prefer delta metrics.\nAttributes Processor Adds, updates, or deletes metric attributes and resource attributes, enabling:\nEnvironment labeling (environment=production) Team ownership tags (team=platform) Cost allocation labels Normalization across different metric sources Batch Processor Groups metrics before export, improving throughput and reducing network overhead. Recommended for all production deployments.\nConfiguration considerations:\nBatch size: Number of metric data points per batch Timeout: Maximum wait before sending partial batch Memory limits: Prevents unbounded memory growth Metrics Exporters Exporters send processed metrics to observability backends and time-series databases.\nOTLP Exporter The OTLP exporter sends metrics using the OpenTelemetry Protocol to OTLP-compatible backends.\nSupported destinations:\nOpenTelemetry-native backends Cloud vendor endpoints (AWS CloudWatch, Google Cloud Monitoring, Azure Monitor) Commercial observability platforms (Datadog, New Relic, Honeycomb) Important: OTLP is now the recommended protocol for sending metrics to modern backends. For example, Prometheus can now accept OTLP directly:\nexport OTEL_EXPORTER_OTLP_PROTOCOL=http/protobuf export OTEL_EXPORTER_OTLP_METRICS_ENDPOINT=http://localhost:9090/api/v1/otlp/v1/metrics Prometheus Remote Write Exporter The Prometheus Remote Write exporter sends OpenTelemetry metrics to Prometheus remote write compatible backends such as:\nCortex Grafana Mimir Thanos Amazon Managed Service for Prometheus Google Cloud Managed Prometheus Capabilities:\nTLS support (required by default) Queued retry mechanisms Authentication options (basic auth, bearer token, OAuth2) Important limitation: Non-cumulative monotonic, histogram summary, and exponential histogram OTLP metrics are dropped by this exporter.\nFor Grafana Mimir specifically, it’s recommended to use OTLP rather than Prometheus remote write.\nPrometheus Exporter The Prometheus exporter exposes metrics in Prometheus format on an HTTP endpoint for Prometheus servers to scrape.\nUse cases:\nExisting Prometheus deployments Push-based collection converted to pull-based Multi-backend export (push to one, expose for scraping by another) File Exporter Writes metrics to local files for debugging, archival, or processing by batch systems.\nFor additional exporters, see the Exporter Components documentation.\nMetrics Pipeline Flow A typical metrics pipeline demonstrates collection, processing, and export to multiple backends:\ngraph LR A[Prometheus Endpoints] --\u003e B[Prometheus Receiver] C[Host System] --\u003e D[Host Metrics Receiver] E[OTLP SDK] --\u003e F[OTLP Receiver] B --\u003e G[Attributes Processor] D --\u003e G F --\u003e G G --\u003e H[Filter Processor] H --\u003e I[Transform Processor] I --\u003e J[Batch Processor] J --\u003e K[OTLP Exporter] K --\u003e L[Prometheus Server] J --\u003e M[Prometheus Remote Write] M --\u003e N[Grafana Mimir] style A fill:#e1f5ff style C fill:#e1f5ff style E fill:#e1f5ff style B fill:#fff4e6 style D fill:#fff4e6 style F fill:#fff4e6 style G fill:#f3e5f5 style H fill:#f3e5f5 style I fill:#f3e5f5 style J fill:#f3e5f5 style K fill:#e8f5e9 style M fill:#e8f5e9 style L fill:#e1f5ff style N fill:#e1f5ff Configuration Considerations Temporality Management Different backends have different temporality preferences:\nPrometheus: Requires cumulative temporality StatsD-like systems: Prefer delta temporality Cloud vendors: Often accept both Configure the Collector to convert between temporalities based on backend requirements using the cumulative-to-delta processor.\nCardinality Control High cardinality metrics (many unique label combinations) can overwhelm backends and increase costs. Strategies include:\nFiltering high-cardinality dimensions Aggregating metrics before export Dropping rarely-used labels Using metric relabeling to reduce dimensions Scrape Interval Tuning Balance data freshness with resource consumption:\nShort intervals (5-15s): Real-time monitoring, higher costs Medium intervals (30-60s): Standard monitoring Long intervals (5m+): Capacity planning, cost optimization Exemplar Support Exemplars link metrics to traces by attaching trace IDs to specific metric data points. This enables:\nJumping from a high-latency histogram bucket to example slow traces Finding traces that contributed to an error rate spike Correlating metrics anomalies with detailed trace analysis Enable exemplar support in the Prometheus receiver and ensure trace context propagation in applications.\nIntegration Points BattleBots Metrics Collection For the BattleBots platform, metrics collection would capture:\nGame Metrics:\nMatch duration and outcome distribution Bot action rates (attacks, defenses, moves) Game state transition frequency Performance Metrics:\nRequest latency percentiles WebSocket connection counts Message throughput rates Server CPU and memory usage Business Metrics:\nActive user count Matches per hour Bot creation rate The combination of Prometheus receiver (for Go runtime metrics), hostmetrics receiver (for infrastructure), and OTLP receiver (for custom metrics) provides comprehensive visibility.\nMetrics-Trace Correlation Connecting metrics and traces enables powerful workflows:\nAlerting on metrics: High error rate triggers investigation Drill-down to traces: Click exemplar to see example failing requests Root cause analysis: Examine detailed trace spans to identify cause Fix validation: Monitor metrics to confirm fix effectiveness This requires:\nApplications emit both metrics and traces Exemplars enabled in metric collection Unified storage backend (or cross-backend linking) Cross-Signal Analysis Metrics complement logs and traces:\nMetrics identify anomalies at scale (response time spike) Traces show affected request flows (which service is slow) Logs provide detailed context (exception messages, stack traces) The Collector’s unified data model enables seamless correlation across all three signals.\nFurther Reading Official Documentation OpenTelemetry Metrics Specification Metrics Data Model Receiver Components Processor Components Exporter Components Integration Guides Collecting Prometheus Metrics with the OpenTelemetry Collector Prometheus and OpenTelemetry Collector Integration OpenTelemetry Host Metrics receiver Using Prometheus as your OpenTelemetry backend Configure the OpenTelemetry Collector to write metrics into Mimir How to collect Prometheus metrics with the OpenTelemetry Collector and Grafana Component-Specific Resources Prometheus Remote Write Exporter OpenTelemetry Collector Chart (Kubernetes) Prometheus and OpenTelemetry - Better Together Analysis and Best Practices OTLP Metrics Types Understanding OpenTelemetry Metrics OpenTelemetry Metrics Aggregation How Prometheus Exporters Work With OpenTelemetry Related Analysis Documents OpenTelemetry Collector Overview - Core architecture and concepts Logs Support - How the Collector handles log data Traces Support - How the Collector handles distributed traces Self-Monitoring - Observing the Collector itself ","categories":"","description":"Deep dive into how the OpenTelemetry Collector handles metrics data, including the metrics data model, receivers, processors, exporters, and temporality concepts.\n","excerpt":"Deep dive into how the OpenTelemetry Collector handles metrics data, …","ref":"/battlebots/pr-preview/pr-153/research_and_development/analysis/observability/otel-collector/otel-collector-metrics/","tags":"","title":"OpenTelemetry Collector: Metrics Support"},{"body":"Overview The OpenTelemetry Collector is designed as an observable service itself, following the principle that observability infrastructure must be observable. The Collector exposes its own telemetry (metrics, logs, and optionally traces) to enable monitoring health, diagnosing issues, and optimizing performance.\nSelf-monitoring is critical for production deployments—without visibility into the Collector’s operation, data loss or performance degradation can go undetected. The Collector provides built-in telemetry, diagnostic extensions, and debugging capabilities to ensure reliable operation at scale.\nKey capabilities include internal metrics exposed via Prometheus endpoints, health check endpoints for liveness/readiness probes, diagnostic extensions for real-time inspection, and structured logging for troubleshooting pipeline issues.\nKey Concepts Internal Telemetry The OpenTelemetry Collector generates internal telemetry by default to expose its operational state. This self-generated observability data helps operators monitor Collector health and performance.\nTelemetry types:\nMetrics: Quantitative measurements of Collector operation (default: Prometheus format on port 8888) Logs: Structured event records emitted to stderr by default Traces: Optional internal tracing of data flow through pipelines Internal telemetry enables:\nReal-time health monitoring Capacity planning and resource optimization Troubleshooting data loss or pipeline issues Performance profiling and bottleneck identification Observability vs. Debugging The Collector provides two complementary approaches:\nObservability (production):\nContinuous metrics collection Health check endpoints Structured logging External monitoring integration Debugging (development/troubleshooting):\nzPages for live data inspection pprof for performance profiling Debug exporters for pipeline validation Verbose logging modes Internal Metrics The Collector exposes comprehensive metrics about its operation through a Prometheus-compatible endpoint.\nMetrics Endpoint By default, the Collector exposes metrics at http://localhost:8888/metrics in Prometheus format. This endpoint can be scraped by Prometheus or any compatible metrics collector.\nConfiguration:\nservice: telemetry: metrics: address: 0.0.0.0:8888 level: detailed # Options: none, basic, normal, detailed Key Metrics Categories Data Ingress Metrics Monitor data received by receivers:\notelcol_receiver_accepted_log_records - Log records accepted otelcol_receiver_accepted_spans - Spans accepted otelcol_receiver_accepted_metric_points - Metric points accepted otelcol_receiver_refused_* - Refused data (errors) These metrics help identify:\nData ingestion rates Receiver errors or rejections Source-specific throughput patterns Data Egress Metrics Monitor data sent by exporters:\notelcol_exporter_sent_log_records - Log records sent otelcol_exporter_sent_spans - Spans sent otelcol_exporter_sent_metric_points - Metric points sent otelcol_exporter_send_failed_* - Failed export attempts These metrics reveal:\nExport success rates Backend connectivity issues Data loss from failed exports Queue Metrics Monitor internal buffer state:\notelcol_exporter_queue_capacity - Queue capacity in batches otelcol_exporter_queue_size - Current queue utilization otelcol_exporter_enqueue_failed_* - Failed enqueues (buffer full) Alert on: Queue size approaching capacity indicates backpressure from slow exporters or high ingestion rates.\nProcessor Metrics Monitor processor operation:\notelcol_processor_batch_batch_send_size - Batch sizes sent otelcol_processor_batch_timeout_trigger_send - Timeouts triggering sends Processor-specific metrics (sampling rates, dropped data, etc.) Resource Metrics Monitor Collector resource usage:\nprocess_runtime_* - Go runtime metrics (memory, goroutines) process_cpu_seconds_total - CPU time consumed process_resident_memory_bytes - Memory usage For comprehensive metric details, see Internal telemetry and How to Monitor Open Telemetry Collector Performance.\nSelf-Monitoring Dashboards Several platforms provide pre-built dashboards for Collector monitoring:\nDynatrace OpenTelemetry Collector Self-Monitoring (June 2025 release) Grafana dashboards from the community Vendor-specific monitoring integrations Extensions for Observability Extensions provide auxiliary functionality that supports Collector operation and debugging.\nHealth Check Extension The health_check extension enables an HTTP endpoint that can be probed to check the Collector’s status.\nConfiguration:\nextensions: health_check: endpoint: 0.0.0.0:13133 path: /health/status check_collector_pipeline: enabled: false # Not recommended—use at own risk service: extensions: [health_check] Endpoints:\n/health/status - Returns 200 OK if the Collector is running Important note: The check_collector_pipeline feature is not working as expected and should not be used. Use metrics-based monitoring instead for pipeline health.\nUse cases:\nKubernetes liveness probes Load balancer health checks Container orchestration health monitoring Service mesh integration For more details, see Health Check Monitoring With OpenTelemetry.\nzPages Extension The zpages extension serves HTTP endpoints that provide live data for debugging different components without depending on external backends.\nConfiguration:\nextensions: zpages: endpoint: 0.0.0.0:55679 service: extensions: [zpages] Available pages:\n/debug/servicez - Service summary and version information /debug/pipelinez - Pipeline configuration and status /debug/extensionz - Loaded extensions /debug/tracez - Sample trace data (if internal tracing enabled) Use cases:\nInspecting live data flowing through pipelines Validating configuration changes Debugging data transformation issues In-process diagnostics during development zPages are particularly useful for answering questions like “Is the Collector receiving data?” and “What does the data look like after processing?”\nFor detailed usage, see Monitoring and Debugging the OpenTelemetry Collector.\npprof Extension The pprof extension enables the Go net/http/pprof endpoint for performance profiling.\nConfiguration:\nextensions: pprof: endpoint: 0.0.0.0:1777 service: extensions: [pprof] Available profiles:\n/debug/pprof/profile - CPU profile /debug/pprof/heap - Memory allocation profile /debug/pprof/goroutine - Goroutine stack traces /debug/pprof/block - Blocking profile /debug/pprof/mutex - Mutex contention profile Use cases:\nInvestigating CPU hotspots Analyzing memory leaks Identifying goroutine leaks Profiling lock contention Collecting profiles:\n# CPU profile (30 seconds) curl http://localhost:1777/debug/pprof/profile?seconds=30 \u003e cpu.prof # Heap profile curl http://localhost:1777/debug/pprof/heap \u003e heap.prof # Analyze with pprof go tool pprof cpu.prof Security note: pprof endpoints should only be exposed internally, never to the public internet, as they can reveal sensitive information and consume resources.\nLogging and Debugging Structured Logging The Collector emits structured logs to stderr by default, which can be redirected to files or collected by log aggregation systems.\nLog levels:\ndebug - Verbose debugging information info - General operational messages (default) warn - Warning conditions error - Error conditions Configuration:\nservice: telemetry: logs: level: info encoding: json # Options: json, console Common log patterns:\nReceiver connection failures Exporter send failures Processor errors Configuration validation warnings Debug Exporter The debug (logging) exporter writes telemetry data to the Collector’s standard output, useful for confirming that data is being received, processed, and exported correctly.\nConfiguration:\nexporters: debug: verbosity: detailed # Options: basic, normal, detailed service: pipelines: traces: receivers: [otlp] exporters: [debug, otlp] # Add debug alongside production exporters Use cases:\nValidating pipeline configuration Inspecting data transformations Troubleshooting receiver issues Confirming data format Warning: Debug exporters should be removed or disabled in production due to performance impact and log volume.\nFor troubleshooting guidance, see the Troubleshooting documentation.\nCommon Issues and Troubleshooting Data Loss Symptoms:\notelcol_exporter_send_failed_* metrics increasing Queue size approaching capacity Export errors in logs Common causes:\nExporter destination unavailable or slow Collector under-provisioned (insufficient CPU/memory) Network connectivity issues Backend rate limiting Solutions:\nIncrease queue size and retry parameters Scale Collector instances horizontally Add buffering through load balancers Implement backpressure handling High Memory Usage Symptoms:\nprocess_resident_memory_bytes continuously increasing OOM kills in container environments Slow garbage collection Common causes:\nLarge batch sizes Tail sampling buffer accumulation Queue size too large Memory leaks in processors Solutions:\nReduce batch size and timeout Tune tail sampling buffer limits Enable memory limiting in batch processor Update to latest Collector version (bug fixes) Use pprof to identify memory leaks Note: Memory usage increases in steps due to Go’s garbage collection characteristics, which is normal.\nCPU Spikes Symptoms:\nprocess_cpu_seconds_total rate spikes Request latency increases Throttled container CPU Common causes:\nBatch processing overhead Complex processor logic High ingestion rates Inefficient regex patterns in processors Solutions:\nOptimize processor configuration Distribute load across multiple instances Use simpler transformation patterns Profile with pprof to identify hotspots For detailed debugging workflows, see Guide — How to Debug OpenTelemetry Pipelines.\nSelf-Monitoring Architecture A production self-monitoring setup exports Collector telemetry to external systems:\ngraph TB A[OTel Collector Instance] --\u003e|Internal Metrics| B[Prometheus Exporter :8888] A --\u003e|Internal Logs| C[Stderr Logs] A --\u003e|Health Checks| D[Health Check Extension :13133] A --\u003e|Debugging| E[zPages Extension :55679] A --\u003e|Profiling| F[pprof Extension :1777] B --\u003e|Scrape| G[Prometheus/Metrics Backend] C --\u003e|Collect| H[Log Aggregation System] D --\u003e|Probe| I[Kubernetes/Load Balancer] G --\u003e J[Alerting \u0026 Dashboards] H --\u003e J K[Monitoring Collector] --\u003e|Scrape :8888| B K --\u003e|Send to Backends| L[External Observability Platform] style A fill:#e1f5ff style B fill:#fff4e6 style C fill:#fff4e6 style D fill:#fff4e6 style E fill:#f3e5f5 style F fill:#f3e5f5 style G fill:#e8f5e9 style H fill:#e8f5e9 style I fill:#e8f5e9 style J fill:#ffe6e6 style K fill:#e1f5ff style L fill:#e8f5e9 Configuration Best Practices Production Monitoring Setup 1. Enable comprehensive internal metrics:\nservice: telemetry: metrics: address: 0.0.0.0:8888 level: detailed logs: level: info encoding: json 2. Deploy monitoring Collector:\nCreate a dedicated Collector instance to scrape other Collectors:\nreceivers: prometheus: config: scrape_configs: - job_name: otel-collector scrape_interval: 15s static_configs: - targets: ['collector-1:8888', 'collector-2:8888'] exporters: otlp: endpoint: monitoring-backend:4317 service: pipelines: metrics: receivers: [prometheus] exporters: [otlp] 3. Configure health checks:\nextensions: health_check: endpoint: 0.0.0.0:13133 service: extensions: [health_check] 4. Set up alerts:\nKey alerts to configure:\nQueue size \u003e 80% capacity Export failure rate \u003e 1% Memory usage \u003e 80% limit CPU throttling detected Receiver refused rate \u003e 0 Development/Debugging Setup Enable all diagnostic extensions:\nextensions: health_check: endpoint: 0.0.0.0:13133 zpages: endpoint: 0.0.0.0:55679 pprof: endpoint: 0.0.0.0:1777 service: extensions: [health_check, zpages, pprof] telemetry: logs: level: debug Add debug exporters:\nexporters: debug: verbosity: detailed service: pipelines: traces: receivers: [otlp] exporters: [debug, jaeger] # Debug alongside production Security Considerations Restrict extension endpoints to internal networks only Never expose pprof to the internet Use TLS for metrics endpoints in production Implement authentication for sensitive endpoints Rate limit health check endpoints to prevent DoS Integration Points BattleBots Collector Monitoring For the BattleBots platform, Collector self-monitoring would track:\nOperational metrics:\nGame event ingestion rate (log records/second) Battle trace throughput (spans/second) Bot performance metric collection (metric points/second) Health indicators:\nExport success rate to observability backends Queue utilization during peak match activity Resource usage (CPU, memory) per Collector instance Alerting scenarios:\nQueue capacity exceeded during tournament events Export failures to game analytics backend High latency in telemetry pipeline affecting real-time dashboards Kubernetes Integration In Kubernetes deployments:\nLiveness probe:\nlivenessProbe: httpGet: path: /health/status port: 13133 initialDelaySeconds: 30 periodSeconds: 10 Readiness probe:\nreadinessProbe: httpGet: path: /health/status port: 13133 initialDelaySeconds: 5 periodSeconds: 5 Metrics scraping:\nannotations: prometheus.io/scrape: \"true\" prometheus.io/port: \"8888\" prometheus.io/path: \"/metrics\" Further Reading Official Documentation Internal telemetry Troubleshooting Configuration Extensions README Extension Documentation Health Check Extension zPages Extension Collector Observability Documentation Guides and Best Practices Monitoring and Debugging the OpenTelemetry Collector How to Monitor Open Telemetry Collector Performance Guide — How to Debug OpenTelemetry Pipelines Health Check Monitoring With OpenTelemetry Vendor Resources Dynatrace: Introducing OpenTelemetry Collector Self-Monitoring Dashboards Dynatrace: OpenTelemetry Collector self-monitoring OpenTelemetry Collector from A to Z: A Production-Ready Guide Related Analysis Documents OpenTelemetry Collector Overview - Core architecture and concepts Logs Support - How the Collector handles log data Metrics Support - How the Collector handles metrics Traces Support - How the Collector handles distributed traces ","categories":"","description":"How to observe and debug the OpenTelemetry Collector itself through internal telemetry, extensions, and monitoring strategies.\n","excerpt":"How to observe and debug the OpenTelemetry Collector itself through …","ref":"/battlebots/pr-preview/pr-153/research_and_development/analysis/observability/otel-collector/otel-collector-self-monitoring/","tags":"","title":"OpenTelemetry Collector: Self-Monitoring"},{"body":"Overview The OpenTelemetry Collector provides comprehensive support for distributed tracing, enabling collection, processing, and export of trace data from multiple sources to various backend systems. Distributed tracing tracks requests as they flow through distributed systems, providing visibility into service interactions, latency bottlenecks, and error propagation paths.\nThe Collector acts as a central hub for trace data, accepting traces in multiple formats (OTLP, Jaeger, Zipkin), performing intelligent sampling decisions, and routing to multiple tracing backends simultaneously. This unified approach simplifies observability infrastructure while preserving the ability to use best-of-breed tools for different use cases.\nKey capabilities include protocol translation between trace formats, sophisticated sampling strategies (head-based and tail-based), trace enrichment with resource and span attributes, and correlation with metrics and logs through shared context identifiers.\nKey Concepts Traces and Spans A trace represents the full journey of one request or transaction across services, while a span is a timed unit of work inside that journey such as a function call, database query, or external API call.\nTrace structure:\nA trace consists of one or more spans organized in a tree structure Each span represents an operation with a start time and duration Spans have parent-child relationships forming the call graph The root span represents the initial request entry point Span characteristics:\nName: Describes the operation (e.g., “GET /api/battles”) Start time and duration: Timing information Status: Success, error, or unset Span kind: Client, server, internal, producer, or consumer Span Context and Propagation Span context is the portion of a span that must be serialized and propagated between services to maintain trace continuity.\nContext components:\nTraceId: Unique identifier for the entire trace (shared across all spans) SpanId: Unique identifier for the specific span TraceFlags: Sampling and other flags TraceState: System-specific trace state values Propagation mechanism:\nContext propagation transmits context between services via protocols such as HTTP headers, gRPC metadata, or message queues. The default propagator uses the W3C TraceContext specification with traceparent and tracestate headers.\nExample HTTP headers:\ntraceparent: 00-4bf92f3577b34da6a3ce929d0e0e4736-00f067aa0ba902b7-01 tracestate: vendor1=value1,vendor2=value2 For detailed propagation concepts, see An overview of Context Propagation in OpenTelemetry.\nSpan Attributes Attributes provide additional context about the operation represented by a span. They are key-value pairs that describe request parameters, database queries, HTTP methods, status codes, and other relevant details.\nCommon attribute categories:\nHTTP attributes: http.method, http.status_code, http.route Database attributes: db.system, db.statement, db.name RPC attributes: rpc.service, rpc.method Network attributes: net.peer.name, net.peer.port Best practice: Set attributes at span creation rather than later, since samplers can only consider information present during span creation.\nSpan Events Span events are structured log messages or annotations on a span, typically used to denote meaningful singular points in time during the span’s duration.\nUse cases:\nException events (including stack traces) Checkpoint markers in long operations State transitions Cache hits/misses Retry attempts Events include a name, timestamp, and optional attributes, providing detailed debugging context without creating separate spans for every sub-operation.\nSpan Links Span links establish relationships between spans in different traces or between causally-related but non-parent-child spans. Common scenarios include:\nBatch processing where one span processes multiple input messages Following redirects across multiple traces Async operations spawned from a parent request Trace Receivers Receivers collect trace data from various sources and convert it into the OpenTelemetry traces data model.\nOTLP Receiver The OTLP receiver accepts trace data transmitted using the OpenTelemetry Protocol, the native and recommended format for OpenTelemetry traces.\nSupported transports:\ngRPC (default port 4317): High-performance binary protocol HTTP (default port 4318): RESTful endpoint at /v1/traces Configuration example:\nreceivers: otlp: protocols: grpc: endpoint: 0.0.0.0:4317 http: endpoint: 0.0.0.0:4318 Use cases:\nCollecting traces from OpenTelemetry-instrumented applications Multi-tier collector deployments (agent → gateway) Modern observability architectures Important: Jaeger V2 natively supports OTLP, making OTLP the recommended protocol for Jaeger backends.\nJaeger Receiver The Jaeger receiver receives trace data in Jaeger format and translates it to OpenTelemetry format. This enables migration from Jaeger-instrumented applications without requiring code changes.\nSupported protocols:\ngRPC (default port 14250): Binary Jaeger protocol thrift_compact (default port 6831): UDP-based compact Thrift thrift_http (default port 14268): HTTP-based Thrift thrift_binary: TCP-based binary Thrift Configuration example:\nreceivers: jaeger: protocols: grpc: endpoint: 0.0.0.0:14250 thrift_http: endpoint: 0.0.0.0:14268 thrift_compact: endpoint: 0.0.0.0:6831 Use cases:\nMigrating from Jaeger agent/collector infrastructure Supporting legacy applications instrumented with Jaeger SDKs Gradual transition to OpenTelemetry Zipkin Receiver The Zipkin receiver receives spans in Zipkin V1 and V2 formats and translates them to OpenTelemetry format.\nConfiguration example:\nreceivers: zipkin: endpoint: 0.0.0.0:9411 Use cases:\nMigrating from Zipkin instrumentation Supporting applications instrumented with Zipkin libraries Integration with Zipkin-compatible systems Protocol Translation The Collector acts as a protocol translator, accepting traces in one format and exporting in another. This enables:\nJaeger-instrumented apps → OTLP export to modern backends OpenTelemetry apps → Zipkin export for legacy systems Unified collection from heterogeneous instrumentation Sampling Strategies Sampling controls which traces are retained for analysis, balancing observability value with storage costs and performance impact.\nHead Sampling Head sampling makes sampling decisions at trace creation time, before seeing the complete trace. The decision applies to the entire trace and propagates to downstream services.\nCommon algorithms:\nAlways On: Sample 100% of traces (development/debugging) Always Off: Sample 0% of traces (disable tracing) TraceID Ratio: Sample a percentage based on TraceId hash (e.g., 10%) Rate Limiting: Sample at most N traces per second Advantages:\nLow latency decision (immediate) Low memory overhead (no buffering) Consistent across distributed services Limitations:\nCannot make decisions based on complete trace data Cannot guarantee capturing all error traces Cannot sample based on span attributes or duration For consistent probability sampling details, see OpenTelemetry Sampling.\nTail Sampling Tail sampling makes sampling decisions after seeing all or most spans in a trace, enabling more intelligent sampling based on trace characteristics.\nAvailable policies:\nLatency: Sample traces exceeding duration threshold Status code: Always sample traces with errors Numeric attribute: Sample based on attribute values (min/max thresholds) Probabilistic: Sample a percentage of traces String attribute: Sample traces matching string attributes Rate limiting: Limit traces per second per policy Composite: Combine multiple policies (AND/OR logic) Configuration example:\nprocessors: tail_sampling: policies: - name: errors-policy type: status_code status_code: status_codes: [ERROR] - name: slow-requests type: latency latency: threshold_ms: 1000 - name: sample-10-percent type: probabilistic probabilistic: sampling_percentage: 10 Architecture requirements:\nAll spans for a given trace MUST be received by the same collector instance for effective sampling decisions. This requires:\nLoad balancing exporter: Routes spans by TraceId to consistent collectors Two-tier architecture: Agent collectors → tail sampling gateway collectors For implementation guidance, see Tail Sampling with OpenTelemetry and New Relic and Sampling at scale with OpenTelemetry.\nAdvantages:\nSample all error traces regardless of volume Capture slow requests while dropping fast ones Make sampling decisions based on complete trace data Challenges:\nHigher memory overhead (buffering complete traces) Increased latency (waiting for trace completion) Requires stateful, coordinated collectors Sampling Best Practices For production deployments:\nUse head sampling for baseline traffic reduction (e.g., 10% sampling) Add tail sampling to always capture errors and slow traces Implement two-tier architecture for tail sampling at scale Monitor sampled vs. unsampled trace ratios Adjust policies based on traffic patterns and costs For recent sampling updates, see OpenTelemetry Sampling update.\nTrace Processors Processors transform and enrich trace data as it flows through pipelines.\nSpan Processor The span processor modifies span names, attributes, and other properties.\nCommon operations:\nRename spans for consistency Add/remove span attributes Set span status Modify span kind Attributes Processor Adds, updates, or deletes span and resource attributes, enabling:\nEnvironment labeling Team ownership tags PII removal Attribute normalization Resource Detection Processor Enriches traces with environment metadata:\nCloud provider information (AWS, GCP, Azure) Kubernetes metadata (pod, namespace, node) Container information Host details This automatic enrichment enables filtering and grouping traces by infrastructure context.\nBatch Processor Groups spans before export, improving throughput and reducing network overhead. Recommended for all production deployments.\nService Graph Processor Generates metrics representing service call relationships from trace data, creating:\nRequest rate between services Error rate between services Latency between services These derived metrics enable service dependency visualization without query-time trace aggregation.\nTrace Exporters Exporters send processed trace data to observability backends and storage systems.\nOTLP Exporter (Recommended) The OTLP exporter sends traces using the OpenTelemetry Protocol to OTLP-compatible backends. OTLP is the recommended choice for new deployments as it’s designed with the OpenTelemetry data model in mind, emitting trace data without loss of information.\nSupported destinations:\nJaeger V2 (native OTLP support) Commercial platforms (Datadog, New Relic, Honeycomb, Dynatrace) Cloud vendor endpoints (AWS X-Ray, Google Cloud Trace, Azure Monitor) Open source backends (Uptrace, Grafana Tempo) Configuration example:\nexporters: otlp: endpoint: jaeger:4317 tls: insecure: false For Jaeger V2 integration, see Using OpenTelemetry to send traces to Jaeger V2.\nJaeger Exporter The Jaeger exporter sends traces to Jaeger backends using the Jaeger gRPC protocol.\nNote: For Jaeger V2, use the OTLP exporter instead. The dedicated Jaeger exporter is maintained for backward compatibility with Jaeger V1 deployments.\nZipkin Exporter The Zipkin exporter sends traces to Zipkin-compatible backends.\nUse cases:\nLegacy Zipkin deployments Systems expecting Zipkin format Gradual migration scenarios Logging Exporter Writes traces to collector standard output for debugging and development.\nFor comprehensive exporter documentation, see OpenTelemetry Collector Exporters.\nTrace Pipeline Flow A sophisticated trace pipeline with multiple receivers, sampling, and multi-backend export:\ngraph LR A[OTLP SDK] --\u003e B[OTLP Receiver] C[Jaeger SDK] --\u003e D[Jaeger Receiver] E[Zipkin SDK] --\u003e F[Zipkin Receiver] B --\u003e G[Resource Detection] D --\u003e G F --\u003e G G --\u003e H[Attributes Processor] H --\u003e I{Load Balancer} I --\u003e|By TraceId| J[Tail Sampling Processor] J --\u003e K[Batch Processor] K --\u003e L[OTLP Exporter] L --\u003e M[Jaeger V2] K --\u003e N[OTLP Exporter] N --\u003e O[Cloud Backend] style A fill:#e1f5ff style C fill:#e1f5ff style E fill:#e1f5ff style B fill:#fff4e6 style D fill:#fff4e6 style F fill:#fff4e6 style G fill:#f3e5f5 style H fill:#f3e5f5 style I fill:#f3e5f5 style J fill:#f3e5f5 style K fill:#f3e5f5 style L fill:#e8f5e9 style N fill:#e8f5e9 style M fill:#e1f5ff style O fill:#e1f5ff Configuration Considerations Context Propagation Ensure consistent propagation across all services:\nConfigure the same propagators in all SDKs Use W3C TraceContext (standard default) Include Baggage propagation if using cross-cutting concerns Test propagation across language boundaries Sampling Trade-offs Balance observability and cost:\nHigh sampling (50-100%): Development, debugging, low-traffic systems Medium sampling (10-30%): Production with moderate traffic Low sampling (1-10%): High-traffic production systems Tail sampling: Always capture errors regardless of base rate Performance Tuning For high-throughput trace collection:\nEnable batching with appropriate size/timeout Use multiple collector instances with load balancing Configure adequate memory for tail sampling buffers Monitor collector CPU and memory usage Consider two-tier architecture (agent + gateway) Storage Optimization Manage trace storage costs:\nImplement retention policies in backends Use sampling to reduce volume Drop high-cardinality attributes if needed Compress trace data before export Integration Points BattleBots Trace Collection For the BattleBots platform, distributed tracing would track:\nRequest flows:\nClient WebSocket connection → authentication → game state sync Player action → validation → state update → broadcast Match creation → bot pairing → game initialization Service interactions:\nAPI gateway → game service → persistence layer Event publisher → message broker → subscriber services Load balancer → multiple game server instances Timing analysis:\nEnd-to-end battle action latency Database query performance WebSocket message propagation time The OTLP receiver collects traces from Go services instrumented with the OpenTelemetry Go SDK, while Jaeger/Zipkin receivers support any legacy instrumentation.\nTrace-Log Correlation Connecting traces and logs enables powerful debugging workflows:\nStart with trace: Identify slow or failing request Find associated logs: Query logs by TraceId and SpanId Examine context: Read detailed log messages and exceptions Understand causation: See timeline of events leading to issue This requires applications to inject trace context into log records, which OpenTelemetry SDKs handle automatically when both signals are instrumented.\nTrace-Metric Correlation Link traces and metrics through exemplars:\nHistogram buckets contain sample trace IDs Click from high-latency metric to example slow trace Correlate error rate spike with specific failing traces Validate fixes by monitoring metrics and inspecting traces Further Reading Official Documentation OpenTelemetry Traces Specification Context Propagation Sampling Receiver Components Processor Components Exporter Components Sampling Resources Tail Sampling Processor OpenTelemetry Sampling Tail Sampling with OpenTelemetry and New Relic Sampling at scale with OpenTelemetry OpenTelemetry Sampling update Integration Guides Getting Started with the Jaeger and Zipkin Receivers Using OpenTelemetry to send traces to Jaeger V2 OpenTelemetry Collector Exporters Context Propagation Deep Dives An overview of Context Propagation in OpenTelemetry OpenTelemetry Context Propagation Explained Related Analysis Documents OpenTelemetry Collector Overview - Core architecture and concepts Logs Support - How the Collector handles log data Metrics Support - How the Collector handles metrics Self-Monitoring - Observing the Collector itself ","categories":"","description":"Deep dive into how the OpenTelemetry Collector handles distributed tracing data, including the span model, receivers, sampling strategies, and exporters.\n","excerpt":"Deep dive into how the OpenTelemetry Collector handles distributed …","ref":"/battlebots/pr-preview/pr-153/research_and_development/analysis/observability/otel-collector/otel-collector-traces/","tags":"","title":"OpenTelemetry Collector: Traces Support"},{"body":"","categories":"","description":"","excerpt":"","ref":"/battlebots/pr-preview/pr-153/tags/","tags":"","title":"Tags"},{"body":"Overview This document provides comprehensive guidance on integrating Grafana Tempo with the OpenTelemetry Collector, addressing two critical questions:\nDoes Tempo support OTLP? → YES - Native OTLP ingestion since version 1.3.0 (January 2022) Can the OTel Collector export to Tempo? → YES - Full integration via otlp (gRPC) or otlphttp (HTTP) exporters The integration enables a vendor-neutral observability pipeline where the OpenTelemetry Collector collects traces from instrumented applications and forwards them to Tempo for cost-effective, long-term trace storage, querying with TraceQL, and correlation with metrics and logs.\nWhy OTLP Matters for Tracing OpenTelemetry Protocol (OTLP) is the native protocol of the OpenTelemetry project, designed as a vendor-neutral standard for telemetry data transmission. Using OTLP with Tempo provides:\nNative Protocol: OTLP is Tempo’s primary ingestion protocol—no translation overhead Future-Proof: OTLP is the CNCF industry standard for distributed tracing Simplified Pipeline: No protocol conversion required (App → OTel SDK → OTel Collector → OTLP → Tempo) Full Fidelity: All span attributes, events, links, and context preserved Unified Stack: Same protocol for logs (Loki), metrics (Mimir), and traces (Tempo) Vendor Independence: Easy migration between OTLP-compatible backends (Jaeger V2, Tempo, cloud vendors) Tempo’s Position in the OTLP Ecosystem Tempo acts as an OTLP-native distributed tracing backend, receiving traces via:\nPrimary Path (Recommended): OpenTelemetry Collector → OTLP/gRPC (port 4317) → Tempo distributor Alternative Path: OpenTelemetry Collector → OTLP/HTTP (port 4318) → Tempo distributor Legacy Paths (Also Supported): Jaeger protocol, Zipkin protocol, OpenCensus Recommendation: Use OTLP/gRPC (port 4317) for best performance and lowest latency. Use OTLP/HTTP (port 4318) when gRPC is not available or firewall-restricted.\nOTLP Support in Tempo Native OTLP Support: YES Status: Grafana Tempo has full native OTLP ingestion support for both gRPC and HTTP protocols.\nSupported Protocols:\n✅ OTLP over gRPC (port 4317): High-performance binary protocol, recommended for production ✅ OTLP over HTTP (port 4318): RESTful endpoint at /v1/traces, firewall-friendly Version History:\nv1.3.0 (January 2022): Updated OpenTelemetry libraries to v0.40.0; changed OTLP gRPC default port from legacy 55680 to standard 4317 v2.7 (2024): Updated OpenTelemetry dependencies to v0.116.0; changed receiver binding from 0.0.0.0 to localhost by default (security improvement) v2.8 (2024): Upgraded OTLP to v1.3.0; removed deprecated InstrumentationLibrary from receivers v2.9 (2024): Migrated internal testing from deprecated Jaeger agent/exporter to standard OTLP exporter Current (2025): Full production-ready OTLP support with gRPC and HTTP protocols Minimum Recommended Version: v1.3.0 or later (for standard OTLP port 4317)\nProduction Recommendation: v2.8 or v2.9+ (latest stable releases with OTLP 1.3.0)\nOTLP Endpoint Configuration Default Endpoints and Ports Tempo’s distributor component exposes OTLP receivers on these default ports:\nOTLP/gRPC: Default Port: 4317/TCP Default Bind: localhost:4317 (Tempo v2.7+) Recommended Bind: 0.0.0.0:4317 (for containerized/networked deployments) OTLP/HTTP: Default Port: 4318/TCP HTTP Path: /v1/traces Default Bind: localhost:4318 (Tempo v2.7+) Recommended Bind: 0.0.0.0:4318 (for containerized/networked deployments) Important Change in Tempo v2.7+: If an endpoint is not explicitly specified, receivers default to binding on localhost only (instead of 0.0.0.0). For containerized environments (Docker, Kubernetes), you must explicitly configure 0.0.0.0 to listen on all interfaces and accept external connections.\nBasic Tempo Configuration Minimal OTLP receiver configuration:\ndistributor: receivers: otlp: protocols: grpc: # Defaults to localhost:4317 (Tempo v2.7+) http: # Defaults to localhost:4318 (Tempo v2.7+) Production configuration (all interfaces):\ndistributor: receivers: otlp: protocols: grpc: endpoint: 0.0.0.0:4317 # Listen on all interfaces http: endpoint: 0.0.0.0:4318 # Listen on all interfaces TLS/mTLS Configuration Enable TLS on OTLP receivers:\ndistributor: receivers: otlp: protocols: grpc: endpoint: 0.0.0.0:4317 tls: cert_file: /certs/server.crt key_file: /certs/server.key http: endpoint: 0.0.0.0:4318 tls: cert_file: /certs/server.crt key_file: /certs/server.key Enable mutual TLS (mTLS):\ndistributor: receivers: otlp: protocols: grpc: endpoint: 0.0.0.0:4317 tls: cert_file: /certs/server.crt key_file: /certs/server.key client_ca_file: /certs/ca.crt require_client_auth: true Multi-Tenancy with OTLP Tempo supports multi-tenancy using the X-Scope-OrgID header. When multi-tenancy is enabled, every OTLP request must include this header to identify the tenant.\nEnable multi-tenancy in Tempo:\nserver: http_listen_port: 3200 distributor: receivers: otlp: protocols: grpc: endpoint: 0.0.0.0:4317 http: endpoint: 0.0.0.0:4318 # Enable multi-tenancy multitenancy_enabled: true OpenTelemetry Collector configuration with tenant header:\nexporters: otlp: endpoint: tempo:4317 headers: X-Scope-OrgID: \"tenant-123\" # Tenant identifier tls: insecure: true Multi-tenancy benefits:\nIsolated trace data per tenant Per-tenant retention policies Per-tenant rate limits Per-tenant query isolation OpenTelemetry Collector Export Configuration The OpenTelemetry Collector provides two exporters for sending traces to Tempo:\notlp exporter: Sends traces via OTLP over gRPC (recommended) otlphttp exporter: Sends traces via OTLP over HTTP OTLP Exporter (gRPC) - Recommended The otlp exporter uses gRPC for high-performance trace transmission.\nBasic configuration:\nexporters: otlp: endpoint: tempo:4317 tls: insecure: true # Use TLS in production Production configuration with retry and queue:\nexporters: otlp: endpoint: tempo:4317 tls: insecure: false cert_file: /certs/client.crt key_file: /certs/client.key ca_file: /certs/ca.crt # Retry configuration retry_on_failure: enabled: true initial_interval: 5s max_interval: 30s max_elapsed_time: 10m # Sending queue (enables disk buffering) sending_queue: enabled: true queue_size: 1000 # Compression (enabled by default in Tempo 2.7.1+) compression: snappy # Timeout timeout: 30s Key parameters:\nendpoint: Tempo distributor address and port (format: host:port, no http:// prefix) tls.insecure: Set to false for production (enable TLS) retry_on_failure: Handles transient network failures sending_queue: Buffers traces during Tempo downtime (prevents data loss) compression: snappy (recommended), gzip, or none timeout: Max time to wait for Tempo to acknowledge OTLPHTTP Exporter (HTTP) - Alternative The otlphttp exporter uses HTTP/1.1 for trace transmission.\nBasic configuration:\nexporters: otlphttp: endpoint: http://tempo:4318 tls: insecure: true Production configuration:\nexporters: otlphttp: endpoint: https://tempo:4318 tls: insecure: false cert_file: /certs/client.crt key_file: /certs/client.key ca_file: /certs/ca.crt # Headers (multi-tenancy) headers: X-Scope-OrgID: \"tenant-123\" # Retry configuration retry_on_failure: enabled: true initial_interval: 5s max_interval: 30s max_elapsed_time: 10m # Sending queue sending_queue: enabled: true queue_size: 1000 # Compression compression: gzip # Timeout timeout: 30s Key differences from gRPC:\nendpoint: Includes http:// or https:// prefix headers: Custom HTTP headers (useful for multi-tenancy) compression: Typically use gzip for HTTP When to use OTLPHTTP:\nFirewall restrictions block gRPC/HTTP2 Need to inspect traffic with HTTP debugging tools Existing infrastructure is HTTP/1.1-only When to use OTLP (gRPC):\nPerformance is critical (gRPC is faster) Low latency requirements High trace volume (gRPC handles backpressure better) Batch Processor Configuration The batch processor is critical for performance—it batches multiple spans before export, reducing network overhead and improving throughput.\nRecommended configuration:\nprocessors: batch: send_batch_size: 1000 # Send when batch reaches 1000 spans send_batch_max_size: 1500 # Max batch size (hard limit) timeout: 10s # Send every 10s regardless of size Parameter guidance:\nsend_batch_size: Grafana Labs internally uses 1,000 spans (recommended baseline) send_batch_max_size: Safety limit to prevent excessive memory usage timeout: Balance latency vs. efficiency (10s typical, 5s for low-latency needs) Effect of batching:\nWithout batching: 10,000 spans = 10,000 network requests With batching (1000/batch): 10,000 spans = 10 network requests (100x reduction) CPU/Memory savings: Larger batches = lower overhead, but higher latency Memory Limiter Processor Prevents the Collector from consuming excessive memory during traffic spikes.\nConfiguration:\nprocessors: memory_limiter: check_interval: 1s limit_mib: 512 # Hard memory limit (512MB) spike_limit_mib: 128 # Allow 128MB spikes above limit How it works:\nCollector monitors memory usage every check_interval If memory exceeds limit_mib, stop accepting new data Allow temporary spikes up to limit_mib + spike_limit_mib Resume accepting data when memory drops below limit Recommendation: Always use memory_limiter as the first processor in production.\nComplete Pipeline Configuration Full OpenTelemetry Collector configuration for Tempo:\nreceivers: otlp: protocols: grpc: endpoint: 0.0.0.0:4317 http: endpoint: 0.0.0.0:4318 processors: # Memory limiter (first processor, prevents OOM) memory_limiter: check_interval: 1s limit_mib: 512 spike_limit_mib: 128 # Batch processor (critical for performance) batch: send_batch_size: 1000 send_batch_max_size: 1500 timeout: 10s # Resource detection (adds cloud/K8s metadata) resourcedetection: detectors: [env, system, docker, kubernetes] timeout: 5s # Attributes processor (add/modify span attributes) attributes: actions: - key: environment value: production action: upsert exporters: # OTLP exporter to Tempo (gRPC) otlp: endpoint: tempo:4317 tls: insecure: true retry_on_failure: enabled: true initial_interval: 5s max_interval: 30s max_elapsed_time: 10m sending_queue: enabled: true queue_size: 1000 compression: snappy # Logging exporter (debugging) logging: loglevel: info service: pipelines: traces: receivers: [otlp] processors: [memory_limiter, batch, resourcedetection, attributes] exporters: [otlp, logging] Pipeline flow:\nOTLP Receiver (4317/4318) ↓ Memory Limiter (prevent OOM) ↓ Batch Processor (group spans) ↓ Resource Detection (add metadata) ↓ Attributes Processor (modify spans) ↓ OTLP Exporter → Tempo (4317) Resource Attribute Mapping OpenTelemetry traces include resource attributes (metadata about the entity producing spans, such as service name, host, container ID) and span attributes (operation-specific metadata).\nHow Tempo Handles Attributes Resource Attributes:\nStored with every span in the trace Queryable via TraceQL using resource.* selector Examples: resource.service.name, resource.host.name, resource.k8s.pod.name Span Attributes:\nStored with individual spans Queryable via TraceQL using span.* selector Examples: span.http.method, span.db.statement, span.action.type Key Resource Attributes for BattleBots Service identification:\nresource.service.name = \"game-server\" resource.service.version = \"1.2.3\" resource.service.namespace = \"production\" Infrastructure:\nresource.host.name = \"game-server-01\" resource.k8s.pod.name = \"game-server-abc123\" resource.k8s.namespace.name = \"battlebots\" resource.container.id = \"docker://abc123\" Environment:\nresource.deployment.environment = \"production\" resource.cloud.region = \"us-east-1\" TraceQL Queries with Attributes Find traces by service name:\n{ resource.service.name = \"game-server\" } Find traces by span attribute:\n{ span.http.status_code \u003e= 500 } Combine resource and span attributes:\n{ resource.service.name = \"game-server\" \u0026\u0026 span.action.type = \"bot_move\" \u0026\u0026 duration \u003e 100ms } Best Practices for Attributes Use low-cardinality resource attributes:\n✅ Service name, environment, region (bounded values) ❌ User IDs, trace IDs, timestamps (unbounded values) Use descriptive span attributes:\nInclude operation-specific context: http.method, db.statement, bot.id Add BattleBots-specific attributes: battle.id, action.type, player.id Avoid attribute explosion:\nToo many unique attributes can degrade Tempo performance Keep total unique attribute count \u003c 1000 per service Sampling Strategies in the OTel Collector Sampling controls which traces are sent to Tempo. The OpenTelemetry Collector supports multiple sampling strategies.\nHead-Based Sampling Decision point: Made at span creation time (before seeing complete trace).\nConfiguration:\nprocessors: probabilistic_sampler: sampling_percentage: 10 # Sample 10% of traces Use cases:\nBaseline traffic reduction Simple, predictable sampling rate Low overhead, low latency Limitations:\nCannot make decisions based on trace outcome (errors, latency) May miss rare but important traces Tail-Based Sampling (Recommended for Production) Decision point: Made after seeing all/most spans in a trace.\nConfiguration:\nprocessors: tail_sampling: policies: # Always sample errors - name: errors-policy type: status_code status_code: status_codes: [ERROR] # Always sample slow traces - name: slow-requests type: latency latency: threshold_ms: 1000 # Sample 10% of successful traces - name: sample-10-percent type: probabilistic probabilistic: sampling_percentage: 10 # Sample specific span attributes - name: critical-actions type: string_attribute string_attribute: key: span.action.type values: [bot_death, battle_end] Architecture requirement: All spans for a given trace ID must be routed to the same Collector instance.\nSolution: Use a two-tier architecture:\nApplication Instances ↓ Agent Collectors (no tail sampling) ↓ Load Balancing Exporter (shard by trace ID) ↓ Gateway Collectors (tail sampling) ↓ Tempo Benefits:\nCapture 100% of errors Capture 100% of slow requests Sample normal traffic to reduce volume Sampling Recommendations for BattleBots Development: 100% sampling (no sampling)\nProduction:\nprocessors: tail_sampling: policies: # Always sample errors - name: errors type: status_code status_code: status_codes: [ERROR] # Always sample critical game events - name: critical-events type: string_attribute string_attribute: key: span.event.type values: [bot_death, battle_end, matchmaking_failed] # Always sample slow battles (\u003e 10 seconds) - name: slow-battles type: latency latency: threshold_ms: 10000 # Sample 20% of normal bot actions - name: baseline type: probabilistic probabilistic: sampling_percentage: 20 Complete Working Examples Example 1: Basic OpenTelemetry Collector → Tempo OpenTelemetry Collector config (otel-collector.yaml):\nreceivers: otlp: protocols: grpc: endpoint: 0.0.0.0:4317 http: endpoint: 0.0.0.0:4318 processors: batch: send_batch_size: 1000 timeout: 10s exporters: otlp: endpoint: tempo:4317 tls: insecure: true service: pipelines: traces: receivers: [otlp] processors: [batch] exporters: [otlp] Tempo config (tempo.yaml):\nserver: http_listen_port: 3200 distributor: receivers: otlp: protocols: grpc: endpoint: 0.0.0.0:4317 http: endpoint: 0.0.0.0:4318 storage: trace: backend: local local: path: /var/tempo Docker Compose:\nversion: '3' services: otel-collector: image: otel/opentelemetry-collector:latest command: [\"--config=/etc/otel-collector.yaml\"] volumes: - ./otel-collector.yaml:/etc/otel-collector.yaml ports: - \"4317:4317\" - \"4318:4318\" tempo: image: grafana/tempo:latest command: [\"-config.file=/etc/tempo.yaml\"] volumes: - ./tempo.yaml:/etc/tempo.yaml - tempo-data:/var/tempo ports: - \"3200:3200\" volumes: tempo-data: Example 2: Production with Multi-Tenancy and TLS OpenTelemetry Collector config:\nreceivers: otlp: protocols: grpc: endpoint: 0.0.0.0:4317 processors: memory_limiter: check_interval: 1s limit_mib: 512 batch: send_batch_size: 1000 timeout: 10s resourcedetection: detectors: [env, system, kubernetes] exporters: otlp: endpoint: tempo:4317 headers: X-Scope-OrgID: \"tenant-battlebots\" tls: insecure: false cert_file: /certs/client.crt key_file: /certs/client.key ca_file: /certs/ca.crt retry_on_failure: enabled: true sending_queue: enabled: true queue_size: 1000 compression: snappy service: pipelines: traces: receivers: [otlp] processors: [memory_limiter, batch, resourcedetection] exporters: [otlp] Tempo config:\nserver: http_listen_port: 3200 distributor: receivers: otlp: protocols: grpc: endpoint: 0.0.0.0:4317 tls: cert_file: /certs/server.crt key_file: /certs/server.key ingester: lifecycler: ring: replication_factor: 3 storage: trace: backend: s3 s3: bucket: tempo-traces endpoint: s3.amazonaws.com region: us-east-1 multitenancy_enabled: true overrides: per_tenant_override_config: /etc/overrides.yaml Troubleshooting Issue: Connection Refused on Port 4317/4318 Symptoms:\nError: rpc error: code = Unavailable desc = connection error: dial tcp 192.168.1.10:4317: connect: connection refused Causes:\nTempo’s OTLP receivers not configured properly Tempo v2.7+ defaulting to localhost (not accessible from other containers) Firewall blocking ports 4317/4318 Solutions:\nVerify Tempo OTLP configuration:\ndistributor: receivers: otlp: protocols: grpc: endpoint: 0.0.0.0:4317 # Must be 0.0.0.0, not localhost Check Tempo logs:\ndocker logs tempo | grep \"OTLP\" Verify ports are exposed:\ndocker ps | grep tempo # Should show 4317/tcp and 4318/tcp Test connectivity:\n# From OTel Collector container nc -zv tempo 4317 Issue: Traces Not Appearing in Tempo Symptoms:\nOTel Collector shows no errors Traces not visible in Grafana Debugging steps:\nEnable debug logging in OTel Collector:\nexporters: logging: loglevel: debug service: pipelines: traces: receivers: [otlp] processors: [batch] exporters: [otlp, logging] # Add logging Check OTel Collector metrics:\ncurl http://otel-collector:8888/metrics | grep otelcol_exporter_sent_spans # Should show \u003e 0 if spans are being sent Check Tempo metrics:\ncurl http://tempo:3200/metrics | grep tempo_distributor_spans_received_total # Should show \u003e 0 if Tempo is receiving spans Wait for ingester flush:\nTraces are buffered in ingesters before flushing to storage Default max_block_duration = 30-60 minutes For POC, set max_block_duration: 5m for faster availability Query by trace ID directly:\ncurl \"http://tempo:3200/api/traces/\u003ctrace-id\u003e\" Issue: High Memory Usage in OTel Collector Symptoms:\nOTel Collector OOM (out of memory) Collector restarts frequently Solutions:\nAdd memory limiter processor:\nprocessors: memory_limiter: check_interval: 1s limit_mib: 512 service: pipelines: traces: processors: [memory_limiter, batch] # memory_limiter first Reduce batch size:\nprocessors: batch: send_batch_size: 500 # Reduce from 1000 timeout: 5s # Reduce from 10s Increase OTel Collector resources:\n# Docker Compose otel-collector: deploy: resources: limits: memory: 1G Issue: Spans Dropped or Missing Symptoms:\nIncomplete traces (missing spans) OTel Collector shows dropped spans Causes:\nRate limiting in Tempo Batch processor queue full Network timeouts Solutions:\nCheck OTel Collector queue metrics:\ncurl http://otel-collector:8888/metrics | grep otelcol_exporter_queue_size Increase queue size:\nexporters: otlp: sending_queue: enabled: true queue_size: 5000 # Increase from 1000 Check Tempo rate limits:\n# tempo.yaml overrides: defaults: ingestion_rate_limit_bytes: 10485760 # 10 MB/s ingestion_burst_size_bytes: 20971520 # 20 MB burst Enable retry on failure:\nexporters: otlp: retry_on_failure: enabled: true max_elapsed_time: 10m Issue: “Unimplemented” or Wrong Endpoint Errors Symptoms:\nError: rpc error: code = Unimplemented desc = unknown service Cause: OpenTelemetry Collector trying to send to wrong endpoint or using wrong protocol.\nSolutions:\nVerify endpoint format:\n✅ Correct: endpoint: tempo:4317 (no protocol prefix for gRPC) ❌ Wrong: endpoint: http://tempo:4317 (http prefix for gRPC) Match exporter to protocol:\nUse otlp exporter for gRPC (port 4317) Use otlphttp exporter for HTTP (port 4318 with http:// prefix) Verify Tempo receiver is enabled:\ndistributor: receivers: otlp: protocols: grpc: # Must be enabled http: # Must be enabled BattleBots Integration Patterns Complete LGTM Stack Configuration OpenTelemetry Collector configuration for BattleBots:\nreceivers: # OTLP receiver for application traces otlp: protocols: grpc: endpoint: 0.0.0.0:4317 http: endpoint: 0.0.0.0:4318 processors: memory_limiter: check_interval: 1s limit_mib: 512 batch: send_batch_size: 1000 timeout: 10s # Add BattleBots-specific attributes attributes: actions: - key: platform value: battlebots action: upsert - key: environment value: production action: upsert # Detect cloud/K8s metadata resourcedetection: detectors: [env, system, docker, kubernetes] # Tail sampling for intelligent trace selection tail_sampling: policies: # Always sample errors - name: errors type: status_code status_code: status_codes: [ERROR] # Always sample critical game events - name: critical-events type: string_attribute string_attribute: key: span.event.type values: [bot_death, battle_end, matchmaking_failed] # Always sample slow operations - name: slow-operations type: latency latency: threshold_ms: 1000 # Sample 20% of normal traffic - name: baseline type: probabilistic probabilistic: sampling_percentage: 20 exporters: # Tempo - traces otlp: endpoint: tempo:4317 tls: insecure: true retry_on_failure: enabled: true sending_queue: enabled: true compression: snappy # Logging for debugging logging: loglevel: info service: pipelines: traces: receivers: [otlp] processors: [memory_limiter, batch, attributes, resourcedetection, tail_sampling] exporters: [otlp, logging] BattleBots-Specific TraceQL Queries Find all battles with errors:\n{ resource.service.name = \"game-server\" \u0026\u0026 status = error } Find slow bot actions (\u003e 100ms):\n{ span.action.type =~ \"bot_.*\" \u0026\u0026 duration \u003e 100ms } Find battles where a specific bot died:\n{ span.event.type = \"bot_death\" \u0026\u0026 span.bot.id = \"bot_xyz123\" } Find database queries in battle processing:\n{ resource.service.name = \"game-server\" \u0026\u0026 span.db.statement != nil \u0026\u0026 duration \u003e 50ms } Aggregate: Count battles by winner:\n{ span.battle.result != nil } | by(span.battle.winner) | count() Aggregate: Average battle duration by game mode:\n{ resource.service.name = \"game-server\" \u0026\u0026 span.name = \"ExecuteBattle\" } | by(span.battle.mode) | avg(duration) Trace-Metric-Log Correlation Example Application instrumentation (Go):\nimport ( \"context\" \"go.opentelemetry.io/otel\" \"go.opentelemetry.io/otel/trace\" \"github.com/sirupsen/logrus\" ) func ProcessBotAction(ctx context.Context, action BotAction) error { // Create span tracer := otel.Tracer(\"game-server\") ctx, span := tracer.Start(ctx, \"ProcessBotAction\") defer span.End() // Add span attributes span.SetAttributes( attribute.String(\"action.type\", action.Type), attribute.String(\"bot.id\", action.BotID), attribute.String(\"battle.id\", action.BattleID), ) // Log with trace context traceID := span.SpanContext().TraceID().String() spanID := span.SpanContext().SpanID().String() logger.WithFields(logrus.Fields{ \"trace_id\": traceID, \"span_id\": spanID, \"bot_id\": action.BotID, }).Info(\"Processing bot action\") // ... process action ... if err != nil { span.RecordError(err) span.SetStatus(codes.Error, \"Action failed\") logger.WithField(\"trace_id\", traceID).Error(\"Action failed\", err) return err } return nil } Workflow in Grafana:\nStart with metric alert: “Bot action latency P99 \u003e 500ms” Click exemplar: Jump to example slow trace Identify span: See ProcessBotAction span took 800ms View logs: Click “Logs for this span” → see detailed error logs with same trace_id Root cause: Logs show “database connection pool exhausted at 12:34:56” Further Reading Official Documentation Configure Tempo Pushing Spans with HTTP Enable Multi-tenancy Tempo Release Notes OpenTelemetry Collector Resources OpenTelemetry Collector Configuration OTLP Exporter OTLPHTTP Exporter Batch Processor Tail Sampling Processor Integration Guides How to Send Traces to Grafana Cloud Tempo with OpenTelemetry Collector End-to-End Distributed Tracing in Kubernetes with Grafana Tempo and OpenTelemetry Send Data to the Grafana Cloud OTLP Endpoint Troubleshooting Resources Tempo Troubleshooting Guide OpenTelemetry Collector Troubleshooting Grafana Community Forums - Tempo Related BattleBots Documentation Tempo Overview - Architecture, deployment, and how to run Tempo OpenTelemetry Collector: Traces Support - Understanding distributed tracing Grafana Loki: OTLP Integration - Log correlation Grafana Mimir: OTLP Integration - Metrics correlation ","categories":"","description":"Deep dive into Grafana Tempo's native OTLP support and integration with the OpenTelemetry Collector, including configuration examples, best practices, and troubleshooting guidance.\n","excerpt":"Deep dive into Grafana Tempo's native OTLP support and integration …","ref":"/battlebots/pr-preview/pr-153/research_and_development/analysis/observability/traces/tempo/tempo-otlp-integration/","tags":"","title":"Tempo: OTLP and OpenTelemetry Collector Integration"},{"body":"Overview Grafana Tempo is a high-volume, minimal dependency distributed tracing backend designed for cost-efficiency and operational simplicity. Unlike traditional distributed tracing systems that require complex database infrastructure like Cassandra or Elasticsearch, Tempo leverages object storage as its only dependency, dramatically reducing operational complexity while providing powerful trace querying capabilities through TraceQL.\nThe core innovation of Tempo is its index-free, object storage-first architecture: traces are stored as immutable blocks in cost-effective object storage (S3, GCS, Azure, MinIO) without requiring expensive indexing infrastructure. While this trades off some search flexibility compared to fully-indexed systems like Jaeger, it enables storing 100% of traces at a fraction of the cost. TraceQL, Tempo’s SQL-like query language, provides sophisticated trace analysis capabilities including filtering by span attributes, duration thresholds, and span relationships.\nTempo integrates seamlessly with the Grafana observability stack, enabling powerful trace-to-metrics correlation through exemplars and trace-to-logs correlation through shared trace IDs. Combined with Loki (logs) and Mimir (metrics), Tempo completes the LGTM stack for unified observability.\nWhat is Grafana Tempo? Grafana Tempo is an open-source distributed tracing backend that fundamentally changes the economics and operational model of trace storage at scale. Launched by Grafana Labs, Tempo addresses the primary pain points of traditional tracing systems: expensive storage infrastructure, complex database management, and prohibitive costs that force aggressive sampling.\nDesign Philosophy:\nCost-Efficient: Object storage costs 90% less than Cassandra or Elasticsearch for trace storage Minimal Dependencies: Only requires object storage—no databases, no indexes, no complex infrastructure Standards-Based: Native OpenTelemetry Protocol (OTLP) support with full compatibility for Jaeger and Zipkin formats High Scale with Simplicity: Handle millions of spans per second while maintaining operational simplicity Deep Integration: Seamless correlation with Grafana, Loki, Mimir, and Prometheus Key Characteristics:\nIndex-Free Architecture: Primary lookup method is by trace ID; advanced queries use TraceQL with on-demand scanning Blocks Storage Model: Traces stored in columnar Apache Parquet format optimized for fast scanning (300 GB/s search speed) Query Language: TraceQL provides SQL-like syntax for powerful trace analysis Multi-Protocol Ingestion: Accepts OTLP, Jaeger, Zipkin, and OpenCensus protocols Multi-Tenancy: Native support for isolated tenant data with per-tenant limits and retention Problem It Solves:\nTraditional tracing backends (Jaeger, Zipkin) require expensive, complex database infrastructure that:\nIncurs high storage costs (forcing aggressive sampling to 1-10% of traces) Requires skilled operators to manage Cassandra or Elasticsearch clusters Creates operational overhead for database tuning, backups, and scaling Limits retention to days or weeks due to cost constraints Tempo eliminates these issues by leveraging cheap object storage and an index-free design, enabling teams to store 100% of traces for weeks or months at a fraction of the cost, with minimal operational burden.\nWhy Research Tempo? For the BattleBots platform’s observability stack, Tempo offers several strategic advantages:\nCost Efficiency at Scale 10x Storage Cost Reduction: Object storage costs $0.023/GB/month (S3) vs. $0.10-0.30/GB/month for databases Store 100% of Traces: No sampling required—capture every battle, every bot action, every error Long-Term Retention: Affordable retention for 30+ days enables historical analysis and debugging Operational Simplicity No Database Management: No Cassandra tuning, no Elasticsearch cluster management Minimal Infrastructure: Deploy Tempo components + object storage (which you likely already have) Simple Scaling: Add more distributors/ingesters/queriers independently as needed Native OpenTelemetry Integration OTLP First-Class Protocol: Native OTLP/gRPC (port 4317) and OTLP/HTTP (port 4318) support since v1.3.0 Zero Translation Overhead: Direct ingestion without protocol conversion Future-Proof: Built on CNCF standard used by entire industry Powerful Query Capabilities TraceQL: SQL-like query language for filtering by span attributes, duration, status, and relationships Structural Queries: Find traces with specific span patterns (e.g., “database call \u003e 100ms following API call”) Aggregations: Generate metrics from traces (span counts, duration distributions) Unified Observability Trace-to-Metrics: Exemplars link metric spikes to example slow traces Trace-to-Logs: Shared trace ID enables jumping from trace span to correlated log lines Grafana Ecosystem: Native integration with Loki, Mimir, Prometheus, and Grafana Battle-Specific Benefits Debug Complete Battles: Trace entire battle workflow from matchmaking → execution → results persistence Bot Performance Analysis: Analyze every bot action’s latency and success/failure patterns Error Investigation: Capture 100% of failed actions without worrying about sampling missing critical traces Historical Analysis: Compare bot performance across battles over weeks or months Key Concepts Understanding Tempo’s data model and terminology is essential for effective deployment and usage.\nTraces and Spans A trace represents the full journey of one request or transaction across distributed services, while a span is a timed unit of work within that journey.\nTrace structure:\nTraces consist of one or more spans organized in a tree/hierarchy Each span represents an operation with a start time and duration Spans have parent-child relationships forming the call graph The root span represents the initial request entry point Spans can have events (annotations at specific timestamps) and links (references to spans in other traces) Example BattleBots trace:\nTrace: Battle Execution (trace_id: abc123) ├─ Root Span: ProcessBattleAction (100ms) ├─ Child Span: ValidateAction (10ms) ├─ Child Span: UpdateGameState (30ms) │ └─ Child Span: PersistState (database) (20ms) └─ Child Span: BroadcastUpdate (WebSocket) (15ms) Span characteristics:\nName: Describes the operation (e.g., “GET /api/battles”, “ProcessBotAction”, “database.query”) Start time and duration: Nanosecond precision timing information Status: Success (ok), error, or unset Span kind: Client, server, internal, producer, or consumer Attributes: Key-value metadata (e.g., http.method=GET, bot.id=bot123, action.type=attack) Events: Timestamped annotations (e.g., exceptions, state changes, cache hits) Links: References to causally-related spans in different traces Trace ID and Span ID Trace ID\nUnique identifier for the entire trace (128-bit or 64-bit hex string) Follows the trace through all services and operations Used as the primary key for trace retrieval in Tempo Example: 4bf92f3577b34da6a3ce929d0e0e4736 Span ID\nUnique identifier for an individual span within a trace (64-bit hex string) Used to reconstruct parent-child relationships Combined with trace ID for precise span references Example: 00f067aa0ba902b7 Parent Span ID\nReferences the span ID of the parent span Enables reconstruction of the trace tree structure Root spans have no parent span ID Blocks Storage Blocks are immutable units of trace data stored in object storage, representing Tempo’s fundamental persistence mechanism.\nBlock characteristics:\nFormat: Apache Parquet columnar storage (vParquet4 as of Tempo 2.5+) Immutability: Once written, blocks are never modified (only compacted/deleted) Time-based: Blocks typically represent traces from a specific time window Columnar: Span attributes stored in columns for efficient filtering Compressed: Parquet provides excellent compression ratios Block lifecycle:\nCreation: Ingesters accumulate spans in memory over configured time period (default 30-60 minutes) Flushing: Ingester writes complete block to object storage with bloom filters and indexes Querying: Queriers read blocks, using bloom filters to skip irrelevant blocks Compaction: Compactor merges small blocks into larger ones for query efficiency Expiration: Compactor deletes blocks older than retention period Performance:\nPrevious block format: ~40-50 GB/s search speed Parquet format (vParquet4): ~300 GB/s search speed (6x improvement) Bloom filters enable skipping 99%+ of irrelevant blocks TraceQL Query Language TraceQL is Tempo’s powerful SQL-like query language for selecting, filtering, and analyzing distributed traces.\nDesign characteristics:\nStructure-aware: Understands trace architecture (root spans, parent-child relationships) Attribute-focused: Query by span attributes, resource attributes, and intrinsics Familiar syntax: Borrows concepts from PromQL and LogQL for consistency Aggregation support: Generate metrics from traces (counts, averages, histograms) Query structure:\n{ \u003cspan-selector\u003e } | \u003cpipeline-operations\u003e Attribute scopes:\nspan.*: Span-level attributes (e.g., span.http.method, span.db.statement) resource.*: Resource-level attributes (e.g., resource.service.name, resource.host.name) event.*: Event attributes link.*: Link attributes to related spans Intrinsics (built-in span properties):\nname: Span name duration: Span duration in nanoseconds status: Span status (ok, error, unset) kind: Span kind (client, server, internal, producer, consumer) Example TraceQL queries:\n# Find all traces with HTTP GET requests { span.http.method = \"GET\" } # Find slow database queries (\u003e 1 second) { span.db.statement =~ \"SELECT.*\" \u0026\u0026 duration \u003e 1s } # Find errors in specific service { resource.service.name = \"game-server\" \u0026\u0026 status = error } # Complex: API calls that resulted in slow database queries { span.http.route = \"/api/battles\" } \u003e\u003e { span.db.statement != nil \u0026\u0026 duration \u003e 100ms } # Aggregate: Count traces by service { } | by(resource.service.name) | count() \u003e 10 # BattleBots: Find all battles where bot actions took \u003e 500ms { resource.service.name = \"game-server\" \u0026\u0026 span.action.type = \"bot_move\" \u0026\u0026 duration \u003e 500ms } Query execution: Tempo evaluates TraceQL queries by:\nIdentifying relevant blocks using time range and bloom filters Scanning blocks in parallel using columnar Parquet format Applying span selectors and filters Executing pipeline operations (aggregations, grouping) Returning matching traces or aggregated results Sampling Strategies Sampling controls which traces are retained for analysis, balancing observability value with storage costs and performance impact.\nHead-Based Sampling\nDecision point: Made at trace creation time, before seeing complete trace Characteristics: Low latency, minimal overhead, consistent across services Use cases: Baseline traffic reduction, predictable sampling rates Limitation: Cannot make decisions based on trace outcome (errors, latency) Tail-Based Sampling\nDecision point: Made after seeing all/most spans in a trace Characteristics: Intelligent decisions based on complete trace data, higher overhead Policies: Always sample errors, sample slow traces (latency threshold), probabilistic, rate limiting Requirement: Multi-tier collector deployment (agent → tail sampling gateway) Use cases: Capture 100% of errors while sampling successful traces Adaptive Sampling\nTraceQL support: with(sample=true) automatically determines optimal strategy Fixed span sampling: with(span_sample=0.10) selects 10% of spans Fixed trace sampling: with(trace_sample=0.10) selects complete traces Recommendation for BattleBots:\nDevelopment: 100% sampling (no sampling) Production: Tail-based sampling with policies: Always sample traces with status = error Always sample traces with duration \u003e 2 seconds Sample 10-20% of successful, fast traces Always sample traces with span.action.type = \"bot_death\" (critical game events) Architecture Components Tempo uses a microservices architecture where each component can be scaled independently or combined into larger deployment targets. The architecture is inspired by Grafana Loki and optimized for object storage.\ngraph TB subgraph \"Instrumented Applications\" APP1[\"Game Server\u003cbr/\u003e(OTel Instrumented)\"] APP2[\"Matchmaking Service\u003cbr/\u003e(OTel Instrumented)\"] APP3[\"Bot Runtime\u003cbr/\u003e(OTel Instrumented)\"] end subgraph \"Ingestion Path\" COLL[\"OpenTelemetry Collector\u003cbr/\u003e(Protocol Conversion)\"] DIST[\"Distributor\u003cbr/\u003e(Load Balancing \u0026 Sharding)\"] end subgraph \"Write Path\" ING1[\"Ingester 1\"] ING2[\"Ingester 2\"] ING3[\"Ingester 3\"] BLOOM[\"Bloom Filters\u003cbr/\u003e\u0026 Indexes\"] end subgraph \"Object Storage\" S3[\"S3 / GCS / Azure / MinIO\"] BLOCKS[\"Parquet Blocks\u003cbr/\u003e(vParquet4)\"] end subgraph \"Maintenance\" COMPACT[\"Compactor\u003cbr/\u003e(Block Merging,\u003cbr/\u003eRetention)\"] METRICS[\"Metrics-Generator\u003cbr/\u003e(Optional)\"] end subgraph \"Read Path\" QFRONT[\"Query Frontend\u003cbr/\u003e(Query Optimization)\"] Q1[\"Querier 1\"] Q2[\"Querier 2\"] Q3[\"Querier 3\"] end subgraph \"Query Interface\" TRACEQL[\"TraceQL Engine\"] GRAFANA[\"Grafana UI\"] end APP1 --\u003e|\"Traces (OTLP)\"| COLL APP2 --\u003e|\"Traces (OTLP)\"| COLL APP3 --\u003e|\"Traces (OTLP)\"| COLL COLL --\u003e|\"OTLP/Jaeger/Zipkin\"| DIST DIST --\u003e|\"Hash(Trace ID)\"| ING1 DIST --\u003e|\"Hash(Trace ID)\"| ING2 DIST --\u003e|\"Hash(Trace ID)\"| ING3 ING1 \u0026 ING2 \u0026 ING3 --\u003e BLOOM BLOOM --\u003e BLOCKS BLOCKS --\u003e S3 COMPACT -.-\u003e|\"Merge \u0026 Optimize\"| BLOCKS ING1 \u0026 ING2 \u0026 ING3 -.-\u003e|\"Span Metrics\"| METRICS GRAFANA --\u003e|\"TraceQL / Trace ID\"| QFRONT QFRONT --\u003e Q1 \u0026 Q2 \u0026 Q3 Q1 \u0026 Q2 \u0026 Q3 --\u003e|\"Recent Data\"| ING1 \u0026 ING2 \u0026 ING3 Q1 \u0026 Q2 \u0026 Q3 --\u003e|\"Bloom + Block Read\"| BLOCKS Q1 \u0026 Q2 \u0026 Q3 --\u003e TRACEQL TRACEQL --\u003e GRAFANA METRICS -.-\u003e|\"Service Graphs\"| GRAFANA style DIST fill:#fff4e6 style ING1 fill:#fff4e6 style ING2 fill:#fff4e6 style ING3 fill:#fff4e6 style QFRONT fill:#e1f5ff style Q1 fill:#e1f5ff style Q2 fill:#e1f5ff style Q3 fill:#e1f5ff style COMPACT fill:#f3e5f5 style METRICS fill:#e8f5e9 style S3 fill:#fce4ec Distributor The distributor is the entry point for all incoming span data, receiving traces in multiple formats and routing them to ingesters.\nResponsibilities:\nAccept spans in multiple protocols: OTLP (gRPC/HTTP), Jaeger (gRPC/Thrift), Zipkin, OpenCensus Validate incoming span data for correctness and completeness Apply rate limiting per tenant (if multi-tenancy enabled) Hash spans by trace ID to determine target ingesters Route spans to ingesters using consistent hashing on trace ID Load balance across available ingesters Key characteristics:\nStateless component (can be horizontally scaled easily) Uses OpenTelemetry Collector’s receiver layer for protocol handling Leverages distributed consistent hash ring for sharding All spans for a given trace ID route to the same ingester set Configuration considerations:\nEnable only the receivers you need (OTLP recommended, disable unused protocols) Configure appropriate rate limits per tenant Set batch sizes to balance latency vs. throughput Enable gRPC compression (snappy) for bandwidth efficiency Ingester The ingester indexes and batches span data for efficient storage, creating the immutable blocks that form Tempo’s storage layer.\nResponsibilities:\nReceive spans from distributors (sharded by trace ID) Buffer spans in memory, organizing by trace ID Generate bloom filters and indexes for fast retrieval Batch spans into blocks based on time or size thresholds Write complete blocks to object storage (S3, GCS, Azure, MinIO) Serve recent, not-yet-persisted trace data to queriers (for real-time queries) Maintain Write-Ahead Log (WAL) for crash recovery Block creation process:\nAccumulate spans in memory for configured duration (default 30-60 min) Partition span data into Apache Parquet columnar schema Generate bloom filters for efficient trace ID lookups Compress data using Parquet compression Write immutable block to object storage Update internal metadata for recent blocks Key characteristics:\nStateful component (requires careful scaling and shutdown) Uses consistent hashing with replication (default RF=3 for durability) Memory usage scales with trace volume and max_block_duration WAL ensures data durability during crashes Configuration considerations:\nmax_block_duration: 30-60 minutes optimal (balance memory vs. block count) max_block_bytes: Default 100GB (prevents excessive block sizes) trace_idle_period: How long to wait before flushing a trace (default 10s) Replication factor: RF=3 recommended for production Querier The querier executes trace searches and retrievals, scanning object storage blocks and querying ingesters for recent data.\nResponsibilities:\nExecute trace ID lookups (primary query method) Execute TraceQL queries across blocks Read bloom filters and indexes from object storage Skip irrelevant blocks using bloom filter checks Scan relevant blocks in parallel using Parquet columnar format Query ingesters for recent, not-yet-persisted traces Merge results from multiple sources (ingesters + blocks) Return matching spans to Query Frontend Query execution:\nReceive query from Query Frontend Determine time range and relevant blocks Check bloom filters to skip blocks without matching trace IDs Read relevant blocks from object storage in parallel Query ingesters for recent data Apply TraceQL filters and aggregations Return results Key characteristics:\nStateless component (horizontally scalable) Query performance depends on block count, trace size, and time range Uses caching to improve repeated query performance Configuration considerations:\nScale based on query concurrency and complexity Configure appropriate CPU/memory for parallel block scanning Enable query result caching Query Frontend The query Frontend optimizes and coordinates incoming trace queries, sharding large queries across multiple queriers in parallel.\nResponsibilities:\nAct as the interface between Grafana and the tracing backend Split large time-range queries into smaller sub-queries (query sharding) Distribute sub-queries across multiple queriers in parallel Aggregate and concatenate results from queriers Manage query queuing to prevent querier overload Cache query results to improve performance Key characteristics:\nStateless component (horizontally scalable) Significantly improves query performance for large time ranges Required for high availability (minimum 2 replicas recommended) Configuration considerations:\nDeploy at least 2 replicas for HA Configure query sharding parameters based on trace volume Enable query result caching Compactor The compactor maintains and optimizes stored blocks, running on scheduled intervals to compress and deduplicate data.\nResponsibilities:\nMerge small blocks into larger blocks (reduces block count by ~90%) Deduplicate spans from replicated writes (RF=3 creates duplicates) Apply retention policies by deleting blocks older than configured retention Optimize bloom filters for merged blocks Update block metadata Compaction process:\nList all blocks in object storage for a given time window Download blocks to be compacted Merge and deduplicate spans Generate new, larger block with optimized bloom filters Upload merged block to object storage Delete source blocks Key characteristics:\nI/O-bound component (minimal CPU requirements) Only one compactor should run per tenant (to avoid conflicts) Critical for long-term storage efficiency and query performance Configuration considerations:\nblock_retention: 30 days default (configurable per tenant) compacted_block_retention: 0-1 hour (how long to keep source blocks after compaction) Schedule compaction during low-traffic periods if possible Metrics-Generator (Optional) The metrics-generator derives metrics from ingested traces, enabling span metrics and service graphs.\nResponsibilities:\nAnalyze incoming span data Extract span metrics (request rates, error rates, latencies by service) Generate service graph metrics (call relationships between services) Write derived metrics to metrics storage (Prometheus, Mimir) Enable trace-to-metrics correlation through exemplars Generated metrics:\nSpan metrics: traces_spanmetrics_calls_total, traces_spanmetrics_latency_bucket Service graph metrics: Request rate, error rate, latency between service pairs Key characteristics:\nOptional component (not required for core tracing functionality) Enables powerful trace-to-metrics workflows in Grafana Adds memory overhead to ingesters Configuration considerations:\nConfigure remote write endpoint (Prometheus, Mimir) Set histogram buckets for latency metrics Enable exemplar support for trace correlation Deployment Modes Tempo supports three deployment modes, each balancing simplicity against scalability and operational flexibility. The architecture is similar to Loki’s deployment model.\nMonolithic Mode In monolithic mode, all Tempo components run in a single process. This is the simplest deployment option, ideal for POC, development, and small-scale production.\nConfiguration:\ntempo -target=all -config.file=tempo.yaml Characteristics:\nSingle binary or container runs all components All components share memory and resources Minimal operational complexity Limited horizontal scalability (vertical scaling only) Suitable for development and small deployments When to use:\nDevelopment and testing environments Proof-of-concept deployments Small-scale production (\u003c 1,000 traces/second) Single-server or minimal infrastructure deployments Resource requirements:\n2-4 CPU cores 4-8GB RAM Local SSD for fast block storage (50GB+) Object storage access (S3, GCS, MinIO, or local filesystem) Limitations:\nCannot scale components independently Single point of failure Resource contention between components (ingesters and queriers compete for CPU/memory) Not recommended for Kubernetes production deployments Recommended for BattleBots POC: This mode is perfect for initial evaluation and development.\nScalable Single Binary Mode Scalable single binary mode (or “scalable mode”) runs all components within one process, but multiple instances can be deployed with read-write separation, providing horizontal scalability.\nConfiguration:\n# Set target for each instance tempo -target=scalable-single-binary -config.file=tempo.yaml Characteristics:\nComponents act as if in distributed setup but packaged as single binary Multiple instances deployed for redundancy and scale Read and write paths can be scaled independently Balanced approach between monolithic simplicity and microservices scalability Suitable for small-to-medium volume traces (10K-100K+ traces/second) When to use:\nMedium-scale production deployments Transitioning from monolithic to highly available setup Kubernetes environments using Helm charts Teams wanting operational simplicity with growth capacity Resource requirements:\n4 CPU cores, 8-12GB memory per instance 3-5 instances typical Shared object storage (S3, GCS, etc.) Typical throughput: 10K-50K traces/second Benefits:\nHorizontal scalability without full microservices complexity Reduced operational burden vs. microservices Suitable for Kubernetes deployments Components benefit from distributed hash ring Limitations:\nLess robust than fully distributed deployment Still some resource contention within single process Cannot optimize per-component scaling Recommended for BattleBots production: This mode is ideal for initial production deployment, providing scalability and HA without excessive complexity.\nMicroservices Mode Microservices mode runs each Tempo component as a separate deployment with independent replicas, providing maximum flexibility and scale.\nComponents deployed separately:\nDistributor (multiple instances, stateless) Ingester (multiple instances, stateful) Querier (multiple instances, stateless) Query Frontend (multiple instances, stateless) Compactor (single instance per tenant) Metrics-Generator (optional, multiple instances) Characteristics:\nEach component scaled independently based on workload Fine-grained resource allocation per component Granular failure domains (one component failure doesn’t affect others) Most complex to deploy and maintain Supports enterprise-scale deployments (multi-million traces/second) When to use:\nProduction environments with high-availability requirements Large-scale trace volumes (100K+ traces/second) Multi-tenant deployments Organizations with dedicated observability operations teams Need for independent component scaling (e.g., scale queriers independently during high query load) Resource requirements (large deployment example):\nDistributors: 4-8 instances (2 CPU, 2GB each) Ingesters: 6-12 instances (2.5 CPU, 8-12GB each) Queriers: 4-8 instances (2 CPU, 4-8GB each) Query Frontend: 2 instances (1 CPU, 4GB each) Compactor: 2-3 instances (1 CPU, 4GB each) Typical throughput: 500K-2M+ traces/second Benefits:\nFully horizontally scaled—each component has dedicated replicas Data replication prevents catastrophic failures (RF=3) Granular failure domains Flexible, independent scaling per component Can temporarily scale during traffic spikes with no adverse impact Challenges:\nSignificantly increased operational complexity More components to orchestrate, monitor, and maintain Requires sophisticated orchestration (Kubernetes with Helm) Network communication overhead between components Higher total cost of ownership (TCO) Not recommended for BattleBots initially: Start with scalable mode; migrate to microservices only if scale demands it.\nDeployment Mode Comparison Aspect Monolithic Scalable Single Binary Microservices Best Use Case POC, dev, demos Production (small-medium) Production (large scale) Deployment Complexity Very Simple Moderate Complex Horizontal Scaling None Instance-level Per-component (flexible) Failure Isolation None (SPOF) Basic (full process) Excellent (per-component) Data Replication Not available Limited Full (RF=3) Operational Overhead Minimal Moderate High Resource Efficiency High (no duplication) Moderate Lower (replication overhead) Configuration Complexity Minimal Moderate High Traces/Second Capacity \u003c 1K 10K-100K+ 100K-2M+ Recommended for Battle Bots POC/Dev Production Not initially How to Run Tempo This section provides practical guidance for running Grafana Tempo, focusing on Docker Compose for POC and development environments.\nQuick Start with Docker Compose The following Docker Compose setup includes Tempo, Grafana, Prometheus, and tools for generating and visualizing traces.\nStep 1: Create directory structure\nmkdir tempo-poc \u0026\u0026 cd tempo-poc mkdir -p tempo-data Step 2: Create tempo.yaml configuration\nCreate a file named tempo.yaml:\nstream_over_http_enabled: true server: http_listen_port: 3200 grpc_listen_port: 9095 log_level: info distributor: log_received_spans: enabled: true log_sampling_fraction: 0.1 receivers: jaeger: protocols: thrift_http: endpoint: \"0.0.0.0:14268\" grpc: endpoint: \"0.0.0.0:14250\" zipkin: endpoint: \"0.0.0.0:9411\" otlp: protocols: grpc: endpoint: \"0.0.0.0:4317\" http: endpoint: \"0.0.0.0:4318\" ingester: lifecycler: ring: replication_factor: 1 kvstore: store: inmemory max_block_duration: 5m trace_idle_period: 5s compactor: compaction: block_retention: 720h # 30 days compacted_block_retention: 0h query_frontend: search: duration_slo: 5s throughput_bytes_slo: 1.073741824e+09 trace_by_id: duration_slo: 100ms metrics_generator: registry: external_labels: source: tempo cluster: docker-compose storage: path: /var/tempo/generator/wal remote_write: - url: http://prometheus:9090/api/v1/write send_exemplars: true processor: service_graphs: histogram_buckets: [0.1, 0.5, 1, 2, 5, 10] span_metrics: histogram_buckets: [0.1, 0.5, 1, 2, 5, 10] storage: trace: backend: local wal: path: /var/tempo/wal local: path: /var/tempo/blocks overrides: defaults: metrics_generator: processors: [service-graphs, span-metrics] Step 3: Create docker-compose.yaml\nCreate a file named docker-compose.yaml:\nversion: '3' services: # Initialize directory with proper permissions init: image: busybox:latest user: root entrypoint: sh -c 'mkdir -p /var/tempo/wal /var/tempo/blocks /var/tempo/generator/wal \u0026\u0026 chmod -R 777 /var/tempo' volumes: - tempo-data:/var/tempo # Tempo - distributed tracing backend tempo: image: grafana/tempo:latest command: [ \"-config.file=/etc/tempo.yaml\" ] volumes: - ./tempo.yaml:/etc/tempo.yaml - tempo-data:/var/tempo ports: # OTLP API - \"4317:4317\" # gRPC - \"4318:4318\" # HTTP # Jaeger API - \"14250:14250\" # gRPC - \"14268:14268\" # Thrift HTTP # Zipkin API - \"9411:9411\" # Tempo HTTP API - \"3200:3200\" # Tempo gRPC API - \"9095:9095\" depends_on: init: condition: service_completed_successfully # Prometheus - metrics storage for metrics-generator prometheus: image: prom/prometheus:latest command: - '--config.file=/etc/prometheus/prometheus.yaml' - '--storage.tsdb.path=/prometheus' - '--storage.tsdb.retention.time=24h' volumes: - ./prometheus.yaml:/etc/prometheus/prometheus.yaml - prometheus-data:/prometheus ports: - \"9090:9090\" depends_on: - tempo # Grafana - visualization and dashboards grafana: image: grafana/grafana:12.2.1 environment: GF_AUTH_ANONYMOUS_ENABLED: \"true\" GF_AUTH_ANONYMOUS_ORG_ROLE: \"Admin\" GF_SECURITY_ADMIN_PASSWORD: \"admin\" volumes: - grafana-data:/var/lib/grafana - ./grafana-datasources.yaml:/etc/grafana/provisioning/datasources/datasources.yaml ports: - \"3000:3000\" depends_on: - tempo - prometheus volumes: tempo-data: prometheus-data: grafana-data: Step 4: Create prometheus.yaml\nCreate a file named prometheus.yaml:\nglobal: scrape_interval: 15s evaluation_interval: 15s scrape_configs: - job_name: 'prometheus' static_configs: - targets: ['localhost:9090'] - job_name: 'tempo' static_configs: - targets: ['tempo:3200'] Step 5: Create grafana-datasources.yaml\nCreate a file named grafana-datasources.yaml:\napiVersion: 1 datasources: - name: Tempo type: tempo uid: tempo-uid access: proxy url: http://tempo:3200 basicAuth: false isDefault: true editable: true jsonData: httpMethod: GET tracesToMetrics: datasourceUid: prometheus-uid nodeGraph: enabled: true - name: Prometheus type: prometheus uid: prometheus-uid access: proxy url: http://prometheus:9090 basicAuth: false isDefault: false editable: true jsonData: timeInterval: 15s exemplarTraceIdDestinations: - name: trace_id datasourceUid: tempo-uid Step 6: Start the stack\ndocker compose up -d Step 7: Verify deployment\nCheck that all services are running:\ndocker compose ps Expected output:\nNAME COMMAND SERVICE STATUS tempo-poc-grafana-1 \"/run.sh\" grafana Up tempo-poc-init-1 \"sh -c 'mkdir -p /va…\" init Exited (0) tempo-poc-prometheus-1 \"/bin/prometheus --c…\" prometheus Up tempo-poc-tempo-1 \"/tempo -config.file…\" tempo Up Step 8: Verify Tempo is healthy\ncurl http://localhost:3200/ready Expected response: ready (HTTP 200)\nCheck Tempo status:\ncurl http://localhost:3200/status/services | jq Step 9: Access Grafana\nNavigate to http://localhost:3000 Login: admin / admin Go to Explore tab (left sidebar, compass icon) Select Tempo datasource from dropdown Click Search tab to find traces Step 10: Send test traces\nUsing curl with OTLP/HTTP:\ncurl -X POST http://localhost:4318/v1/traces \\ -H \"Content-Type: application/json\" \\ -d '{ \"resourceSpans\": [{ \"resource\": { \"attributes\": [{ \"key\": \"service.name\", \"value\": {\"stringValue\": \"test-service\"} }] }, \"scopeSpans\": [{ \"spans\": [{ \"traceId\": \"5b8aa5a2d2c872e8321cf37308d69df2\", \"spanId\": \"051581bf3cb55c13\", \"name\": \"test-operation\", \"kind\": 1, \"startTimeUnixNano\": \"1000000000000000000\", \"endTimeUnixNano\": \"1000000001000000000\" }] }] }] }' Verify the trace was received:\n# Wait a few seconds for ingestion sleep 5 # Query trace by ID curl \"http://localhost:3200/api/traces/5b8aa5a2d2c872e8321cf37308d69df2\" | jq Step 11: Query traces in Grafana\nIn Grafana Explore, select Tempo datasource Click Search tab Click Run query to see all traces Filter by service name: service.name = \"test-service\" Click on a trace to view the trace details Configuration Breakdown Key configuration sections explained:\nDistributor receivers:\nreceivers: otlp: protocols: grpc: endpoint: \"0.0.0.0:4317\" # Listen on all interfaces (required for Docker) http: endpoint: \"0.0.0.0:4318\" 0.0.0.0: Required for Docker containers to accept external connections In Tempo v2.7+, defaults to localhost (which only works within same container) OTLP is the recommended protocol for new instrumentation Ingester configuration:\ningester: max_block_duration: 5m # Flush blocks every 5 minutes (faster for POC) trace_idle_period: 5s # Flush trace if no new spans for 5 seconds Shorter durations = faster trace availability, more blocks created Production: Use 30-60 minutes for max_block_duration Storage configuration:\nstorage: trace: backend: local # Use local filesystem (POC only) local: path: /var/tempo/blocks # Path inside container POC: Use local backend Production: Use s3, gcs, or azure backend Metrics generator:\nmetrics_generator: storage: remote_write: - url: http://prometheus:9090/api/v1/write send_exemplars: true # Enable trace-to-metrics correlation Generates service graph and span metrics Enables powerful trace-to-metrics workflows in Grafana Exposed Ports and Their Purposes Port Protocol Purpose 3200 HTTP Tempo HTTP API (queries, health checks) 9095 gRPC Tempo gRPC API 4317 gRPC OTLP gRPC receiver (recommended) 4318 HTTP OTLP HTTP receiver (recommended) 14250 gRPC Jaeger gRPC receiver 14268 HTTP Jaeger Thrift HTTP receiver 9411 HTTP Zipkin HTTP receiver 3000 HTTP Grafana web UI 9090 HTTP Prometheus web UI Recommendation: For new instrumentation, use OTLP on port 4317 (gRPC) or 4318 (HTTP).\nHealth Check Endpoints Tempo ready check:\ncurl http://localhost:3200/ready # Returns: ready (HTTP 200) Tempo health status:\ncurl http://localhost:3200/status/services | jq Tempo metrics (Prometheus format):\ncurl http://localhost:3200/metrics Grafana health:\ncurl http://localhost:3000/api/health # Returns: {\"status\":\"ok\"} Troubleshooting Common Issues Issue: “permission denied” on tempo-data directory\nSolution: The init service automatically fixes permissions with chmod -R 777. Ensure init completes successfully before Tempo starts.\nIssue: Tempo fails to start\nCheck logs:\ndocker compose logs tempo Verify config syntax:\ndocker compose exec tempo tempo --verify-config -config.file=/etc/tempo.yaml Issue: No traces appear in Grafana\nVerify Tempo is receiving spans:\ndocker compose logs tempo | grep \"received\" Check Tempo metrics for ingestion:\ncurl http://localhost:3200/metrics | grep tempo_distributor_spans_received_total Verify data source configuration in Grafana:\nGo to Configuration → Data Sources Click Tempo Click Save \u0026 Test Should see: “Data source is working” Wait a few seconds—traces need to be flushed from ingester\nIssue: Connection refused on port 4317/4318\nEnsure endpoint: \"0.0.0.0:4317\" is set (not localhost) in tempo.yaml. Tempo v2.7+ defaults to localhost, which doesn’t work in Docker.\nShutting Down Stop all services:\ndocker compose down Remove data volumes (WARNING: deletes all traces):\ndocker compose down -v rm -rf tempo-data/ Best Practices Sampling Strategies Development environments:\n100% sampling (no sampling) Capture all traces for comprehensive debugging Production environments:\nTail-based sampling (recommended):\nAlways sample traces with status = error Always sample traces with duration \u003e P99 latency threshold Sample 10-20% of successful, fast traces Use OpenTelemetry Collector tail sampling processor Head-based sampling (simpler alternative):\nSample 10-30% of all traces Trade-off: May miss rare errors BattleBots-specific:\nAlways sample traces with critical game events: span.action.type = \"bot_death\" span.event.type = \"battle_end\" status = error Sample 20% of normal bot actions Sample 100% of battles with unusual duration (\u003e 5 minutes or \u003c 10 seconds) Storage Optimization Block configuration:\nmax_block_duration: 30-60 minutes (balance memory vs. block count) max_block_bytes: Default 100GB (prevents excessive block sizes) trace_idle_period: 10 seconds default (flush traces after idle period) Retention policies:\nblock_retention: 30 days recommended (industry sweet spot) compacted_block_retention: 0-1 hour (delete source blocks after compaction) Object storage lifecycle:\nSet S3/GCS lifecycle policies to delete objects 1-2 days post-retention Prevents orphaned data accumulation Storage cost formula:\nStorage Cost = (Ingested Spans/Day × Average Span Size × Retention Days) × Storage Rate Example:\n1M spans/day × 1KB/span × 30 days × $0.023/GB/month = $0.69/month Compare to Jaeger with Cassandra: ~$50-100/month for same volume.\nConfiguration Best Practices Distributor:\nEnable only needed receivers (disable unused protocols) Use OTLP as primary protocol (best performance) Configure rate limiting for multi-tenant deployments Ingester:\nDeploy with RF=3 (replication factor 3) for production Enable WAL (Write-Ahead Log) for crash recovery Set lifecycle hooks for graceful shutdown (flush before termination) Querier:\nScale based on query concurrency and complexity Enable query result caching Monitor querier CPU/memory usage Compactor:\nSchedule during low-traffic periods if possible Monitor compaction lag (blocks pending compaction) Only one compactor per tenant (avoid conflicts) Performance Tuning Ingestion throughput:\nUse OTLP protocol (recommended, most efficient) Enable gRPC compression (snappy) for bandwidth efficiency Increase concurrent_flushes for parallelized block writing Reduce trace_idle_period for faster memory clearing Query performance:\nUse trace ID lookups when possible (fastest) TraceQL queries: Filter by indexed attributes first Limit time range to reduce blocks scanned Use with(span_sample=0.1) for approximate queries on large datasets Resource allocation (microservices mode):\nDistributors: 1 replica per 10MB/s of received traffic (2 CPU, 2GB) Ingesters: 1 replica per 3-5MB/s of traffic (2.5 CPU, 8-12GB) Queriers: 1 replica per 1-2MB/s of traffic (2 CPU, 4-8GB) Monitoring Tempo Itself Critical metrics to monitor:\ntempo_distributor_spans_received_total: Ingestion volume tempo_distributor_spans_rejected_total: Rejected spans (rate limiting) tempo_ingester_blocks_flushed_total: Block flush operations tempo_ingester_memory_usage: Memory consumption tempo_query_frontend_bytes_inspected_total: Query load tempo_compactor_blocks_compacted_total: Compaction activity Set up alerts for:\nIngester OOM risk (memory trending toward limits) Distributor span rejection rate \u003e 1% Compactor failures or lag Query response time \u003e SLA threshold Use Tempo’s built-in dashboards:\nImport from Tempo GitHub repo Includes: Tempo Reads, Tempo Writes, Tempo Resources, Tempo Operational When to Use Tempo Ideal Use Cases for Tempo 1. Cost-Conscious Organizations\nNeed to store high volumes of traces affordably Want to avoid expensive Cassandra or Elasticsearch infrastructure Require long-term retention (30+ days) at reasonable cost 2. Cloud-Native Applications\nAlready using or planning to use Grafana ecosystem (Loki, Mimir, Prometheus) Need trace-metric-log correlation for unified observability Deployed on Kubernetes with object storage available 3. Trace-ID-First Workflows\nDebugging starts with trace IDs from logs or metrics Use exemplars to jump from metric spikes to traces Don’t require ad-hoc exploratory search across all traces 4. High-Volume Tracing\nWant to store 100% of traces (no sampling) Traffic volume makes traditional backends prohibitively expensive Need to scale from thousands to millions of traces/second 5. Multi-Tenant Platforms\nSaaS platforms requiring tenant isolation Per-tenant retention and limits Cost attribution per tenant When to Choose Tempo vs. Jaeger Factor Choose Tempo Choose Jaeger Cost High trace volume, limited budget Cost not a primary concern Search Trace ID lookups + TraceQL queries Need powerful tag-based ad-hoc search Operations Want minimal infrastructure Have Cassandra/Elasticsearch expertise Integration Using Grafana ecosystem Need standalone solution Maturity Comfortable with newer project Require CNCF graduated project Sampling Want to store 100% of traces Acceptable to sample aggressively Tempo Advantages:\n10x+ lower storage costs Minimal operational complexity (no database management) Native Grafana integration with trace-metric-log correlation TraceQL provides powerful query capabilities Multi-tenancy support Jaeger Advantages:\nMature, battle-tested (CNCF graduated since 2019) Powerful tag-based search without needing trace ID Better for exploratory debugging of unknown issues Larger community and ecosystem More UI features out-of-the-box Migration path: Tempo can ingest Jaeger-format traces, enabling gradual migration.\nWhen to Choose Tempo vs. Zipkin Factor Choose Tempo Choose Zipkin Architecture Modern, cloud-native Traditional, database-backed Cost Object storage (very low) Database storage (medium-high) Query TraceQL (powerful) Tag-based search (simpler) Scale Millions of traces/second Moderate scale Integration Grafana ecosystem Standalone, Zipkin UI Tempo Advantages:\nMuch lower cost at scale More powerful query language (TraceQL) Better integration with modern observability stacks Horizontal scalability Zipkin Advantages:\nLonger history (since 2012), very mature Simpler architecture for small deployments Native Zipkin UI Migration path: Tempo can ingest Zipkin-format traces natively.\nWhen NOT to Use Tempo 1. Exploratory Debugging is Primary Workflow\nIf you frequently need to search traces without knowing trace IDs If you need to find “all traces for customer_id=123 with errors” ad-hoc Consider: Jaeger’s full indexing better suits this workflow 2. Standalone Tracing Requirements\nIf you need tracing independent of logs/metrics If you’re not using or planning to use Grafana Consider: Jaeger or Zipkin provide standalone UIs 3. Very Low Trace Volume\nIf you’re ingesting \u003c 1,000 traces/day If cost is not a concern Consider: Jaeger may be simpler for small scale 4. Need Immediate Full-Text Search\nIf you require searching trace content (span names, attribute values) without trace ID If TraceQL’s capabilities are insufficient Consider: Jaeger or Elasticsearch-backed solutions 5. Require Managed Solution\nIf you don’t want to manage infrastructure If you need enterprise support and SLAs Consider: Grafana Cloud Tempo, Honeycomb, or Lightstep BattleBots Integration Battle Workflow Tracing Tempo enables comprehensive tracing of the entire battle lifecycle in BattleBots:\nMatchmaking → Battle Execution → Results Persistence:\nTrace: Complete Battle (trace_id: battle_abc123) ├─ Span: MatchmakingRequest (50ms) │ ├─ Span: FindAvailablePlayers (database query, 30ms) │ └─ Span: CreateBattleSession (20ms) ├─ Span: InitializeBattle (200ms) │ ├─ Span: LoadBot1 (container start, 100ms) │ ├─ Span: LoadBot2 (container start, 100ms) │ └─ Span: InitializeGameState (10ms) ├─ Span: ExecuteBattle (5000ms) │ ├─ Span: GameLoop-Tick-1 (10ms) │ │ ├─ Span: Bot1Action-Move (5ms) │ │ ├─ Span: Bot2Action-Attack (5ms) │ │ └─ Span: UpdateState (2ms) │ ├─ Span: GameLoop-Tick-2 (10ms) │ │ ... │ └─ Span: GameLoop-Tick-N (10ms) └─ Span: PersistResults (100ms) ├─ Span: SaveBattleResults (database, 50ms) └─ Span: UpdateLeaderboard (50ms) Span attributes for battles:\nspan.battle.id = \"battle_abc123\" span.battle.mode = \"1v1\" span.bot.1.id = \"bot_xyz\" span.bot.2.id = \"bot_def\" span.game.tick = 42 span.action.type = \"attack\" span.action.success = true span.result.winner = \"bot_xyz\" TraceQL Queries for BattleBots Find slow bot actions:\n{ resource.service.name = \"game-server\" \u0026\u0026 span.action.type = \"bot_move\" \u0026\u0026 duration \u003e 100ms } Find all battles where a bot died:\n{ span.event.type = \"bot_death\" } Find battles with database latency issues:\n{ span.db.statement != nil \u0026\u0026 duration \u003e 500ms } Find error traces in matchmaking:\n{ resource.service.name = \"matchmaking\" \u0026\u0026 status = error } Aggregate: Count battles by result:\n{ span.result.winner != nil } | by(span.result.winner) | count() Unified Observability Workflows Workflow 1: Metric Spike → Trace → Logs\nMetric alert: Battle action latency P99 \u003e 500ms Jump to exemplar trace: Click exemplar in Grafana metric graph Identify slow span: See PersistState (database) span is 450ms View correlated logs: Click span → view logs with same trace_id Root cause: Logs show “database connection pool exhausted” Workflow 2: Trace → Metrics\nIdentify slow trace: Find trace with 10-second battle duration View service metrics: Click “Related Metrics” in Grafana Correlate: See CPU usage spike at same timestamp Conclusion: Resource contention caused slow battle Workflow 3: Log → Trace\nError log: See log line “failed to process bot action” Extract trace_id: Log contains trace_id=abc123 Query trace: Search Tempo for abc123 Analyze: See exact span where failure occurred with full context Integration with Loki and Mimir Complete LGTM Stack for BattleBots:\n┌─────────────────────────────────────────────────────┐ │ BattleBots Observability Stack │ ├─────────────────────────────────────────────────────┤ │ │ │ Game Servers / Bot Runtimes / Matchmaking │ │ (Instrumented with OpenTelemetry) │ │ ↓ │ │ OpenTelemetry Collector │ │ (receives logs, metrics, traces via OTLP) │ │ ↓ │ │ ┌───────────┼───────────┐ │ │ ↓ ↓ ↓ │ │ Loki Mimir Tempo │ │ (Logs) (Metrics) (Traces) │ │ ↓ ↓ ↓ │ │ Grafana │ │ (Unified Visualization \u0026 Correlation) │ │ │ │ Features: │ │ - Exemplars: Metric → Trace │ │ - Trace ID: Log → Trace │ │ - Service Graphs: Trace → Metrics │ │ - Unified Dashboards: All signals in one view │ └─────────────────────────────────────────────────────┘ Configuration for correlation:\nApplication instrumentation (Go example):\nimport ( \"go.opentelemetry.io/otel\" \"go.opentelemetry.io/otel/trace\" \"github.com/sirupsen/logrus\" ) // Inject trace ID into logs func logWithTrace(ctx context.Context, msg string) { span := trace.SpanFromContext(ctx) logger.WithFields(logrus.Fields{ \"trace_id\": span.SpanContext().TraceID().String(), \"span_id\": span.SpanContext().SpanID().String(), }).Info(msg) } Grafana datasource configuration:\ndatasources: - name: Tempo type: tempo jsonData: tracesToLogs: datasourceUid: loki-uid tags: ['trace_id'] tracesToMetrics: datasourceUid: mimir-uid - name: Loki type: loki jsonData: derivedFields: - name: TraceID matcherRegex: \"trace_id=(\\\\w+)\" url: \"$${__value.raw}\" datasourceUid: tempo-uid - name: Mimir type: prometheus jsonData: exemplarTraceIdDestinations: - name: trace_id datasourceUid: tempo-uid Further Reading Official Documentation Grafana Tempo Official Documentation Tempo GitHub Repository TraceQL Query Language Reference Tempo Configuration Reference Tempo Architecture Deep Dive Deployment and Operations Deploy Tempo using Docker Compose Monolithic and Microservices Modes Size the Cluster Best Practices for Traces Monitor Tempo TraceQL and Querying TraceQL Query Language Construct a TraceQL Query TraceQL Metrics Integration Guides Configure Tempo Data Source in Grafana Trace Discovery using Exemplars and Loki Introduction to Exemplars LGTM Stack: Loki, Grafana, Tempo, Mimir Comparisons and Alternatives Grafana Tempo vs Jaeger Jaeger vs Tempo - Key Features and Differences Open-Source Tracing Tools: Jaeger vs Zipkin vs Tempo Community Resources Grafana Labs Blog - Tempo Grafana Community Forums - Tempo CNCF OpenTelemetry Project Related BattleBots Documentation OpenTelemetry Collector: Traces Support - Understanding distributed tracing concepts Grafana Loki Overview - Log aggregation for correlation Grafana Mimir Overview - Metrics storage for correlation Observability Stack Overview - How Tempo fits into the complete observability architecture ","categories":"","description":"Comprehensive overview of Grafana Tempo distributed tracing backend, covering architecture, deployment modes, and operational best practices.\n","excerpt":"Comprehensive overview of Grafana Tempo distributed tracing backend, …","ref":"/battlebots/pr-preview/pr-153/research_and_development/analysis/observability/traces/tempo/tempo-overview/","tags":"","title":"Tempo: Overview"}]