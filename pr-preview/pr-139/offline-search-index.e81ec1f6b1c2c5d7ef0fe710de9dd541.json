[{"body":" Context and Problem Statement As the project grows, architectural decisions are made that have long-term impacts on the system’s design, maintainability, and scalability. Without a structured way to document these decisions, we risk losing the context and rationale behind important choices, making it difficult for current and future team members to understand why certain approaches were taken.\nHow should we document architectural decisions in a way that is accessible, maintainable, and provides sufficient context for future reference?\nDecision Drivers Need for clear documentation of architectural decisions and their rationale Easy accessibility and searchability of past decisions Low barrier to entry for creating and maintaining decision records Integration with existing documentation workflow Version control friendly format Industry-standard approach that team members may already be familiar with Considered Options MADR (Markdown Architectural Decision Records) ADR using custom format Wiki-based documentation No formal ADR process Decision Outcome Chosen option: “MADR (Markdown Architectural Decision Records)”, because it provides a well-established, standardized format that is lightweight, version-controlled, and integrates seamlessly with our existing documentation structure. MADR 4.0.0 offers a clear template that captures all necessary information while remaining flexible enough for different types of decisions.\nConsequences Good, because MADR is a widely adopted standard with clear documentation and examples Good, because markdown files are easy to create, edit, and review through pull requests Good, because ADRs will be version-controlled alongside code, maintaining historical context Good, because the format is flexible enough to accommodate strategic, user-journey, and API design decisions Good, because team members can easily search and reference past decisions Neutral, because requires discipline to maintain and update ADR status as decisions evolve Bad, because team members need to learn and follow the MADR format conventions Confirmation Compliance will be confirmed through:\nCode reviews ensuring new architectural decisions are documented as ADRs ADRs are stored in docs/content/r\u0026d/adrs/ following the naming convention NNNN-title-with-dashes.md Regular reviews during architecture discussions to reference and update existing ADRs Pros and Cons of the Options MADR (Markdown Architectural Decision Records) MADR 4.0.0 is a standardized format for documenting architectural decisions using markdown.\nGood, because it’s a well-established standard with extensive documentation Good, because markdown is simple, portable, and version-control friendly Good, because it provides a clear structure while remaining flexible Good, because it integrates with static site generators and documentation tools Good, because it’s lightweight and doesn’t require special tools Neutral, because it requires some initial learning of the format Neutral, because maintaining consistency requires discipline ADR using custom format Create our own custom format for architectural decision records.\nGood, because we can tailor it exactly to our needs Bad, because it requires defining and maintaining our own standard Bad, because new team members won’t be familiar with the format Bad, because we lose the benefits of community knowledge and tooling Bad, because it may evolve inconsistently over time Wiki-based documentation Use a wiki system (like Confluence, Notion, or GitHub Wiki) to document decisions.\nGood, because wikis provide easy editing and hyperlinking Good, because some team members may be familiar with wiki tools Neutral, because it may or may not integrate with version control Bad, because content may not be version-controlled alongside code Bad, because it creates a separate system to maintain Bad, because it’s harder to review changes through standard PR process Bad, because portability and long-term accessibility may be concerns No formal ADR process Continue without a structured approach to documenting architectural decisions.\nGood, because it requires no additional overhead Bad, because context and rationale for decisions are lost over time Bad, because new team members struggle to understand why decisions were made Bad, because it leads to repeated discussions of previously settled questions Bad, because it makes it difficult to track when decisions should be revisited More Information MADR 4.0.0 specification: https://adr.github.io/madr/ ADRs will be categorized as: strategic, user-journey, or api-design ADR status values: proposed | accepted | rejected | deprecated | superseded by ADR-XXXX All ADRs are stored in docs/content/r\u0026d/adrs/ directory ","categories":"","description":"Adopt Markdown Architectural Decision Records (MADR) as the standard format for documenting architectural decisions in the project.\n","excerpt":"Adopt Markdown Architectural Decision Records (MADR) as the standard …","ref":"/battlebots/pr-preview/pr-139/rd/adrs/0001-use-madr-for-architecture-decision-records/","tags":"","title":"[0001] Use MADR for Architecture Decision Records"},{"body":"Overview The User Registration journey describes how new users create an account on the Battlebots platform. This is the first step in a user’s experience and sets the foundation for their identity, access control, and personalization throughout the platform. A smooth registration process is critical for user acquisition and reduces friction in getting started with battlebots.\nUser Personas Primary Persona: New Battlebot Developer\nDescription: A developer or team looking to deploy and compete with their battlebots in automated competitions Goals: Quickly create an account to start deploying battlebots Understand what access and capabilities they’ll have Feel confident their data and bots are secure Avoid creating yet another username/password combination Pain Points: Concern about granting OAuth permissions without understanding what data is accessed Unclear terms of service or data usage policies Friction if they need to create a GitHub account first (rare for developer audience) Journey Flow Diagram Use Mermaid syntax to create a flowchart representing the user journey:\ngraph TD A[User lands on platform] --\u003e B{Has account?} B --\u003e|Yes| C[Direct to login] B --\u003e|No| D[Click 'Sign in with GitHub'] D --\u003e E[Redirect to GitHub OAuth] E --\u003e F[User authorizes on GitHub] F --\u003e G{Authorization successful?} G --\u003e|No| H[Show error message] H --\u003e D G --\u003e|Yes| I[GitHub redirects with auth code] I --\u003e J[Exchange code for tokens] J --\u003e K[Fetch user profile from GitHub] K --\u003e L{User exists in system?} L --\u003e|Yes| M[Update user profile data] M --\u003e N[Generate JWT access token] L --\u003e|No| O[Show terms of service] O --\u003e P{User accepts terms?} P --\u003e|No| Q[Cancel registration] Q --\u003e A P --\u003e|Yes| R[Create user account] R --\u003e S[Store GitHub ID and profile] S --\u003e N N --\u003e T[Generate refresh token] T --\u003e U[Set httpOnly cookies] U --\u003e V[Redirect to onboarding/dashboard] Flow Narrative:\nEntry Point: User arrives at the platform homepage or a direct registration link Account Check: System determines if user already has an account; if yes, redirects to login flow GitHub OAuth Initiation: User clicks “Sign in with GitHub” button OAuth Redirect: System redirects user to GitHub’s OAuth authorization page with: Client ID for the Battlebots application Requested scopes (user:email, read:user) State parameter for CSRF protection Callback URL for return redirect GitHub Authorization: User reviews permissions and authorizes the Battlebots application on GitHub OAuth Callback: GitHub redirects back to Battlebots with: Authorization code (if successful) State parameter (for validation) Error code (if authorization failed or was cancelled) Token Exchange: System exchanges authorization code for access token via GitHub’s token endpoint Profile Fetch: System uses access token to fetch user’s GitHub profile including: GitHub ID (unique identifier) Username Email address (primary verified email) Name, avatar URL User Lookup: System checks if GitHub ID already exists in database New User Flow: If user doesn’t exist: Display terms of service acceptance screen Upon acceptance, create new user account with GitHub profile data Store GitHub ID as primary identifier Use GitHub username as default platform username (allow customization later) Existing User Flow: If user exists, update profile data with latest from GitHub JWT Token Generation: Generate internal JWT access token with user claims (15 min expiry, RS256 signing) Refresh Token Generation: Generate cryptographic refresh token (7 days expiry) and store hash in database Cookie Setup: Set httpOnly, secure, SameSite=strict cookies (access_token, refresh_token, csrf_token) Redirect: Redirect to onboarding (new users) or dashboard (returning users) Persona-Specific Variations:\nNew Battlebot Developer: After accepting terms, redirected to onboarding flow to learn about deploying their first bot Platform Administrator: Automatically granted admin privileges if GitHub username is in configured admin list; has access to admin dashboard showing new registrations Requirements Access Control REQ-AC-001 Priority: P0 Description: GitHub user IDs must be unique and serve as the primary account identifier Rationale: Ensures each user has a distinct identity tied to their GitHub account. GitHub ID is immutable and prevents account conflicts even if users change their GitHub username. REQ-AC-002 Priority: P0 Description: Platform usernames default to GitHub username but must be unique across the platform Rationale: Provides a familiar starting point using GitHub identity while allowing customization. Prevents impersonation and confusion in competitions and leaderboards. REQ-AC-003 Priority: P0 Description: GitHub OAuth integration with proper scope requests (user:email, read:user) Rationale: Enables secure authentication without managing passwords. Requests minimal necessary permissions to access user identity and primary verified email. REQ-AC-004 Priority: P0 Description: CSRF protection using state parameter in OAuth flow Rationale: Prevents cross-site request forgery attacks during the OAuth authorization process, ensuring the callback is legitimate. REQ-AC-005 Priority: P0 Description: Generate internal JWT access tokens (RS256, 15 min expiry) after GitHub OAuth authentication Rationale: Enables stateless API authentication without server-side session lookups. JWT claims include user identity for authorization decisions on every request. REQ-AC-005a Priority: P0 Description: Generate and rotate refresh tokens (7 days expiry) with database storage of token hash Rationale: Allows users to obtain new access tokens without re-authentication. Token rotation detects theft via reuse detection. REQ-AC-005b Priority: P0 Description: Store JWT tokens in httpOnly, secure, SameSite=strict cookies Rationale: Protects tokens from XSS attacks (httpOnly) and CSRF attacks (SameSite=strict). Secure flag ensures HTTPS-only transmission. REQ-AC-006 Priority: P1 Description: Rate limiting on OAuth callback endpoint (max 10 requests per IP per minute) Rationale: Prevents abuse of the OAuth flow and protects against denial of service attacks on the authentication system. REQ-AC-007 Priority: P1 Description: Terms of service acceptance required before account creation Rationale: Ensures users explicitly consent to platform policies before gaining access, meeting legal requirements. REQ-AC-008 Priority: P0 Description: CSRF token validation for state-changing API requests (POST, PUT, PATCH, DELETE) Rationale: Defense-in-depth CSRF protection. Requires X-CSRF-Token header matching CSRF cookie value for all state-changing operations. REQ-AC-009 Priority: P0 Description: JWT signature and claims validation on every authenticated API request Rationale: Ensures token authenticity (signature) and validity (exp, iss, aud claims). Prevents token tampering and expired token usage. Analytics REQ-AN-001 Priority: P0 Description: Track OAuth funnel metrics (GitHub button clicks, OAuth redirects, successful authorizations, account creations) Rationale: Provides visibility into conversion rates and identifies where users drop off in the OAuth flow, enabling optimization. REQ-AN-002 Priority: P0 Description: Track OAuth authorization failures and cancellations Rationale: Helps identify friction points in the GitHub authorization process and opportunities to improve messaging or user experience. REQ-AN-003 Priority: P1 Description: Track time-to-complete-registration (from initial button click to account creation) Rationale: Measures overall friction in the registration process and helps validate that OAuth provides a faster experience. REQ-AN-004 Priority: P1 Description: Track registration source (direct, referral, marketing campaign) Rationale: Helps understand which acquisition channels are most effective and informs marketing strategy. REQ-AN-005 Priority: P2 Description: Track terms of service acceptance vs. rejection rates Rationale: Identifies if terms of service are causing user drop-off and may need simplification or clarification. Success Metrics Success for the User Registration journey is measured by how efficiently and securely users can create accounts while maintaining platform integrity.\nQuantitative Metrics:\nOAuth Authorization Rate: Target 85%+ of users who initiate GitHub OAuth complete authorization Measures: Number of successful authorizations / Number of GitHub button clicks Registration Completion Rate: Target 90%+ of authorized users complete registration Measures: Number of completed registrations / Number of successful OAuth authorizations Time to Registration: Target median time \u003c 2 minutes Measures: Time between initial GitHub button click and account creation OAuth Error Rate: Target \u003c 5% of OAuth flows result in errors Measures: Number of OAuth errors / Number of OAuth attempts Terms Acceptance Rate: Target 95%+ of users accept terms of service Measures: Number of terms acceptances / Number of users shown terms Qualitative Metrics:\nUser Satisfaction: Target 4.5+ out of 5 rating on post-registration survey How it will be gathered: Optional survey after registration asking “How easy was the registration process?” GitHub OAuth Trust: Target 90%+ of users feel comfortable authorizing GitHub access How it will be gathered: Track authorization cancellation reasons via optional feedback prompt Related Documentation Existing ADRs:\nADR-0002: User Registration via GitHub OAuth - Defines GitHub OAuth as authentication method with stateless JWT tokens ADR-0003: Stateless Authentication via JWT Tokens - Defines JWT token strategy, refresh token rotation, and CSRF protection Required ADRs (Not Yet Created):\nData Privacy \u0026 Compliance - How user data from GitHub is stored, processed, and protected (GDPR, CCPA considerations) Rate Limiting Strategy - Approach for preventing OAuth abuse while not impacting legitimate users Username Customization Policy - Rules for when/how users can customize their username after initial GitHub-based registration Related User Journeys:\n(To be created) User Login via GitHub OAuth (To be created) User Session Management (To be created) User Onboarding (To be created) User Profile Management External Documentation:\nGitHub OAuth Documentation: https://docs.github.com/en/developers/apps/building-oauth-apps/authorizing-oauth-apps GitHub API - User endpoints: https://docs.github.com/en/rest/users/users Notes Future Enhancements:\nSocial proof during registration (e.g., “Join 10,000+ battlebot developers”) Support for additional OAuth providers (GitLab, Bitbucket) for users without GitHub accounts Ability to link multiple OAuth providers to a single account Username suggestions when preferred GitHub username is already taken Rich profile data import from GitHub (bio, location, organization) GitHub organization membership detection for team/enterprise features Progressive disclosure - collect minimal info upfront, gather more during onboarding Technical Considerations:\nOAuth state parameter must be cryptographically random and validated on callback Use PKCE (Proof Key for Code Exchange) for OAuth flow to prevent authorization code interception GitHub access tokens should be encrypted at rest using strong encryption (AES-256) for future GitHub API calls Generate internal JWT access tokens (RS256, 15 min expiry) with user claims after OAuth callback Generate refresh tokens (random 32-byte, 7 days expiry) and store SHA256 hash in database Set httpOnly, secure, SameSite=strict cookies for access_token, refresh_token, csrf_token Implement proper error handling for GitHub API rate limits Store registration attempt metadata for abuse detection Consider implementing a waiting room or queue during high-traffic periods Handle edge cases: user revokes GitHub app access, user deletes GitHub account, user changes GitHub email Implement proper logging for OAuth flow debugging without exposing sensitive tokens Implement JWT validation middleware to verify signature and claims on every API request Implement refresh token rotation - issue new refresh token on every refresh, revoke old token Optional: Redis token blacklist for immediate JWT revocation (logout, security breach) Business Considerations:\nClear terms of service and privacy policy explaining what GitHub data is accessed and stored Transparency about GitHub permission scopes and why they’re needed Consider offering different account tiers (free vs paid) at registration Opportunity to capture user intent/interests during onboarding for personalization Legal requirements vary by jurisdiction - may need age verification or parental consent flows GitHub-only authentication may limit accessibility for users without GitHub accounts Battlebots platform targets developers, making GitHub auth a natural fit for the primary persona ","categories":"","description":"Defines the flow for new users to create an account and gain access to the Battlebots platform\n","excerpt":"Defines the flow for new users to create an account and gain access to …","ref":"/battlebots/pr-preview/pr-139/rd/user-journeys/0001-user-registration/","tags":"","title":"[0001] User Registration"},{"body":"Executive Summary This document analyzes Auth0’s login page solutions to determine whether using Auth0 as an authentication provider would be beneficial for the Battle Bots platform instead of implementing custom login pages. Given that Battle Bots plans to use GitHub OAuth for user registration and authentication, this analysis evaluates how Auth0 could serve as an intermediary authentication layer.\nKey Finding: While Auth0 provides robust, secure login solutions with excellent GitHub OAuth integration, it introduces significant complexity and cost for a platform primarily using a single social identity provider (GitHub). For Battle Bots’ specific use case, direct GitHub OAuth implementation may be more appropriate unless multi-provider authentication or advanced identity management features are anticipated.\nOverview of Auth0 Login Page Options Auth0 provides two primary approaches to authentication: hosted login pages and embedded login flows.\nUniversal Login (Recommended by Auth0) What it is: Universal Login is Auth0’s primary hosted authentication solution where users are redirected to Auth0’s centralized authorization server for authentication, then returned to the application with tokens.\nKey Characteristics:\nHosted on Auth0’s infrastructure (auth0.com domain or custom domain) Redirect-based authentication flow Centralized security management Two variants: Universal Login (modern, actively developed) and Classic Login (legacy, JavaScript-dependent) How it works:\nUser attempts to access Battle Bots application Application redirects to Auth0’s Universal Login page Auth0 handles authentication (password, social providers like GitHub, MFA) Auth0 returns user to application with authentication tokens No embedded authentication code required in application Embedded Login (Not Recommended by Auth0) What it is: Embedded Login allows users to authenticate directly within your application by transmitting credentials to the Auth0 server without leaving your application’s domain.\nKey Characteristics:\nAuthentication UI hosted within your application Requires Cross-Origin Resource Sharing (CORS) configuration Requires Lock SDK, Auth0.js SDK, or direct Authentication API calls Auth0 explicitly states: “We do not recommend using Embedded Login” Comparison of Approaches Security Aspect Universal Login Embedded Login Cross-Origin Security Eliminates cross-origin requests; authentication occurs on same domain (Auth0’s) Requires sending credentials cross-origin, increasing vulnerability to phishing and MITM attacks CSRF Protection Seamless CSRF protection built-in Must implement CSRF protection manually Attack Protection Auth0’s attack protection filters bot traffic and malicious attempts before authentication Cannot implement attack protection; lives inside your application Security Updates Auth0 monitors trends and updates automatically Application responsible for implementing security best practices Credential Exposure Credentials never touch application server Application has access to credentials, vulnerable to recording or malicious use Security Verdict: Universal Login is significantly more secure. Embedded login creates attack vectors through cross-origin authentication and exposes the application to credential handling responsibilities.\nSingle Sign-On (SSO) Capabilities Feature Universal Login Embedded Login SSO Support Full support through session cookies on Auth0 server Limited support; web apps can share sessions, native apps support Native-to-Web SSO Implementation Automatic across all applications using Auth0 tenant Must be configured per application SSO Verdict: Universal Login provides superior SSO capabilities, which could be valuable if Battle Bots expands to multiple applications or services.\nImplementation Complexity Aspect Universal Login Embedded Login Integration Effort Minimal - register app, configure redirect URIs, enable GitHub connection Higher - implement CORS, integrate SDKs, handle authentication flows User Experience Redirect to external page (may feel less integrated) Users stay in application (feels more integrated) Native Apps Requires universal/deep links implementation Simpler for native app UX Maintenance Auth0 handles updates automatically Must update each application individually Implementation Verdict: Universal Login is simpler to implement and maintain. Embedded login requires significantly more development effort for marginal UX improvement.\nFeature Management \u0026 Maintenance Aspect Universal Login Embedded Login Feature Updates Centrally managed in Auth0 Dashboard or Management API Must update each application individually Authentication Methods Add social login, MFA, passwordless without code changes Requires code updates to add new authentication methods Automatic Improvements Applications automatically benefit from Auth0 improvements Must manually integrate new features Maintenance Verdict: Universal Login dramatically reduces ongoing maintenance burden.\nCustomization Capabilities Customization Level Universal Login Embedded Login Basic Branding No-code editor for colors, fonts, logos, backgrounds Full control over all UI/UX elements Advanced Customization Template modification with HTML/CSS/JavaScript Complete freedom to design authentication flow Text Customization All text elements customizable through Dashboard Unlimited text customization Custom Domain Supported for seamless branding Supported (recommended to avoid cross-origin issues) Customization Options:\nStandard Mode (No-Code): Visual editor for colors, fonts, borders, backgrounds, logo, favicon Advanced Mode: Full HTML template customization for granular control API-Driven: Management API with Branding endpoints for programmatic customization Customization Verdict: While Embedded Login offers maximum control, Universal Login’s Advanced Mode provides sufficient customization for most branding needs while maintaining security benefits.\nGitHub OAuth Integration with Auth0 Setup Process Auth0 provides native GitHub social connection support:\nAuth0 Dashboard Configuration:\nNavigate to Authentication \u003e Social Create GitHub connection Enter GitHub OAuth app Client ID and Client Secret GitHub OAuth App Configuration:\nCreate OAuth app in GitHub Set callback URL to Auth0’s callback endpoint Copy credentials to Auth0 Application Enablement:\nEnable GitHub connection for specific Auth0 applications Test through Auth0’s “Try it out” feature User Experience Flow With GitHub social connection through Universal Login:\nUser visits Battle Bots application User clicks “Sign In” Redirected to Auth0 Universal Login page User clicks “Continue with GitHub” button Redirected to GitHub authorization page (if not already authenticated) User authorizes Battle Bots access to GitHub profile Redirected back to Auth0 Auth0 creates user session and returns tokens User redirected back to Battle Bots application authenticated Authentication Data Available Through GitHub social connection, Auth0 provides:\nGitHub user ID GitHub username Email address Profile information GitHub access token (for API calls) Auth0 stores this in a normalized user profile structure accessible through Auth0 Management API.\nPros and Cons for Battle Bots Platform Pros of Using Auth0 Enterprise-Grade Security\nAutomatic security updates and patch management Built-in attack protection (bot detection, brute-force prevention) CSRF protection without custom implementation SOC 2 Type II, GDPR, HIPAA compliance capabilities Reduced Development Effort\nNo custom authentication UI development required No security infrastructure to build and maintain Pre-built GitHub OAuth integration Automatic token management and refresh Scalability and Flexibility\nEasy to add additional social providers (Google, Discord, etc.) without code changes Built-in MFA support if needed in the future User management dashboard included Passwordless authentication options available User Management Features\nUser profile management and normalization User search and filtering User metadata storage Audit logs and analytics SSO Capabilities\nIf Battle Bots expands to multiple services, SSO works automatically Session management handled by Auth0 Accessibility Compliance\nWCAG 2.2 AA and EN 301 549 standards Automatic compliance updates (full WCAG migration by July 31, 2025) Testing and Development\nBuilt-in test environment Separate dev/staging/prod tenants Mock authentication for testing Cons of Using Auth0 Cost Implications\nAuth0 pricing based on monthly active users (MAUs) Free tier: 7,500 MAUs, limited to 2 social connections Essential tier: Starts at $35/month + usage Costs increase significantly with user growth Additional charges for enterprise features (custom domains, advanced MFA) Vendor Lock-In\nMigration away from Auth0 requires significant refactoring User data export and migration complexity Dependency on Auth0’s service availability and pricing Unnecessary Complexity for Single Provider\nIf Battle Bots only uses GitHub OAuth, Auth0 is an intermediary layer Could authenticate directly with GitHub OAuth without Auth0 Extra redirect hop in authentication flow Limited Control\nSubject to Auth0’s service level agreements Feature deprecations (like Classic Login) may force changes Customization constraints even in Advanced Mode User Experience Considerations\nAdditional redirect to Auth0’s domain (unless using custom domain) Custom domain requires additional configuration and cost Users may see Auth0 branding unless customized Integration Complexity\nRequires understanding OAuth 2.0 and OpenID Connect flows Token management across application Session synchronization between Auth0 and application Overkill for MVP\nBattle Bots may not need enterprise-grade identity management initially Many Auth0 features (MFA, passwordless, multiple providers) may be unused Security Considerations For Auth0 Universal Login Security Strengths:\nIndustry-standard OAuth 2.0 and OpenID Connect implementation Automatic security patching and vulnerability remediation Attack protection (anomaly detection, brute-force protection, breached password detection) Token-based authentication with automatic rotation Secure session management Compliance certifications (SOC 2, ISO 27001, GDPR) Security Concerns:\nThird-party dependency for critical authentication function Trust in Auth0’s security practices and infrastructure Potential data breach impacts if Auth0 is compromised API keys and secrets management for Auth0 configuration For Direct GitHub OAuth Security Strengths:\nDirect relationship with GitHub (no intermediary) Fewer moving parts and potential failure points GitHub’s own security infrastructure for authentication Security Concerns:\nApplication must implement: OAuth 2.0 flow correctly CSRF protection Token storage and management Session management Attack protection (rate limiting, bot detection) Responsibility for security updates and patches No built-in MFA unless separately implemented Security Verdict: Auth0 provides significantly better security posture out-of-the-box, but requires proper configuration and monitoring. Direct GitHub OAuth is simpler but places security burden on Battle Bots development team.\nIntegration Complexity Analysis Auth0 Integration Requirements Backend Integration:\nConfigure Auth0 tenant and application Set up GitHub social connection Implement OAuth 2.0 callback handling Validate and verify JWT tokens Extract user information from tokens Store user session Frontend Integration:\nRedirect to Auth0 login URL with appropriate parameters Handle callback and token exchange Store and manage access/refresh tokens Implement logout flow Handle token expiration and refresh Estimated Implementation Time: 2-4 days for basic integration, 1-2 weeks for production-ready implementation with proper error handling and testing.\nDirect GitHub OAuth Integration Requirements Backend Integration:\nRegister GitHub OAuth application Implement OAuth 2.0 authorization flow Handle callback and token exchange Verify state parameter for CSRF protection Call GitHub API to retrieve user information Create user session Implement token refresh logic Implement logout Frontend Integration:\nCreate login UI Redirect to GitHub authorization URL Handle callback Manage session state Implement logout UI Estimated Implementation Time: 3-5 days for basic integration, 2-3 weeks for production-ready implementation with security hardening, attack protection, and comprehensive testing.\nIntegration Complexity Verdict: Auth0 is slightly faster for initial implementation and significantly faster for production-ready security features. However, both approaches are reasonable for a development team with OAuth experience.\nCost Analysis Auth0 Pricing (as of 2025) Free Tier:\n7,500 MAUs 2 social connections (sufficient for GitHub + one backup) Community support only Limited to development/testing use cases Essentials (Professional) Tier:\nStarting at $35/month base + $0.0175 per MAU 10,000 MAUs: $35 + $175 = $210/month 25,000 MAUs: $35 + $437.50 = $472.50/month Unlimited social connections Email support Professional Tier:\nStarting at $240/month base + usage Advanced features (custom domains, MFA, etc.) 24/7 support Example Cost Scenarios for Battle Bots:\n1,000 active users: Free tier or ~$52/month (Essentials) 10,000 active users: ~$210/month 50,000 active users: ~$910/month 100,000 active users: ~$1,785/month Direct GitHub OAuth Costs Infrastructure Costs:\n$0 for GitHub OAuth (free) Server costs for authentication service (minimal incremental cost) Development Costs:\nInitial implementation: Higher development time Ongoing maintenance: Security updates, attack protection implementation Feature additions: Must build each feature (MFA, additional providers) Cost Verdict: For early-stage Battle Bots (\u003c 10,000 users), direct implementation may be more cost-effective. As platform grows and needs enterprise features, Auth0’s value proposition improves.\nRecommendations for Battle Bots Project Recommendation 1: Start with Direct GitHub OAuth Rationale:\nBattle Bots is using GitHub OAuth as the sole authentication method Adding Auth0 as an intermediary adds complexity without immediate value Team maintains full control and understanding of authentication flow No recurring costs or vendor dependency Simpler architecture for MVP phase When to Implement:\nImmediately for MVP and initial launch Maintain through early growth phase (\u003c 5,000 users) Implementation Approach:\nImplement OAuth 2.0 flow with GitHub directly Use established Go OAuth libraries (e.g., golang.org/x/oauth2) Implement secure session management Add rate limiting and basic attack protection Monitor for security updates Recommendation 2: Plan for Auth0 Migration Path Rationale:\nKeep Auth0 as strategic option for future growth Design authentication abstraction layer to enable migration Evaluate Auth0 when reaching thresholds: Need for multiple social providers Need for enterprise SSO Need for advanced MFA User base exceeds 10,000 active users Security compliance requirements emerge When to Evaluate Migration:\nBefore adding second social provider When security/compliance requirements increase When team lacks capacity for security maintenance When advanced identity features are needed Migration Approach:\nDesign authentication interface abstraction Implement GitHub OAuth behind abstraction When needed, implement Auth0 adapter for same interface Migrate users gradually using Auth0’s user import capabilities Recommendation 3: Consider Auth0 for Enterprise Features Use Auth0 if Battle Bots needs:\nMultiple social providers (GitHub, Google, Discord, Steam, etc.) Enterprise SSO (SAML, LDAP for team/organization accounts) Advanced MFA (SMS, authenticator apps, hardware keys) Compliance requirements (SOC 2, HIPAA, GDPR with DPA) User management dashboard and analytics Passwordless authentication Account linking (multiple providers per user) Use Direct Implementation if:\nGitHub OAuth is sufficient long-term Team has OAuth/security expertise Cost optimization is priority Maximum control over authentication flow is required Minimal external dependencies preferred Alternative Considerations Alternative 1: Ory Kratos (Open Source) Pros:\nSelf-hosted, no per-user costs Open source, no vendor lock-in GitHub OAuth support Modern identity architecture Cons:\nHigher operational complexity (self-hosting) Team must manage infrastructure Less mature ecosystem than Auth0 Alternative 2: Supabase Auth Pros:\nOpen source with hosted option GitHub OAuth built-in Integrated with database and storage Lower cost than Auth0 Cons:\nRelatively newer platform Vendor lock-in if using hosted version May require adopting Supabase ecosystem Alternative 3: Firebase Authentication Pros:\nGoogle infrastructure reliability GitHub OAuth support Free tier generous (10,000 MAUs) Lower cost than Auth0 Cons:\nGoogle vendor lock-in Less flexible than Auth0 Feature set less comprehensive Implementation Roadmap Phase 1: MVP (Direct GitHub OAuth) Timeline: Sprint 1-2\nImplement GitHub OAuth 2.0 flow Create basic login/logout UI Implement secure session management Add CSRF protection Implement rate limiting Deploy to production Phase 2: Hardening Timeline: Sprint 3-4\nAdd comprehensive attack protection Implement monitoring and alerting Security audit and penetration testing Optimize user experience Add session timeout and refresh Phase 3: Growth Evaluation Timeline: When reaching 5,000+ active users\nEvaluate authentication metrics and pain points Assess need for additional providers Compare operational costs vs. Auth0 costs Make build vs. buy decision for advanced features Phase 4: Potential Migration (If Needed) Timeline: TBD based on Phase 3 evaluation\nDesign authentication abstraction layer (if not already done) Set up Auth0 tenant and configure GitHub connection Implement Auth0 integration behind abstraction Migrate subset of users for testing Gradual rollout to all users Decommission direct OAuth implementation Conclusion While Auth0 provides an excellent, secure, feature-rich authentication solution with straightforward GitHub OAuth integration, it introduces unnecessary complexity and cost for Battle Bots’ current requirements. For MVP and initial growth phases, implementing GitHub OAuth directly is recommended. This approach:\nReduces architectural complexity Eliminates recurring costs Maintains full control over authentication Provides sufficient security with proper implementation Avoids vendor lock-in during critical early stages Auth0 should be reconsidered when Battle Bots requires multiple authentication providers, enterprise features, advanced compliance, or when operational costs of maintaining authentication infrastructure exceed Auth0’s subscription costs.\nThe key to success is designing an authentication abstraction layer from the start, enabling seamless migration to Auth0 (or alternative) when business requirements justify the additional complexity and cost.\nReferences Auth0 Universal Login Documentation Auth0 Customize Login Pages Auth0 Universal Login vs. Embedded Login Auth0 Embedded Login Documentation Auth0 GitHub Social Connection Setup Auth0 Universal Login Customization ","categories":"","description":"Comprehensive analysis of Auth0 login page options and their applicability to the Battle Bots platform's GitHub OAuth authentication strategy.\n","excerpt":"Comprehensive analysis of Auth0 login page options and their …","ref":"/battlebots/pr-preview/pr-139/rd/analysis/security/auth0-login-pages-analysis/","tags":"","title":"Auth0 Login Pages Analysis"},{"body":"Executive Summary This document analyzes OpenFGA (Open Fine-Grained Authorization), a high-performance authorization system inspired by Google Zanzibar, to determine its suitability for implementing fine-grained access control in the Battle Bots platform. OpenFGA provides Relationship-Based Access Control (ReBAC) that answers authorization questions like “Does user U have relation R with object O?” rather than traditional role-based approaches.\nKey Finding: OpenFGA is a mature, production-ready authorization system that separates authentication from authorization, allowing it to work seamlessly with JWT-based authentication systems. It offers flexible deployment options (Docker, Kubernetes, binary), uses an intuitive DSL for policy definition, and supports dynamic authorization decisions through contextual tuples. For Battle Bots’ planned GitHub OAuth authentication strategy, OpenFGA provides a robust path to implementing fine-grained permissions for bot management, organization access, and game resources.\nOverview of OpenFGA What is OpenFGA? OpenFGA is a high-performance, flexible authorization/permission engine built for developers and inspired by Google’s Zanzibar paper. It implements Relationship-Based Access Control (ReBAC), which models permissions as relationships between users and resources.\nCore Characteristics:\nOpen source (Apache 2.0 license) Inspired by Google Zanzibar (used by Google Drive, Calendar, Photos, etc.) Focuses exclusively on authorization (not authentication) Designed for fine-grained permissions at scale Supports both direct relationships and computed permissions Provides APIs for authorization checks, relationship management, and model queries Key Concepts Authorization Model: Defines the types of objects in your system and how they relate to each other (e.g., users can be viewers, editors, or owners of documents).\nRelationship Tuples: Store the actual relationships between users and objects (e.g., “anne is owner of document:1”).\nCheck API: Evaluates whether a user has a specific relation/permission on an object based on the model and stored tuples.\nContextual Tuples: Temporary relationships provided at query time that exist only for that specific authorization check.\nReBAC vs. RBAC Aspect Traditional RBAC OpenFGA ReBAC Permission Model Users assigned to roles; roles have permissions Users have relationships with specific objects Granularity Coarse-grained (role-level) Fine-grained (object-level) Hierarchy Simple role hierarchies Complex relationship graphs with inheritance Question Answered “Does user have role X?” “Does user have relation R with object O?” Examples “Is user an admin?” “Can user edit document:123?” Scalability Limited for complex scenarios Designed for millions of relationships JWT Verification and Integration Separation of Authentication and Authorization OpenFGA focuses exclusively on authorization, making it designed to work alongside authentication systems like JWT verification rather than replacing them. The typical integration pattern separates concerns:\nAuthentication (AuthN): Verifies user identity through JWT token validation Authorization (AuthZ): Determines what the authenticated user can do via OpenFGA\nIntegration Pattern The standard integration flow for JWT + OpenFGA:\n1. Request arrives with JWT Bearer token ↓ 2. Middleware validates JWT signature ↓ 3. Middleware extracts user identity from JWT claims ↓ 4. Application calls OpenFGA Check API - User: extracted from JWT (e.g., \"user:anne\") - Relation: mapped from operation (e.g., \"can_edit\") - Object: target resource (e.g., \"document:123\") ↓ 5. OpenFGA evaluates authorization ↓ 6. Application allows or denies request Framework-Specific Implementations Node.js / Fastify Example // Step 1: JWT Authentication app.decorate(\"authenticate\", async function(request, reply) { try { await request.jwtVerify(); // Validates JWT signature } catch (err) { reply.send(err); } }); // Step 2: Authorization Preparation app.decorate(\"preauthorize\", async function(request, reply) { const method = request.method; const documentName = request.params.documentName; // Map HTTP method to OpenFGA relation const relation = method === 'GET' ? 'reader' : method === 'POST' ? 'writer' : method === 'DELETE' ? 'owner' : null; // Extract user from JWT claims const user = `user:${request.user.username}`; // Format resource const object = `document:${documentName}`; request.authParams = { user, relation, object }; }); // Step 3: OpenFGA Check app.addHook('preHandler', async (request, reply) =\u003e { const { user, relation, object } = request.authParams; const { allowed } = await fgaClient.check({ user, relation, object }); if (!allowed) { reply.code(403).send({ error: 'Forbidden' }); } }); Go / Fiber Example // JWT Middleware (Authentication) app.Use(jwtware.New(jwtware.Config{ SigningKey: []byte(os.Getenv(\"JWT_SECRET\")), })) // Authorization Middleware app.Use(func(c *fiber.Ctx) error { user := c.Locals(\"user\").(*jwt.Token) claims := user.Claims.(jwt.MapClaims) username := claims[\"username\"].(string) // Map method to relation method := c.Method() relation := methodToRelation(method) // OpenFGA Check body, err := fgaClient.Check(context.Background()). Body(ClientCheckRequest{ User: fmt.Sprintf(\"user:%s\", username), Relation: relation, Object: fmt.Sprintf(\"document:%s\", c.Params(\"name\")), }). Execute() if err != nil || !body.GetAllowed() { return c.Status(403).JSON(fiber.Map{ \"error\": \"Forbidden\", }) } return c.Next() }) JWT Claims as Contextual Data OpenFGA supports using JWT claims as contextual tuples for dynamic authorization. This pattern is useful for:\nMulti-Tenancy: JWT contains current organization context\n// JWT payload { \"sub\": \"user:anne\", \"current_org\": \"org:acme\" } // OpenFGA Check with contextual tuple await fgaClient.check({ user: \"user:anne\", relation: \"can_manage_bots\", object: \"bot:battle-bot-1\", contextualTuples: [ { user: \"user:anne\", relation: \"member\", object: \"org:acme\" // From JWT claim } ] }); Time-Based Access: JWT contains role assignments with temporal context IP-Based Restrictions: JWT contains location/IP information for access decisions\nOIDC Support OpenFGA supports OIDC authentication for its own API access (not to be confused with application-level authentication):\nClient credentials flow with client ID and secret JWT tokens with kid header for key identification Integration with identity providers (Auth0, Keycloak, etc.) Audience and issuer validation This enables secure API access for administrative operations and service-to-service communication.\nBest Practices for JWT + OpenFGA Integration Always verify JWT first: Never call OpenFGA without valid authentication Extract user identity from JWT claims: Use standardized claims (sub, username, etc.) Map operations to relations: Create consistent mapping from HTTP methods/actions to OpenFGA relations Use contextual tuples sparingly: Prefer storing relationships in OpenFGA when they’re stable Cache authorization decisions: Implement caching layer for frequently checked permissions Handle errors gracefully: Distinguish between authentication failures and authorization denials Deployment Options OpenFGA provides multiple deployment options suitable for different environments and requirements.\nDocker Deployment Quick Start (Memory Storage) The simplest deployment uses in-memory storage for development:\n# Pull the latest image docker pull openfga/openfga # Run with memory storage (development only) docker run -p 8080:8080 -p 8081:8081 -p 3000:3000 openfga/openfga run Exposed Ports:\n8080: HTTP API 8081: gRPC API 3000: Playground UI (web-based testing interface) Warning: Memory storage loses all data on restart. Not suitable for production.\nProduction with PostgreSQL # Create Docker network docker network create openfga # Run PostgreSQL docker run -d \\ --name postgres \\ --network openfga \\ -e POSTGRES_USER=postgres \\ -e POSTGRES_PASSWORD=password \\ -e POSTGRES_DB=openfga \\ postgres:17 # Run migrations (first time or after upgrades) docker run --rm \\ --network openfga \\ openfga/openfga migrate \\ --datastore-engine postgres \\ --datastore-uri 'postgres://postgres:password@postgres:5432/openfga' # Run OpenFGA server docker run -d \\ --name openfga \\ --network openfga \\ -p 8080:8080 \\ -p 8081:8081 \\ -p 3000:3000 \\ -e OPENFGA_DATASTORE_ENGINE=postgres \\ -e OPENFGA_DATASTORE_URI='postgres://postgres:password@postgres:5432/openfga' \\ openfga/openfga run Production with MySQL # Run MySQL docker run -d \\ --name mysql \\ --network openfga \\ -e MYSQL_ROOT_PASSWORD=secret \\ -e MYSQL_DATABASE=openfga \\ mysql:8 # Run migrations docker run --rm \\ --network openfga \\ openfga/openfga migrate \\ --datastore-engine mysql \\ --datastore-uri 'root:secret@tcp(mysql:3306)/openfga?parseTime=true' # Run OpenFGA server docker run -d \\ --name openfga \\ --network openfga \\ -p 8080:8080 \\ -e OPENFGA_DATASTORE_ENGINE=mysql \\ -e OPENFGA_DATASTORE_URI='root:secret@tcp(mysql:3306)/openfga?parseTime=true' \\ openfga/openfga run Production with SQLite # Create volume for persistence docker volume create openfga-data # Run OpenFGA with SQLite docker run -d \\ --name openfga \\ -p 8080:8080 \\ -v openfga-data:/home/nonroot \\ -e OPENFGA_DATASTORE_ENGINE=sqlite \\ -e OPENFGA_DATASTORE_URI='/home/nonroot/openfga.db' \\ openfga/openfga run Docker Compose Example version: '3.8' services: postgres: image: postgres:17 environment: POSTGRES_USER: postgres POSTGRES_PASSWORD: password POSTGRES_DB: openfga volumes: - postgres_data:/var/lib/postgresql/data networks: - openfga openfga-migrate: image: openfga/openfga:latest command: migrate environment: OPENFGA_DATASTORE_ENGINE: postgres OPENFGA_DATASTORE_URI: 'postgres://postgres:password@postgres:5432/openfga' depends_on: - postgres networks: - openfga openfga: image: openfga/openfga:latest command: run environment: OPENFGA_DATASTORE_ENGINE: postgres OPENFGA_DATASTORE_URI: 'postgres://postgres:password@postgres:5432/openfga' ports: - \"8080:8080\" # HTTP API - \"8081:8081\" # gRPC API - \"3000:3000\" # Playground depends_on: openfga-migrate: condition: service_completed_successfully networks: - openfga volumes: postgres_data: networks: openfga: Kubernetes Deployment Helm Chart (Recommended) Official Helm chart available at ArtifactHub:\n# Add Helm repository helm repo add openfga https://openfga.github.io/helm-charts helm repo update # Install with default settings (memory storage) helm install openfga openfga/openfga # Install with PostgreSQL helm install openfga openfga/openfga \\ --set datastore.engine=postgres \\ --set datastore.uri=\"postgres://user:pass@postgres:5432/openfga\" Helm Chart Features:\nHigh Availability: Defaults to 3 replicas for production (1 for memory storage) Horizontal Scaling: Support for multiple replicas with persistent datastores Service Types: ClusterIP, NodePort, LoadBalancer options Health Probes: Built-in liveness and readiness probes Monitoring: Integration with Prometheus and Grafana Ingress: Optional ingress configuration for external access Kubernetes Operators Multiple operator options available for managing OpenFGA deployments:\n1. ZEISS OpenFGA Operator\nRepository: github.com/ZEISS/openfga-operator Installation via Helm Manages OpenFGA lifecycle and configuration Custom Resource Definitions (CRDs) for OpenFGA instances 2. Canonical OpenFGA Operator\nRepository: github.com/canonical/openfga-operator Juju Charm for Kubernetes Integration with Canonical Observability Stack (COS) Built-in Grafana dashboards Prometheus and Loki alert rules Available on Charmhub Sample Kubernetes Deployment apiVersion: apps/v1 kind: Deployment metadata: name: openfga spec: replicas: 3 selector: matchLabels: app: openfga template: metadata: labels: app: openfga spec: containers: - name: openfga image: openfga/openfga:latest args: [\"run\"] env: - name: OPENFGA_DATASTORE_ENGINE value: \"postgres\" - name: OPENFGA_DATASTORE_URI valueFrom: secretKeyRef: name: openfga-db-secret key: database-uri ports: - containerPort: 8080 name: http - containerPort: 8081 name: grpc livenessProbe: httpGet: path: /healthz port: 8080 initialDelaySeconds: 30 periodSeconds: 10 readinessProbe: httpGet: path: /healthz port: 8080 initialDelaySeconds: 5 periodSeconds: 5 --- apiVersion: v1 kind: Service metadata: name: openfga spec: selector: app: openfga ports: - name: http port: 8080 targetPort: 8080 - name: grpc port: 8081 targetPort: 8081 type: ClusterIP Binary Deployment OpenFGA can run as a standalone binary:\n# Download binary from GitHub releases # https://github.com/openfga/openfga/releases # Run with environment variables export OPENFGA_DATASTORE_ENGINE=postgres export OPENFGA_DATASTORE_URI='postgres://user:pass@localhost:5432/openfga' ./openfga run # Or with command-line flags ./openfga run \\ --datastore-engine postgres \\ --datastore-uri 'postgres://user:pass@localhost:5432/openfga' # Run migrations before first use or after upgrades ./openfga migrate \\ --datastore-engine postgres \\ --datastore-uri 'postgres://user:pass@localhost:5432/openfga' Storage Backend Options Storage Backend Use Case Production Ready Data Persistence Version Support Memory Development, testing No Lost on restart All versions PostgreSQL Production Yes Full persistence PostgreSQL 14+ MySQL Production Yes Full persistence MySQL 8+ SQLite Small deployments, embedded Beta File-based persistence SQLite 3+ Production Recommendation: Use PostgreSQL or MySQL with regular backups. Memory storage is only suitable for development and testing.\nConfiguration Options OpenFGA supports configuration via:\nEnvironment Variables: Prefixed with OPENFGA_ (e.g., OPENFGA_DATASTORE_ENGINE) Command-Line Flags: Prefixed with -- (e.g., --datastore-engine) Configuration File: YAML-based configuration for complex setups Key Configuration Parameters:\ndatastore.engine: Storage backend (memory, postgres, mysql, sqlite) datastore.uri: Database connection string http.addr: HTTP API listen address (default: 0.0.0.0:8080) grpc.addr: gRPC API listen address (default: 0.0.0.0:8081) playground.enabled: Enable web playground (default: true) playground.port: Playground port (default: 3000) authn.method: Authentication method (none, preshared, oidc) log.level: Logging level (debug, info, warn, error) Security Configuration Pre-Shared Keys docker run -d \\ -e OPENFGA_AUTHN_METHOD=preshared \\ -e OPENFGA_AUTHN_PRESHARED_KEYS=key1,key2 \\ openfga/openfga run OIDC Authentication docker run -d \\ -e OPENFGA_AUTHN_METHOD=oidc \\ -e OPENFGA_AUTHN_OIDC_ISSUER=https://auth.example.com \\ -e OPENFGA_AUTHN_OIDC_AUDIENCE=openfga-api \\ openfga/openfga run TLS Support Mount certificate files and configure TLS:\ndocker run -d \\ -v /path/to/certs:/certs \\ -e OPENFGA_HTTP_TLS_ENABLED=true \\ -e OPENFGA_HTTP_TLS_CERT=/certs/server.crt \\ -e OPENFGA_HTTP_TLS_KEY=/certs/server.key \\ openfga/openfga run Monitoring and Profiling # Enable profiling endpoint docker run -d \\ -e OPENFGA_PROFILER_ENABLED=true \\ -e OPENFGA_PROFILER_ADDR=:3002 \\ -p 3002:3002 \\ openfga/openfga run Access profiling data at http://localhost:3002/debug/pprof/\nPolicy Definition OpenFGA uses a configuration language to define authorization models. The language supports two formats: a human-friendly DSL and a JSON API format.\nConfiguration Language Overview Purpose: Define the types of objects in your system and how they relate to each other\nTwo Formats:\nDSL (Domain Specific Language): User-friendly syntax for humans JSON: API-compatible format for programmatic use Where DSL is Used:\nPlayground web interface OpenFGA CLI VS Code extension IntelliJ extension Where JSON is Used:\nAPI calls SDK integration Programmatic model management Converting Between Formats Use the OpenFGA CLI to convert:\n# DSL to JSON fga model transform --from dsl --to json # JSON to DSL fga model transform --from json --to dsl DSL Syntax Basic Structure model schema 1.1 type user type document relations define owner: [user] define editor: [user] define viewer: [user] define can_view: viewer or editor or owner define can_edit: editor or owner define can_delete: owner Key Elements:\nmodel schema 1.1: Schema version declaration type: Defines an object type relations: Section containing relationship definitions define: Declares a relation or computed permission [user]: Direct relationship type restrictions Type Definitions Types represent objects in your system:\ntype user # Users/subjects type organization # Organizations type bot # Battle bots type game # Games/matches type document # Documents type folder # Folders Relationship Definitions Direct Relationships Specify which types can be directly assigned to a relation:\ntype document relations define owner: [user] define editor: [user, organization#member] define viewer: [user, user:*, organization#member] Formats:\n[user]: Specific user objects [user:*]: Any user (public access) [organization#member]: Users with specific relation on another type Union Operator (or) User has permission if they match ANY condition:\ntype document relations define owner: [user] define editor: [user] define viewer: [user] define can_view: viewer or editor or owner Example tuples:\nuser:anne, editor, document:1 Result: anne has can_view because she’s an editor\nIntersection Operator (and) User has permission if they match ALL conditions:\ntype document relations define restricted: [user] define approved_viewer: [user] define can_view_restricted: approved_viewer and restricted Example tuples:\nuser:anne, approved_viewer, document:1 user:anne, restricted, document:1 Result: anne has can_view_restricted only if both tuples exist\nExclusion Operator (but not) Include users from base set while excluding others:\ntype document relations define viewer: [user] define blocked: [user] define can_view: viewer but not blocked Example tuples:\nuser:anne, viewer, document:1 user:bob, viewer, document:1 user:bob, blocked, document:1 Result: anne has can_view, but bob does not (blocked)\nUse Cases:\nBlock lists Revoked access Temporary suspensions Transitivity (from) Inherit relationships through related objects:\ntype folder relations define owner: [user] define viewer: [user] type document relations define parent: [folder] define owner: [user] or owner from parent define viewer: [user] or viewer from parent Example tuples:\nfolder:docs, owner, user:anne folder:docs, parent, document:readme Result: anne is owner of document:readme (inherited from folder)\nUse Cases:\nHierarchical permissions (folder → documents) Organization membership (org → resources) Group-based access (group → members) Complex Authorization Models Multi-Level Hierarchies model schema 1.1 type user type organization relations define member: [user] define admin: [user] type team relations define parent_org: [organization] define member: [user] or admin from parent_org define admin: [user] type bot relations define parent_team: [team] define owner: [user] or admin from parent_team define can_deploy: owner or admin from parent_team define can_configure: owner or admin from parent_team define can_view: member from parent_team or owner This model enables:\nOrganization admins automatically have admin rights on all teams Team admins can deploy and configure bots Team members can view bots Bot owners have full control Battle Bots Example model schema 1.1 type user type organization relations define member: [user] define owner: [user] define admin: [user] or owner define can_invite_members: admin define can_create_teams: admin or member type team relations define parent_org: [organization] define member: [user] or admin from parent_org define admin: [user] define can_manage_bots: admin or admin from parent_org type bot relations define parent_team: [team] define creator: [user] define can_edit: creator or can_manage_bots from parent_team define can_delete: creator or admin from parent_team define can_deploy: creator or can_manage_bots from parent_team define can_view: member from parent_team type game relations define participant_bot: [bot] define creator: [user] define can_view: creator or can_view from participant_bot JSON Format Example The same model in JSON API format:\n{ \"schema_version\": \"1.1\", \"type_definitions\": [ { \"type\": \"user\" }, { \"type\": \"document\", \"relations\": { \"owner\": { \"this\": {} }, \"editor\": { \"this\": {} }, \"viewer\": { \"this\": {} }, \"can_view\": { \"union\": { \"child\": [ {\"this\": {}}, {\"computedUserset\": {\"relation\": \"editor\"}}, {\"computedUserset\": {\"relation\": \"owner\"}} ] } } }, \"metadata\": { \"relations\": { \"owner\": { \"directly_related_user_types\": [ {\"type\": \"user\"} ] }, \"editor\": { \"directly_related_user_types\": [ {\"type\": \"user\"} ] }, \"viewer\": { \"directly_related_user_types\": [ {\"type\": \"user\"} ] } } } } ] } Testing Authorization Models Assertions Define expected behavior to prevent regressions:\n# model_test.yaml name: Document Permissions Test model: | model schema 1.1 type user type document relations define owner: [user] define viewer: [user] define can_view: viewer or owner tuples: - user: user:anne relation: owner object: document:1 - user: user:bob relation: viewer object: document:2 assertions: # Positive assertions - check: - user: user:anne relation: can_view object: document:1 expected: true # Negative assertions - check: - user: user:bob relation: can_view object: document:1 expected: false Run tests with OpenFGA CLI:\nfga model test --file model_test.yaml Modeling Best Practices Start Simple: Begin with most critical feature, iterate to add complexity Use Meaningful Names: Relation names should clearly indicate permission (e.g., can_edit not just edit) Leverage Inheritance: Use from operator to avoid duplicating relationships Test Thoroughly: Write assertions for expected and unexpected behaviors Version Models: Track changes to authorization models like code Document Decisions: Explain why relations are structured a certain way Tools for Modeling Playground: Web UI at http://localhost:3000 for interactive modeling CLI: Command-line tool for model management and testing VS Code Extension: Syntax highlighting and validation IntelliJ Extension: IDE integration for JetBrains products Dynamic Data and Contextual Tuples OpenFGA supports dynamic authorization decisions through contextual tuples, enabling runtime data to influence authorization without storing relationships permanently.\nWhat are Contextual Tuples? Definition: Contextual tuples are temporary relationship tuples provided at query time that exist only for the duration of a specific authorization check.\nKey Characteristics:\nNot persisted to the database Provided with each Check, BatchCheck, ListObjects, ListUsers, or Expand request Treated as if they exist in the store during evaluation Override database tuples if the same relationship exists Limited to 100 tuples per request How Contextual Tuples Work Normal Authorization Check (Stored Tuples) // Relationship stored in database await fgaClient.write({ writes: [ { user: \"user:anne\", relation: \"member\", object: \"organization:acme\" } ] }); // Authorization check const { allowed } = await fgaClient.check({ user: \"user:anne\", relation: \"can_manage_bots\", object: \"bot:battle-bot-1\" }); With Contextual Tuples (Dynamic Data) // No pre-stored relationship needed // Context provided at query time const { allowed } = await fgaClient.check({ user: \"user:anne\", relation: \"can_manage_bots\", object: \"bot:battle-bot-1\", contextualTuples: [ { user: \"user:anne\", relation: \"member\", object: \"organization:acme\" // Dynamic context } ] }); Use Cases 1. Multi-Tenancy / Organization Context User works in multiple organizations; current context comes from session/JWT:\n// JWT payload contains current organization const token = { sub: \"user:anne\", current_org: \"org:acme\", orgs: [\"org:acme\", \"org:techcorp\"] }; // Authorization check uses JWT org context const { allowed } = await fgaClient.check({ user: token.sub, relation: \"can_manage_bots\", object: \"bot:battle-bot-1\", contextualTuples: [ { user: token.sub, relation: \"active_member\", object: token.current_org // From JWT } ] }); Authorization Model:\ntype organization relations define member: [user] define active_member: [user] type bot relations define parent_org: [organization] define can_manage: active_member from parent_org Benefits:\nUser can switch organizations without changing stored relationships Same user session, different authorization context No need to write/delete relationships on org switch 2. Avoiding Data Synchronization Some authorization data lives in external systems (identity provider, HR system):\n// User roles come from external IAM system const externalRoles = await iamSystem.getUserRoles(userId); // Use contextual tuples instead of syncing to OpenFGA const contextualTuples = externalRoles.map(role =\u003e ({ user: `user:${userId}`, relation: \"member\", object: `role:${role.id}` })); const { allowed } = await fgaClient.check({ user: `user:${userId}`, relation: \"can_deploy\", object: \"bot:battle-bot-1\", contextualTuples }); Benefits:\nNo dual-write coordination Single source of truth in external system Always current data without sync delays 3. Time-Based Access Authorization depends on current time (though conditional relationships are preferred):\nconst now = new Date(); const isBusinessHours = now.getHours() \u003e= 9 \u0026\u0026 now.getHours() \u003c 17; const contextualTuples = []; if (isBusinessHours) { contextualTuples.push({ user: \"user:anne\", relation: \"business_hours_user\", object: \"system:battlebots\" }); } const { allowed } = await fgaClient.check({ user: \"user:anne\", relation: \"can_deploy_to_production\", object: \"bot:battle-bot-1\", contextualTuples }); Authorization Model:\ntype system relations define business_hours_user: [user] type bot relations define can_deploy_to_production: business_hours_user from parent_system 4. IP-Based or Location Restrictions const userIp = request.ip; const isInternalNetwork = ipRangeCheck(userIp, \"10.0.0.0/8\"); const contextualTuples = []; if (isInternalNetwork) { contextualTuples.push({ user: `user:${userId}`, relation: \"internal_network_user\", object: \"network:corporate\" }); } const { allowed } = await fgaClient.check({ user: `user:${userId}`, relation: \"can_access_admin_panel\", object: \"system:battlebots\", contextualTuples }); 5. Disambiguating Multiple Relationships User has multiple relationships with same object; specify which applies:\n// User is member of multiple teams // Specify which team context for this request const { allowed } = await fgaClient.check({ user: \"user:anne\", relation: \"can_view_metrics\", object: \"dashboard:team-performance\", contextualTuples: [ { user: \"user:anne\", relation: \"viewing_as_member\", object: \"team:red-team\" // Which team context } ] }); Contextual Tuples API Examples Node.js SDK const { OpenFgaClient } = require('@openfga/sdk'); const fgaClient = new OpenFgaClient({ apiUrl: process.env.FGA_API_URL, storeId: process.env.FGA_STORE_ID, authorizationModelId: process.env.FGA_MODEL_ID, }); // Check with contextual tuples const response = await fgaClient.check({ user: 'user:anne', relation: 'can_edit', object: 'document:1', contextualTuples: [ { user: 'user:anne', relation: 'member', object: 'organization:acme' }, { user: 'organization:acme', relation: 'owner', object: 'document:1' } ] }); console.log(response.allowed); // true or false Go SDK import ( \"context\" \"github.com/openfga/go-sdk/client\" ) func checkWithContext(userId, botId, orgId string) (bool, error) { resp, err := fgaClient.Check(context.Background()). Body(client.ClientCheckRequest{ User: fmt.Sprintf(\"user:%s\", userId), Relation: \"can_deploy\", Object: fmt.Sprintf(\"bot:%s\", botId), ContextualTuples: []client.ClientTupleKey{ { User: fmt.Sprintf(\"user:%s\", userId), Relation: \"active_member\", Object: fmt.Sprintf(\"organization:%s\", orgId), }, }, }). Execute() if err != nil { return false, err } return resp.GetAllowed(), nil } REST API curl -X POST http://localhost:8080/stores/${STORE_ID}/check \\ -H \"Content-Type: application/json\" \\ -d '{ \"authorization_model_id\": \"${MODEL_ID}\", \"tuple_key\": { \"user\": \"user:anne\", \"relation\": \"can_edit\", \"object\": \"document:1\" }, \"contextual_tuples\": { \"tuple_keys\": [ { \"user\": \"user:anne\", \"relation\": \"member\", \"object\": \"organization:acme\" } ] } }' Limitations and Considerations Hard Limits Limitation Value Reason Maximum contextual tuples 100 per request Performance and complexity bounds Tuple lifetime Single request Not persisted to database Validation Same as stored tuples Must conform to authorization model Precedence Rules When both a contextual tuple and stored tuple exist with same user, relation, and object:\nContextual tuple takes precedence and stored tuple is ignored for that check.\n// Database has: // user:anne, viewer, document:1 // Check with contextual tuple: const { allowed } = await fgaClient.check({ user: \"user:anne\", relation: \"can_edit\", object: \"document:1\", contextualTuples: [ { user: \"user:anne\", relation: \"editor\", // Different relation object: \"document:1\" } ] }); // Evaluation uses contextual \"editor\" relation, not stored \"viewer\" Performance Considerations Pros:\nAvoids database writes for temporary/dynamic data Reduces data synchronization complexity Enables runtime-dependent authorization Cons:\nIncreases request payload size Cannot be indexed or optimized like stored tuples May increase check latency for complex models Requires client to provide context data Recommendation: Use contextual tuples for truly dynamic data. For stable relationships, store tuples in database for better performance.\nSecurity Considerations Trust Boundary: Application must validate contextual tuple data before sending to OpenFGA.\n// ❌ DANGEROUS: Using user-provided data directly const { allowed } = await fgaClient.check({ user: currentUser, relation: \"can_delete\", object: targetBot, contextualTuples: req.body.context // User controls this! }); // ✅ SAFE: Validate and construct context from trusted sources const orgId = await getValidatedOrgFromSession(req); const { allowed } = await fgaClient.check({ user: currentUser, relation: \"can_delete\", object: targetBot, contextualTuples: [ { user: currentUser, relation: \"member\", object: `organization:${orgId}` // Validated } ] }); Token Expiration Issue: If using JWT claims as contextual tuples, access continues until token expires even if underlying claims change in identity provider.\nMitigation: Use short-lived tokens or implement token revocation checking.\nBest Practices Use for Truly Dynamic Data: Session context, current time, IP address, temporary grants Store Stable Relationships: User-organization membership, resource ownership, team membership Validate Context Data: Never trust user-provided contextual tuples Limit Contextual Tuple Count: Stay well below 100-tuple limit for performance Document Context Requirements: Make clear what context is needed for each authorization check Cache When Appropriate: Some dynamic data can be cached short-term to reduce computation Integration Patterns for Battle Bots Recommended Architecture ┌─────────────────────────────────────────────────────────┐ │ Battle Bots Platform │ ├─────────────────────────────────────────────────────────┤ │ │ │ ┌──────────────┐ ┌──────────────┐ │ │ │ Frontend │ │ API Gateway │ │ │ │ (React/etc) │─────▶│ (Go) │ │ │ └──────────────┘ └───────┬───────┘ │ │ │ │ │ ▼ │ │ ┌───────────────────────┐ │ │ │ Auth Middleware │ │ │ │ 1. Verify JWT │ │ │ │ 2. Extract user ID │ │ │ └───────────┬───────────┘ │ │ │ │ │ ▼ │ │ ┌───────────────────────┐ │ │ │ AuthZ Middleware │ │ │ │ 1. Map operation │ │ │ │ 2. Call OpenFGA │ │ │ │ 3. Allow/Deny │ │ │ └───────────┬───────────┘ │ │ │ │ │ ┌───────────▼───────────┐ │ │ │ Business Logic │ │ │ │ - Bot Management │ │ │ │ - Game Services │ │ │ │ - Team Management │ │ │ └───────────────────────┘ │ │ │ └─────────────────────────────────────────────────────────┘ │ │ │ GitHub OAuth │ gRPC/HTTP ▼ ▼ ┌─────────────────┐ ┌─────────────────┐ │ GitHub OAuth │ │ OpenFGA │ │ │ │ - PostgreSQL │ │ │ │ - K8s/Docker │ └─────────────────┘ └─────────────────┘ Example: Bot Deployment Authorization // middleware/authz.go package middleware import ( \"context\" \"fmt\" \"github.com/gofiber/fiber/v2\" fgaClient \"github.com/openfga/go-sdk/client\" ) type AuthZMiddleware struct { fga *fgaClient.OpenFgaClient } func (m *AuthZMiddleware) RequirePermission( resourceType string, relation string, ) fiber.Handler { return func(c *fiber.Ctx) error { // Extract user from JWT (set by auth middleware) userID := c.Locals(\"userID\").(string) // Get resource ID from route params resourceID := c.Params(\"id\") // Construct OpenFGA object object := fmt.Sprintf(\"%s:%s\", resourceType, resourceID) user := fmt.Sprintf(\"user:%s\", userID) // Check authorization resp, err := m.fga.Check(context.Background()). Body(fgaClient.ClientCheckRequest{ User: user, Relation: relation, Object: object, }). Execute() if err != nil { return c.Status(500).JSON(fiber.Map{ \"error\": \"Authorization check failed\", }) } if !resp.GetAllowed() { return c.Status(403).JSON(fiber.Map{ \"error\": \"Forbidden\", }) } return c.Next() } } // Usage in routes app.Post(\"/bots/:id/deploy\", authMiddleware.Authenticate, authzMiddleware.RequirePermission(\"bot\", \"can_deploy\"), handlers.DeployBot, ) Relationship Management // services/organization.go func (s *OrgService) AddTeamMember( ctx context.Context, teamID string, userID string, ) error { // Write relationship to OpenFGA _, err := s.fga.Write(ctx). Body(fgaClient.ClientWriteRequest{ Writes: []fgaClient.ClientTupleKey{ { User: fmt.Sprintf(\"user:%s\", userID), Relation: \"member\", Object: fmt.Sprintf(\"team:%s\", teamID), }, }, }). Execute() return err } func (s *OrgService) RemoveTeamMember( ctx context.Context, teamID string, userID string, ) error { // Delete relationship from OpenFGA _, err := s.fga.Write(ctx). Body(fgaClient.ClientWriteRequest{ Deletes: []fgaClient.ClientTupleKey{ { User: fmt.Sprintf(\"user:%s\", userID), Relation: \"member\", Object: fmt.Sprintf(\"team:%s\", teamID), }, }, }). Execute() return err } Pros and Cons for Battle Bots Pros of Using OpenFGA Fine-Grained Authorization\nObject-level permissions instead of coarse role-based access Can express complex relationships (org → team → bot → game) Supports hierarchical permission inheritance Scales to millions of authorization decisions per second Separation of Concerns\nAuthentication (GitHub OAuth + JWT) completely separate from authorization OpenFGA focuses solely on “who can do what” Clean architecture with well-defined boundaries Flexible and Expressive\nModel any relationship pattern (ReBAC, RBAC, ABAC hybrid) Union, intersection, exclusion, transitivity operators Contextual tuples for dynamic authorization Easy to evolve authorization model over time Production-Ready\nInspired by Google Zanzibar (battle-tested at massive scale) High performance with proper database backend Horizontal scaling with stateless API servers Multiple deployment options (Docker, K8s, binary) Developer Experience\nIntuitive DSL for modeling SDKs for Go, JavaScript, Python, .NET, Java Playground for testing models CLI for model management and testing IDE extensions (VS Code, IntelliJ) Open Source\nApache 2.0 license No vendor lock-in Self-hosted (no per-user costs) Active community and development Backed by Okta/Auth0 but truly open Multi-Tenancy Native\nPerfect for organization/team/bot hierarchy Contextual tuples for session-based org context Clean permission inheritance across tenants Auditability\nAll relationship changes can be logged Query history for “why can user X access Y?” Compliance-friendly authorization tracking Cons of Using OpenFGA Additional Infrastructure\nRequires separate service deployment Database dependency (PostgreSQL/MySQL for production) Monitoring and maintenance overhead Network hop for authorization checks Learning Curve\nReBAC is different from traditional RBAC Authorization modeling requires thoughtful design Team must understand relationship-based concepts DSL syntax learning required Performance Considerations\nEvery protected operation requires OpenFGA call Network latency added to request path Complex models can have slower evaluation times Requires caching strategy for hot paths Operational Complexity\nAnother service to deploy, monitor, and scale Database backup and migration procedures Version management for authorization models Need observability into authorization decisions May Be Overkill for MVP\nSimple RBAC might suffice initially Early-stage apps may not need fine-grained permissions Added complexity before product-market fit Could implement later when requirements are clearer Data Consistency Challenges\nMust keep OpenFGA relationships in sync with application data Deleting resources requires cleaning up relationships Risk of orphaned tuples if cleanup fails Eventual consistency considerations Limited ABAC Support\nPrimarily relationship-based, not attribute-based Contextual tuples help but have limitations Cannot directly query external attributes during evaluation May need hybrid approach for complex ABAC requirements Recommendations for Battle Bots Recommendation 1: Adopt OpenFGA for Authorization Rationale:\nBattle Bots has inherent hierarchy (org → team → bot → game) Fine-grained permissions are required (not all team members should deploy bots) Self-hosted OpenFGA aligns with control requirements Go platform matches well with OpenFGA’s Go SDK No per-user costs (important for platform growth) When to Implement:\nDesign authorization model during MVP planning phase Implement alongside GitHub OAuth authentication Deploy before adding multi-user features Implementation Approach:\nDefine authorization model for MVP (orgs, teams, bots) Deploy OpenFGA with PostgreSQL on Kubernetes Implement authorization middleware for all protected resources Write relationships when resources are created/modified Monitor and optimize based on usage patterns Recommendation 2: Start Simple, Iterate Phase 1: Basic Permissions (MVP)\n- Organization owners can create teams - Team admins can manage bots - Bot creators can edit/deploy their bots - Team members can view team bots Phase 2: Advanced Permissions\n- Delegation (team admins grant deploy rights) - Shared bots (multiple teams) - Temporary access grants - Audit logs Phase 3: Complex Scenarios\n- Tournament organizers - Spectator access controls - Sponsor/partner access - API rate limiting by permission tier Recommendation 3: Design Authorization Model Carefully Avoid Over-Modeling:\nDon’t model every possible permission from day one Start with clear use cases Add relations as needed Test model thoroughly before production Example Starter Model for Battle Bots:\nmodel schema 1.1 type user type organization relations define owner: [user] define member: [user] define can_create_teams: owner or member define can_invite_members: owner type team relations define parent_org: [organization] define admin: [user] define member: [user] or admin or owner from parent_org define can_manage_bots: admin or owner from parent_org type bot relations define parent_team: [team] define creator: [user] define can_view: member from parent_team define can_edit: creator or can_manage_bots from parent_team define can_deploy: creator or can_manage_bots from parent_team define can_delete: creator or admin from parent_team Recommendation 4: Implement Caching Authorization Check Caching:\n// Cache authorization decisions for short periods type AuthCache struct { cache *ttlcache.Cache } func (c *AuthCache) Check( user, relation, object string, ) (bool, error) { // Check cache first key := fmt.Sprintf(\"%s:%s:%s\", user, relation, object) if cached, found := c.cache.Get(key); found { return cached.(bool), nil } // Call OpenFGA allowed, err := c.fgaCheck(user, relation, object) if err != nil { return false, err } // Cache for 30 seconds c.cache.Set(key, allowed, 30*time.Second) return allowed, nil } When to Invalidate:\nUser permissions change Resource relationships modified Organization membership updated Recommendation 5: Monitor OpenFGA Performance Metrics to Track:\nAuthorization check latency (p50, p95, p99) Check throughput (requests/second) Model evaluation complexity Cache hit rates Database query performance Alerting Thresholds:\nCheck latency \u003e 100ms (p95) Error rate \u003e 1% Database connection pool exhaustion Tuple write failures Recommendation 6: Plan for Model Evolution Version Control:\nStore authorization models in git Test model changes thoroughly Use separate stores for dev/staging/prod Document model changes in ADRs Migration Strategy:\n# Test new model in playground/staging fga model write --file new-model.fga --store-id staging # Run validation tests fga model test --file model_test.yaml # Deploy to production fga model write --file new-model.fga --store-id production Alternative Considerations Alternative 1: Ory Keto Pros:\nSimilar to OpenFGA (also Zanzibar-inspired) Part of Ory ecosystem (with Kratos, Hydra) Open source (Apache 2.0) Cons:\nLess mature than OpenFGA Smaller community Fewer SDKs and tools Alternative 2: SpiceDB Pros:\nAlso Zanzibar-inspired Strong consistency guarantees Built-in schema validation Cons:\nMore complex deployment Requires CockroachDB or PostgreSQL Different query language Alternative 3: Custom Authorization Service Pros:\nFull control over implementation Optimized for specific use case No external dependencies Cons:\nSignificant development time Security burden on team Difficult to evolve Reinventing proven solutions Verdict: OpenFGA provides the best balance of features, maturity, and operational simplicity for Battle Bots.\nConclusion OpenFGA is a production-ready, scalable authorization system that fits Battle Bots’ requirements exceptionally well. Its separation from authentication allows seamless integration with the planned GitHub OAuth strategy, while its ReBAC model naturally represents the platform’s organizational hierarchy (organizations → teams → bots → games).\nKey Takeaways:\nJWT Integration: OpenFGA works alongside JWT authentication, using extracted user identity for authorization checks Deployment Flexibility: Multiple options (Docker, Kubernetes Helm charts, operators, binary) for various environments Intuitive Policy Definition: DSL provides human-readable authorization models that compile to JSON for API use Dynamic Authorization: Contextual tuples enable runtime data (session context, time, location) to influence decisions Recommended Path Forward:\nDesign authorization model during planning phase Deploy OpenFGA on Kubernetes with PostgreSQL Start with simple permissions, iterate based on user needs Implement caching for performance Monitor and optimize as platform scales OpenFGA’s self-hosted nature eliminates per-user costs while providing enterprise-grade authorization capabilities, making it an excellent choice for Battle Bots’ long-term growth.\nReferences OpenFGA Official Documentation OpenFGA GitHub Repository OpenFGA Configuration Language OpenFGA Kubernetes Setup OpenFGA Docker Setup OpenFGA Contextual Tuples OpenFGA Framework Integration OpenFGA Modeling Guide OpenFGA Helm Chart ZEISS OpenFGA Operator Canonical OpenFGA Operator Google Zanzibar Paper Auth0 FGA Blog Posts OpenFGA CLI OpenFGA Language Grammar ","categories":"","description":"Comprehensive analysis of OpenFGA fine-grained authorization system, including JWT integration, deployment options, policy definition, and dynamic data capabilities.\n","excerpt":"Comprehensive analysis of OpenFGA fine-grained authorization system, …","ref":"/battlebots/pr-preview/pr-139/rd/analysis/open-source-applications/openfga-analysis/","tags":"","title":"OpenFGA Analysis"},{"body":" Context and Problem Statement Users need a way to register and authenticate with the Battle Bots platform to create and manage their autonomous bots. The registration process should be secure, user-friendly, and minimize friction for developers who are our target audience.\nHow should we implement user registration and authentication for the Battle Bots platform?\nDecision Drivers User experience: Minimize registration friction for developer audience Security: Ensure secure authentication without managing passwords Implementation complexity: Reduce development and maintenance burden Timeline: Need to launch quickly with minimal authentication infrastructure Trust: Leverage existing identity providers that developers already use Bot deployment: Need to tie bot ownership to verified user accounts Considered Options GitHub OAuth authentication Email/password registration with JWT Google OAuth authentication Support multiple OAuth providers (GitHub, Google, GitLab) Decision Outcome Chosen option: “GitHub OAuth authentication with stateless JWT tokens”, because it best meets our decision drivers:\nUser experience: Developers already have GitHub accounts - minimal registration friction Security: Leverages GitHub’s OAuth 2.0 without password management burden Implementation complexity: Single OAuth provider reduces development time Timeline: Fastest path to launch with proven technology Trust: GitHub is the natural identity provider for our developer audience Scalability: Stateless JWT tokens enable horizontal scaling without session synchronization The implementation uses GitHub OAuth for initial authentication, then converts the GitHub access token to internal JWT tokens for stateless API authentication. This hybrid approach provides OAuth convenience with JWT scalability.\nConsequences Good, because no server-side session state enables horizontal scalability Good, because JWT tokens reduce database lookups (user info in token claims) Good, because stateless architecture simplifies microservices integration Good, because developers trust GitHub as identity provider Good, because refresh token rotation provides security without UX friction Neutral, because requires implementing JWT token service (RS256 signing/validation) Neutral, because GitHub OAuth is OAuth 2.0, not OIDC (must generate our own ID tokens) Bad, because vendor dependency on GitHub for initial authentication Bad, because requires token blacklist for immediate revocation (adds some state) Bad, because limits to users with GitHub accounts (acceptable for developer audience) Confirmation Implementation compliance will be confirmed through:\nSecurity Testing: Penetration testing validates XSS/CSRF protection, token validation, and PKCE implementation Integration Tests: Automated tests verify complete OAuth flow and JWT token generation/validation Code Review: Security-focused review of JWT signing, token storage, and refresh token rotation Load Testing: Horizontal scalability validated with 10,000+ concurrent users across multiple servers Documentation Review: Architecture diagrams and sequence diagrams accurately reflect stateless JWT implementation Pros and Cons of the Options GitHub OAuth authentication with OpenFGA authorization Single OAuth provider (GitHub) for registration and authentication, combined with OpenFGA for fine-grained authorization.\nAuthentication vs Authorization:\nAuthentication (GitHub OAuth + JWT): Verifies user identity - “Who are you?” Authorization (OpenFGA): Determines permissions - “What can you do?” This option separates authentication concerns (handled by GitHub OAuth and JWT tokens) from authorization concerns (handled by OpenFGA). Users authenticate once via GitHub, receive JWT tokens for API access, and every protected operation checks permissions through OpenFGA based on relationships between users and resources (organizations, teams, bots, games).\nGood, because target audience (developers) already have GitHub accounts Good, because no password management or reset flows needed Good, because GitHub’s OAuth is well-documented and reliable Good, because reduces implementation complexity and time to launch Good, because GitHub identity ties naturally to developer workflows Good, because OpenFGA provides fine-grained authorization (object-level permissions, not just roles) Good, because OpenFGA naturally models organizational hierarchy (organization → team → bot → game) Good, because OpenFGA scales to millions of authorization relationships and checks Good, because separation of authentication (GitHub OAuth) and authorization (OpenFGA) follows security best practices Good, because self-hosted OpenFGA has no per-user costs (important for platform growth) Good, because OpenFGA’s ReBAC model supports complex permission inheritance and delegation Neutral, because limits to users with GitHub accounts (acceptable for developer audience) Neutral, because requires deploying and maintaining OpenFGA service infrastructure Neutral, because requires learning ReBAC authorization modeling concepts Bad, because vendor dependency on GitHub for authentication Bad, because no fallback if GitHub OAuth is unavailable Bad, because additional infrastructure complexity (OpenFGA service + database for authorization data) Bad, because network latency added for OpenFGA authorization checks on every protected operation Implementation Visualization Architecture Diagram:\ngraph LR User[User Browser] --\u003e WebApp[Battle Bots Web App] WebApp --\u003e GitHub[GitHub OAuth] WebApp --\u003e DB[(Application Database)] WebApp --\u003e AuthSvc[Auth Service\u003cbr/\u003e+ JWKS Endpoint] WebApp --\u003e Redis[(Redis - Token Blacklist)] WebApp --\u003e AuthZ[OpenFGA Service] AuthZ --\u003e FGA_DB[(OpenFGA Database)] GitHub --\u003e User style WebApp fill:#e1f5ff style GitHub fill:#f0f0f0 style DB fill:#fff4e1 style AuthSvc fill:#f3e5f5 style Redis fill:#ffe0e0 style AuthZ fill:#e8f5e9 style FGA_DB fill:#c8e6c9 Architecture Notes:\nAuthentication Layer: GitHub OAuth validates user identity during initial login Auth Service generates JWT tokens signed with RS256 private key JWKS endpoint (/.well-known/jwks.json) publishes public keys for token validation Battle Bots app validates JWT signatures locally using cached public keys (no per-request service call) Authorization Layer: OpenFGA Service handles fine-grained permissions checks for all protected operations Stateless Design: JWT tokens eliminate session storage; Redis is optional for token revocation blacklist Separation of Concerns: Authentication database stores user accounts and refresh tokens Authorization database (OpenFGA) stores relationships and permissions Token generation and token validation are decoupled via JWKS standard REST API Endpoints:\nMethod Endpoint Auth Required Purpose GET /auth/github/login No Initiates GitHub OAuth flow with PKCE by generating code_challenge and CSRF state token, redirecting to GitHub authorization page GET /auth/github/callback No Handles OAuth callback from GitHub, exchanges auth code for GitHub access token, fetches user profile, creates/updates account, generates internal JWT access token + refresh token, sets httpOnly cookies POST /auth/terms/accept JWT (Cookie) Accepts terms of service for new user accounts (called before account creation) POST /auth/refresh Refresh Token (Cookie) Exchanges valid refresh token for new JWT access token + new refresh token (rotation), updates httpOnly cookies GET /auth/session JWT (Cookie) Returns current authenticated user information from JWT claims (no database lookup) POST /auth/logout JWT (Cookie) Revokes refresh token in database, optionally blacklists JWT, clears authentication cookies GET /.well-known/jwks.json No Returns JSON Web Key Set (JWKS) containing public keys for JWT signature validation. Used by Battle Bots app to validate tokens locally. Protected Resource Endpoints (with OpenFGA Authorization):\nProtected endpoints follow a two-step security model: JWT authentication validates identity, then OpenFGA authorization checks permissions.\nMethod Endpoint Authentication Authorization Check Purpose POST /bots/:id/deploy JWT (Cookie) OpenFGA: user:github|username has can_deploy on bot:id Deploy bot to game server PUT /bots/:id JWT (Cookie) OpenFGA: user:github|username has can_edit on bot:id Update bot configuration DELETE /bots/:id JWT (Cookie) OpenFGA: user:github|username has can_delete on bot:id Delete bot POST /teams/:id/members JWT (Cookie) OpenFGA: user:github|username has can_manage_members on team:id Add member to team POST /organizations/:id/teams JWT (Cookie) OpenFGA: user:github|username has can_create_teams on organization:id Create team in organization Authorization Flow Pattern:\nMiddleware validates JWT and extracts user identity (e.g., github|username) Middleware maps HTTP method + route to OpenFGA relation (e.g., POST /bots/:id/deploy → can_deploy) Middleware calls OpenFGA Check API: check(user, relation, object) If OpenFGA returns allowed: true, request proceeds to handler If OpenFGA returns allowed: false, return 403 Forbidden Sequence Diagram - Registration/Login Flow:\nsequenceDiagram actor User participant WebApp as Battle Bots Web App participant GitHub as GitHub OAuth participant DB as Database participant AuthSvc as Auth Service User-\u003e\u003eWebApp: GET /auth/github/login WebApp-\u003e\u003eWebApp: Generate code_verifier + code_challenge (PKCE) WebApp-\u003e\u003eWebApp: Generate CSRF state token WebApp-\u003e\u003eUser: 302 Redirect to GitHub OAuth (with code_challenge) User-\u003e\u003eGitHub: Authorize Battle Bots application alt Authorization Successful GitHub-\u003e\u003eWebApp: GET /auth/github/callback?code=xxx\u0026state=yyy WebApp-\u003e\u003eWebApp: Validate state token (CSRF protection) WebApp-\u003e\u003eGitHub: POST /login/oauth/access_token\u003cbr/\u003e(exchange code + code_verifier) GitHub--\u003e\u003eWebApp: Return GitHub access token WebApp-\u003e\u003eGitHub: GET /user (fetch profile) GitHub--\u003e\u003eWebApp: Return user data (ID, username, email) alt User Exists WebApp-\u003e\u003eDB: Update user profile DB--\u003e\u003eWebApp: Profile updated else New User WebApp-\u003e\u003eUser: Show Terms of Service page User-\u003e\u003eWebApp: POST /auth/terms/accept (with JWT cookie) WebApp-\u003e\u003eDB: Create user account DB--\u003e\u003eWebApp: Account created end WebApp-\u003e\u003eAuthSvc: Generate JWT access token (RS256, 15min expiry) AuthSvc--\u003e\u003eWebApp: Signed JWT with claims (sub, iss, aud, exp, github_id, ...) Note over AuthSvc: Public keys available at\u003cbr/\u003e/.well-known/jwks.json WebApp-\u003e\u003eWebApp: Generate refresh token (random 32-byte) WebApp-\u003e\u003eDB: Store refresh token hash (user_id, token_hash, expires_at) DB--\u003e\u003eWebApp: Token stored WebApp-\u003e\u003eUser: 302 Redirect to dashboard\u003cbr/\u003e(Set httpOnly cookies: access_token, refresh_token, csrf_token) else Authorization Failed/Cancelled GitHub-\u003e\u003eWebApp: GET /auth/github/callback?error=xxx WebApp-\u003e\u003eUser: Show error message end Sequence Diagram - Protected Operation with OpenFGA Authorization:\nsequenceDiagram actor User participant WebApp as Battle Bots Web App participant AuthMiddleware as Auth Middleware participant AuthZMiddleware as AuthZ Middleware participant OpenFGA as OpenFGA Service participant Handler as Request Handler participant DB as Database Note over User,DB: User already authenticated with JWT cookie User-\u003e\u003eWebApp: POST /bots/battle-bot-1/deploy\u003cbr/\u003e(JWT in httpOnly cookie) WebApp-\u003e\u003eAuthMiddleware: Validate authentication AuthMiddleware-\u003e\u003eAuthMiddleware: Verify JWT signature using cached public key\u003cbr/\u003e(from /.well-known/jwks.json) Note over AuthMiddleware: Public keys cached locally,\u003cbr/\u003erefreshed periodically or on validation failure alt JWT Invalid or Expired AuthMiddleware--\u003e\u003eWebApp: 401 Unauthorized WebApp-\u003e\u003eUser: Redirect to login or show error else JWT Valid AuthMiddleware-\u003e\u003eAuthMiddleware: Extract user claims from JWT AuthMiddleware-\u003e\u003eAuthZMiddleware: user_id: github|alice, operation: deploy, resource: bot:battle-bot-1 AuthZMiddleware-\u003e\u003eOpenFGA: Check(user: \"user:github|alice\",\u003cbr/\u003erelation: \"can_deploy\",\u003cbr/\u003eobject: \"bot:battle-bot-1\") OpenFGA-\u003e\u003eOpenFGA: Evaluate authorization model\u003cbr/\u003e(check relationships and rules) alt User Not Authorized OpenFGA--\u003e\u003eAuthZMiddleware: allowed: false AuthZMiddleware--\u003e\u003eWebApp: 403 Forbidden WebApp-\u003e\u003eUser: Show \"You don't have permission\" error else User Authorized OpenFGA--\u003e\u003eAuthZMiddleware: allowed: true AuthZMiddleware-\u003e\u003eHandler: Forward request Handler-\u003e\u003eDB: Execute deployment logic DB--\u003e\u003eHandler: Deployment successful Handler--\u003e\u003eWebApp: 200 OK {deployment_status} WebApp-\u003e\u003eUser: Show success message end end Authorization Decision Flow:\nThe authorization middleware performs the following steps for every protected endpoint:\nExtract User Identity: Get user ID from validated JWT claims (e.g., github|alice) Map Operation to Relation: Translate HTTP method + endpoint to OpenFGA relation POST /bots/:id/deploy → can_deploy PUT /bots/:id → can_edit DELETE /bots/:id → can_delete Construct OpenFGA Check: Build check request with user, relation, and object Evaluate Permission: OpenFGA traverses relationship graph based on authorization model Enforce Decision: Allow (200/201) or deny (403) based on OpenFGA response OpenFGA Authorization Model (Starter):\nThis is the initial authorization model for Battle Bots MVP. It defines the organizational hierarchy and permission inheritance patterns.\nmodel schema 1.1 type user type organization relations define owner: [user] define member: [user] define can_create_teams: owner or member define can_invite_members: owner type team relations define parent_org: [organization] define admin: [user] define member: [user] or admin or owner from parent_org define can_manage_bots: admin or owner from parent_org define can_manage_members: admin or owner from parent_org type bot relations define parent_team: [team] define creator: [user] define can_view: member from parent_team define can_edit: creator or can_manage_bots from parent_team define can_deploy: creator or can_manage_bots from parent_team define can_delete: creator or admin from parent_team type game relations define participant_bot: [bot] define creator: [user] define can_view: creator or can_view from participant_bot define can_cancel: creator Model Explanation:\nOrganizations: Top-level entities with owners and members. Owners can invite members; both can create teams. Teams: Belong to organizations. Organization owners automatically have admin rights on all teams in their org. Team admins can manage bots and members. Bots: Belong to teams. Bot creators can edit/deploy/delete their bots. Team admins can also manage all bots in their team. All team members can view bots. Games: Include participating bots. Game creator and anyone who can view participating bots can view the game. Permission Inheritance Examples:\nAlice is owner of Org A → Alice is automatically admin of Team X (part of Org A) → Alice can manage all bots in Team X Bob is creator of Bot Y in Team X → Bob can edit, deploy, and delete Bot Y Carol is member of Team X → Carol can view all bots in Team X, but cannot edit/deploy them Relationship Tuple Examples:\n# Organization membership user:github|alice, owner, organization:acme-corp user:github|bob, member, organization:acme-corp # Team structure organization:acme-corp, parent_org, team:alpha-team user:github|carol, admin, team:alpha-team # Bot ownership team:alpha-team, parent_team, bot:battle-bot-1 user:github|bob, creator, bot:battle-bot-1 # Game participation bot:battle-bot-1, participant_bot, game:match-123 user:github|alice, creator, game:match-123 For complete OpenFGA deployment and configuration details, see OpenFGA Analysis.\nJWKS (JSON Web Key Set) Implementation Details:\nThe JWKS endpoint provides a standard mechanism for Battle Bots app to validate JWT tokens without coupling to the token generation service.\nJWKS Endpoint Format:\nThe Auth Service exposes public keys at /.well-known/jwks.json:\n{ \"keys\": [ { \"kty\": \"RSA\", \"kid\": \"2024-11-primary\", \"use\": \"sig\", \"alg\": \"RS256\", \"n\": \"0vx7agoebGcQSuuPiLJXZptN9nndrQmbXEps2aiAFbWhM78LhWx...\", \"e\": \"AQAB\" }, { \"kty\": \"RSA\", \"kid\": \"2024-10-rotated\", \"use\": \"sig\", \"alg\": \"RS256\", \"n\": \"xjlKJN9C5xW7JVZkGwmZZN3NnPQmbXEps2aiAFbWhM78LhWx...\", \"e\": \"AQAB\" } ] } Key Fields:\nkty: Key type (RSA for RS256 signatures) kid: Key ID used in JWT header to identify which key signed the token use: Key usage (sig for signature verification) alg: Algorithm (RS256 = RSA signature with SHA-256) n: RSA modulus (base64url-encoded) e: RSA exponent (typically AQAB = 65537) Key Rotation Strategy:\nNew Key Generation: Auth Service generates new RSA key pair monthly Dual Key Period: Both old and new public keys published in JWKS for 30 days Grace Period: Old key remains in JWKS while tokens signed with it are still valid (15min access token + 7 day refresh token = keep old key for 8 days minimum) Key Removal: Old key removed from JWKS after grace period expires Client-Side Caching (Battle Bots App):\n1. On startup: Fetch JWKS from /.well-known/jwks.json 2. Cache keys in memory with 1-hour TTL 3. When validating JWT: - Extract 'kid' from JWT header - Look up public key in cache by 'kid' - Verify signature using cached key 4. On signature validation failure: - Refresh JWKS from endpoint (handle key rotation) - Retry validation with updated keys - Return 401 if still invalid 5. Periodic refresh: Re-fetch JWKS every hour to stay current Security Considerations:\nPublic keys are safe to cache and distribute (cannot sign tokens, only verify) Always validate JWT signature before trusting claims Respect kid header to select correct key (prevents downgrade attacks) JWKS endpoint should be served over HTTPS only Rate limit JWKS endpoint to prevent abuse (recommended: 100 req/min per IP) Email/password registration with JWT Traditional registration with email/password and JWT tokens.\nGood, because no dependency on external OAuth providers Good, because works for users without third-party accounts Good, because full control over authentication flow Bad, because requires implementing password reset, email verification Bad, because need to securely store and hash passwords Bad, because higher implementation and maintenance complexity Bad, because more friction in registration process Bad, because security burden of password management Implementation Visualization Architecture Diagram:\ngraph LR User[User Browser] --\u003e WebApp[Battle Bots Web App] WebApp --\u003e AuthService[Auth Service] AuthService --\u003e DB[(Database)] AuthService --\u003e JWT[JWT Token Service] AuthService --\u003e Email[Email Service] Email --\u003e SMTP[SMTP Server] style WebApp fill:#e1f5ff style AuthService fill:#e8f5e9 style DB fill:#fff4e1 style JWT fill:#f3e5f5 style Email fill:#fff3e0 style SMTP fill:#f0f0f0 REST API Endpoints:\nAuthentication Endpoints:\nMethod Endpoint Auth Required Purpose POST /auth/register No Register new user account with email, password, and username. Sends verification email. POST /auth/login No Authenticate with email/password credentials. Returns JWT access token (15min) and refresh token (7 day). POST /auth/logout JWT Invalidates refresh token and terminates user session. POST /auth/refresh Refresh Token Exchanges valid refresh token for new access token. Email Verification Endpoints:\nMethod Endpoint Auth Required Purpose GET /auth/verify-email No Verifies email address using token from verification email (query param: token). POST /auth/resend-verification No Resends verification email to user’s registered email address. Password Management Endpoints:\nMethod Endpoint Auth Required Purpose POST /auth/forgot-password No Requests password reset. Sends reset email if account exists (always returns success to prevent enumeration). POST /auth/reset-password No Resets password using token from reset email. Requires token and new_password in request body. POST /auth/change-password JWT Changes password for authenticated user. Requires current_password and new_password. Sequence Diagram - Registration Flow:\nsequenceDiagram actor User participant WebApp as Battle Bots Web App participant Auth as Auth Service participant DB as Database participant Email as Email Service User-\u003e\u003eWebApp: POST /auth/register\u003cbr/\u003e{email, password, username} WebApp-\u003e\u003eAuth: Validate input (email format, password strength) alt Validation Failed Auth--\u003e\u003eWebApp: 400 Bad Request {errors} WebApp-\u003e\u003eUser: Show validation error messages else Validation Passed Auth-\u003e\u003eDB: Check if email exists DB--\u003e\u003eAuth: Email availability alt Email Already Exists Auth--\u003e\u003eWebApp: 409 Conflict WebApp-\u003e\u003eUser: Show \"Email already registered\" error else Email Available Auth-\u003e\u003eAuth: Hash password (bcrypt/argon2) Auth-\u003e\u003eDB: Create user account (unverified) DB--\u003e\u003eAuth: Account created Auth-\u003e\u003eAuth: Generate email verification token Auth-\u003e\u003eDB: Store verification token (with expiry) Auth-\u003e\u003eEmail: Send verification email with link:\u003cbr/\u003eGET /auth/verify-email?token=xxx Email--\u003e\u003eUser: Verification email delivered Auth--\u003e\u003eWebApp: 201 Created WebApp-\u003e\u003eUser: Show \"Check your email\" message end end Note over User,Email: User clicks verification link in email User-\u003e\u003eWebApp: GET /auth/verify-email?token=xxx WebApp-\u003e\u003eAuth: Validate verification token Auth-\u003e\u003eDB: Mark email as verified WebApp-\u003e\u003eUser: 200 OK - Email verified, redirect to login Sequence Diagram - Login Flow:\nsequenceDiagram actor User participant WebApp as Battle Bots Web App participant Auth as Auth Service participant DB as Database participant JWT as JWT Service User-\u003e\u003eWebApp: POST /auth/login\u003cbr/\u003e{email, password} WebApp-\u003e\u003eAuth: Authenticate credentials Auth-\u003e\u003eDB: Fetch user by email DB--\u003e\u003eAuth: User record alt User Not Found Auth--\u003e\u003eWebApp: 401 Unauthorized WebApp-\u003e\u003eUser: Show \"Invalid credentials\" error else User Found Auth-\u003e\u003eAuth: Verify password hash (bcrypt/argon2) alt Password Invalid Auth--\u003e\u003eWebApp: 401 Unauthorized WebApp-\u003e\u003eUser: Show \"Invalid credentials\" error else Password Valid alt Email Not Verified Auth--\u003e\u003eWebApp: 403 Forbidden {reason: \"email_not_verified\"} WebApp-\u003e\u003eUser: Show verification reminder +\u003cbr/\u003eoption to POST /auth/resend-verification else Email Verified Auth-\u003e\u003eJWT: Generate access token (15min expiry) JWT--\u003e\u003eAuth: Access token (JWT) Auth-\u003e\u003eJWT: Generate refresh token (7 day expiry) JWT--\u003e\u003eAuth: Refresh token Auth-\u003e\u003eDB: Store refresh token hash Auth--\u003e\u003eWebApp: 200 OK {access_token, refresh_token, expires_in} WebApp-\u003e\u003eUser: Store tokens, redirect to dashboard end end end Sequence Diagram - Password Reset Flow:\nsequenceDiagram actor User participant WebApp as Battle Bots Web App participant Auth as Auth Service participant DB as Database participant Email as Email Service Note over User,Email: Request Password Reset User-\u003e\u003eWebApp: Click \"Forgot Password\" link User-\u003e\u003eWebApp: POST /auth/forgot-password\u003cbr/\u003e{email} WebApp-\u003e\u003eAuth: Request password reset Auth-\u003e\u003eDB: Check if email exists Note over Auth,Email: Always return success (prevent email enumeration) Auth--\u003e\u003eWebApp: 200 OK {message: \"If account exists, email sent\"} WebApp-\u003e\u003eUser: Show \"Check your email\" message opt Email Exists Auth-\u003e\u003eAuth: Generate reset token (1 hour expiry) Auth-\u003e\u003eDB: Store reset token hash Auth-\u003e\u003eEmail: Send reset email with link:\u003cbr/\u003eGET /auth/reset-password?token=xxx Email--\u003e\u003eUser: Reset email delivered end Note over User,DB: Reset Password User-\u003e\u003eWebApp: GET /auth/reset-password?token=xxx\u003cbr/\u003e(click link in email) WebApp-\u003e\u003eAuth: Validate reset token Auth-\u003e\u003eDB: Check token validity \u0026 expiry alt Token Invalid/Expired Auth--\u003e\u003eWebApp: 400 Bad Request {error: \"invalid_token\"} WebApp-\u003e\u003eUser: Show error, offer POST /auth/forgot-password else Token Valid Auth--\u003e\u003eWebApp: 200 OK WebApp-\u003e\u003eUser: Show new password form User-\u003e\u003eWebApp: POST /auth/reset-password\u003cbr/\u003e{token, new_password} WebApp-\u003e\u003eAuth: Update password Auth-\u003e\u003eAuth: Hash new password (bcrypt/argon2) Auth-\u003e\u003eDB: Update password hash Auth-\u003e\u003eDB: Invalidate reset token Auth-\u003e\u003eEmail: Send password changed notification email Auth--\u003e\u003eWebApp: 200 OK WebApp-\u003e\u003eUser: Show success, redirect to POST /auth/login end Google OAuth authentication Single OAuth provider (Google) for registration and authentication.\nGood, because most users have Google accounts Good, because no password management needed Good, because Google OAuth is reliable and well-documented Neutral, because less aligned with developer-focused audience than GitHub Bad, because vendor dependency on Google Bad, because no fallback if Google OAuth is unavailable Implementation Visualization Architecture Diagram:\ngraph LR User[User Browser] --\u003e WebApp[Battle Bots Web App] WebApp --\u003e Google[Google OAuth] WebApp --\u003e DB[(Database)] WebApp --\u003e Session[Session Store] Google --\u003e User style WebApp fill:#e1f5ff style Google fill:#f0f0f0 style DB fill:#fff4e1 style Session fill:#fff4e1 REST API Endpoints:\nMethod Endpoint Auth Required Purpose GET /auth/google/login No Initiates Google OAuth flow by generating CSRF state token and redirecting to Google authorization page GET /auth/google/callback No Handles OAuth callback from Google, exchanges auth code for access token, validates ID token, fetches user profile, creates/updates account POST /auth/terms/accept Session Accepts terms of service for new user accounts (called before account creation) GET /auth/session Session Returns current authenticated user information and session status POST /auth/logout Session Terminates user session and clears authentication cookies/tokens Sequence Diagram - Registration/Login Flow:\nsequenceDiagram actor User participant WebApp as Battle Bots Web App participant Google as Google OAuth participant DB as Database participant Session as Session Store User-\u003e\u003eWebApp: GET /auth/google/login WebApp-\u003e\u003eWebApp: Generate CSRF state token WebApp-\u003e\u003eUser: 302 Redirect to Google OAuth User-\u003e\u003eGoogle: Authorize Battle Bots application alt Authorization Successful Google-\u003e\u003eWebApp: GET /auth/google/callback?code=xxx\u0026state=yyy WebApp-\u003e\u003eWebApp: Validate state token WebApp-\u003e\u003eGoogle: POST /token (exchange code) Google--\u003e\u003eWebApp: Return access_token \u0026 id_token (JWT) WebApp-\u003e\u003eWebApp: Validate ID token (JWT signature + claims) WebApp-\u003e\u003eGoogle: GET /oauth2/v2/userinfo (optional) Google--\u003e\u003eWebApp: Return user data (sub, email, name, picture) alt User Exists WebApp-\u003e\u003eDB: Update user profile DB--\u003e\u003eWebApp: Profile updated else New User WebApp-\u003e\u003eUser: Show Terms of Service page User-\u003e\u003eWebApp: POST /auth/terms/accept WebApp-\u003e\u003eDB: Create user account DB--\u003e\u003eWebApp: Account created end WebApp-\u003e\u003eSession: Create authenticated session Session--\u003e\u003eWebApp: Session token WebApp-\u003e\u003eUser: 302 Redirect to dashboard (with session cookie) else Authorization Failed/Cancelled Google-\u003e\u003eWebApp: GET /auth/google/callback?error=xxx WebApp-\u003e\u003eUser: Show error message end Support multiple OAuth providers (GitHub, Google, GitLab) Allow users to choose from multiple OAuth providers.\nGood, because provides user choice and flexibility Good, because reduces single vendor dependency Good, because accommodates different user preferences Bad, because significantly higher implementation complexity Bad, because need to handle account linking/merging Bad, because increases testing surface area Bad, because delays time to launch Bad, because more complex user experience (choice paralysis) Implementation Visualization Architecture Diagram:\ngraph TB User[User Browser] --\u003e WebApp[Battle Bots Web App] WebApp --\u003e OAuthGateway[OAuth Gateway/Strategy] OAuthGateway --\u003e GitHub[GitHub OAuth Provider] OAuthGateway --\u003e Google[Google OAuth Provider] OAuthGateway --\u003e GitLab[GitLab OAuth Provider] WebApp --\u003e DB[(Database)] WebApp --\u003e Session[Session Store] DB --\u003e UserAccounts[User Accounts Table] DB --\u003e LinkedProviders[Linked Providers Table] style WebApp fill:#e1f5ff style OAuthGateway fill:#e8f5e9 style GitHub fill:#f0f0f0 style Google fill:#f0f0f0 style GitLab fill:#f0f0f0 style DB fill:#fff4e1 style Session fill:#fff4e1 style UserAccounts fill:#fff9c4 style LinkedProviders fill:#fff9c4 REST API Endpoints:\nOAuth Authentication Endpoints (Provider-Agnostic):\nMethod Endpoint Auth Required Purpose GET /auth/:provider/login No Initiates OAuth flow for specified provider (:provider = github, google, or gitlab). Generates CSRF state and redirects. GET /auth/:provider/callback No Handles OAuth callback from specified provider. Exchanges code for token, fetches profile, handles account creation/linking logic. POST /auth/terms/accept Session Accepts terms of service for new user accounts (called before account creation). GET /auth/session Session Returns current authenticated user information, session status, and list of linked providers. POST /auth/logout Session Terminates user session and clears authentication cookies/tokens. Provider Management Endpoints:\nMethod Endpoint Auth Required Purpose GET /auth/providers Session (optional) Lists available OAuth providers. If authenticated, includes which providers are linked to current user’s account. POST /auth/link/:provider Session Initiates OAuth flow to link an additional provider to the authenticated user’s existing account. DELETE /auth/unlink/:provider Session Unlinks specified provider from authenticated user’s account. Requires at least one provider to remain linked. Sequence Diagram - Provider Selection and Registration:\nsequenceDiagram actor User participant WebApp as Battle Bots Web App participant Gateway as OAuth Gateway participant Provider as Selected OAuth Provider participant DB as Database participant Session as Session Store User-\u003e\u003eWebApp: GET /login (view login page) WebApp-\u003e\u003eWebApp: GET /auth/providers (fetch available) WebApp-\u003e\u003eUser: Show provider buttons (GitHub, Google, GitLab) User-\u003e\u003eWebApp: GET /auth/github/login (example: select GitHub) WebApp-\u003e\u003eGateway: Initiate OAuth with GitHub Gateway-\u003e\u003eGateway: Load provider-specific config \u0026 strategy Gateway-\u003e\u003eWebApp: Generate CSRF state token WebApp-\u003e\u003eUser: 302 Redirect to github.com/login/oauth/authorize User-\u003e\u003eProvider: Authorize Battle Bots application alt Authorization Successful Provider-\u003e\u003eGateway: GET /auth/github/callback?code=xxx\u0026state=yyy Gateway-\u003e\u003eGateway: Validate state token Gateway-\u003e\u003eProvider: Exchange code for access token Provider--\u003e\u003eGateway: Return access token Gateway-\u003e\u003eProvider: Fetch user profile Provider--\u003e\u003eGateway: Return user data (provider_id, email, name) Gateway-\u003e\u003eDB: Check if provider user ID exists alt Provider Account Already Linked DB--\u003e\u003eGateway: Found existing account Gateway-\u003e\u003eDB: Update profile from provider Gateway-\u003e\u003eSession: Create authenticated session Session--\u003e\u003eGateway: Session token Gateway-\u003e\u003eWebApp: 200 OK WebApp-\u003e\u003eUser: 302 Redirect to dashboard else New Provider Account Gateway-\u003e\u003eDB: Check email across all providers DB--\u003e\u003eGateway: Email lookup results alt Email Exists with Different Provider DB--\u003e\u003eGateway: Found account with same email Gateway-\u003e\u003eWebApp: Show account linking confirmation UI WebApp-\u003e\u003eUser: \"Link to existing account or create new?\" opt User Chooses to Link User-\u003e\u003eWebApp: POST /auth/link/github {confirm: true} WebApp-\u003e\u003eGateway: Link provider to existing account Gateway-\u003e\u003eDB: INSERT INTO linked_providers Gateway-\u003e\u003eSession: Create authenticated session WebApp-\u003e\u003eUser: 302 Redirect to dashboard end opt User Chooses New Account User-\u003e\u003eWebApp: Create separate account WebApp-\u003e\u003eUser: Show Terms of Service page User-\u003e\u003eWebApp: POST /auth/terms/accept Gateway-\u003e\u003eDB: INSERT INTO users (new account) Gateway-\u003e\u003eSession: Create authenticated session WebApp-\u003e\u003eUser: 302 Redirect to onboarding end else Email Not Found WebApp-\u003e\u003eUser: Show Terms of Service page User-\u003e\u003eWebApp: POST /auth/terms/accept Gateway-\u003e\u003eDB: INSERT INTO users + linked_providers Gateway-\u003e\u003eSession: Create authenticated session WebApp-\u003e\u003eUser: 302 Redirect to onboarding end end else Authorization Failed/Cancelled Provider-\u003e\u003eGateway: GET /auth/github/callback?error=access_denied Gateway-\u003e\u003eWebApp: OAuth failed WebApp-\u003e\u003eUser: Show error, return to GET /login end Sequence Diagram - Account Linking (Authenticated User):\nsequenceDiagram actor User participant WebApp as Battle Bots Web App participant Gateway as OAuth Gateway participant NewProvider as New OAuth Provider participant DB as Database Note over User,DB: User already authenticated, wants to link additional provider User-\u003e\u003eWebApp: GET /account/settings WebApp-\u003e\u003eWebApp: GET /auth/providers (with auth token) WebApp-\u003e\u003eUser: Show linked providers + \"Link GitHub\" button User-\u003e\u003eWebApp: POST /auth/link/github (click \"Link GitHub\") WebApp-\u003e\u003eGateway: Initiate OAuth for linking Gateway-\u003e\u003eGateway: Generate state token with user_id embedded Gateway-\u003e\u003eUser: 302 Redirect to github.com/login/oauth/authorize User-\u003e\u003eNewProvider: Authorize Battle Bots application alt Authorization Successful NewProvider-\u003e\u003eGateway: GET /auth/github/callback?code=xxx\u0026state=yyy Gateway-\u003e\u003eGateway: Validate state \u0026 extract user_id from state Gateway-\u003e\u003eNewProvider: POST /login/oauth/access_token (exchange code) NewProvider--\u003e\u003eGateway: Return access token Gateway-\u003e\u003eNewProvider: GET /user (fetch profile) NewProvider--\u003e\u003eGateway: Return provider user data (github_id, email) Gateway-\u003e\u003eDB: SELECT * FROM linked_providers\u003cbr/\u003eWHERE provider='github'\u003cbr/\u003eAND provider_user_id=github_id alt Provider Account Already Linked to Different User DB--\u003e\u003eGateway: Conflict - belongs to user_id=999 Gateway-\u003e\u003eWebApp: 409 Conflict {error: \"provider_already_linked\"} WebApp-\u003e\u003eUser: Show \"This GitHub account is already linked\u003cbr/\u003eto a different Battle Bots account\" else Provider Account Available Gateway-\u003e\u003eDB: INSERT INTO linked_providers\u003cbr/\u003e(user_id, provider, provider_user_id) DB--\u003e\u003eGateway: Link created successfully Gateway-\u003e\u003eWebApp: 200 OK {linked_providers: [...]} WebApp-\u003e\u003eUser: Show success + refresh GET /auth/providers end else Authorization Failed/Cancelled NewProvider-\u003e\u003eGateway: GET /auth/github/callback?error=access_denied Gateway-\u003e\u003eWebApp: 400 Bad Request {error: \"oauth_cancelled\"} WebApp-\u003e\u003eUser: Show \"Linking cancelled\" message end Key Implementation Considerations:\nProvider Strategy Pattern: Each OAuth provider (GitHub, Google, GitLab) has its own strategy implementing a common interface for authorization, token exchange, and profile fetching Account Linking Logic: Must handle cases where users authenticate with different providers but share the same email Data Model: Requires linked_providers table with columns: user_id, provider, provider_user_id, provider_username, linked_at Testing Complexity: Need integration tests for each provider plus account linking scenarios User Experience: Clear messaging when email conflicts occur across providers More Information Related to User Journey 0001 (User Registration and Authentication).\nThis decision focuses on the initial launch strategy. Future ADRs may address:\nAdding additional OAuth providers based on user feedback Account migration strategies if switching providers Service account or API key authentication for bot deployments ","categories":"","description":"How users will register and authenticate with the Battle Bots platform using GitHub OAuth and stateless JWT tokens\n","excerpt":"How users will register and authenticate with the Battle Bots platform …","ref":"/battlebots/pr-preview/pr-139/rd/adrs/0002-user-registration-via-github-oauth/","tags":"","title":"[0002] User Registration via GitHub OAuth"},{"body":"Executive Summary This document analyzes Keycloak’s login page solutions to determine whether using Keycloak as an open-source identity and access management (IAM) provider would be beneficial for the Battle Bots platform instead of implementing custom login pages or using a managed service like Auth0. Given that Battle Bots plans to use GitHub OAuth for user registration and authentication, this analysis evaluates how Keycloak could serve as an authentication layer.\nKey Finding: Keycloak offers a powerful, open-source alternative to managed services like Auth0, providing enterprise-grade authentication features without per-user licensing costs. However, it requires significant operational investment in hosting, maintenance, and security management. For Battle Bots’ specific use case with a single social identity provider (GitHub), Keycloak introduces substantial infrastructure complexity that may outweigh its benefits during the MVP and early growth phases. Direct GitHub OAuth implementation is recommended for MVP, with Keycloak as a strategic option only if self-hosted identity management becomes a priority.\nOverview of Keycloak What is Keycloak? Keycloak is an open-source Identity and Access Management (IAM) solution sponsored by Red Hat and maintained by a large community. It provides single sign-on (SSO) with Identity and Access Management aimed at modern applications and services.\nCore Capabilities:\nOAuth 2.0, OpenID Connect (OIDC), and SAML 2.0 protocol support Social login with GitHub, Google, Facebook, Twitter, and other providers Identity brokering and federation User federation (LDAP, Active Directory) Fine-grained authorization services Built-in user management console Account management console for end users Admin REST API License: Apache 2.0 (completely free and open-source)\nKeycloak Architecture Keycloak follows a centralized authentication model:\nRealm: Isolated authentication and authorization domain Clients: Applications that use Keycloak for authentication Users: Individuals who authenticate through Keycloak Identity Providers: External authentication sources (GitHub, Google, LDAP, etc.) Roles and Groups: Authorization constructs for access control Keycloak Login Page Options Hosted Login (Primary Approach) What it is: Keycloak’s default authentication flow where users are redirected to Keycloak’s centralized login page for authentication, then returned to the application with tokens.\nKey Characteristics:\nHosted on your Keycloak infrastructure (self-hosted or managed service) Redirect-based authentication flow (similar to Auth0 Universal Login) Centralized security management across all applications in a realm Supports all authentication methods: password, social providers, MFA, passwordless How it works:\nUser attempts to access Battle Bots application Application redirects to Keycloak’s login page Keycloak handles authentication (password, GitHub OAuth, MFA, etc.) Keycloak creates user session and returns tokens User redirected back to Battle Bots application authenticated No embedded authentication code required in application Direct Grant Flow (Not Recommended for Web Apps) What it is: REST API-based authentication where the application directly sends credentials to Keycloak’s token endpoint.\nKey Characteristics:\nNo redirect required; application handles credentials directly Credentials flow directly from application to Keycloak Primarily designed for non-browser clients (CLI tools, mobile apps) Disabled by default due to security concerns Why Not Recommended:\nViolates OAuth 2.0 best practices for web applications Application has access to user credentials (security risk) Cannot leverage social login providers effectively Susceptible to phishing and credential theft Recommendation: Use hosted login (authorization code flow) for web applications.\nUI Customization Capabilities Keycloak provides extensive theming and customization options for its login pages.\nTheme Architecture Keycloak uses a theme-based architecture with multiple theme types:\nLogin: Login, registration, forgot password, email verification pages Account: User account management console Admin: Administrative console Email: Email templates for verification, password reset, etc. Welcome: Initial welcome page Customization Methods 1. Quick Theme (New in Recent Versions) What it is: Experimental utility for rapidly customizing themes without editing files.\nCapabilities:\nChange logos and branding Modify color schemes Update visual appearance of login, admin, and account consoles No file system access required Limitations:\nLimited to basic visual customization Cannot modify HTML structure or authentication flows Experimental feature, may change in future versions 2. Theme Templates (Full Customization) What it is: File-based theme system using Apache FreeMarker templates.\nTechnology Stack:\nTemplating Engine: Apache FreeMarker (.ftl files) Styling: CSS/SCSS Scripts: JavaScript Resources: Images, fonts, custom assets Customization Process:\nCreate theme directory in themes/ folder (e.g., themes/battlebots/) Add login/ subdirectory for login page themes Create or override FreeMarker templates Add custom CSS in login/resources/css/ Add custom JavaScript in login/resources/js/ Configure theme properties in theme.properties Extend existing theme (e.g., parent=keycloak) to inherit base styles Deploy theme to Keycloak instance What Can Be Customized:\nComplete HTML structure through FreeMarker templates All CSS styling and layouts JavaScript behavior and interactivity Login flow UI (username/password form, social login buttons, MFA screens) Registration forms and fields Error messages and validation Language and localization (i18n support) Branding elements (logos, colors, fonts, backgrounds) Example Theme Structure:\nthemes/battlebots/ ├── login/ │ ├── theme.properties # Theme configuration │ ├── messages/ # Localization files │ │ ├── messages_en.properties │ │ └── messages_es.properties │ ├── resources/ │ │ ├── css/ │ │ │ └── login.css # Custom styles │ │ ├── js/ │ │ │ └── custom.js # Custom scripts │ │ └── img/ │ │ └── logo.png # Branding assets │ └── login.ftl # Main login template │ └── register.ftl # Registration template │ └── error.ftl # Error page template Development Workflow:\nDisable caching during development: --spi-theme-static-max-age=-1 --spi-theme-cache-themes=false --spi-theme-cache-templates=false Edit templates and resources directly Refresh browser to see changes immediately Enable caching for production deployment Community Themes The Keycloak community has developed numerous pre-built themes:\nKeywind: Modern theme built with Tailwind CSS Material UI Theme: Material Design-based login pages Custom corporate themes: Banking, healthcare, enterprise designs These themes can serve as starting points for custom Battle Bots theming.\nCustomization Comparison Aspect Quick Theme Template Customization Setup Complexity Very low (UI-based) Medium (file-based) Branding Control Basic (colors, logos) Complete (all HTML/CSS/JS) HTML Structure Fixed Fully customizable Authentication Flow Standard only Can modify presentations Maintenance Easy (UI updates) Requires theme version management Developer Skills None required HTML, CSS, FreeMarker knowledge Production Suitability Limited Full production-ready Customization Verdict: Keycloak provides superior customization capabilities compared to Auth0, with complete control over HTML/CSS/JavaScript. However, this requires more technical expertise and maintenance effort.\nGitHub OAuth Integration with Keycloak Keycloak provides native support for GitHub as a social identity provider.\nSetup Process 1. Create GitHub OAuth App Navigate to GitHub Developer Settings:\nGo to GitHub Settings \u003e Developer Settings \u003e OAuth Apps Click “New OAuth App” Configure application details: Application name: Battle Bots (Keycloak) Homepage URL: https://battlebots.com Authorization callback URL: https://\u003ckeycloak-domain\u003e/realms/\u003crealm-name\u003e/broker/github/endpoint Generate client secret and save credentials 2. Configure Keycloak Identity Provider In Keycloak Admin Console:\nNavigate to Identity Providers Select GitHub from social providers list Enter configuration: Client ID: From GitHub OAuth app Client Secret: From GitHub OAuth app First Login Flow: first broker login (default) Sync Mode: force (to sync profile updates) Configure optional settings: Store tokens: Enable to access GitHub API on behalf of user Trust email: Verify email from GitHub Default scopes: user:email (can request additional scopes) Save configuration 3. Enable for Application Navigate to Clients in Keycloak Select Battle Bots application client Verify GitHub identity provider is enabled Test using “Try it out” feature in Identity Provider settings User Authentication Flow With GitHub social identity provider configured:\nUser visits Battle Bots application User clicks “Sign In” Application redirects to Keycloak login page Keycloak displays “Sign in with GitHub” button (customizable) User clicks GitHub button Redirected to GitHub authorization page User authorizes Battle Bots access to GitHub profile GitHub redirects back to Keycloak callback URL Keycloak processes GitHub response: Creates or updates user account in realm Establishes Keycloak session Generates OAuth/OIDC tokens for application User redirected back to Battle Bots application with tokens Data Synchronization User Profile Mapping: Keycloak automatically maps GitHub profile data to user attributes:\nUsername: GitHub username (or email, configurable) Email: Primary GitHub email First Name: Parsed from GitHub name field Last Name: Parsed from GitHub name field Profile Picture: GitHub avatar URL GitHub User ID: Stored as identity provider link Custom Attribute Mapping: Use Identity Provider Mappers to:\nExtract additional GitHub profile data Map GitHub organizations to Keycloak roles Sync GitHub team membership to groups Store GitHub access token for API calls Token Storage: When “Store Tokens” is enabled:\nGitHub access token stored in Keycloak database Available through Admin REST API Can be used for GitHub API calls on behalf of user Refreshed according to GitHub token lifecycle Identity Brokering Features Account Linking:\nUsers can link multiple identity providers to single Keycloak account GitHub account + password authentication GitHub account + Google account (if added later) First Login Flow:\nCustomizable authentication flow for first-time GitHub users Can request additional profile information Enforce terms of service acceptance Set default roles and group memberships Deployment Options Keycloak’s self-hosted nature requires infrastructure planning and operational management.\nSelf-Hosted Deployment Container-Based Deployment (Recommended) Docker Standalone:\ndocker run -p 8443:8443 \\ -e KC_BOOTSTRAP_ADMIN_USERNAME=admin \\ -e KC_BOOTSTRAP_ADMIN_PASSWORD=\u003csecure-password\u003e \\ -e KC_DB=postgres \\ -e KC_DB_URL=jdbc:postgresql://db:5432/keycloak \\ -e KC_DB_USERNAME=keycloak \\ -e KC_DB_PASSWORD=\u003cdb-password\u003e \\ -e KC_HOSTNAME=auth.battlebots.com \\ quay.io/keycloak/keycloak:latest \\ start --optimized Kubernetes/OpenShift:\nUse Keycloak Operator for automated deployment Supports horizontal scaling and high availability Integrates with Kubernetes ingress and cert-manager Declarative configuration with Custom Resources Docker Compose (Development/Small Production):\nservices: postgres: image: postgres:15 environment: POSTGRES_DB: keycloak POSTGRES_USER: keycloak POSTGRES_PASSWORD: ${DB_PASSWORD} volumes: - postgres_data:/var/lib/postgresql/data keycloak: image: quay.io/keycloak/keycloak:latest command: start --optimized environment: KC_DB: postgres KC_DB_URL: jdbc:postgresql://postgres:5432/keycloak KC_DB_USERNAME: keycloak KC_DB_PASSWORD: ${DB_PASSWORD} KC_HOSTNAME: auth.battlebots.com KC_BOOTSTRAP_ADMIN_USERNAME: admin KC_BOOTSTRAP_ADMIN_PASSWORD: ${ADMIN_PASSWORD} ports: - \"8443:8443\" depends_on: - postgres Virtual Machine / Bare Metal System Requirements:\nCPU: 2+ cores for development, 4+ cores for production Memory: Minimum 2 GB, recommended 4-8 GB for production Storage: 10+ GB for application and database Operating System: Linux (preferred), Windows, macOS Installation Methods:\nDownload standalone distribution (ZIP/TAR.GZ) Install from package manager (RPM, DEB) Build from source Database Requirements Supported Databases:\nPostgreSQL (recommended) MySQL / MariaDB Oracle Microsoft SQL Server H2 (development only, NOT for production) Production Database Configuration:\nHigh Availability: Primary-secondary replication Connection Pooling: Initial/Min/Max pool size should be equal for best performance Recommended: initial=20, min=20, max=100 for 3-5 node cluster Connection Limits: Max connections × max Keycloak instances ≤ database connection limit Default PostgreSQL limit: 100 connections Security: SSL/TLS for database connections Network isolation (database in private subnet) Backups: Regular automated backups Point-in-time recovery capability High Availability and Clustering Clustering Requirements: Keycloak runs on JGroups and Infinispan for distributed caching.\nCluster Configuration:\nMinimum: 2 Keycloak instances behind load balancer Recommended Production: 3-5 instances across availability zones Load Balancer: Sticky sessions NOT required (stateless tokens) Health check endpoints: /health, /health/ready, /health/live SSL/TLS termination at load balancer or end-to-end encryption Cache Distribution:\nUser sessions distributed across cluster Authentication sessions synchronized Realm and client metadata cached Database Considerations:\nAll instances share single database Database becomes single point of failure (use replication) Database connection pool sizing critical for performance TLS/HTTPS Requirements Production Security: Keycloak enforces “secure by default” in production mode:\nHTTPS required (HTTP disabled) Valid TLS certificate required at startup Hostname must be configured Without proper TLS, Keycloak fails to start Certificate Options:\nLet’s Encrypt (free, automated renewal) Commercial CA certificates Internal CA for private networks Reverse proxy TLS termination (nginx, HAProxy, Traefik) Resource Requirements Summary Environment CPU Memory Storage Instances Development 2 cores 750 MB - 2 GB 10 GB 1 Small Production 4 cores 2-4 GB 20 GB 2 Medium Production 8 cores 4-8 GB 50 GB 3-5 Enterprise 16+ cores 8-16 GB 100+ GB 5-10+ Managed Keycloak Services For organizations wanting Keycloak without self-hosting complexity:\nCommercial Providers:\nRed Hat SSO: Enterprise support for Keycloak ($50,000-$200,000/year) Phase Two: Managed Keycloak hosting ($500-$5,000/month) Inteca: Architecture-driven pricing (not per-user) SkyCloak: Managed Keycloak service Cloud IAM: Keycloak-based identity platform Managed Service Benefits:\nNo infrastructure management Automatic updates and security patches Professional support and SLAs Reduced operational burden Faster time to deployment Managed Service Costs:\nSignificantly lower than Auth0 for high user volumes Fixed monthly fees (not per-user) Ranges from $500/month (small) to $5,000+/month (enterprise) Pros and Cons for Battle Bots Platform Pros of Using Keycloak 1. Cost Advantages (Long-Term) No Per-User Licensing:\nOpen-source with Apache 2.0 license No costs based on monthly active users (MAUs) Predictable infrastructure costs regardless of user growth Scales from thousands to millions of users without licensing fees Cost Comparison (100,000 Users):\nAuth0: ~$1,785/month + usage fees Keycloak Self-Hosted: ~$1,250-$2,000/month (infrastructure only) Keycloak Managed: ~$2,000-$5,000/month (full service) Break-Even Analysis: For user bases exceeding 25,000-50,000 active users, Keycloak becomes significantly more cost-effective than managed services like Auth0.\n2. Complete Control and Customization No Vendor Lock-In:\nFull access to source code Can fork and modify if needed Export users and configurations anytime No dependency on external vendor roadmap or pricing changes Deep Customization:\nModify authentication flows completely Custom authentication mechanisms (SPIs) Custom user storage providers Complete theme control (HTML/CSS/JavaScript) Extend functionality through plugins 3. Privacy and Data Sovereignty Data Ownership:\nAll user data stored in your infrastructure No third-party service has access to user credentials Complete audit trail ownership Compliance with data residency requirements Security Posture:\nInternal security team controls all aspects No external attack surface through vendor Can implement company-specific security policies Custom vulnerability scanning and penetration testing 4. Enterprise-Grade Features (Free) Included Capabilities:\nSingle Sign-On (SSO) across unlimited applications Identity brokering with unlimited providers User federation (LDAP, Active Directory) Fine-grained authorization services Multi-factor authentication (TOTP, WebAuthn) Social login (GitHub, Google, Facebook, etc.) SAML and OpenID Connect support Kerberos integration Custom authentication flows No Feature Paywalls: Unlike Auth0, advanced features like custom domains, MFA, and multiple social providers are included without additional costs.\n5. Active Open-Source Community Community Benefits:\nLarge, active community for support Extensive documentation and tutorials Community-contributed themes and extensions Regular security updates Transparent development process Sponsored by Red Hat (long-term stability) 6. Flexibility and Integration Integration Options:\nREST Admin API for automation Client adapters for multiple languages (Java, Node.js, JavaScript) OpenID Connect and OAuth 2.0 standard compliance SAML 2.0 for enterprise integrations Event listeners for custom business logic 7. GitHub OAuth Native Support Built-In Provider:\nGitHub identity provider included out-of-box Simple configuration (just Client ID and Secret) Profile mapping and synchronization Token storage for GitHub API access Support for GitHub organizations and teams Cons of Using Keycloak 1. Operational Complexity Infrastructure Management:\nRequires provisioning and managing servers/containers Database setup, configuration, and maintenance Load balancer configuration TLS/SSL certificate management Monitoring and alerting setup Log aggregation and analysis Backup and disaster recovery planning Maintenance Burden:\nSecurity updates must be applied manually Version upgrades require planning and testing Cluster coordination during updates Database migrations and backups Regular health checks and monitoring Approximately 12 hours/month of maintenance work Expertise Required:\nDevOps knowledge for infrastructure Database administration Security hardening Kubernetes/Docker proficiency (for container deployment) Java/JBoss troubleshooting skills 2. Initial Implementation Time Longer Setup: Compared to managed services, Keycloak requires:\nInfrastructure provisioning (1-3 days) Keycloak installation and configuration (1-2 days) Database setup and tuning (1-2 days) TLS/HTTPS configuration (0.5-1 day) Theme development (2-5 days) Integration testing (2-3 days) Security hardening (2-3 days) Total Estimated Implementation:\nBasic setup: 1-2 weeks Production-ready with custom theming: 3-4 weeks Enterprise-ready with HA: 4-6 weeks 3. Hosting and Infrastructure Costs Initial Costs:\nDevelopment environment setup: $45,000-$75,000 (opportunity cost) Production infrastructure: $600-$800/month minimum High-availability setup: $1,250-$2,000/month Ongoing Costs:\nInfrastructure hosting: $600-$2,000/month Maintenance labor: ~12 hours/month ($360-$600/month) Security audits: $20,000-$50,000/year (amortized) Backup storage: $50-$200/month Monitoring tools: $100-$500/month Hidden Costs:\nDeveloper time for troubleshooting issues Incident response and on-call rotation Disaster recovery testing Compliance documentation and audits 4. Security Responsibility Self-Managed Security:\nTeam responsible for all security patches Must monitor CVE databases and security advisories Vulnerability scanning and penetration testing required Security audit trail implementation CSRF, XSS, and injection attack protection Rate limiting and bot detection implementation No Automatic Updates: Unlike managed services, security patches require:\nMonitoring security channels Testing patches in staging environment Scheduling maintenance window Deploying to production Verifying successful deployment Risk: Delayed patching due to internal processes could expose vulnerabilities.\n5. Limited Commercial Support Community Support Only (Free):\nStack Overflow, mailing lists, GitHub issues Response time not guaranteed Quality varies depending on community availability Complex issues may go unresolved Paid Support Options:\nRed Hat SSO: Expensive ($50,000-$200,000/year) Third-party consultants: Variable quality and cost Managed Keycloak providers: Adds cost similar to managed services 6. Version Upgrade Complexity Breaking Changes:\nMajor version upgrades may require code changes Theme customizations may break with new versions Database migration scripts required Testing burden for each upgrade Upgrade Process:\nReview release notes for breaking changes Test in development environment Update custom themes and extensions Run database migrations Test all authentication flows Deploy to staging for integration testing Schedule production upgrade maintenance window Monitor for issues post-upgrade 7. Scalability Challenges Scaling Complexity:\nHorizontal scaling requires cluster configuration Database becomes bottleneck at high scale Cache invalidation complexity across cluster Session replication overhead Requires load testing and performance tuning Database Scaling:\nRead replicas for query distribution Connection pool optimization critical May need database sharding for extreme scale Requires database administration expertise 8. Overkill for MVP / Early Stage Feature Overload:\nMany advanced features unused in early stages Complex configuration options overwhelming Maintenance overhead not justified by user base Simpler solutions (direct OAuth) more appropriate initially Time to Market: Keycloak deployment delays MVP launch compared to:\nDirect GitHub OAuth: 3-5 days Auth0: 2-4 days Keycloak: 3-4 weeks Security Considerations Security Strengths Standards Compliance:\nOAuth 2.0 and OpenID Connect 1.0 certified SAML 2.0 protocol support Industry-standard cryptographic algorithms Regular security audits by community and Red Hat Built-In Security Features:\nCSRF protection through state parameter Brute-force detection and account lockout Password policies and complexity requirements Session timeout and idle timeout Token expiration and refresh mechanisms Secure token storage (signed and encrypted JWTs) Attack Protection:\nBot detection capabilities Rate limiting (requires configuration) IP allowlisting/blocklisting Captcha integration support Security headers (X-Frame-Options, CSP, HSTS) Compliance Capabilities:\nGDPR compliance features (data export, right to be forgotten) Audit logging of all authentication events User consent management Data retention policies Security Weaknesses Self-Managed Responsibility:\nNo automatic security patching (manual process) Delayed response to zero-day vulnerabilities Requires dedicated security monitoring Team must stay current on security best practices Configuration Complexity:\nMisconfigurations can create vulnerabilities Many security settings require manual configuration Default settings may not meet all security requirements Requires security expertise to harden properly Open Source Considerations:\nSource code publicly available (transparent but also visible to attackers) Community-driven security response (not SLA-backed) Security patches depend on community reporting and response time Security Comparison Aspect Keycloak Self-Hosted Auth0 Direct GitHub OAuth Automatic Security Updates No (manual) Yes N/A (developer responsibility) Attack Protection Yes (requires configuration) Yes (automatic) No (must implement) Security Certifications Community audits SOC 2, ISO 27001, GDPR GitHub’s security Vulnerability Response Community-driven Vendor SLA Developer responsibility CSRF Protection Built-in Built-in Must implement MFA Support Yes (free) Yes (paid tier) Must implement separately Audit Logging Yes (self-managed) Yes (managed) Must implement Security Team Requirement Yes (internal) No (vendor provides) Yes (internal) Security Verdict: Keycloak provides robust security features comparable to Auth0, but requires internal expertise to configure, monitor, and maintain. Auth0 offers better “security by default” with managed updates. Direct GitHub OAuth places entire security burden on Battle Bots team.\nIntegration Complexity Analysis Keycloak Integration Requirements Backend Integration Setup Tasks:\nDeploy Keycloak infrastructure (database, application, load balancer) Create realm for Battle Bots Configure GitHub identity provider Register Battle Bots as client application Configure redirect URIs and CORS settings Implement OIDC/OAuth 2.0 client in application Validate and verify JWT tokens from Keycloak Extract user information from ID tokens Map Keycloak user IDs to application users Implement token refresh logic Handle session synchronization Implement logout (local + SSO logout) Go Integration Example:\nimport ( \"github.com/coreos/go-oidc/v3/oidc\" \"golang.org/x/oauth2\" ) // Configure OAuth2 client oauth2Config := oauth2.Config{ ClientID: \"battlebots\", ClientSecret: \"client-secret\", Endpoint: oauth2.Endpoint{ AuthURL: \"https://auth.battlebots.com/realms/battlebots/protocol/openid-connect/auth\", TokenURL: \"https://auth.battlebots.com/realms/battlebots/protocol/openid-connect/token\", }, RedirectURL: \"https://battlebots.com/callback\", Scopes: []string{oidc.ScopeOpenID, \"profile\", \"email\"}, } // Verify ID tokens provider, _ := oidc.NewProvider(ctx, \"https://auth.battlebots.com/realms/battlebots\") verifier := provider.Verifier(\u0026oidc.Config{ClientID: \"battlebots\"}) Frontend Integration Implementation Tasks:\nAdd “Sign In” button that redirects to Keycloak Handle callback from Keycloak Store tokens (access, refresh, ID tokens) securely Implement token refresh before expiration Send access token with API requests Handle token expiration and re-authentication Implement logout functionality Handle session timeout Estimated Implementation Time:\nInfrastructure setup: 1-2 weeks Application integration: 3-5 days Testing and hardening: 3-5 days Total: 3-4 weeks for production-ready implementation Comparison with Alternatives Aspect Keycloak Auth0 Direct GitHub OAuth Infrastructure Setup 1-2 weeks (self-host) None (managed) None (GitHub API) Application Integration 3-5 days 2-4 days 3-5 days Security Hardening 3-5 days Included 2-3 weeks Total Time to Production 3-4 weeks 2-4 days 2-3 weeks Ongoing Maintenance 12 hours/month None 2-4 hours/month Scaling Complexity High (cluster management) None (managed) Low (stateless) Integration Complexity Verdict: Keycloak has highest initial complexity due to infrastructure requirements, but ongoing application integration is comparable to other OAuth/OIDC providers. Auth0 is fastest to production. Direct GitHub OAuth is simpler architecturally but requires more security implementation work.\nCost Analysis Self-Hosted Keycloak Total Cost of Ownership Initial Setup Costs (One-Time) Development and Implementation:\nInfrastructure design and provisioning: 40-60 hours ($6,000-$9,000) Keycloak installation and configuration: 40-60 hours ($6,000-$9,000) Database setup and optimization: 20-30 hours ($3,000-$4,500) Security hardening and audit: 60-80 hours ($9,000-$12,000) Theme development and customization: 40-80 hours ($6,000-$12,000) Integration development and testing: 60-80 hours ($9,000-$12,000) Total Initial Investment: $39,000-$58,500 Alternatively, using opportunity cost calculation:\nSenior developer time: 300-500 hours At $150/hour: $45,000-$75,000 opportunity cost Monthly Recurring Costs Infrastructure (Minimum Production Setup):\nCompute (2-3 Keycloak instances): $200-$400/month Database (PostgreSQL with replication): $150-$300/month Load balancer: $50-$100/month Storage and backups: $50-$100/month Networking and data transfer: $50-$100/month Monitoring and logging tools: $100-$200/month Total Infrastructure: $600-$1,200/month Labor and Maintenance:\nSystem administration (12 hours/month at $50/hour): $600/month Security monitoring and patching: $200/month (amortized) Backup verification and DR testing: $100/month (amortized) Total Labor: $900/month Other Costs:\nSecurity audits and penetration testing: $1,667/month ($20,000/year amortized) SSL certificates: $10-$50/month (or free with Let’s Encrypt) Total Other: $1,677-$1,717/month Total Monthly Cost (Self-Hosted): $2,100-$3,800/month\nHigh-Availability Setup For production-grade HA deployment:\nAdditional Keycloak instances (3-5 total): $300-$600/month Multi-AZ database with failover: $300-$500/month Additional load balancer redundancy: $50-$100/month Enhanced monitoring and alerting: $100-$200/month Total Monthly Cost (HA): $3,000-$5,000/month Managed Keycloak Services Costs Commercial Providers:\nRed Hat SSO: $50,000-$200,000/year ($4,167-$16,667/month)\nEnterprise support and SLAs Self-hosted with vendor support Priced per CPU core or subscription tier Phase Two Managed Keycloak: $500-$5,000/month\nFully hosted and managed No per-user fees Professional support included Custom domains and theming Inteca Managed Keycloak: $1,000-$5,000/month\nArchitecture-driven pricing (not per-user) Suitable for millions of users No scaling cost surprises Cost Comparison by User Volume Monthly Active Users Self-Hosted Keycloak Managed Keycloak Auth0 Direct GitHub OAuth 1,000 $2,100-$3,800 $500-$1,000 Free - $52 $0 + dev time 10,000 $2,100-$3,800 $1,000-$2,000 $210 $0 + dev time 25,000 $2,500-$4,000 $1,500-$3,000 $472 $0 + dev time 50,000 $3,000-$5,000 $2,000-$4,000 $910 $0 + dev time 100,000 $3,000-$5,000 $2,500-$5,000 $1,785 $0 + dev time 500,000 $3,500-$6,000 $3,000-$5,000 $8,785 $0 + dev time 1,000,000 $4,000-$7,000 $4,000-$5,000 $17,535 $0 + dev time Cost Analysis Observations:\nBelow 25,000 Users:\nDirect GitHub OAuth most cost-effective Auth0 competitive with managed Keycloak Self-hosted Keycloak not justified by user volume 25,000-100,000 Users:\nManaged Keycloak becomes competitive Auth0 costs rising significantly Self-hosted Keycloak approaching break-even Above 100,000 Users:\nKeycloak (self-hosted or managed) significantly cheaper Auth0 costs escalate dramatically Keycloak cost scales minimally with user growth 1 Million+ Users:\nSelf-hosted Keycloak: $4,000-$7,000/month Managed Keycloak: $4,000-$5,000/month Auth0: $17,535+/month (continues scaling) Direct OAuth: Still $0 licensing but high operational burden Cost Verdict For Battle Bots:\nMVP Phase (\u003c 5,000 users): Direct GitHub OAuth is most cost-effective Growth Phase (5,000-25,000 users): Auth0 or managed Keycloak comparable Scale Phase (25,000+ users): Keycloak becomes significantly more economical Enterprise Phase (100,000+ users): Keycloak provides 60-80% cost savings vs. Auth0 Comparison with Alternatives Keycloak vs. Auth0 Aspect Keycloak Auth0 Deployment Self-hosted or managed service Fully managed cloud service Cost Model Infrastructure + labor, no per-user fees Per-user subscription pricing Initial Setup 3-4 weeks 2-4 days Customization Complete control (HTML/CSS/JS/Java) Limited to theme templates Maintenance Self-managed (12 hours/month) Fully managed by vendor Security Updates Manual application Automatic Vendor Lock-In None (open-source) High GitHub OAuth Native support Native support MFA Included free Paid tier Custom Domain Included free Paid tier Social Providers Unlimited free Limited by tier Cost at 100K Users $3,000-$5,000/month $1,785/month Cost at 1M Users $4,000-$7,000/month $17,535/month Community Support Active open-source community Commercial support SLAs None (self-hosted) or vendor SLA (managed) Tier-based SLAs When to Choose Keycloak over Auth0:\nUser base expected to exceed 50,000 active users Need complete control over authentication infrastructure Data sovereignty and privacy requirements Want to avoid vendor lock-in Have DevOps/infrastructure team capacity Need advanced customization beyond theme templates Budget-constrained with high projected user growth When to Choose Auth0 over Keycloak:\nRapid time to market is priority Small team without DevOps expertise User base under 50,000 for foreseeable future Prefer managed service over infrastructure management Need commercial SLAs and support Want automatic security updates without maintenance burden Keycloak vs. Direct GitHub OAuth Aspect Keycloak Direct GitHub OAuth Architecture Centralized IAM layer Direct integration Initial Setup 3-4 weeks 3-5 days Infrastructure Requires servers, database, LB No additional infrastructure GitHub Integration Pre-built identity provider Custom OAuth 2.0 implementation Multi-Provider Support Easy to add Google, Discord, etc. Requires implementing each provider MFA Built-in (TOTP, WebAuthn) Must implement separately User Management Admin console included Must build custom admin SSO Across Apps Automatic Must implement session sharing Maintenance 12 hours/month 2-4 hours/month (once stable) Complexity High (infrastructure + app) Low (application only) Cost $2,100-$3,800/month $0 licensing Control Complete Complete Vendor Dependency None None When to Choose Keycloak over Direct GitHub OAuth:\nPlan to add multiple authentication providers (Google, Discord, Steam) Need SSO across multiple Battle Bots services Want enterprise features (LDAP, SAML, user federation) Need advanced MFA options Require user management admin console Have compliance requirements (audit logs, consent management) Organization has existing Keycloak deployment When to Choose Direct GitHub OAuth over Keycloak:\nGitHub is only authentication method needed long-term Want simplest possible architecture Small team focused on core product features No infrastructure management capacity Prefer fewer moving parts and dependencies MVP and early-stage product Cost optimization is priority Alternative Open-Source IAM Solutions Ory Kratos Pros:\nModern, cloud-native architecture API-first design (headless) Self-hosted, open-source (Apache 2.0) Lower resource requirements than Keycloak Cons:\nSmaller community than Keycloak Less mature ecosystem Fewer pre-built integrations Limited admin UI (API-focused) Best For: Organizations wanting cloud-native, API-first IAM with less complexity than Keycloak.\nAuthentik Pros:\nModern Python-based architecture Excellent admin UI Built-in application proxy Active development and community Cons:\nSmaller community than Keycloak Fewer enterprise deployments Less documentation Best For: Organizations preferring Python stack and modern UI over Java-based Keycloak.\nComparison Summary For Battle Bots’ requirements (GitHub OAuth, developer audience, Go backend):\nDirect GitHub OAuth: Best for MVP and early stage Auth0: Best for rapid deployment with managed service Keycloak: Best for scale (50,000+ users) with internal DevOps team Ory Kratos: Best for cloud-native, API-first approach Authentik: Best for Python-friendly teams wanting open-source Recommendations for Battle Bots Project Primary Recommendation: Start with Direct GitHub OAuth Rationale:\nBattle Bots is using GitHub OAuth as sole authentication method Keycloak introduces significant infrastructure complexity without immediate value Team can focus on core product features instead of IAM infrastructure No recurring costs or operational overhead Simpler architecture appropriate for MVP phase Sufficient security with proper OAuth 2.0 implementation Timeline:\nImplement for MVP and initial launch Maintain through early growth phase (\u003c 10,000 users) Re-evaluate when reaching architectural decision thresholds Implementation Approach:\nUse established Go OAuth library (golang.org/x/oauth2) Implement GitHub OAuth 2.0 authorization code flow Add CSRF protection via state parameter Implement secure session management (HTTPOnly, Secure cookies) Add rate limiting to prevent abuse Implement basic audit logging Document authentication flow for future reference Secondary Recommendation: Design for Future Migration Rationale:\nKeep Keycloak as strategic option for future growth Design authentication abstraction layer enabling easy migration Avoid tight coupling to GitHub OAuth implementation Prepare for potential multi-provider future Authentication Abstraction Pattern:\n// Define authentication interface type Authenticator interface { GetAuthURL(state string) string Exchange(code string) (*User, error) GetUser(token string) (*User, error) RefreshToken(refreshToken string) (*Token, error) } // Implement GitHub OAuth adapter type GitHubAuthenticator struct { oauth2Config *oauth2.Config } // Future: Implement Keycloak adapter type KeycloakAuthenticator struct { oidcProvider *oidc.Provider oauth2Config *oauth2.Config } When to Consider Keycloak Evaluate Keycloak migration when Battle Bots reaches any of these thresholds:\nThreshold 1: Multiple Authentication Providers Needed Adding Google, Discord, Steam, or other social providers Enterprise customers requesting SAML or LDAP integration Team authentication (GitHub Organizations not sufficient) Why Keycloak: Pre-built identity providers vs. implementing each OAuth flow manually.\nThreshold 2: User Scale (25,000+ Active Users) Infrastructure costs of direct implementation approaching Keycloak costs Need for advanced user management capabilities SSO across multiple Battle Bots services Why Keycloak: Cost-effective at scale, centralized user management.\nThreshold 3: Compliance Requirements GDPR data processing agreements needed SOC 2 audit requirements Industry-specific compliance (HIPAA, PCI-DSS) Comprehensive audit logging and reporting Why Keycloak: Built-in compliance features, audit trails, data export capabilities.\nThreshold 4: Advanced Security Features Multi-factor authentication (TOTP, WebAuthn, SMS) Step-up authentication for sensitive operations Risk-based authentication Advanced session management Why Keycloak: Enterprise security features without building from scratch.\nThreshold 5: DevOps Team Capacity Dedicated DevOps/platform team established Infrastructure management expertise available 24/7 on-call rotation in place Automated deployment pipelines mature Why Keycloak: Infrastructure complexity manageable with proper team.\nMigration Path (If Keycloak Becomes Necessary) Phase 1: Planning (Month 1) Design Keycloak realm and client configuration Plan user migration strategy Design custom theme matching Battle Bots branding Provision infrastructure (Kubernetes, database, monitoring) Phase 2: Deployment (Month 2) Deploy Keycloak cluster (HA configuration) Configure GitHub identity provider Develop and deploy custom theme Set up monitoring and alerting Implement backup and disaster recovery Phase 3: Integration (Month 3) Implement Keycloak adapter behind authentication interface Deploy to staging environment End-to-end integration testing Performance and load testing Security audit and penetration testing Phase 4: Migration (Month 4) Migrate subset of users for beta testing Monitor for issues and gather feedback Gradual rollout (10% → 25% → 50% → 100%) Run parallel systems during transition Decommission direct OAuth implementation Post-migration monitoring and optimization Alternative: Managed Keycloak Service If Keycloak features are needed but infrastructure management is not desirable:\nConsider Managed Keycloak:\nPhase Two (phasetwо.io): $500-$5,000/month Inteca: Architecture-driven pricing SkyCloak: Managed Keycloak hosting Benefits:\nKeycloak features without operational burden Lower cost than Auth0 at scale Professional support included No vendor lock-in (can self-host later) Trade-offs:\nStill requires Keycloak expertise Less mature than Auth0 Smaller support organization Implementation Roadmap Immediate: Direct GitHub OAuth (MVP) Timeline: Sprint 1-2 (2-4 weeks)\nTasks:\nImplement GitHub OAuth 2.0 authorization code flow Create login/logout UI Implement secure session management Add CSRF protection via state parameter Implement token refresh logic Add rate limiting Basic audit logging Security review and testing Deploy to production Deliverables:\nFunctional GitHub authentication Secure session management Basic security hardening Documentation of authentication flow Near-Term: Monitoring and Hardening Timeline: Sprint 3-4 (4-6 weeks post-launch)\nTasks:\nImplement comprehensive logging Set up authentication metrics and dashboards Add advanced rate limiting and bot detection Implement session timeout and idle detection Security audit and penetration testing Optimize user experience Document security practices Deliverables:\nProduction-grade security Monitoring and alerting Performance optimization Security audit report Mid-Term: Evaluation Point Timeline: When reaching 10,000+ active users or 6-12 months post-launch\nTasks:\nEvaluate authentication pain points Assess user feedback and feature requests Analyze operational costs vs. alternatives Review security incidents and issues Assess team capacity for IAM management Make build vs. buy decision Decision Criteria:\nCurrent monthly active users Need for additional authentication providers Infrastructure management capacity Budget for authentication services Security and compliance requirements Product roadmap (multiple services, enterprise features) Long-Term: Potential Keycloak Migration (If Justified) Timeline: 12-24 months post-launch (if thresholds reached)\nApproach:\nIf Self-Hosting:\nProvision Keycloak infrastructure Deploy HA cluster Migrate users gradually Timeline: 3-4 months If Using Managed Service:\nSelect managed Keycloak provider Configure instance Migrate users Timeline: 1-2 months If Staying with Direct OAuth:\nContinue optimizing current implementation Add features as needed (MFA, additional providers) Timeline: Ongoing maintenance Operational Considerations Self-Hosted Keycloak Operational Requirements Team Skills Required DevOps Engineer: Infrastructure provisioning, container orchestration, CI/CD Database Administrator: PostgreSQL tuning, backup/recovery, replication Security Engineer: Security hardening, vulnerability management, penetration testing Backend Developer: Integration development, troubleshooting, custom extensions Minimum Team Size: 1-2 engineers with cross-functional skills or dedicated platform team.\nMonitoring and Observability Metrics: CPU, memory, database connections, authentication rates, error rates Logging: Authentication events, errors, security events, audit logs Alerting: Service health, database issues, high error rates, security incidents Tools: Prometheus, Grafana, ELK Stack, or commercial APM solutions Backup and Disaster Recovery Database Backups: Daily full backups, continuous transaction log backups Configuration Backups: Realm configurations, themes, custom extensions Recovery Testing: Quarterly DR drills RTO/RPO Targets: Define acceptable downtime and data loss thresholds Update and Patch Management Security Patches: Within 48 hours of critical CVE disclosure Minor Version Updates: Monthly or quarterly Major Version Updates: Annual with extensive testing Testing Process: Dev → Staging → Production with rollback plan Managed Keycloak Operational Requirements Reduced Operational Burden No Infrastructure Management: Provider handles servers, database, scaling Automatic Updates: Security patches applied by provider Professional Support: SLA-backed support for issues Monitoring Included: Basic monitoring and alerting provided Remaining Responsibilities Configuration Management: Realm and client configuration Theme Development: Custom theming and branding Integration Development: Application integration code User Management: User administration and support Monitoring Application Side: Application-level authentication metrics Cost-Benefit Analysis by Phase Phase Users Recommended Solution Justification MVP 0-1,000 Direct GitHub OAuth Fastest to market, lowest cost, simplest architecture Early Growth 1,000-10,000 Direct GitHub OAuth Still cost-effective, team focused on product Growth 10,000-25,000 Evaluate options Consider Auth0 or managed Keycloak if multi-provider needed Scale 25,000-100,000 Managed Keycloak or Auth0 Keycloak becoming cost-effective, Auth0 still viable Enterprise 100,000+ Self-hosted or Managed Keycloak Significant cost savings vs. Auth0, feature maturity needed Conclusion Keycloak is a powerful, enterprise-grade, open-source identity and access management solution that offers significant advantages for organizations with large user bases, complex authentication requirements, or specific data sovereignty needs. However, for Battle Bots in the MVP and early growth phases, Keycloak introduces unnecessary complexity and operational overhead without providing immediate value over simpler alternatives.\nKey Takeaways Keycloak is Not Appropriate for Battle Bots MVP\nInfrastructure complexity delays time to market Operational burden (12+ hours/month maintenance) Initial setup cost ($45,000-$75,000 opportunity cost) Overkill for single GitHub OAuth provider Team should focus on core product features Keycloak Becomes Valuable at Scale\nCost-effective above 25,000-50,000 users 60-80% cost savings vs. Auth0 at 100,000+ users No per-user licensing enables predictable budgeting Enterprise features included without additional fees Operational Maturity Required\nRequires DevOps expertise and infrastructure management Security responsibility falls on internal team Manual update and patch management Suitable for organizations with dedicated platform teams Managed Keycloak is a Middle Ground\nLower operational burden than self-hosting Cost-effective compared to Auth0 at scale Professional support included Retains flexibility and avoids lock-in Final Recommendation Phase 1 (Now - 10,000 Users): Direct GitHub OAuth\nImplement GitHub OAuth 2.0 directly in Battle Bots application Use Go oauth2 library for standard implementation Focus development effort on core product features Design authentication abstraction layer for future flexibility Phase 2 (10,000-25,000 Users): Re-evaluate\nMonitor operational costs of maintaining direct OAuth Assess need for additional authentication providers Consider managed Keycloak if multi-provider support needed Consider Auth0 if team lacks DevOps capacity Phase 3 (25,000+ Users): Consider Keycloak\nEvaluate self-hosted Keycloak if platform team exists Evaluate managed Keycloak for balance of cost and simplicity Cost analysis strongly favors Keycloak at this scale Migration justified by cost savings and feature needs Avoid Keycloak If:\nBattle Bots will only ever use GitHub OAuth Team lacks infrastructure management expertise Rapid time to market is critical priority User base unlikely to exceed 25,000 active users Small team focused entirely on product features Choose Keycloak When:\nUser base exceeds 25,000-50,000 active users Multiple authentication providers needed Enterprise features required (SAML, LDAP, advanced MFA) Data sovereignty and privacy are requirements Platform team available for infrastructure management Budget requires cost optimization at scale The key to success is starting simple with direct GitHub OAuth, monitoring growth and requirements, and migrating to Keycloak only when thresholds justify the complexity and operational investment. Designing an authentication abstraction layer from the start ensures seamless migration when the time comes.\nReferences Keycloak Official Documentation Keycloak UI Customization Guide Keycloak Server Configuration Keycloak Container Deployment Keycloak GitHub Identity Provider Setup Keycloak vs Auth0 Comparison Keycloak Production Configuration Best Practices Keycloak Cluster Configuration Best Practices Self-Hosting Keycloak Cost Analysis Managed Keycloak Providers Comparison Keycloak Theme Customization Tutorial ","categories":"","description":"Comprehensive analysis of Keycloak login page options and their applicability to the Battle Bots platform's GitHub OAuth authentication strategy, including comparison with Auth0 and direct OAuth implementation.\n","excerpt":"Comprehensive analysis of Keycloak login page options and their …","ref":"/battlebots/pr-preview/pr-139/rd/analysis/security/keycloak-login-pages-analysis/","tags":"","title":"Keycloak Login Pages Analysis"},{"body":" Context and Problem Statement After users authenticate via GitHub OAuth (ADR-0002), the platform needs to authenticate subsequent API requests. Traditional session-based authentication stores user state on the server, requiring session lookup on every request and creating horizontal scaling challenges. How should the Battle Bots platform authenticate API requests in a scalable, secure manner without server-side session state?\nDecision Drivers Horizontal Scalability: Need to scale across multiple servers without session synchronization Performance: Minimize database lookups on every API request Security: Protect against XSS, CSRF, token replay, and unauthorized access User Experience: Seamless authentication without frequent re-login Token Revocation: Ability to invalidate tokens when needed (logout, security breach) Microservices Architecture: Enable stateless token validation across multiple services Developer Experience: Simple implementation with well-supported libraries Cost: Minimize infrastructure overhead (no distributed session store required) Considered Options Option 1: JWT tokens with RS256 signing and httpOnly cookies Option 2: Server-side sessions with distributed session store (Redis) Option 3: OAuth2 opaque tokens with token introspection endpoint Option 4: JWT tokens with HS256 signing and localStorage Decision Outcome Chosen option: “Option 1: JWT tokens with RS256 signing and httpOnly cookies”, because it provides the best balance of security, scalability, and developer experience for our use case.\nThe implementation uses:\nAccess Tokens: Short-lived (15 min) JWT tokens signed with RS256, stored in httpOnly cookies Refresh Tokens: Long-lived (7 days) random tokens with rotation, stored in httpOnly cookies CSRF Protection: CSRF tokens in separate cookies, validated via request headers Token Revocation: Optional Redis blacklist for immediate revocation needs Consequences Good, because stateless tokens enable horizontal scaling without session synchronization Good, because JWT claims eliminate database lookups for user identity on every request Good, because RS256 allows signature verification with public key (multiple services can validate) Good, because httpOnly cookies protect tokens from XSS attacks Good, because short-lived access tokens limit exposure window if compromised Good, because refresh token rotation detects and prevents token theft Good, because mature JWT libraries available in all languages (Go, JavaScript, Python) Good, because tokens can be shared across multiple microservices Neutral, because requires implementing JWT signing/validation service Neutral, because token blacklist adds minimal state for revocation (optional, TTL-based) Bad, because tokens valid until expiry (requires short expiry or blacklist for revocation) Bad, because JWT tokens larger than session IDs (network overhead) Bad, because clock skew between servers requires tolerance window in validation Confirmation Implementation compliance will be confirmed through:\nUnit Tests: JWT generation, validation, signature verification, claim validation, token rotation Security Tests: XSS prevention (httpOnly cookies), CSRF prevention (SameSite + tokens), token replay protection, expiry enforcement Integration Tests: Complete OAuth → JWT flow, token refresh with rotation, logout and revocation Performance Tests: JWT validation latency \u003c 1ms, horizontal scaling across multiple servers Code Review: Security-focused review of cryptographic operations, token storage, and validation logic Pros and Cons of the Options Option 1: JWT tokens with RS256 signing and httpOnly cookies Use JSON Web Tokens signed with RSA asymmetric keys (RS256), stored in httpOnly cookies with CSRF protection.\nAccess Token Strategy:\nFormat: JWT with standard claims (iss, sub, aud, exp, iat, jti) + custom claims (github_id, username, email, roles) Signing: RS256 (private key signs, public key verifies) Storage: httpOnly, secure, SameSite=strict cookie Expiry: 15 minutes Validation: Signature + claims validation on every request Refresh Token Strategy:\nFormat: Random 32-byte cryptographic token (NOT JWT) Storage: httpOnly, secure, SameSite=strict cookie (path: /auth/refresh) Database: Hashed token stored with user_id, created_at, expires_at, revoked flag Expiry: 7 days Rotation: New refresh token issued on every refresh, old token revoked CSRF Protection:\nCSRF token in separate cookie (readable by JavaScript) Required in X-CSRF-Token header for state-changing requests SameSite=strict prevents cross-site cookie sending Token Revocation:\nShort expiry (15 min) limits exposure window Refresh tokens revoked in database on logout Optional: Redis blacklist for immediate JWT revocation (Key: revoked:jwt:{jti}, TTL: token expiry) Good, because stateless - any server can validate JWT with public key Good, because RS256 allows key rotation without redeploying all services Good, because httpOnly cookies prevent XSS token theft Good, because SameSite=strict + CSRF tokens prevent CSRF attacks Good, because refresh token rotation detects theft (reuse triggers revocation) Good, because JWT claims include user identity (no database lookup on every request) Good, because mature libraries (golang-jwt/jwt, lestrrat-go/jwx) Good, because tokens portable across microservices Neutral, because requires key management (generate, store, rotate RSA keys) Neutral, because optional Redis for blacklist adds minimal infrastructure Bad, because JWT size larger than session ID (250-500 bytes vs 32 bytes) Bad, because requires clock synchronization between servers (allow 5-min skew) Bad, because token claims fixed until expiry (can’t update roles mid-session) Option 2: Server-side sessions with distributed session store (Redis) Store user session data in Redis, use session IDs in httpOnly cookies for lookup.\nSession Strategy:\nSession ID: Random 32-byte token in httpOnly cookie Session Data: User identity, roles, permissions stored in Redis Expiry: Sliding window (e.g., 24 hours of inactivity) Validation: Lookup session data from Redis on every request Good, because session data mutable (can update roles immediately) Good, because session IDs small (32 bytes) Good, because mature session management libraries Good, because easy to revoke individual sessions (delete from Redis) Good, because httpOnly cookies prevent XSS Neutral, because requires Redis infrastructure (additional cost, complexity) Bad, because every request requires Redis lookup (latency, cost) Bad, because Redis becomes single point of failure (requires HA setup) Bad, because horizontal scaling requires session replication across regions Bad, because Redis memory costs scale with active users Bad, because network hop to Redis on every request adds latency (1-5ms) Bad, because each service needs Redis access (violates stateless architecture) Option 3: OAuth2 opaque tokens with token introspection endpoint Use opaque access tokens from GitHub OAuth, validate via token introspection on every request.\nToken Strategy:\nAccess Token: GitHub OAuth opaque token stored in httpOnly cookie Validation: Call token introspection endpoint on every request Introspection: Returns user identity, scopes, expiry Good, because no custom token generation needed Good, because GitHub manages token lifecycle Good, because httpOnly cookies prevent XSS Neutral, because introspection endpoint can be cached (reduces calls) Bad, because GitHub API rate limits apply (5,000 requests/hour) Bad, because network call to GitHub on every request (latency, availability risk) Bad, because vendor dependency - GitHub outage blocks all authentication Bad, because no control over token expiry or claims Bad, because difficult to add custom claims (roles, permissions) Bad, because doesn’t scale for high-traffic applications Option 4: JWT tokens with HS256 signing and localStorage Use JSON Web Tokens signed with HMAC symmetric key (HS256), stored in browser localStorage.\nToken Strategy:\nFormat: JWT with standard + custom claims Signing: HS256 (shared secret key) Storage: Browser localStorage Transmission: Authorization: Bearer header Good, because stateless - no session lookup Good, because simple shared secret (no key pair management) Good, because localStorage survives browser refresh Good, because explicit Authorization header (RESTful) Neutral, because requires CORS configuration Bad, because localStorage vulnerable to XSS attacks (JavaScript can read token) Bad, because HS256 requires shared secret across all services (key rotation difficult) Bad, because shared secret leak compromises entire system Bad, because no CSRF protection from browser (requires manual implementation) Bad, because tokens in localStorage exposed if XSS vulnerability exists Bad, because key rotation requires redeploying all services simultaneously More Information Related ADRs ADR-0002: User Registration via GitHub OAuth - Defines initial OAuth authentication flow Related User Journeys User Journey 0001: User Registration - Specifies authentication requirements JWT Token Structure Access Token Claims:\n{ \"iss\": \"https://auth.battlebots.com\", \"sub\": \"github:87654321\", \"aud\": \"battlebots-api\", \"exp\": 1735689600, \"iat\": 1735686000, \"nbf\": 1735686000, \"jti\": \"unique-token-id-abc123\", \"github_id\": \"87654321\", \"github_username\": \"bot_master_3000\", \"email\": \"user@example.com\", \"username\": \"bot_master_3000\", \"roles\": [\"user\"], \"permissions\": [\"bot:create\", \"bot:deploy\", \"competition:join\"] } Validation Requirements:\nVerify signature using RSA public key Validate exp \u003e current_time (allow 5-min clock skew) Validate nbf \u003c= current_time (allow 5-min clock skew) Validate iss matches expected issuer (allow-list) Validate aud matches service identifier Validate algorithm is RS256 (prevent algorithm substitution) Optional: Check JWT ID (jti) not in revocation blacklist Refresh Token Flow sequenceDiagram actor User participant Client as Web App participant API as Battle Bots API participant DB as Database participant JWT as JWT Service Note over Client,API: Access token expires (15 min) Client-\u003e\u003eAPI: POST /auth/refresh\u003cbr/\u003e(httpOnly cookie: refresh_token) API-\u003e\u003eAPI: Extract refresh_token from cookie API-\u003e\u003eAPI: Hash refresh token (SHA256) API-\u003e\u003eDB: SELECT * FROM refresh_tokens\u003cbr/\u003eWHERE token_hash = ? AND revoked = false alt Refresh Token Valid DB--\u003e\u003eAPI: Return token record (user_id, expires_at) API-\u003e\u003eAPI: Validate expires_at \u003e current_time API-\u003e\u003eJWT: Generate new access token (15 min expiry) JWT--\u003e\u003eAPI: Signed JWT API-\u003e\u003eAPI: Generate new refresh token (random 32-byte) API-\u003e\u003eDB: Mark old refresh token as revoked API-\u003e\u003eDB: INSERT new refresh token\u003cbr/\u003e(user_id, token_hash, parent_token_hash, expires_at) API-\u003e\u003eClient: 200 OK\u003cbr/\u003e(Set-Cookie: access_token, refresh_token) else Refresh Token Invalid/Revoked DB--\u003e\u003eAPI: Token not found or revoked = true API-\u003e\u003eDB: Check if token used in rotation chain (reuse detection) alt Token Reuse Detected API-\u003e\u003eDB: Revoke entire token family (security breach) API-\u003e\u003eClient: 401 Unauthorized (force re-authentication) else Token Expired/Not Found API-\u003e\u003eClient: 401 Unauthorized (session expired) end end Cookie Configuration Access Token Cookie:\nSet-Cookie: access_token=eyJhbGc...; HttpOnly; Secure; SameSite=Strict; Path=/; Max-Age=900 Refresh Token Cookie:\nSet-Cookie: refresh_token=a1b2c3d4...; HttpOnly; Secure; SameSite=Strict; Path=/auth/refresh; Max-Age=604800 CSRF Token Cookie:\nSet-Cookie: csrf_token=x9y8z7...; Secure; SameSite=Strict; Path=/; Max-Age=900 Security Best Practices Use RS256, not HS256: Asymmetric keys allow public verification without secret sharing Store tokens in httpOnly cookies: Prevents XSS token theft Set SameSite=Strict: Prevents CSRF attacks via cross-site requests Require CSRF tokens: Defense-in-depth for state-changing requests Use short expiry: 15-minute access tokens limit exposure window Rotate refresh tokens: Detect and prevent token theft via reuse detection Hash refresh tokens: Protect against database leaks (store SHA256 hash, not plaintext) Implement token blacklist: Enable immediate revocation for critical scenarios Validate all claims: Verify signature, exp, iss, aud, alg on every request Allow clock skew: 5-minute tolerance for time-based claims (exp, nbf) Use cryptography libraries: Never implement JWT validation manually Monitor authentication events: Log and alert on unusual patterns Rotate signing keys: Annual rotation or immediately after security incident Rate limit auth endpoints: Prevent brute-force attacks Use PKCE for OAuth: Prevent authorization code interception Database Schema refresh_tokens table:\nCREATE TABLE refresh_tokens ( id BIGSERIAL PRIMARY KEY, user_id BIGINT NOT NULL REFERENCES users(id) ON DELETE CASCADE, token_hash VARCHAR(64) NOT NULL, -- SHA256 hash parent_token_hash VARCHAR(64), -- For rotation chain tracking created_at TIMESTAMP NOT NULL DEFAULT NOW(), expires_at TIMESTAMP NOT NULL, revoked BOOLEAN NOT NULL DEFAULT false, revoked_at TIMESTAMP, user_agent TEXT, ip_address INET, INDEX idx_token_hash (token_hash), INDEX idx_user_id (user_id), INDEX idx_expires_at (expires_at) ); Performance Characteristics JWT Validation Latency:\nSignature verification (RS256): \u003c 1ms Claims validation: \u003c 0.1ms Total: \u003c 1ms per request Refresh Token Rotation:\nDatabase writes: 2 (revoke old + insert new) Database reads: 1 (validate old token) Total latency: 5-10ms Scalability:\nHorizontal: Unlimited (stateless validation with shared public key) Vertical: 10,000+ requests/second per server Multi-region: Public key replication, no state synchronization needed Implementation Libraries (Go) JWT Libraries:\ngithub.com/golang-jwt/jwt/v5 - Standard, widely used github.com/lestrrat-go/jwx/v2 - More features, better performance, JWK support Crypto:\ncrypto/rsa - RSA key generation and signing crypto/sha256 - Refresh token hashing crypto/rand - Cryptographically secure random token generation Recommended: github.com/lestrrat-go/jwx/v2 for production (better JWK handling, key rotation support)\nFuture Enhancements API Keys: Separate authentication mechanism for bot deployments (long-lived, scoped tokens) Service Accounts: Machine-to-machine authentication for CI/CD pipelines MFA: Multi-factor authentication for high-value accounts WebAuthn: Passwordless authentication with security keys Account Linking: Support multiple OAuth providers per user Geographic Token Pinning: Detect and alert on suspicious location changes Device Fingerprinting: Track and manage authenticated devices Step-up Authentication: Require re-authentication for sensitive operations References RFC 7519: JSON Web Token (JWT) RFC 7518: JSON Web Algorithms (JWA) RFC 6749: OAuth 2.0 Authorization Framework OWASP JWT Cheat Sheet OWASP Session Management Cheat Sheet ","categories":"","description":"How the platform authenticates API requests using JWT tokens without server-side session state\n","excerpt":"How the platform authenticates API requests using JWT tokens without …","ref":"/battlebots/pr-preview/pr-139/rd/adrs/0003-stateless-jwt-authentication/","tags":"","title":"[0003] Stateless Authentication via JWT Tokens"},{"body":"User Journeys This section contains detailed user journey documentation that defines how users interact with the Battlebots platform. Each journey document includes:\nUser personas and their goals Step-by-step flow diagrams Technical requirements (access control, analytics, etc.) Success metrics These documents serve as the foundation for feature development and help ensure a consistent, user-centered experience.\n","categories":"","description":"Documentation of user flows and experiences for the Battlebots platform\n","excerpt":"Documentation of user flows and experiences for the Battlebots …","ref":"/battlebots/pr-preview/pr-139/rd/user-journeys/","tags":"","title":"User Journeys"},{"body":"Architecture Decision Records (ADRs) This section contains architectural decision records that document the key design choices made for the Battlebots platform. Each ADR follows the MADR 4.0.0 format and includes:\nContext and problem statement Decision drivers and constraints Considered options with pros and cons Decision outcome and rationale Consequences (positive and negative) Confirmation methods ADR Categories ADRs are classified into three categories:\nStrategic - High-level architectural decisions affecting the entire system (frameworks, authentication strategies, cross-cutting patterns). Use for foundational technology choices. User Journey - Decisions solving specific user journey problems. More tactical than strategic, but still architectural. Use when evaluating approaches to implement user-facing features. API Design - API endpoint implementation decisions (pagination, filtering, bulk operations). Use for significant API design trade-offs that warrant documentation. Status Values Each ADR has a status that reflects its current state:\nproposed - Decision is under consideration accepted - Decision has been approved and should be implemented rejected - Decision was considered but not approved deprecated - Decision is no longer relevant or has been superseded superseded by ADR-XXXX - Decision has been replaced by a newer ADR These records provide historical context for architectural decisions and help ensure consistency across the platform.\n","categories":"","description":"Documentation of architectural decisions made in the Battlebots platform using MADR 4.0.0 standard\n","excerpt":"Documentation of architectural decisions made in the Battlebots …","ref":"/battlebots/pr-preview/pr-139/rd/adrs/","tags":"","title":"Architecture Decision Records"},{"body":"","categories":"","description":"","excerpt":"","ref":"/battlebots/pr-preview/pr-139/rd/analysis/","tags":"","title":"Analysis"},{"body":"Welcome! Battle Bots is a game in which you, the human, implement an autonomous “bot” to do battle with “bots” implemented by other humans.\nWhat is a Bot? A bot is a independent piece of software which is programmed to battle other bots by reacting to state updates (e.g. bot B moved to point A) and performing its own actions (e.g. fire missile at point A).\n","categories":"","description":"Battle Bots is a PVP game for autonomous players","excerpt":"Battle Bots is a PVP game for autonomous players","ref":"/battlebots/pr-preview/pr-139/","tags":"","title":"Battle Bots"},{"body":"R\u0026D Process The Research \u0026 Design process follows a structured workflow to ensure comprehensive analysis and documentation of user experiences, technical solutions, and implementation details.\nProcess Steps Document the User Journey\nCreate a user journey document for the specific user experience Include flow diagrams using Mermaid to visualize user interactions Define prioritized technical requirements (P0/P1/P2) Use the /new-user-journey command to create standardized documentation Design the Solution\nCreate an ADR that designs a solution to implement the user journey Identify and document: Additional ADRs needed for specific components APIs that need to be defined User interface flows (mobile, web, etc.) Data flow from user to end systems (database, notification system, etc.) Capture the complete system architecture and integration points Document Component ADRs\nCreate ADRs for specific technical components identified in the solution design Examples: authentication strategy, session management, account linking, data storage Use the /new-adr command to create standardized MADR 4.0.0 format documents Document technical decisions with context, considered options, and consequences Document Required APIs\nFor each API endpoint identified in the solution, create comprehensive API documentation Use the /new-api-doc command to create standardized documentation Include: Request/response schemas Authentication requirements Business logic flows (Mermaid diagrams) Error responses and status codes Example curl requests Document API Implementation\nFor each documented API, create an ADR describing the implementation approach Document technical decisions including: Programming language selection Framework and libraries Architecture patterns Testing strategy Example: ADR-0006 documents the tech stack for API development (z5labs/humus framework) Design User Interface\nCreate UI/UX designs for the user journey Ensure designs align with the documented user flows and API contracts Consider platform-specific requirements (mobile, web, desktop) Documentation Structure The R\u0026D documentation is organized into the following sections:\nUser Journeys - User experience flows with technical requirements ADRs - Architectural Decision Records documenting technical decisions APIs - REST API endpoint documentation with schemas and examples Analysis - Research and analysis of technologies and solutions ","categories":"","description":"","excerpt":"R\u0026D Process The Research \u0026 Design process follows a structured …","ref":"/battlebots/pr-preview/pr-139/rd/","tags":"","title":"Research \u0026 Design"},{"body":"","categories":"","description":"","excerpt":"","ref":"/battlebots/pr-preview/pr-139/rd/analysis/open-source-applications/","tags":"","title":"Open Source Applications"},{"body":"","categories":"","description":"","excerpt":"","ref":"/battlebots/pr-preview/pr-139/rd/analysis/security/","tags":"","title":"Security"},{"body":"","categories":"","description":"","excerpt":"","ref":"/battlebots/pr-preview/pr-139/categories/","tags":"","title":"Categories"},{"body":"","categories":"","description":"","excerpt":"","ref":"/battlebots/pr-preview/pr-139/tags/","tags":"","title":"Tags"}]